{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3891,"status":"ok","timestamp":1680434819700,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"50S27W_Vj_Bi","outputId":"49c09f21-90eb-4441-a0b4-b8896ca6e632"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3327,"status":"ok","timestamp":1680434823022,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"frHag4z7kGdZ","outputId":"b754a6b8-0938-4b13-f5be-f688e41d2a78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n"]}],"source":["pip install sastrawi"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5384,"status":"ok","timestamp":1680434828402,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"kk8ilth6kH1d","outputId":"d3e6239e-3776-4fca-92ca-9e79846a13f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk) (1.16.0)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680434828403,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"Ph17gJD0kKb4","outputId":"bef61b96-b7ad-4401-e97d-d8b58c73cd62"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1680434828403,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"gs4oMdsrkL3E","outputId":"07b33ab3-658f-4e2a-82ba-cfdf66ad730b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3717,"status":"ok","timestamp":1680434832115,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"OGmxzhivkNRJ","outputId":"0e286e92-26f1-46e5-d826-03a02027a7a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nlp_id in /usr/local/lib/python3.9/dist-packages (0.1.13.0)\n","Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.4.5)\n","Requirement already satisfied: scikit-learn==1.1.0 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (1.1.0)\n","Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.4.5->nlp_id) (1.16.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (3.1.0)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.1.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.22.4)\n"]}],"source":["pip install nlp_id"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3867,"status":"ok","timestamp":1680434835979,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"K9ZXuJrokX-x","outputId":"2a403ad7-f0d4-408a-ffa5-73d63d4790a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"LEM8axq7kjkZ","executionInfo":{"status":"ok","timestamp":1680434841180,"user_tz":-420,"elapsed":5205,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["import re\n","import random\n","import pandas as pd\n","import torch\n","import tensorflow as tf\n","import numpy as np\n","\n","from nlp_id.lemmatizer import Lemmatizer\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.metrics import f1_score, cohen_kappa_score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from nltk.corpus import stopwords\n","\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def qwk_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return cohen_kappa_score(labels_flat, preds_flat)\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","\n","def evaluate(dataloader_val, device, model):\n","\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_val:\n","\n","        batch = tuple(b.to(device) for b in batch)\n","\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total/len(dataloader_val)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals\n","\n","def train_eval(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False, duplicates='drop')\n","\n","    # concatenate soal and jawaban\n","    df_final['soal-jawaban'] = df_final['soal']+df_final['jawaban']\n","\n","    # preprocessing\n","    # lowercasing\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: x.lower())\n","    # lemmatization\n","    lemmatizer = Lemmatizer()\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: lemmatizer.lemmatize(x))\n","    # stopword removal\n","    list_stopwords = set(stopwords.words('indonesian'))\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: ' '.join([item for item in x.split() if item not in list_stopwords]))\n","    # punctuation removal\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["00093a7738e44be5a726da8720cfedc1","417da303ef7941f5880cf6240053d4a6","ca3dfb9047c042a5a2c52f1dc421f6ca","252a6ca0efe44a3b895cf2aecc6c483b","16942d7c125646b1a3c4cebab6c73085","5e79de76a257417884df569d052ecc58","2b6ed3a4aefb430babcc0e869438a842","189ef25f48554471b2f6290399964e61","1741bdf6811f42cab7680580d4286b9f","822216ea942744a793a25c5e5162df1e","b85fab09e1424cfda1907a75a6584d63","3af26c7c61644084942f3ce6bebecffc","68850496b75445ef9048bc8db7753475","370281fbb45542a4b374c25ead1e38bc","efa3e5b4244242389d3d855b99a9c067","235353f0f83a4bcfae39713b56963711","4490cf6e1e4745178051a04e65412b73","5ee1620e22ad497fada8dee819920e1b","3fd954d56b3741d29f06f9ea8df0a4a1","38a75ad10b4d40fda6bc7f63f42f9f6b","5317c2721dc84323b2eddf0a322c6ba9","2b67e710394643a98ad3a2994966c68b","4903585dc5884c1587fe030489318546","6521369110ce47daa3609879aede00fb","e2e0eda571e24470abebfaa3f8dca047","bbee9f37246645848d5d7a4a114e1114","85e3d84e07694cd8b313dd1d8832ec91","cb01501f49e04c3580534ebc8b425ca4","86249bff82b04da7bb25f251b35f1db3","b58541e936e94ad09b919696c8c2c35e","46d17e86ab574419a98a4f07be11c8d5","a41a4105a2814334a9ca804b42f478de","612f4e06b09949eb9722144b409f6d8c","50561c2392a6483da84891df594e7a0a","153d2b7cceb14082b8e113ae0facb246","3eb7525bfcb342808f59cec9112d0b91","b34004ee5f3340fda946db85bb4543d6","b92f0c98b36a49b3a64daa95f3aae2dc","0c2d63a624f448f89af1656ea5b912c3","eca65f23d0444457b09fa563ba24405d","cf0f1ed09ac44f18931a0c0bdb164a1f","385694d10b7f40409ef70c152b99111e","e1ce6f9c1ac1427bbcceefd3fbb754d2","78b2c606a73e44e9a350d53e832aedf1","0ff5fd193356486797114dea880c2d1b","efcbe723dc9c4ab49c4851c112a7699a","5b4818ecacd64e68abaad6981e938b58","661f9b5b145d43f989b24127c57a996f","c920a52c755745dc904ffb62c5757788","d9231e25cdae4ef1a5273ef454e1ca0d","d852a055bf7a474aa98aab34ff3a93ad","d93c8a6e2c034aaa8b2d98341505d3bf","2772b1ad0fde48a9a37ecb8ec5ecdcbb","2697a5c1d84143edb59ef63003242b56","9a515ea53654401289d150000d16f8e9"]},"id":"AwIDxQ2UklHF","executionInfo":{"status":"ok","timestamp":1680446106470,"user_tz":-420,"elapsed":11265293,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"a19a23fd-f5f7-47b3-90a0-648227715dc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["indobenchmark/indobert-lite-base-p2\n","Analisis Essay Grading Teknologi\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00093a7738e44be5a726da8720cfedc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3af26c7c61644084942f3ce6bebecffc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4903585dc5884c1587fe030489318546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50561c2392a6483da84891df594e7a0a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ff5fd193356486797114dea880c2d1b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'pooler.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.3.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'classifier.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/105 [00:38<?, ?it/s, training_loss=0.610]\u001b[A\n","Epoch 1:   1%|          | 1/105 [00:38<1:06:39, 38.46s/it, training_loss=0.610]\u001b[A\n","Epoch 1:   1%|          | 1/105 [01:03<1:06:39, 38.46s/it, training_loss=0.842]\u001b[A\n","Epoch 1:   2%|▏         | 2/105 [01:03<52:31, 30.60s/it, training_loss=0.842]  \u001b[A\n","Epoch 1:   2%|▏         | 2/105 [01:27<52:31, 30.60s/it, training_loss=0.735]\u001b[A\n","Epoch 1:   3%|▎         | 3/105 [01:27<46:44, 27.49s/it, training_loss=0.735]\u001b[A\n","Epoch 1:   3%|▎         | 3/105 [01:54<46:44, 27.49s/it, training_loss=0.439]\u001b[A\n","Epoch 1:   4%|▍         | 4/105 [02:19<45:55, 27.28s/it, training_loss=0.561]\u001b[A\n","Epoch 1:   5%|▍         | 5/105 [02:19<44:11, 26.52s/it, training_loss=0.561]\u001b[A\n","Epoch 1:   5%|▍         | 5/105 [02:43<44:11, 26.52s/it, training_loss=0.673]\u001b[A\n","Epoch 1:   6%|▌         | 6/105 [02:43<42:12, 25.58s/it, training_loss=0.673]\u001b[A\n","Epoch 1:   6%|▌         | 6/105 [03:07<42:12, 25.58s/it, training_loss=0.690]\u001b[A\n","Epoch 1:   7%|▋         | 7/105 [03:07<41:13, 25.24s/it, training_loss=0.690]\u001b[A\n","Epoch 1:   7%|▋         | 7/105 [03:32<41:13, 25.24s/it, training_loss=0.574]\u001b[A\n","Epoch 1:   8%|▊         | 8/105 [03:32<40:47, 25.23s/it, training_loss=0.574]\u001b[A\n","Epoch 1:   8%|▊         | 8/105 [03:57<40:47, 25.23s/it, training_loss=0.594]\u001b[A\n","Epoch 1:   9%|▊         | 9/105 [03:57<40:10, 25.11s/it, training_loss=0.594]\u001b[A\n","Epoch 1:   9%|▊         | 9/105 [04:21<40:10, 25.11s/it, training_loss=0.612]\u001b[A\n","Epoch 1:  10%|▉         | 10/105 [04:21<39:01, 24.65s/it, training_loss=0.612]\u001b[A\n","Epoch 1:  10%|▉         | 10/105 [04:47<39:01, 24.65s/it, training_loss=0.745]\u001b[A\n","Epoch 1:  10%|█         | 11/105 [04:47<39:11, 25.01s/it, training_loss=0.745]\u001b[A\n","Epoch 1:  10%|█         | 11/105 [05:12<39:11, 25.01s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  11%|█▏        | 12/105 [05:12<38:56, 25.12s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  11%|█▏        | 12/105 [05:35<38:56, 25.12s/it, training_loss=0.464]\u001b[A\n","Epoch 1:  12%|█▏        | 13/105 [05:35<37:40, 24.58s/it, training_loss=0.464]\u001b[A\n","Epoch 1:  12%|█▏        | 13/105 [06:01<37:40, 24.58s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  13%|█▎        | 14/105 [06:01<37:32, 24.76s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  13%|█▎        | 14/105 [06:26<37:32, 24.76s/it, training_loss=0.649]\u001b[A\n","Epoch 1:  14%|█▍        | 15/105 [06:26<37:26, 24.96s/it, training_loss=0.649]\u001b[A\n","Epoch 1:  14%|█▍        | 15/105 [06:50<37:26, 24.96s/it, training_loss=0.646]\u001b[A\n","Epoch 1:  15%|█▌        | 16/105 [06:50<36:35, 24.66s/it, training_loss=0.646]\u001b[A\n","Epoch 1:  15%|█▌        | 16/105 [07:15<36:35, 24.66s/it, training_loss=0.402]\u001b[A\n","Epoch 1:  16%|█▌        | 17/105 [07:15<36:07, 24.63s/it, training_loss=0.402]\u001b[A\n","Epoch 1:  16%|█▌        | 17/105 [07:40<36:07, 24.63s/it, training_loss=0.480]\u001b[A\n","Epoch 1:  17%|█▋        | 18/105 [07:40<36:10, 24.95s/it, training_loss=0.480]\u001b[A\n","Epoch 1:  17%|█▋        | 18/105 [08:05<36:10, 24.95s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  18%|█▊        | 19/105 [08:05<35:44, 24.93s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  18%|█▊        | 19/105 [08:29<35:44, 24.93s/it, training_loss=0.768]\u001b[A\n","Epoch 1:  19%|█▉        | 20/105 [08:29<34:48, 24.57s/it, training_loss=0.768]\u001b[A\n","Epoch 1:  19%|█▉        | 20/105 [08:54<34:48, 24.57s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  20%|██        | 21/105 [08:54<34:40, 24.77s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  20%|██        | 21/105 [09:19<34:40, 24.77s/it, training_loss=0.448]\u001b[A\n","Epoch 1:  21%|██        | 22/105 [09:19<34:28, 24.92s/it, training_loss=0.448]\u001b[A\n","Epoch 1:  21%|██        | 22/105 [09:43<34:28, 24.92s/it, training_loss=0.504]\u001b[A\n","Epoch 1:  22%|██▏       | 23/105 [09:43<33:27, 24.48s/it, training_loss=0.504]\u001b[A\n","Epoch 1:  22%|██▏       | 23/105 [10:08<33:27, 24.48s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  23%|██▎       | 24/105 [10:08<33:22, 24.72s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  23%|██▎       | 24/105 [10:33<33:22, 24.72s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  24%|██▍       | 25/105 [10:33<33:11, 24.89s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  24%|██▍       | 25/105 [10:57<33:11, 24.89s/it, training_loss=0.585]\u001b[A\n","Epoch 1:  25%|██▍       | 26/105 [10:57<32:20, 24.57s/it, training_loss=0.585]\u001b[A\n","Epoch 1:  25%|██▍       | 26/105 [11:22<32:20, 24.57s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  26%|██▌       | 27/105 [11:22<31:55, 24.55s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  26%|██▌       | 27/105 [11:47<31:55, 24.55s/it, training_loss=0.482]\u001b[A\n","Epoch 1:  27%|██▋       | 28/105 [11:47<31:44, 24.74s/it, training_loss=0.482]\u001b[A\n","Epoch 1:  27%|██▋       | 28/105 [12:12<31:44, 24.74s/it, training_loss=0.605]\u001b[A\n","Epoch 1:  28%|██▊       | 29/105 [12:12<31:20, 24.74s/it, training_loss=0.605]\u001b[A\n","Epoch 1:  28%|██▊       | 29/105 [12:36<31:20, 24.74s/it, training_loss=0.441]\u001b[A\n","Epoch 1:  29%|██▊       | 30/105 [12:36<30:37, 24.50s/it, training_loss=0.441]\u001b[A\n","Epoch 1:  29%|██▊       | 30/105 [13:01<30:37, 24.50s/it, training_loss=0.422]\u001b[A\n","Epoch 1:  30%|██▉       | 31/105 [13:01<30:30, 24.74s/it, training_loss=0.422]\u001b[A\n","Epoch 1:  30%|██▉       | 31/105 [13:26<30:30, 24.74s/it, training_loss=0.636]\u001b[A\n","Epoch 1:  30%|███       | 32/105 [13:26<30:17, 24.90s/it, training_loss=0.636]\u001b[A\n","Epoch 1:  30%|███       | 32/105 [13:50<30:17, 24.90s/it, training_loss=0.447]\u001b[A\n","Epoch 1:  31%|███▏      | 33/105 [13:50<29:20, 24.46s/it, training_loss=0.447]\u001b[A\n","Epoch 1:  31%|███▏      | 33/105 [14:15<29:20, 24.46s/it, training_loss=0.754]\u001b[A\n","Epoch 1:  32%|███▏      | 34/105 [14:15<29:13, 24.70s/it, training_loss=0.754]\u001b[A\n","Epoch 1:  32%|███▏      | 34/105 [14:40<29:13, 24.70s/it, training_loss=0.708]\u001b[A\n","Epoch 1:  33%|███▎      | 35/105 [14:40<29:02, 24.89s/it, training_loss=0.708]\u001b[A\n","Epoch 1:  33%|███▎      | 35/105 [15:06<29:02, 24.89s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  34%|███▍      | 36/105 [15:06<28:47, 25.04s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  34%|███▍      | 36/105 [15:30<28:47, 25.04s/it, training_loss=0.442]\u001b[A\n","Epoch 1:  35%|███▌      | 37/105 [15:30<28:12, 24.89s/it, training_loss=0.442]\u001b[A\n","Epoch 1:  35%|███▌      | 37/105 [15:56<28:12, 24.89s/it, training_loss=0.435]\u001b[A\n","Epoch 1:  36%|███▌      | 38/105 [15:56<27:57, 25.03s/it, training_loss=0.435]\u001b[A\n","Epoch 1:  36%|███▌      | 38/105 [16:21<27:57, 25.03s/it, training_loss=0.644]\u001b[A\n","Epoch 1:  37%|███▋      | 39/105 [16:21<27:34, 25.07s/it, training_loss=0.644]\u001b[A\n","Epoch 1:  37%|███▋      | 39/105 [16:44<27:34, 25.07s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  38%|███▊      | 40/105 [16:44<26:42, 24.65s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  38%|███▊      | 40/105 [17:10<26:42, 24.65s/it, training_loss=0.464]\u001b[A\n","Epoch 1:  39%|███▉      | 41/105 [17:10<26:33, 24.89s/it, training_loss=0.464]\u001b[A\n","Epoch 1:  39%|███▉      | 41/105 [17:35<26:33, 24.89s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  40%|████      | 42/105 [17:35<26:16, 25.03s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  40%|████      | 42/105 [17:59<26:16, 25.03s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  41%|████      | 43/105 [17:59<25:27, 24.63s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  41%|████      | 43/105 [18:24<25:27, 24.63s/it, training_loss=0.494]\u001b[A\n","Epoch 1:  42%|████▏     | 44/105 [18:24<25:09, 24.74s/it, training_loss=0.494]\u001b[A\n","Epoch 1:  42%|████▏     | 44/105 [18:49<25:09, 24.74s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  43%|████▎     | 45/105 [18:49<24:59, 24.99s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  43%|████▎     | 45/105 [19:14<24:59, 24.99s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  44%|████▍     | 46/105 [19:14<24:31, 24.95s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  44%|████▍     | 46/105 [19:38<24:31, 24.95s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  45%|████▍     | 47/105 [19:38<23:46, 24.60s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  45%|████▍     | 47/105 [20:03<23:46, 24.60s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  46%|████▌     | 48/105 [20:03<23:34, 24.81s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  46%|████▌     | 48/105 [20:29<23:34, 24.81s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  47%|████▋     | 49/105 [20:29<23:15, 24.93s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  47%|████▋     | 49/105 [20:52<23:15, 24.93s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  48%|████▊     | 50/105 [20:52<22:25, 24.46s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  48%|████▊     | 50/105 [21:17<22:25, 24.46s/it, training_loss=0.650]\u001b[A\n","Epoch 1:  49%|████▊     | 51/105 [21:17<22:13, 24.70s/it, training_loss=0.650]\u001b[A\n","Epoch 1:  49%|████▊     | 51/105 [21:42<22:13, 24.70s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  50%|████▉     | 52/105 [21:42<21:57, 24.85s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  50%|████▉     | 52/105 [22:06<21:57, 24.85s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  50%|█████     | 53/105 [22:06<21:12, 24.47s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  50%|█████     | 53/105 [22:31<21:12, 24.47s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  51%|█████▏    | 54/105 [22:31<20:52, 24.56s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  51%|█████▏    | 54/105 [22:56<20:52, 24.56s/it, training_loss=0.452]\u001b[A\n","Epoch 1:  52%|█████▏    | 55/105 [22:56<20:39, 24.79s/it, training_loss=0.452]\u001b[A\n","Epoch 1:  52%|█████▏    | 55/105 [23:21<20:39, 24.79s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  53%|█████▎    | 56/105 [23:21<20:10, 24.70s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  53%|█████▎    | 56/105 [23:44<20:10, 24.70s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  54%|█████▍    | 57/105 [23:44<19:34, 24.46s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  54%|█████▍    | 57/105 [24:10<19:34, 24.46s/it, training_loss=0.601]\u001b[A\n","Epoch 1:  55%|█████▌    | 58/105 [24:10<19:20, 24.69s/it, training_loss=0.601]\u001b[A\n","Epoch 1:  55%|█████▌    | 58/105 [24:35<19:20, 24.69s/it, training_loss=0.422]\u001b[A\n","Epoch 1:  56%|█████▌    | 59/105 [24:35<19:02, 24.84s/it, training_loss=0.422]\u001b[A\n","Epoch 1:  56%|█████▌    | 59/105 [24:58<19:02, 24.84s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  57%|█████▋    | 60/105 [24:58<18:19, 24.43s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  57%|█████▋    | 60/105 [25:24<18:19, 24.43s/it, training_loss=0.727]\u001b[A\n","Epoch 1:  58%|█████▊    | 61/105 [25:24<18:06, 24.69s/it, training_loss=0.727]\u001b[A\n","Epoch 1:  58%|█████▊    | 61/105 [25:49<18:06, 24.69s/it, training_loss=0.493]\u001b[A\n","Epoch 1:  59%|█████▉    | 62/105 [25:49<17:49, 24.86s/it, training_loss=0.493]\u001b[A\n","Epoch 1:  59%|█████▉    | 62/105 [26:12<17:49, 24.86s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  60%|██████    | 63/105 [26:12<17:06, 24.44s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  60%|██████    | 63/105 [26:38<17:06, 24.44s/it, training_loss=0.653]\u001b[A\n","Epoch 1:  61%|██████    | 64/105 [26:38<16:50, 24.65s/it, training_loss=0.653]\u001b[A\n","Epoch 1:  61%|██████    | 64/105 [27:03<16:50, 24.65s/it, training_loss=0.493]\u001b[A\n","Epoch 1:  62%|██████▏   | 65/105 [27:03<16:36, 24.90s/it, training_loss=0.493]\u001b[A\n","Epoch 1:  62%|██████▏   | 65/105 [27:27<16:36, 24.90s/it, training_loss=0.463]\u001b[A\n","Epoch 1:  63%|██████▎   | 66/105 [27:27<16:05, 24.76s/it, training_loss=0.463]\u001b[A\n","Epoch 1:  63%|██████▎   | 66/105 [27:52<16:05, 24.76s/it, training_loss=0.467]\u001b[A\n","Epoch 1:  64%|██████▍   | 67/105 [27:52<15:33, 24.57s/it, training_loss=0.467]\u001b[A\n","Epoch 1:  64%|██████▍   | 67/105 [28:17<15:33, 24.57s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  65%|██████▍   | 68/105 [28:17<15:17, 24.80s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  65%|██████▍   | 68/105 [28:42<15:17, 24.80s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  66%|██████▌   | 69/105 [28:42<14:57, 24.94s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  66%|██████▌   | 69/105 [29:06<14:57, 24.94s/it, training_loss=0.421]\u001b[A\n","Epoch 1:  67%|██████▋   | 70/105 [29:06<14:17, 24.49s/it, training_loss=0.421]\u001b[A\n","Epoch 1:  67%|██████▋   | 70/105 [29:31<14:17, 24.49s/it, training_loss=0.496]\u001b[A\n","Epoch 1:  68%|██████▊   | 71/105 [29:31<14:00, 24.73s/it, training_loss=0.496]\u001b[A\n","Epoch 1:  68%|██████▊   | 71/105 [29:56<14:00, 24.73s/it, training_loss=0.441]\u001b[A\n","Epoch 1:  69%|██████▊   | 72/105 [29:56<13:42, 24.91s/it, training_loss=0.441]\u001b[A\n","Epoch 1:  69%|██████▊   | 72/105 [30:20<13:42, 24.91s/it, training_loss=0.463]\u001b[A\n","Epoch 1:  70%|██████▉   | 73/105 [30:20<13:04, 24.51s/it, training_loss=0.463]\u001b[A\n","Epoch 1:  70%|██████▉   | 73/105 [30:45<13:04, 24.51s/it, training_loss=0.284]\u001b[A\n","Epoch 1:  70%|███████   | 74/105 [30:45<12:44, 24.66s/it, training_loss=0.284]\u001b[A\n","Epoch 1:  70%|███████   | 74/105 [31:10<12:44, 24.66s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  71%|███████▏  | 75/105 [31:10<12:26, 24.87s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  71%|███████▏  | 75/105 [31:35<12:26, 24.87s/it, training_loss=0.362]\u001b[A\n","Epoch 1:  72%|███████▏  | 76/105 [31:35<11:58, 24.78s/it, training_loss=0.362]\u001b[A\n","Epoch 1:  72%|███████▏  | 76/105 [31:59<11:58, 24.78s/it, training_loss=0.396]\u001b[A\n","Epoch 1:  73%|███████▎  | 77/105 [31:59<11:27, 24.56s/it, training_loss=0.396]\u001b[A\n","Epoch 1:  73%|███████▎  | 77/105 [32:24<11:27, 24.56s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  74%|███████▍  | 78/105 [32:24<11:08, 24.76s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  74%|███████▍  | 78/105 [32:49<11:08, 24.76s/it, training_loss=0.479]\u001b[A\n","Epoch 1:  75%|███████▌  | 79/105 [32:49<10:48, 24.93s/it, training_loss=0.479]\u001b[A\n","Epoch 1:  75%|███████▌  | 79/105 [33:13<10:48, 24.93s/it, training_loss=0.301]\u001b[A\n","Epoch 1:  76%|███████▌  | 80/105 [33:13<10:12, 24.51s/it, training_loss=0.301]\u001b[A\n","Epoch 1:  76%|███████▌  | 80/105 [33:38<10:12, 24.51s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  77%|███████▋  | 81/105 [33:38<09:54, 24.75s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  77%|███████▋  | 81/105 [34:04<09:54, 24.75s/it, training_loss=0.395]\u001b[A\n","Epoch 1:  78%|███████▊  | 82/105 [34:04<09:33, 24.92s/it, training_loss=0.395]\u001b[A\n","Epoch 1:  78%|███████▊  | 82/105 [34:27<09:33, 24.92s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  79%|███████▉  | 83/105 [34:27<09:00, 24.56s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  79%|███████▉  | 83/105 [34:52<09:00, 24.56s/it, training_loss=0.372]\u001b[A\n","Epoch 1:  80%|████████  | 84/105 [34:52<08:36, 24.59s/it, training_loss=0.372]\u001b[A\n","Epoch 1:  80%|████████  | 84/105 [35:17<08:36, 24.59s/it, training_loss=0.683]\u001b[A\n","Epoch 1:  81%|████████  | 85/105 [35:17<08:16, 24.80s/it, training_loss=0.683]\u001b[A\n","Epoch 1:  81%|████████  | 85/105 [35:42<08:16, 24.80s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  82%|████████▏ | 86/105 [35:42<07:50, 24.79s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  82%|████████▏ | 86/105 [36:06<07:50, 24.79s/it, training_loss=0.460]\u001b[A\n","Epoch 1:  83%|████████▎ | 87/105 [36:06<07:21, 24.51s/it, training_loss=0.460]\u001b[A\n","Epoch 1:  83%|████████▎ | 87/105 [36:31<07:21, 24.51s/it, training_loss=0.382]\u001b[A\n","Epoch 1:  84%|████████▍ | 88/105 [36:31<07:00, 24.73s/it, training_loss=0.382]\u001b[A\n","Epoch 1:  84%|████████▍ | 88/105 [36:56<07:00, 24.73s/it, training_loss=0.283]\u001b[A\n","Epoch 1:  85%|████████▍ | 89/105 [36:56<06:38, 24.88s/it, training_loss=0.283]\u001b[A\n","Epoch 1:  85%|████████▍ | 89/105 [37:20<06:38, 24.88s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  86%|████████▌ | 90/105 [37:20<06:06, 24.44s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  86%|████████▌ | 90/105 [37:45<06:06, 24.44s/it, training_loss=0.426]\u001b[A\n","Epoch 1:  87%|████████▋ | 91/105 [37:45<05:45, 24.71s/it, training_loss=0.426]\u001b[A\n","Epoch 1:  87%|████████▋ | 91/105 [38:10<05:45, 24.71s/it, training_loss=0.376]\u001b[A\n","Epoch 1:  88%|████████▊ | 92/105 [38:10<05:23, 24.89s/it, training_loss=0.376]\u001b[A\n","Epoch 1:  88%|████████▊ | 92/105 [38:34<05:23, 24.89s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  89%|████████▊ | 93/105 [38:34<04:55, 24.64s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  89%|████████▊ | 93/105 [38:59<04:55, 24.64s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  90%|████████▉ | 94/105 [38:59<04:30, 24.63s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  90%|████████▉ | 94/105 [39:24<04:30, 24.63s/it, training_loss=0.357]\u001b[A\n","Epoch 1:  90%|█████████ | 95/105 [39:24<04:08, 24.83s/it, training_loss=0.357]\u001b[A\n","Epoch 1:  90%|█████████ | 95/105 [39:49<04:08, 24.83s/it, training_loss=0.258]\u001b[A\n","Epoch 1:  91%|█████████▏| 96/105 [39:49<03:43, 24.88s/it, training_loss=0.258]\u001b[A\n","Epoch 1:  91%|█████████▏| 96/105 [40:13<03:43, 24.88s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  92%|█████████▏| 97/105 [40:13<03:15, 24.49s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  92%|█████████▏| 97/105 [40:38<03:15, 24.49s/it, training_loss=0.276]\u001b[A\n","Epoch 1:  93%|█████████▎| 98/105 [40:38<02:52, 24.71s/it, training_loss=0.276]\u001b[A\n","Epoch 1:  93%|█████████▎| 98/105 [41:03<02:52, 24.71s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  94%|█████████▍| 99/105 [41:03<02:29, 24.87s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  94%|█████████▍| 99/105 [41:27<02:29, 24.87s/it, training_loss=0.432]\u001b[A\n","Epoch 1:  95%|█████████▌| 100/105 [41:27<02:02, 24.43s/it, training_loss=0.432]\u001b[A\n","Epoch 1:  95%|█████████▌| 100/105 [41:52<02:02, 24.43s/it, training_loss=0.502]\u001b[A\n","Epoch 1:  96%|█████████▌| 101/105 [41:52<01:38, 24.68s/it, training_loss=0.502]\u001b[A\n","Epoch 1:  96%|█████████▌| 101/105 [42:17<01:38, 24.68s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  97%|█████████▋| 102/105 [42:17<01:14, 24.83s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  97%|█████████▋| 102/105 [42:41<01:14, 24.83s/it, training_loss=0.298]\u001b[A\n","Epoch 1:  98%|█████████▊| 103/105 [42:41<00:49, 24.51s/it, training_loss=0.298]\u001b[A\n","Epoch 1:  98%|█████████▊| 103/105 [43:06<00:49, 24.51s/it, training_loss=0.312]\u001b[A\n","Epoch 1:  99%|█████████▉| 104/105 [43:06<00:24, 24.54s/it, training_loss=0.312]\u001b[A\n","Epoch 1:  99%|█████████▉| 104/105 [43:31<00:24, 24.54s/it, training_loss=0.326]\u001b[A\n","Epoch 1: 100%|██████████| 105/105 [43:31<00:00, 24.72s/it, training_loss=0.326]\u001b[A\n","  0%|          | 0/4 [43:31<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.5462007874534243\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [47:03<2:21:09, 2823.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.0715012108838116\n","F1 Score (Weighted): 0.41401254808357135\n","QWK Score: 0.3684748070812528\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/105 [00:24<?, ?it/s, training_loss=0.269]\u001b[A\n","Epoch 2:   1%|          | 1/105 [00:24<42:44, 24.66s/it, training_loss=0.269]\u001b[A\n","Epoch 2:   1%|          | 1/105 [00:49<42:44, 24.66s/it, training_loss=0.717]\u001b[A\n","Epoch 2:   2%|▏         | 2/105 [00:49<42:58, 25.04s/it, training_loss=0.717]\u001b[A\n","Epoch 2:   2%|▏         | 2/105 [01:14<42:58, 25.04s/it, training_loss=0.303]\u001b[A\n","Epoch 2:   3%|▎         | 3/105 [01:14<42:24, 24.94s/it, training_loss=0.303]\u001b[A\n","Epoch 2:   3%|▎         | 3/105 [01:38<42:24, 24.94s/it, training_loss=0.405]\u001b[A\n","Epoch 2:   4%|▍         | 4/105 [01:38<41:08, 24.44s/it, training_loss=0.405]\u001b[A\n","Epoch 2:   4%|▍         | 4/105 [02:03<41:08, 24.44s/it, training_loss=0.198]\u001b[A\n","Epoch 2:   5%|▍         | 5/105 [02:03<41:13, 24.74s/it, training_loss=0.198]\u001b[A\n","Epoch 2:   5%|▍         | 5/105 [02:28<41:13, 24.74s/it, training_loss=0.332]\u001b[A\n","Epoch 2:   6%|▌         | 6/105 [02:28<41:05, 24.90s/it, training_loss=0.332]\u001b[A\n","Epoch 2:   6%|▌         | 6/105 [02:52<41:05, 24.90s/it, training_loss=0.620]\u001b[A\n","Epoch 2:   7%|▋         | 7/105 [02:52<39:51, 24.40s/it, training_loss=0.620]\u001b[A\n","Epoch 2:   7%|▋         | 7/105 [03:17<39:51, 24.40s/it, training_loss=0.488]\u001b[A\n","Epoch 2:   8%|▊         | 8/105 [03:17<39:51, 24.66s/it, training_loss=0.488]\u001b[A\n","Epoch 2:   8%|▊         | 8/105 [03:42<39:51, 24.66s/it, training_loss=0.415]\u001b[A\n","Epoch 2:   9%|▊         | 9/105 [03:42<39:44, 24.84s/it, training_loss=0.415]\u001b[A\n","Epoch 2:   9%|▊         | 9/105 [04:06<39:44, 24.84s/it, training_loss=0.344]\u001b[A\n","Epoch 2:  10%|▉         | 10/105 [04:06<38:44, 24.47s/it, training_loss=0.344]\u001b[A\n","Epoch 2:  10%|▉         | 10/105 [04:31<38:44, 24.47s/it, training_loss=0.309]\u001b[A\n","Epoch 2:  10%|█         | 11/105 [04:31<38:29, 24.57s/it, training_loss=0.309]\u001b[A\n","Epoch 2:  10%|█         | 11/105 [04:56<38:29, 24.57s/it, training_loss=0.313]\u001b[A\n","Epoch 2:  11%|█▏        | 12/105 [04:56<38:25, 24.79s/it, training_loss=0.313]\u001b[A\n","Epoch 2:  11%|█▏        | 12/105 [05:21<38:25, 24.79s/it, training_loss=0.739]\u001b[A\n","Epoch 2:  12%|█▏        | 13/105 [05:21<37:57, 24.76s/it, training_loss=0.739]\u001b[A\n","Epoch 2:  12%|█▏        | 13/105 [05:45<37:57, 24.76s/it, training_loss=0.335]\u001b[A\n","Epoch 2:  13%|█▎        | 14/105 [05:45<37:08, 24.49s/it, training_loss=0.335]\u001b[A\n","Epoch 2:  13%|█▎        | 14/105 [06:10<37:08, 24.49s/it, training_loss=0.307]\u001b[A\n","Epoch 2:  14%|█▍        | 15/105 [06:10<37:05, 24.72s/it, training_loss=0.307]\u001b[A\n","Epoch 2:  14%|█▍        | 15/105 [06:35<37:05, 24.72s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  15%|█▌        | 16/105 [06:35<36:52, 24.86s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  15%|█▌        | 16/105 [06:58<36:52, 24.86s/it, training_loss=0.596]\u001b[A\n","Epoch 2:  16%|█▌        | 17/105 [06:58<35:49, 24.43s/it, training_loss=0.596]\u001b[A\n","Epoch 2:  16%|█▌        | 17/105 [07:24<35:49, 24.43s/it, training_loss=0.319]\u001b[A\n","Epoch 2:  17%|█▋        | 18/105 [07:24<35:47, 24.68s/it, training_loss=0.319]\u001b[A\n","Epoch 2:  17%|█▋        | 18/105 [07:49<35:47, 24.68s/it, training_loss=0.329]\u001b[A\n","Epoch 2:  18%|█▊        | 19/105 [07:49<35:38, 24.87s/it, training_loss=0.329]\u001b[A\n","Epoch 2:  18%|█▊        | 19/105 [08:13<35:38, 24.87s/it, training_loss=0.268]\u001b[A\n","Epoch 2:  19%|█▉        | 20/105 [08:13<34:47, 24.56s/it, training_loss=0.268]\u001b[A\n","Epoch 2:  19%|█▉        | 20/105 [08:38<34:47, 24.56s/it, training_loss=0.429]\u001b[A\n","Epoch 2:  20%|██        | 21/105 [08:38<34:26, 24.60s/it, training_loss=0.429]\u001b[A\n","Epoch 2:  20%|██        | 21/105 [09:03<34:26, 24.60s/it, training_loss=0.423]\u001b[A\n","Epoch 2:  21%|██        | 22/105 [09:03<34:17, 24.79s/it, training_loss=0.423]\u001b[A\n","Epoch 2:  21%|██        | 22/105 [09:27<34:17, 24.79s/it, training_loss=0.277]\u001b[A\n","Epoch 2:  22%|██▏       | 23/105 [09:27<33:43, 24.68s/it, training_loss=0.277]\u001b[A\n","Epoch 2:  22%|██▏       | 23/105 [09:51<33:43, 24.68s/it, training_loss=0.330]\u001b[A\n","Epoch 2:  23%|██▎       | 24/105 [09:51<32:58, 24.43s/it, training_loss=0.330]\u001b[A\n","Epoch 2:  23%|██▎       | 24/105 [10:16<32:58, 24.43s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  24%|██▍       | 25/105 [10:16<32:51, 24.65s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  24%|██▍       | 25/105 [10:41<32:51, 24.65s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  25%|██▍       | 26/105 [10:41<32:40, 24.81s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  25%|██▍       | 26/105 [11:05<32:40, 24.81s/it, training_loss=0.347]\u001b[A\n","Epoch 2:  26%|██▌       | 27/105 [11:05<31:43, 24.41s/it, training_loss=0.347]\u001b[A\n","Epoch 2:  26%|██▌       | 27/105 [11:30<31:43, 24.41s/it, training_loss=0.468]\u001b[A\n","Epoch 2:  27%|██▋       | 28/105 [11:30<31:37, 24.64s/it, training_loss=0.468]\u001b[A\n","Epoch 2:  27%|██▋       | 28/105 [11:55<31:37, 24.64s/it, training_loss=0.422]\u001b[A\n","Epoch 2:  28%|██▊       | 29/105 [11:55<31:28, 24.85s/it, training_loss=0.422]\u001b[A\n","Epoch 2:  28%|██▊       | 29/105 [12:19<31:28, 24.85s/it, training_loss=0.493]\u001b[A\n","Epoch 2:  29%|██▊       | 30/105 [12:19<30:31, 24.43s/it, training_loss=0.493]\u001b[A\n","Epoch 2:  29%|██▊       | 30/105 [12:44<30:31, 24.43s/it, training_loss=0.367]\u001b[A\n","Epoch 2:  30%|██▉       | 31/105 [12:44<30:21, 24.61s/it, training_loss=0.367]\u001b[A\n","Epoch 2:  30%|██▉       | 31/105 [13:09<30:21, 24.61s/it, training_loss=0.559]\u001b[A\n","Epoch 2:  30%|███       | 32/105 [13:09<30:09, 24.79s/it, training_loss=0.559]\u001b[A\n","Epoch 2:  30%|███       | 32/105 [13:33<30:09, 24.79s/it, training_loss=0.615]\u001b[A\n","Epoch 2:  31%|███▏      | 33/105 [13:33<29:32, 24.62s/it, training_loss=0.615]\u001b[A\n","Epoch 2:  31%|███▏      | 33/105 [13:57<29:32, 24.62s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  32%|███▏      | 34/105 [13:57<28:59, 24.50s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  32%|███▏      | 34/105 [14:23<28:59, 24.50s/it, training_loss=0.332]\u001b[A\n","Epoch 2:  33%|███▎      | 35/105 [14:23<28:49, 24.71s/it, training_loss=0.332]\u001b[A\n","Epoch 2:  33%|███▎      | 35/105 [14:48<28:49, 24.71s/it, training_loss=0.292]\u001b[A\n","Epoch 2:  34%|███▍      | 36/105 [14:48<28:31, 24.81s/it, training_loss=0.292]\u001b[A\n","Epoch 2:  34%|███▍      | 36/105 [15:11<28:31, 24.81s/it, training_loss=0.305]\u001b[A\n","Epoch 2:  35%|███▌      | 37/105 [15:11<27:39, 24.41s/it, training_loss=0.305]\u001b[A\n","Epoch 2:  35%|███▌      | 37/105 [15:36<27:39, 24.41s/it, training_loss=0.254]\u001b[A\n","Epoch 2:  36%|███▌      | 38/105 [15:36<27:31, 24.65s/it, training_loss=0.254]\u001b[A\n","Epoch 2:  36%|███▌      | 38/105 [16:02<27:31, 24.65s/it, training_loss=0.154]\u001b[A\n","Epoch 2:  37%|███▋      | 39/105 [16:02<27:19, 24.83s/it, training_loss=0.154]\u001b[A\n","Epoch 2:  37%|███▋      | 39/105 [16:25<27:19, 24.83s/it, training_loss=0.330]\u001b[A\n","Epoch 2:  38%|███▊      | 40/105 [16:25<26:28, 24.44s/it, training_loss=0.330]\u001b[A\n","Epoch 2:  38%|███▊      | 40/105 [16:50<26:28, 24.44s/it, training_loss=0.469]\u001b[A\n","Epoch 2:  39%|███▉      | 41/105 [16:50<26:18, 24.67s/it, training_loss=0.469]\u001b[A\n","Epoch 2:  39%|███▉      | 41/105 [17:16<26:18, 24.67s/it, training_loss=0.320]\u001b[A\n","Epoch 2:  40%|████      | 42/105 [17:16<26:05, 24.86s/it, training_loss=0.320]\u001b[A\n","Epoch 2:  40%|████      | 42/105 [17:40<26:05, 24.86s/it, training_loss=0.421]\u001b[A\n","Epoch 2:  41%|████      | 43/105 [17:40<25:28, 24.65s/it, training_loss=0.421]\u001b[A\n","Epoch 2:  41%|████      | 43/105 [18:04<25:28, 24.65s/it, training_loss=0.418]\u001b[A\n","Epoch 2:  42%|████▏     | 44/105 [18:04<24:56, 24.53s/it, training_loss=0.418]\u001b[A\n","Epoch 2:  42%|████▏     | 44/105 [18:29<24:56, 24.53s/it, training_loss=0.237]\u001b[A\n","Epoch 2:  43%|████▎     | 45/105 [18:29<24:43, 24.73s/it, training_loss=0.237]\u001b[A\n","Epoch 2:  43%|████▎     | 45/105 [18:54<24:43, 24.73s/it, training_loss=0.274]\u001b[A\n","Epoch 2:  44%|████▍     | 46/105 [18:54<24:26, 24.85s/it, training_loss=0.274]\u001b[A\n","Epoch 2:  44%|████▍     | 46/105 [19:18<24:26, 24.85s/it, training_loss=0.379]\u001b[A\n","Epoch 2:  45%|████▍     | 47/105 [19:18<23:41, 24.50s/it, training_loss=0.379]\u001b[A\n","Epoch 2:  45%|████▍     | 47/105 [19:43<23:41, 24.50s/it, training_loss=0.585]\u001b[A\n","Epoch 2:  46%|████▌     | 48/105 [19:43<23:29, 24.73s/it, training_loss=0.585]\u001b[A\n","Epoch 2:  46%|████▌     | 48/105 [20:09<23:29, 24.73s/it, training_loss=0.426]\u001b[A\n","Epoch 2:  47%|████▋     | 49/105 [20:09<23:15, 24.92s/it, training_loss=0.426]\u001b[A\n","Epoch 2:  47%|████▋     | 49/105 [20:32<23:15, 24.92s/it, training_loss=0.195]\u001b[A\n","Epoch 2:  48%|████▊     | 50/105 [20:32<22:25, 24.47s/it, training_loss=0.195]\u001b[A\n","Epoch 2:  48%|████▊     | 50/105 [20:57<22:25, 24.47s/it, training_loss=0.392]\u001b[A\n","Epoch 2:  49%|████▊     | 51/105 [20:57<22:15, 24.72s/it, training_loss=0.392]\u001b[A\n","Epoch 2:  49%|████▊     | 51/105 [21:23<22:15, 24.72s/it, training_loss=0.456]\u001b[A\n","Epoch 2:  50%|████▉     | 52/105 [21:23<22:00, 24.92s/it, training_loss=0.456]\u001b[A\n","Epoch 2:  50%|████▉     | 52/105 [21:47<22:00, 24.92s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  50%|█████     | 53/105 [21:47<21:24, 24.69s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  50%|█████     | 53/105 [22:11<21:24, 24.69s/it, training_loss=0.584]\u001b[A\n","Epoch 2:  51%|█████▏    | 54/105 [22:11<20:54, 24.59s/it, training_loss=0.584]\u001b[A\n","Epoch 2:  51%|█████▏    | 54/105 [22:37<20:54, 24.59s/it, training_loss=0.443]\u001b[A\n","Epoch 2:  52%|█████▏    | 55/105 [22:37<20:40, 24.81s/it, training_loss=0.443]\u001b[A\n","Epoch 2:  52%|█████▏    | 55/105 [23:02<20:40, 24.81s/it, training_loss=0.442]\u001b[A\n","Epoch 2:  53%|█████▎    | 56/105 [23:02<20:22, 24.95s/it, training_loss=0.442]\u001b[A\n","Epoch 2:  53%|█████▎    | 56/105 [23:25<20:22, 24.95s/it, training_loss=0.587]\u001b[A\n","Epoch 2:  54%|█████▍    | 57/105 [23:25<19:36, 24.52s/it, training_loss=0.587]\u001b[A\n","Epoch 2:  54%|█████▍    | 57/105 [23:51<19:36, 24.52s/it, training_loss=0.150]\u001b[A\n","Epoch 2:  55%|█████▌    | 58/105 [23:51<19:23, 24.76s/it, training_loss=0.150]\u001b[A\n","Epoch 2:  55%|█████▌    | 58/105 [24:16<19:23, 24.76s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  56%|█████▌    | 59/105 [24:16<19:06, 24.92s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  56%|█████▌    | 59/105 [24:40<19:06, 24.92s/it, training_loss=0.365]\u001b[A\n","Epoch 2:  57%|█████▋    | 60/105 [24:40<18:21, 24.47s/it, training_loss=0.365]\u001b[A\n","Epoch 2:  57%|█████▋    | 60/105 [25:05<18:21, 24.47s/it, training_loss=0.277]\u001b[A\n","Epoch 2:  58%|█████▊    | 61/105 [25:05<18:06, 24.68s/it, training_loss=0.277]\u001b[A\n","Epoch 2:  58%|█████▊    | 61/105 [25:30<18:06, 24.68s/it, training_loss=0.220]\u001b[A\n","Epoch 2:  59%|█████▉    | 62/105 [25:30<17:49, 24.88s/it, training_loss=0.220]\u001b[A\n","Epoch 2:  59%|█████▉    | 62/105 [25:54<17:49, 24.88s/it, training_loss=0.352]\u001b[A\n","Epoch 2:  60%|██████    | 63/105 [25:54<17:18, 24.72s/it, training_loss=0.352]\u001b[A\n","Epoch 2:  60%|██████    | 63/105 [26:19<17:18, 24.72s/it, training_loss=0.471]\u001b[A\n","Epoch 2:  61%|██████    | 64/105 [26:19<16:46, 24.55s/it, training_loss=0.471]\u001b[A\n","Epoch 2:  61%|██████    | 64/105 [26:44<16:46, 24.55s/it, training_loss=0.404]\u001b[A\n","Epoch 2:  62%|██████▏   | 65/105 [26:44<16:31, 24.79s/it, training_loss=0.404]\u001b[A\n","Epoch 2:  62%|██████▏   | 65/105 [27:09<16:31, 24.79s/it, training_loss=0.310]\u001b[A\n","Epoch 2:  63%|██████▎   | 66/105 [27:09<16:12, 24.92s/it, training_loss=0.310]\u001b[A\n","Epoch 2:  63%|██████▎   | 66/105 [27:33<16:12, 24.92s/it, training_loss=0.334]\u001b[A\n","Epoch 2:  64%|██████▍   | 67/105 [27:33<15:31, 24.50s/it, training_loss=0.334]\u001b[A\n","Epoch 2:  64%|██████▍   | 67/105 [27:58<15:31, 24.50s/it, training_loss=0.326]\u001b[A\n","Epoch 2:  65%|██████▍   | 68/105 [27:58<15:15, 24.75s/it, training_loss=0.326]\u001b[A\n","Epoch 2:  65%|██████▍   | 68/105 [28:23<15:15, 24.75s/it, training_loss=0.067]\u001b[A\n","Epoch 2:  66%|██████▌   | 69/105 [28:23<14:56, 24.92s/it, training_loss=0.067]\u001b[A\n","Epoch 2:  66%|██████▌   | 69/105 [28:47<14:56, 24.92s/it, training_loss=0.329]\u001b[A\n","Epoch 2:  67%|██████▋   | 70/105 [28:47<14:16, 24.48s/it, training_loss=0.329]\u001b[A\n","Epoch 2:  67%|██████▋   | 70/105 [29:12<14:16, 24.48s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  68%|██████▊   | 71/105 [29:12<13:59, 24.68s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  68%|██████▊   | 71/105 [29:37<13:59, 24.68s/it, training_loss=0.189]\u001b[A\n","Epoch 2:  69%|██████▊   | 72/105 [29:37<13:40, 24.88s/it, training_loss=0.189]\u001b[A\n","Epoch 2:  69%|██████▊   | 72/105 [30:02<13:40, 24.88s/it, training_loss=0.166]\u001b[A\n","Epoch 2:  70%|██████▉   | 73/105 [30:02<13:11, 24.74s/it, training_loss=0.166]\u001b[A\n","Epoch 2:  70%|██████▉   | 73/105 [30:26<13:11, 24.74s/it, training_loss=0.188]\u001b[A\n","Epoch 2:  70%|███████   | 74/105 [30:26<12:41, 24.55s/it, training_loss=0.188]\u001b[A\n","Epoch 2:  70%|███████   | 74/105 [30:51<12:41, 24.55s/it, training_loss=0.271]\u001b[A\n","Epoch 2:  71%|███████▏  | 75/105 [30:51<12:23, 24.77s/it, training_loss=0.271]\u001b[A\n","Epoch 2:  71%|███████▏  | 75/105 [31:16<12:23, 24.77s/it, training_loss=0.467]\u001b[A\n","Epoch 2:  72%|███████▏  | 76/105 [31:16<12:03, 24.94s/it, training_loss=0.467]\u001b[A\n","Epoch 2:  72%|███████▏  | 76/105 [31:40<12:03, 24.94s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  73%|███████▎  | 77/105 [31:40<11:26, 24.51s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  73%|███████▎  | 77/105 [32:05<11:26, 24.51s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  74%|███████▍  | 78/105 [32:05<11:08, 24.74s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  74%|███████▍  | 78/105 [32:31<11:08, 24.74s/it, training_loss=0.279]\u001b[A\n","Epoch 2:  75%|███████▌  | 79/105 [32:31<10:48, 24.92s/it, training_loss=0.279]\u001b[A\n","Epoch 2:  75%|███████▌  | 79/105 [32:54<10:48, 24.92s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  76%|███████▌  | 80/105 [32:54<10:13, 24.52s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  76%|███████▌  | 80/105 [33:19<10:13, 24.52s/it, training_loss=0.627]\u001b[A\n","Epoch 2:  77%|███████▋  | 81/105 [33:19<09:51, 24.64s/it, training_loss=0.627]\u001b[A\n","Epoch 2:  77%|███████▋  | 81/105 [33:44<09:51, 24.64s/it, training_loss=0.354]\u001b[A\n","Epoch 2:  78%|███████▊  | 82/105 [33:44<09:31, 24.84s/it, training_loss=0.354]\u001b[A\n","Epoch 2:  78%|███████▊  | 82/105 [34:09<09:31, 24.84s/it, training_loss=0.282]\u001b[A\n","Epoch 2:  79%|███████▉  | 83/105 [34:09<09:03, 24.72s/it, training_loss=0.282]\u001b[A\n","Epoch 2:  79%|███████▉  | 83/105 [34:33<09:03, 24.72s/it, training_loss=0.152]\u001b[A\n","Epoch 2:  80%|████████  | 84/105 [34:33<08:34, 24.51s/it, training_loss=0.152]\u001b[A\n","Epoch 2:  80%|████████  | 84/105 [34:58<08:34, 24.51s/it, training_loss=0.238]\u001b[A\n","Epoch 2:  81%|████████  | 85/105 [34:58<08:15, 24.76s/it, training_loss=0.238]\u001b[A\n","Epoch 2:  81%|████████  | 85/105 [35:23<08:15, 24.76s/it, training_loss=0.435]\u001b[A\n","Epoch 2:  82%|████████▏ | 86/105 [35:23<07:53, 24.90s/it, training_loss=0.435]\u001b[A\n","Epoch 2:  82%|████████▏ | 86/105 [35:47<07:53, 24.90s/it, training_loss=0.199]\u001b[A\n","Epoch 2:  83%|████████▎ | 87/105 [35:47<07:20, 24.46s/it, training_loss=0.199]\u001b[A\n","Epoch 2:  83%|████████▎ | 87/105 [36:12<07:20, 24.46s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  84%|████████▍ | 88/105 [36:12<07:00, 24.72s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  84%|████████▍ | 88/105 [36:37<07:00, 24.72s/it, training_loss=0.321]\u001b[A\n","Epoch 2:  85%|████████▍ | 89/105 [36:37<06:38, 24.89s/it, training_loss=0.321]\u001b[A\n","Epoch 2:  85%|████████▍ | 89/105 [37:01<06:38, 24.89s/it, training_loss=0.381]\u001b[A\n","Epoch 2:  86%|████████▌ | 90/105 [37:01<06:07, 24.51s/it, training_loss=0.381]\u001b[A\n","Epoch 2:  86%|████████▌ | 90/105 [37:26<06:07, 24.51s/it, training_loss=0.304]\u001b[A\n","Epoch 2:  87%|████████▋ | 91/105 [37:26<05:45, 24.65s/it, training_loss=0.304]\u001b[A\n","Epoch 2:  87%|████████▋ | 91/105 [37:51<05:45, 24.65s/it, training_loss=0.179]\u001b[A\n","Epoch 2:  88%|████████▊ | 92/105 [37:51<05:22, 24.84s/it, training_loss=0.179]\u001b[A\n","Epoch 2:  88%|████████▊ | 92/105 [38:16<05:22, 24.84s/it, training_loss=0.233]\u001b[A\n","Epoch 2:  89%|████████▊ | 93/105 [38:16<04:57, 24.76s/it, training_loss=0.233]\u001b[A\n","Epoch 2:  89%|████████▊ | 93/105 [38:40<04:57, 24.76s/it, training_loss=0.257]\u001b[A\n","Epoch 2:  90%|████████▉ | 94/105 [38:40<04:29, 24.55s/it, training_loss=0.257]\u001b[A\n","Epoch 2:  90%|████████▉ | 94/105 [39:05<04:29, 24.55s/it, training_loss=0.288]\u001b[A\n","Epoch 2:  90%|█████████ | 95/105 [39:05<04:07, 24.79s/it, training_loss=0.288]\u001b[A\n","Epoch 2:  90%|█████████ | 95/105 [39:31<04:07, 24.79s/it, training_loss=0.162]\u001b[A\n","Epoch 2:  91%|█████████▏| 96/105 [39:31<03:44, 24.94s/it, training_loss=0.162]\u001b[A\n","Epoch 2:  91%|█████████▏| 96/105 [39:54<03:44, 24.94s/it, training_loss=0.218]\u001b[A\n","Epoch 2:  92%|█████████▏| 97/105 [39:54<03:15, 24.48s/it, training_loss=0.218]\u001b[A\n","Epoch 2:  92%|█████████▏| 97/105 [40:19<03:15, 24.48s/it, training_loss=0.429]\u001b[A\n","Epoch 2:  93%|█████████▎| 98/105 [40:19<02:53, 24.73s/it, training_loss=0.429]\u001b[A\n","Epoch 2:  93%|█████████▎| 98/105 [40:45<02:53, 24.73s/it, training_loss=0.181]\u001b[A\n","Epoch 2:  94%|█████████▍| 99/105 [40:45<02:29, 24.92s/it, training_loss=0.181]\u001b[A\n","Epoch 2:  94%|█████████▍| 99/105 [41:09<02:29, 24.92s/it, training_loss=0.215]\u001b[A\n","Epoch 2:  95%|█████████▌| 100/105 [41:09<02:03, 24.61s/it, training_loss=0.215]\u001b[A\n","Epoch 2:  95%|█████████▌| 100/105 [41:33<02:03, 24.61s/it, training_loss=0.465]\u001b[A\n","Epoch 2:  96%|█████████▌| 101/105 [41:33<01:38, 24.60s/it, training_loss=0.465]\u001b[A\n","Epoch 2:  96%|█████████▌| 101/105 [41:58<01:38, 24.60s/it, training_loss=0.335]\u001b[A\n","Epoch 2:  97%|█████████▋| 102/105 [41:58<01:14, 24.82s/it, training_loss=0.335]\u001b[A\n","Epoch 2:  97%|█████████▋| 102/105 [42:23<01:14, 24.82s/it, training_loss=0.153]\u001b[A\n","Epoch 2:  98%|█████████▊| 103/105 [42:23<00:49, 24.81s/it, training_loss=0.153]\u001b[A\n","Epoch 2:  98%|█████████▊| 103/105 [42:47<00:49, 24.81s/it, training_loss=0.281]\u001b[A\n","Epoch 2:  99%|█████████▉| 104/105 [42:47<00:24, 24.50s/it, training_loss=0.281]\u001b[A\n","Epoch 2:  99%|█████████▉| 104/105 [43:12<00:24, 24.50s/it, training_loss=0.224]\u001b[A\n","Epoch 2: 100%|██████████| 105/105 [43:12<00:00, 24.74s/it, training_loss=0.224]\u001b[A\n"," 25%|██▌       | 1/4 [1:30:15<2:21:09, 2823.04s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.0627156070300512\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [1:33:49<1:33:46, 2813.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.1571721217974469\n","F1 Score (Weighted): 0.46438284348488434\n","QWK Score: 0.39147727272727273\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/105 [00:23<?, ?it/s, training_loss=0.271]\u001b[A\n","Epoch 3:   1%|          | 1/105 [00:23<40:26, 23.33s/it, training_loss=0.271]\u001b[A\n","Epoch 3:   1%|          | 1/105 [00:48<40:26, 23.33s/it, training_loss=0.284]\u001b[A\n","Epoch 3:   2%|▏         | 2/105 [00:48<42:02, 24.49s/it, training_loss=0.284]\u001b[A\n","Epoch 3:   2%|▏         | 2/105 [01:13<42:02, 24.49s/it, training_loss=0.634]\u001b[A\n","Epoch 3:   3%|▎         | 3/105 [01:13<42:17, 24.88s/it, training_loss=0.634]\u001b[A\n","Epoch 3:   3%|▎         | 3/105 [01:37<42:17, 24.88s/it, training_loss=0.162]\u001b[A\n","Epoch 3:   4%|▍         | 4/105 [01:37<41:01, 24.37s/it, training_loss=0.162]\u001b[A\n","Epoch 3:   4%|▍         | 4/105 [02:02<41:01, 24.37s/it, training_loss=0.268]\u001b[A\n","Epoch 3:   5%|▍         | 5/105 [02:02<41:05, 24.65s/it, training_loss=0.268]\u001b[A\n","Epoch 3:   5%|▍         | 5/105 [02:27<41:05, 24.65s/it, training_loss=0.562]\u001b[A\n","Epoch 3:   6%|▌         | 6/105 [02:27<41:01, 24.86s/it, training_loss=0.562]\u001b[A\n","Epoch 3:   6%|▌         | 6/105 [02:52<41:01, 24.86s/it, training_loss=0.367]\u001b[A\n","Epoch 3:   7%|▋         | 7/105 [02:52<40:19, 24.69s/it, training_loss=0.367]\u001b[A\n","Epoch 3:   7%|▋         | 7/105 [03:16<40:19, 24.69s/it, training_loss=0.270]\u001b[A\n","Epoch 3:   8%|▊         | 8/105 [03:16<39:37, 24.51s/it, training_loss=0.270]\u001b[A\n","Epoch 3:   8%|▊         | 8/105 [03:41<39:37, 24.51s/it, training_loss=0.230]\u001b[A\n","Epoch 3:   9%|▊         | 9/105 [03:41<39:36, 24.76s/it, training_loss=0.230]\u001b[A\n","Epoch 3:   9%|▊         | 9/105 [04:07<39:36, 24.76s/it, training_loss=0.327]\u001b[A\n","Epoch 3:  10%|▉         | 10/105 [04:07<39:28, 24.93s/it, training_loss=0.327]\u001b[A\n","Epoch 3:  10%|▉         | 10/105 [04:30<39:28, 24.93s/it, training_loss=0.188]\u001b[A\n","Epoch 3:  10%|█         | 11/105 [04:30<38:19, 24.47s/it, training_loss=0.188]\u001b[A\n","Epoch 3:  10%|█         | 11/105 [04:55<38:19, 24.47s/it, training_loss=0.404]\u001b[A\n","Epoch 3:  11%|█▏        | 12/105 [04:55<38:19, 24.72s/it, training_loss=0.404]\u001b[A\n","Epoch 3:  11%|█▏        | 12/105 [05:21<38:19, 24.72s/it, training_loss=0.235]\u001b[A\n","Epoch 3:  12%|█▏        | 13/105 [05:21<38:11, 24.91s/it, training_loss=0.235]\u001b[A\n","Epoch 3:  12%|█▏        | 13/105 [05:44<38:11, 24.91s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  13%|█▎        | 14/105 [05:44<37:09, 24.50s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  13%|█▎        | 14/105 [06:09<37:09, 24.50s/it, training_loss=0.453]\u001b[A\n","Epoch 3:  14%|█▍        | 15/105 [06:09<36:58, 24.65s/it, training_loss=0.453]\u001b[A\n","Epoch 3:  14%|█▍        | 15/105 [06:34<36:58, 24.65s/it, training_loss=0.230]\u001b[A\n","Epoch 3:  15%|█▌        | 16/105 [06:34<36:48, 24.82s/it, training_loss=0.230]\u001b[A\n","Epoch 3:  15%|█▌        | 16/105 [06:59<36:48, 24.82s/it, training_loss=0.169]\u001b[A\n","Epoch 3:  16%|█▌        | 17/105 [06:59<36:13, 24.70s/it, training_loss=0.169]\u001b[A\n","Epoch 3:  16%|█▌        | 17/105 [07:23<36:13, 24.70s/it, training_loss=0.546]\u001b[A\n","Epoch 3:  17%|█▋        | 18/105 [07:23<35:32, 24.51s/it, training_loss=0.546]\u001b[A\n","Epoch 3:  17%|█▋        | 18/105 [07:48<35:32, 24.51s/it, training_loss=0.081]\u001b[A\n","Epoch 3:  18%|█▊        | 19/105 [07:48<35:30, 24.77s/it, training_loss=0.081]\u001b[A\n","Epoch 3:  18%|█▊        | 19/105 [08:14<35:30, 24.77s/it, training_loss=0.599]\u001b[A\n","Epoch 3:  19%|█▉        | 20/105 [08:14<35:19, 24.94s/it, training_loss=0.599]\u001b[A\n","Epoch 3:  19%|█▉        | 20/105 [08:45<35:19, 24.94s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  20%|██        | 21/105 [08:45<37:26, 26.74s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  20%|██        | 21/105 [09:08<37:26, 26.74s/it, training_loss=0.056]\u001b[A\n","Epoch 3:  21%|██        | 22/105 [09:08<35:46, 25.86s/it, training_loss=0.056]\u001b[A\n","Epoch 3:  21%|██        | 22/105 [09:33<35:46, 25.86s/it, training_loss=0.407]\u001b[A\n","Epoch 3:  22%|██▏       | 23/105 [09:33<34:55, 25.55s/it, training_loss=0.407]\u001b[A\n","Epoch 3:  22%|██▏       | 23/105 [09:58<34:55, 25.55s/it, training_loss=0.476]\u001b[A\n","Epoch 3:  23%|██▎       | 24/105 [09:58<34:24, 25.49s/it, training_loss=0.476]\u001b[A\n","Epoch 3:  23%|██▎       | 24/105 [10:23<34:24, 25.49s/it, training_loss=0.148]\u001b[A\n","Epoch 3:  24%|██▍       | 25/105 [10:23<33:42, 25.28s/it, training_loss=0.148]\u001b[A\n","Epoch 3:  24%|██▍       | 25/105 [10:47<33:42, 25.28s/it, training_loss=0.619]\u001b[A\n","Epoch 3:  25%|██▍       | 26/105 [10:47<32:42, 24.84s/it, training_loss=0.619]\u001b[A\n","Epoch 3:  25%|██▍       | 26/105 [11:12<32:42, 24.84s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  26%|██▌       | 27/105 [11:12<32:28, 24.98s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  26%|██▌       | 27/105 [11:38<32:28, 24.98s/it, training_loss=0.162]\u001b[A\n","Epoch 3:  27%|██▋       | 28/105 [11:38<32:09, 25.05s/it, training_loss=0.162]\u001b[A\n","Epoch 3:  27%|██▋       | 28/105 [12:01<32:09, 25.05s/it, training_loss=0.173]\u001b[A\n","Epoch 3:  28%|██▊       | 29/105 [12:01<31:08, 24.59s/it, training_loss=0.173]\u001b[A\n","Epoch 3:  28%|██▊       | 29/105 [12:26<31:08, 24.59s/it, training_loss=0.741]\u001b[A\n","Epoch 3:  29%|██▊       | 30/105 [12:26<31:00, 24.81s/it, training_loss=0.741]\u001b[A\n","Epoch 3:  29%|██▊       | 30/105 [12:52<31:00, 24.81s/it, training_loss=0.140]\u001b[A\n","Epoch 3:  30%|██▉       | 31/105 [12:52<30:47, 24.96s/it, training_loss=0.140]\u001b[A\n","Epoch 3:  30%|██▉       | 31/105 [13:16<30:47, 24.96s/it, training_loss=0.139]\u001b[A\n","Epoch 3:  30%|███       | 32/105 [13:16<29:55, 24.60s/it, training_loss=0.139]\u001b[A\n","Epoch 3:  30%|███       | 32/105 [13:40<29:55, 24.60s/it, training_loss=0.215]\u001b[A\n","Epoch 3:  31%|███▏      | 33/105 [13:40<29:34, 24.65s/it, training_loss=0.215]\u001b[A\n","Epoch 3:  31%|███▏      | 33/105 [14:06<29:34, 24.65s/it, training_loss=0.220]\u001b[A\n","Epoch 3:  32%|███▏      | 34/105 [14:06<29:25, 24.86s/it, training_loss=0.220]\u001b[A\n","Epoch 3:  32%|███▏      | 34/105 [14:31<29:25, 24.86s/it, training_loss=0.195]\u001b[A\n","Epoch 3:  33%|███▎      | 35/105 [14:31<29:01, 24.87s/it, training_loss=0.195]\u001b[A\n","Epoch 3:  33%|███▎      | 35/105 [14:54<29:01, 24.87s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  34%|███▍      | 36/105 [14:54<28:14, 24.56s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  34%|███▍      | 36/105 [15:20<28:14, 24.56s/it, training_loss=0.200]\u001b[A\n","Epoch 3:  35%|███▌      | 37/105 [15:20<28:07, 24.81s/it, training_loss=0.200]\u001b[A\n","Epoch 3:  35%|███▌      | 37/105 [15:45<28:07, 24.81s/it, training_loss=0.428]\u001b[A\n","Epoch 3:  36%|███▌      | 38/105 [15:45<27:52, 24.97s/it, training_loss=0.428]\u001b[A\n","Epoch 3:  36%|███▌      | 38/105 [16:09<27:52, 24.97s/it, training_loss=0.111]\u001b[A\n","Epoch 3:  37%|███▋      | 39/105 [16:09<26:57, 24.50s/it, training_loss=0.111]\u001b[A\n","Epoch 3:  37%|███▋      | 39/105 [16:34<26:57, 24.50s/it, training_loss=0.124]\u001b[A\n","Epoch 3:  38%|███▊      | 40/105 [16:34<26:47, 24.73s/it, training_loss=0.124]\u001b[A\n","Epoch 3:  38%|███▊      | 40/105 [16:59<26:47, 24.73s/it, training_loss=0.298]\u001b[A\n","Epoch 3:  39%|███▉      | 41/105 [16:59<26:30, 24.86s/it, training_loss=0.298]\u001b[A\n","Epoch 3:  39%|███▉      | 41/105 [17:23<26:30, 24.86s/it, training_loss=0.386]\u001b[A\n","Epoch 3:  40%|████      | 42/105 [17:23<25:43, 24.50s/it, training_loss=0.386]\u001b[A\n","Epoch 3:  40%|████      | 42/105 [17:47<25:43, 24.50s/it, training_loss=0.461]\u001b[A\n","Epoch 3:  41%|████      | 43/105 [17:47<25:23, 24.57s/it, training_loss=0.461]\u001b[A\n","Epoch 3:  41%|████      | 43/105 [18:13<25:23, 24.57s/it, training_loss=0.268]\u001b[A\n","Epoch 3:  42%|████▏     | 44/105 [18:13<25:12, 24.80s/it, training_loss=0.268]\u001b[A\n","Epoch 3:  42%|████▏     | 44/105 [18:37<25:12, 24.80s/it, training_loss=0.348]\u001b[A\n","Epoch 3:  43%|████▎     | 45/105 [18:37<24:45, 24.76s/it, training_loss=0.348]\u001b[A\n","Epoch 3:  43%|████▎     | 45/105 [19:01<24:45, 24.76s/it, training_loss=0.126]\u001b[A\n","Epoch 3:  44%|████▍     | 46/105 [19:01<24:05, 24.50s/it, training_loss=0.126]\u001b[A\n","Epoch 3:  44%|████▍     | 46/105 [19:27<24:05, 24.50s/it, training_loss=0.352]\u001b[A\n","Epoch 3:  45%|████▍     | 47/105 [19:27<23:55, 24.74s/it, training_loss=0.352]\u001b[A\n","Epoch 3:  45%|████▍     | 47/105 [19:52<23:55, 24.74s/it, training_loss=0.371]\u001b[A\n","Epoch 3:  46%|████▌     | 48/105 [19:52<23:38, 24.89s/it, training_loss=0.371]\u001b[A\n","Epoch 3:  46%|████▌     | 48/105 [20:15<23:38, 24.89s/it, training_loss=0.384]\u001b[A\n","Epoch 3:  47%|████▋     | 49/105 [20:15<22:48, 24.44s/it, training_loss=0.384]\u001b[A\n","Epoch 3:  47%|████▋     | 49/105 [20:41<22:48, 24.44s/it, training_loss=0.237]\u001b[A\n","Epoch 3:  48%|████▊     | 50/105 [20:41<22:39, 24.72s/it, training_loss=0.237]\u001b[A\n","Epoch 3:  48%|████▊     | 50/105 [21:06<22:39, 24.72s/it, training_loss=0.323]\u001b[A\n","Epoch 3:  49%|████▊     | 51/105 [21:06<22:21, 24.85s/it, training_loss=0.323]\u001b[A\n","Epoch 3:  49%|████▊     | 51/105 [21:29<22:21, 24.85s/it, training_loss=0.205]\u001b[A\n","Epoch 3:  50%|████▉     | 52/105 [21:29<21:40, 24.53s/it, training_loss=0.205]\u001b[A\n","Epoch 3:  50%|████▉     | 52/105 [21:54<21:40, 24.53s/it, training_loss=0.334]\u001b[A\n","Epoch 3:  50%|█████     | 53/105 [21:54<21:18, 24.58s/it, training_loss=0.334]\u001b[A\n","Epoch 3:  50%|█████     | 53/105 [22:19<21:18, 24.58s/it, training_loss=0.388]\u001b[A\n","Epoch 3:  51%|█████▏    | 54/105 [22:19<21:04, 24.80s/it, training_loss=0.388]\u001b[A\n","Epoch 3:  51%|█████▏    | 54/105 [22:44<21:04, 24.80s/it, training_loss=0.208]\u001b[A\n","Epoch 3:  52%|█████▏    | 55/105 [22:44<20:41, 24.82s/it, training_loss=0.208]\u001b[A\n","Epoch 3:  52%|█████▏    | 55/105 [23:08<20:41, 24.82s/it, training_loss=0.322]\u001b[A\n","Epoch 3:  53%|█████▎    | 56/105 [23:08<20:00, 24.51s/it, training_loss=0.322]\u001b[A\n","Epoch 3:  53%|█████▎    | 56/105 [23:33<20:00, 24.51s/it, training_loss=0.200]\u001b[A\n","Epoch 3:  54%|█████▍    | 57/105 [23:33<19:47, 24.75s/it, training_loss=0.200]\u001b[A\n","Epoch 3:  54%|█████▍    | 57/105 [23:59<19:47, 24.75s/it, training_loss=0.374]\u001b[A\n","Epoch 3:  55%|█████▌    | 58/105 [23:59<19:30, 24.91s/it, training_loss=0.374]\u001b[A\n","Epoch 3:  55%|█████▌    | 58/105 [24:22<19:30, 24.91s/it, training_loss=0.136]\u001b[A\n","Epoch 3:  56%|█████▌    | 59/105 [24:22<18:45, 24.48s/it, training_loss=0.136]\u001b[A\n","Epoch 3:  56%|█████▌    | 59/105 [24:48<18:45, 24.48s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  57%|█████▋    | 60/105 [24:48<18:33, 24.74s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  57%|█████▋    | 60/105 [25:13<18:33, 24.74s/it, training_loss=0.218]\u001b[A\n","Epoch 3:  58%|█████▊    | 61/105 [25:13<18:16, 24.92s/it, training_loss=0.218]\u001b[A\n","Epoch 3:  58%|█████▊    | 61/105 [25:37<18:16, 24.92s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  59%|█████▉    | 62/105 [25:37<17:40, 24.67s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  59%|█████▉    | 62/105 [26:01<17:40, 24.67s/it, training_loss=0.236]\u001b[A\n","Epoch 3:  60%|██████    | 63/105 [26:01<17:14, 24.62s/it, training_loss=0.236]\u001b[A\n","Epoch 3:  60%|██████    | 63/105 [26:27<17:14, 24.62s/it, training_loss=0.384]\u001b[A\n","Epoch 3:  61%|██████    | 64/105 [26:27<16:57, 24.83s/it, training_loss=0.384]\u001b[A\n","Epoch 3:  61%|██████    | 64/105 [26:52<16:57, 24.83s/it, training_loss=0.288]\u001b[A\n","Epoch 3:  62%|██████▏   | 65/105 [26:52<16:34, 24.86s/it, training_loss=0.288]\u001b[A\n","Epoch 3:  62%|██████▏   | 65/105 [27:15<16:34, 24.86s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  63%|██████▎   | 66/105 [27:15<15:56, 24.51s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  63%|██████▎   | 66/105 [27:41<15:56, 24.51s/it, training_loss=0.220]\u001b[A\n","Epoch 3:  64%|██████▍   | 67/105 [27:41<15:41, 24.77s/it, training_loss=0.220]\u001b[A\n","Epoch 3:  64%|██████▍   | 67/105 [28:06<15:41, 24.77s/it, training_loss=0.300]\u001b[A\n","Epoch 3:  65%|██████▍   | 68/105 [28:06<15:22, 24.93s/it, training_loss=0.300]\u001b[A\n","Epoch 3:  65%|██████▍   | 68/105 [28:30<15:22, 24.93s/it, training_loss=0.178]\u001b[A\n","Epoch 3:  66%|██████▌   | 69/105 [28:30<14:41, 24.50s/it, training_loss=0.178]\u001b[A\n","Epoch 3:  66%|██████▌   | 69/105 [28:55<14:41, 24.50s/it, training_loss=0.264]\u001b[A\n","Epoch 3:  67%|██████▋   | 70/105 [28:55<14:26, 24.74s/it, training_loss=0.264]\u001b[A\n","Epoch 3:  67%|██████▋   | 70/105 [29:20<14:26, 24.74s/it, training_loss=0.237]\u001b[A\n","Epoch 3:  68%|██████▊   | 71/105 [29:20<14:07, 24.92s/it, training_loss=0.237]\u001b[A\n","Epoch 3:  68%|██████▊   | 71/105 [29:44<14:07, 24.92s/it, training_loss=0.170]\u001b[A\n","Epoch 3:  69%|██████▊   | 72/105 [29:44<13:35, 24.71s/it, training_loss=0.170]\u001b[A\n","Epoch 3:  69%|██████▊   | 72/105 [30:09<13:35, 24.71s/it, training_loss=0.405]\u001b[A\n","Epoch 3:  70%|██████▉   | 73/105 [30:09<13:05, 24.55s/it, training_loss=0.405]\u001b[A\n","Epoch 3:  70%|██████▉   | 73/105 [30:34<13:05, 24.55s/it, training_loss=0.604]\u001b[A\n","Epoch 3:  70%|███████   | 74/105 [30:34<12:47, 24.76s/it, training_loss=0.604]\u001b[A\n","Epoch 3:  70%|███████   | 74/105 [30:59<12:47, 24.76s/it, training_loss=0.312]\u001b[A\n","Epoch 3:  71%|███████▏  | 75/105 [30:59<12:25, 24.87s/it, training_loss=0.312]\u001b[A\n","Epoch 3:  71%|███████▏  | 75/105 [31:23<12:25, 24.87s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  72%|███████▏  | 76/105 [31:23<11:49, 24.47s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  72%|███████▏  | 76/105 [31:48<11:49, 24.47s/it, training_loss=0.243]\u001b[A\n","Epoch 3:  73%|███████▎  | 77/105 [31:48<11:31, 24.71s/it, training_loss=0.243]\u001b[A\n","Epoch 3:  73%|███████▎  | 77/105 [32:13<11:31, 24.71s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  74%|███████▍  | 78/105 [32:13<11:11, 24.89s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  74%|███████▍  | 78/105 [32:36<11:11, 24.89s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  75%|███████▌  | 79/105 [32:36<10:34, 24.42s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  75%|███████▌  | 79/105 [33:02<10:34, 24.42s/it, training_loss=0.212]\u001b[A\n","Epoch 3:  76%|███████▌  | 80/105 [33:02<10:16, 24.66s/it, training_loss=0.212]\u001b[A\n","Epoch 3:  76%|███████▌  | 80/105 [33:27<10:16, 24.66s/it, training_loss=0.128]\u001b[A\n","Epoch 3:  77%|███████▋  | 81/105 [33:27<09:56, 24.84s/it, training_loss=0.128]\u001b[A\n","Epoch 3:  77%|███████▋  | 81/105 [33:51<09:56, 24.84s/it, training_loss=0.221]\u001b[A\n","Epoch 3:  78%|███████▊  | 82/105 [33:51<09:24, 24.53s/it, training_loss=0.221]\u001b[A\n","Epoch 3:  78%|███████▊  | 82/105 [34:15<09:24, 24.53s/it, training_loss=0.322]\u001b[A\n","Epoch 3:  79%|███████▉  | 83/105 [34:15<09:00, 24.55s/it, training_loss=0.322]\u001b[A\n","Epoch 3:  79%|███████▉  | 83/105 [34:41<09:00, 24.55s/it, training_loss=0.132]\u001b[A\n","Epoch 3:  80%|████████  | 84/105 [34:41<08:39, 24.75s/it, training_loss=0.132]\u001b[A\n","Epoch 3:  80%|████████  | 84/105 [35:05<08:39, 24.75s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  81%|████████  | 85/105 [35:05<08:14, 24.71s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  81%|████████  | 85/105 [35:29<08:14, 24.71s/it, training_loss=0.386]\u001b[A\n","Epoch 3:  82%|████████▏ | 86/105 [35:29<07:44, 24.45s/it, training_loss=0.386]\u001b[A\n","Epoch 3:  82%|████████▏ | 86/105 [35:54<07:44, 24.45s/it, training_loss=0.255]\u001b[A\n","Epoch 3:  83%|████████▎ | 87/105 [35:54<07:25, 24.72s/it, training_loss=0.255]\u001b[A\n","Epoch 3:  83%|████████▎ | 87/105 [36:20<07:25, 24.72s/it, training_loss=0.218]\u001b[A\n","Epoch 3:  84%|████████▍ | 88/105 [36:20<07:03, 24.90s/it, training_loss=0.218]\u001b[A\n","Epoch 3:  84%|████████▍ | 88/105 [36:43<07:03, 24.90s/it, training_loss=0.260]\u001b[A\n","Epoch 3:  85%|████████▍ | 89/105 [36:43<06:31, 24.47s/it, training_loss=0.260]\u001b[A\n","Epoch 3:  85%|████████▍ | 89/105 [37:08<06:31, 24.47s/it, training_loss=0.539]\u001b[A\n","Epoch 3:  86%|████████▌ | 90/105 [37:08<06:10, 24.73s/it, training_loss=0.539]\u001b[A\n","Epoch 3:  86%|████████▌ | 90/105 [37:34<06:10, 24.73s/it, training_loss=0.396]\u001b[A\n","Epoch 3:  87%|████████▋ | 91/105 [37:34<05:48, 24.91s/it, training_loss=0.396]\u001b[A\n","Epoch 3:  87%|████████▋ | 91/105 [37:57<05:48, 24.91s/it, training_loss=0.423]\u001b[A\n","Epoch 3:  88%|████████▊ | 92/105 [37:57<05:18, 24.53s/it, training_loss=0.423]\u001b[A\n","Epoch 3:  88%|████████▊ | 92/105 [38:22<05:18, 24.53s/it, training_loss=0.379]\u001b[A\n","Epoch 3:  89%|████████▊ | 93/105 [38:22<04:55, 24.64s/it, training_loss=0.379]\u001b[A\n","Epoch 3:  89%|████████▊ | 93/105 [38:48<04:55, 24.64s/it, training_loss=0.178]\u001b[A\n","Epoch 3:  90%|████████▉ | 94/105 [38:48<04:33, 24.85s/it, training_loss=0.178]\u001b[A\n","Epoch 3:  90%|████████▉ | 94/105 [39:12<04:33, 24.85s/it, training_loss=0.087]\u001b[A\n","Epoch 3:  90%|█████████ | 95/105 [39:12<04:07, 24.79s/it, training_loss=0.087]\u001b[A\n","Epoch 3:  90%|█████████ | 95/105 [39:36<04:07, 24.79s/it, training_loss=0.186]\u001b[A\n","Epoch 3:  91%|█████████▏| 96/105 [39:36<03:40, 24.51s/it, training_loss=0.186]\u001b[A\n","Epoch 3:  91%|█████████▏| 96/105 [40:01<03:40, 24.51s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  92%|█████████▏| 97/105 [40:01<03:17, 24.74s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  92%|█████████▏| 97/105 [40:27<03:17, 24.74s/it, training_loss=0.164]\u001b[A\n","Epoch 3:  93%|█████████▎| 98/105 [40:27<02:54, 24.93s/it, training_loss=0.164]\u001b[A\n","Epoch 3:  93%|█████████▎| 98/105 [40:50<02:54, 24.93s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  94%|█████████▍| 99/105 [40:50<02:26, 24.49s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  94%|█████████▍| 99/105 [41:16<02:26, 24.49s/it, training_loss=0.422]\u001b[A\n","Epoch 3:  95%|█████████▌| 100/105 [41:16<02:03, 24.76s/it, training_loss=0.422]\u001b[A\n","Epoch 3:  95%|█████████▌| 100/105 [41:41<02:03, 24.76s/it, training_loss=0.287]\u001b[A\n","Epoch 3:  96%|█████████▌| 101/105 [41:41<01:39, 24.92s/it, training_loss=0.287]\u001b[A\n","Epoch 3:  96%|█████████▌| 101/105 [42:05<01:39, 24.92s/it, training_loss=0.211]\u001b[A\n","Epoch 3:  97%|█████████▋| 102/105 [42:05<01:13, 24.64s/it, training_loss=0.211]\u001b[A\n","Epoch 3:  97%|█████████▋| 102/105 [42:30<01:13, 24.64s/it, training_loss=0.517]\u001b[A\n","Epoch 3:  98%|█████████▊| 103/105 [42:30<00:49, 24.62s/it, training_loss=0.517]\u001b[A\n","Epoch 3:  98%|█████████▊| 103/105 [42:55<00:49, 24.62s/it, training_loss=0.434]\u001b[A\n","Epoch 3:  99%|█████████▉| 104/105 [42:55<00:24, 24.80s/it, training_loss=0.434]\u001b[A\n","Epoch 3:  99%|█████████▉| 104/105 [43:20<00:24, 24.80s/it, training_loss=0.521]\u001b[A\n","Epoch 3: 100%|██████████| 105/105 [43:20<00:00, 24.86s/it, training_loss=0.521]\u001b[A\n"," 50%|█████     | 2/4 [2:17:09<1:33:46, 2813.30s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 0.9151070335081646\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [2:20:41<46:52, 2812.86s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.2316300212233156\n","F1 Score (Weighted): 0.48133601452177455\n","QWK Score: 0.4050991501416431\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/105 [00:25<?, ?it/s, training_loss=0.269]\u001b[A\n","Epoch 4:   1%|          | 1/105 [00:25<43:58, 25.37s/it, training_loss=0.269]\u001b[A\n","Epoch 4:   1%|          | 1/105 [00:50<43:58, 25.37s/it, training_loss=0.550]\u001b[A\n","Epoch 4:   2%|▏         | 2/105 [00:50<43:32, 25.36s/it, training_loss=0.550]\u001b[A\n","Epoch 4:   2%|▏         | 2/105 [01:14<43:32, 25.36s/it, training_loss=0.503]\u001b[A\n","Epoch 4:   3%|▎         | 3/105 [01:14<41:34, 24.46s/it, training_loss=0.503]\u001b[A\n","Epoch 4:   3%|▎         | 3/105 [01:39<41:34, 24.46s/it, training_loss=0.515]\u001b[A\n","Epoch 4:   4%|▍         | 4/105 [01:39<41:43, 24.78s/it, training_loss=0.515]\u001b[A\n","Epoch 4:   4%|▍         | 4/105 [02:04<41:43, 24.78s/it, training_loss=0.419]\u001b[A\n","Epoch 4:   5%|▍         | 5/105 [02:04<41:36, 24.96s/it, training_loss=0.419]\u001b[A\n","Epoch 4:   5%|▍         | 5/105 [02:28<41:36, 24.96s/it, training_loss=0.133]\u001b[A\n","Epoch 4:   6%|▌         | 6/105 [02:28<40:25, 24.50s/it, training_loss=0.133]\u001b[A\n","Epoch 4:   6%|▌         | 6/105 [02:53<40:25, 24.50s/it, training_loss=0.396]\u001b[A\n","Epoch 4:   7%|▋         | 7/105 [02:53<40:10, 24.59s/it, training_loss=0.396]\u001b[A\n","Epoch 4:   7%|▋         | 7/105 [03:18<40:10, 24.59s/it, training_loss=0.194]\u001b[A\n","Epoch 4:   8%|▊         | 8/105 [03:18<40:06, 24.81s/it, training_loss=0.194]\u001b[A\n","Epoch 4:   8%|▊         | 8/105 [03:42<40:06, 24.81s/it, training_loss=0.191]\u001b[A\n","Epoch 4:   9%|▊         | 9/105 [03:42<39:30, 24.69s/it, training_loss=0.191]\u001b[A\n","Epoch 4:   9%|▊         | 9/105 [04:06<39:30, 24.69s/it, training_loss=0.470]\u001b[A\n","Epoch 4:  10%|▉         | 10/105 [04:06<38:42, 24.44s/it, training_loss=0.470]\u001b[A\n","Epoch 4:  10%|▉         | 10/105 [04:31<38:42, 24.44s/it, training_loss=0.277]\u001b[A\n","Epoch 4:  10%|█         | 11/105 [04:31<38:40, 24.69s/it, training_loss=0.277]\u001b[A\n","Epoch 4:  10%|█         | 11/105 [04:57<38:40, 24.69s/it, training_loss=0.320]\u001b[A\n","Epoch 4:  11%|█▏        | 12/105 [04:57<38:29, 24.84s/it, training_loss=0.320]\u001b[A\n","Epoch 4:  11%|█▏        | 12/105 [05:20<38:29, 24.84s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  12%|█▏        | 13/105 [05:20<37:21, 24.37s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  12%|█▏        | 13/105 [05:45<37:21, 24.37s/it, training_loss=0.175]\u001b[A\n","Epoch 4:  13%|█▎        | 14/105 [05:45<37:20, 24.62s/it, training_loss=0.175]\u001b[A\n","Epoch 4:  13%|█▎        | 14/105 [06:10<37:20, 24.62s/it, training_loss=0.146]\u001b[A\n","Epoch 4:  14%|█▍        | 15/105 [06:10<37:10, 24.79s/it, training_loss=0.146]\u001b[A\n","Epoch 4:  14%|█▍        | 15/105 [06:34<37:10, 24.79s/it, training_loss=0.652]\u001b[A\n","Epoch 4:  15%|█▌        | 16/105 [06:34<36:09, 24.38s/it, training_loss=0.652]\u001b[A\n","Epoch 4:  15%|█▌        | 16/105 [06:59<36:09, 24.38s/it, training_loss=0.578]\u001b[A\n","Epoch 4:  16%|█▌        | 17/105 [06:59<36:06, 24.62s/it, training_loss=0.578]\u001b[A\n","Epoch 4:  16%|█▌        | 17/105 [07:24<36:06, 24.62s/it, training_loss=0.432]\u001b[A\n","Epoch 4:  17%|█▋        | 18/105 [07:24<35:58, 24.82s/it, training_loss=0.432]\u001b[A\n","Epoch 4:  17%|█▋        | 18/105 [07:48<35:58, 24.82s/it, training_loss=0.609]\u001b[A\n","Epoch 4:  18%|█▊        | 19/105 [07:48<35:16, 24.61s/it, training_loss=0.609]\u001b[A\n","Epoch 4:  18%|█▊        | 19/105 [08:12<35:16, 24.61s/it, training_loss=0.267]\u001b[A\n","Epoch 4:  19%|█▉        | 20/105 [08:12<34:40, 24.47s/it, training_loss=0.267]\u001b[A\n","Epoch 4:  19%|█▉        | 20/105 [08:38<34:40, 24.47s/it, training_loss=0.155]\u001b[A\n","Epoch 4:  20%|██        | 21/105 [08:38<34:34, 24.70s/it, training_loss=0.155]\u001b[A\n","Epoch 4:  20%|██        | 21/105 [09:03<34:34, 24.70s/it, training_loss=0.074]\u001b[A\n","Epoch 4:  21%|██        | 22/105 [09:03<34:18, 24.80s/it, training_loss=0.074]\u001b[A\n","Epoch 4:  21%|██        | 22/105 [09:26<34:18, 24.80s/it, training_loss=0.414]\u001b[A\n","Epoch 4:  22%|██▏       | 23/105 [09:26<33:20, 24.40s/it, training_loss=0.414]\u001b[A\n","Epoch 4:  22%|██▏       | 23/105 [09:51<33:20, 24.40s/it, training_loss=0.306]\u001b[A\n","Epoch 4:  23%|██▎       | 24/105 [09:51<33:16, 24.65s/it, training_loss=0.306]\u001b[A\n","Epoch 4:  23%|██▎       | 24/105 [10:17<33:16, 24.65s/it, training_loss=0.306]\u001b[A\n","Epoch 4:  24%|██▍       | 25/105 [10:17<33:11, 24.89s/it, training_loss=0.306]\u001b[A\n","Epoch 4:  24%|██▍       | 25/105 [10:40<33:11, 24.89s/it, training_loss=0.432]\u001b[A\n","Epoch 4:  25%|██▍       | 26/105 [10:40<32:11, 24.46s/it, training_loss=0.432]\u001b[A\n","Epoch 4:  25%|██▍       | 26/105 [11:05<32:11, 24.46s/it, training_loss=0.120]\u001b[A\n","Epoch 4:  26%|██▌       | 27/105 [11:05<32:05, 24.69s/it, training_loss=0.120]\u001b[A\n","Epoch 4:  26%|██▌       | 27/105 [11:31<32:05, 24.69s/it, training_loss=0.305]\u001b[A\n","Epoch 4:  27%|██▋       | 28/105 [11:31<31:54, 24.87s/it, training_loss=0.305]\u001b[A\n","Epoch 4:  27%|██▋       | 28/105 [11:55<31:54, 24.87s/it, training_loss=0.349]\u001b[A\n","Epoch 4:  28%|██▊       | 29/105 [11:55<31:14, 24.66s/it, training_loss=0.349]\u001b[A\n","Epoch 4:  28%|██▊       | 29/105 [12:19<31:14, 24.66s/it, training_loss=0.232]\u001b[A\n","Epoch 4:  29%|██▊       | 30/105 [12:19<30:41, 24.55s/it, training_loss=0.232]\u001b[A\n","Epoch 4:  29%|██▊       | 30/105 [12:45<30:41, 24.55s/it, training_loss=0.172]\u001b[A\n","Epoch 4:  30%|██▉       | 31/105 [12:45<30:36, 24.82s/it, training_loss=0.172]\u001b[A\n","Epoch 4:  30%|██▉       | 31/105 [13:10<30:36, 24.82s/it, training_loss=0.261]\u001b[A\n","Epoch 4:  30%|███       | 32/105 [13:10<30:19, 24.93s/it, training_loss=0.261]\u001b[A\n","Epoch 4:  30%|███       | 32/105 [13:33<30:19, 24.93s/it, training_loss=0.080]\u001b[A\n","Epoch 4:  31%|███▏      | 33/105 [13:33<29:22, 24.48s/it, training_loss=0.080]\u001b[A\n","Epoch 4:  31%|███▏      | 33/105 [13:59<29:22, 24.48s/it, training_loss=0.317]\u001b[A\n","Epoch 4:  32%|███▏      | 34/105 [13:59<29:15, 24.72s/it, training_loss=0.317]\u001b[A\n","Epoch 4:  32%|███▏      | 34/105 [14:24<29:15, 24.72s/it, training_loss=0.237]\u001b[A\n","Epoch 4:  33%|███▎      | 35/105 [14:24<29:01, 24.88s/it, training_loss=0.237]\u001b[A\n","Epoch 4:  33%|███▎      | 35/105 [14:47<29:01, 24.88s/it, training_loss=0.141]\u001b[A\n","Epoch 4:  34%|███▍      | 36/105 [14:47<28:06, 24.44s/it, training_loss=0.141]\u001b[A\n","Epoch 4:  34%|███▍      | 36/105 [15:12<28:06, 24.44s/it, training_loss=0.284]\u001b[A\n","Epoch 4:  35%|███▌      | 37/105 [15:12<27:57, 24.67s/it, training_loss=0.284]\u001b[A\n","Epoch 4:  35%|███▌      | 37/105 [15:38<27:57, 24.67s/it, training_loss=0.418]\u001b[A\n","Epoch 4:  36%|███▌      | 38/105 [15:38<27:46, 24.87s/it, training_loss=0.418]\u001b[A\n","Epoch 4:  36%|███▌      | 38/105 [16:02<27:46, 24.87s/it, training_loss=0.168]\u001b[A\n","Epoch 4:  37%|███▋      | 39/105 [16:02<27:12, 24.73s/it, training_loss=0.168]\u001b[A\n","Epoch 4:  37%|███▋      | 39/105 [16:26<27:12, 24.73s/it, training_loss=0.184]\u001b[A\n","Epoch 4:  38%|███▊      | 40/105 [16:26<26:34, 24.53s/it, training_loss=0.184]\u001b[A\n","Epoch 4:  38%|███▊      | 40/105 [16:51<26:34, 24.53s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  39%|███▉      | 41/105 [16:51<26:22, 24.72s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  39%|███▉      | 41/105 [17:17<26:22, 24.72s/it, training_loss=0.126]\u001b[A\n","Epoch 4:  40%|████      | 42/105 [17:17<26:06, 24.87s/it, training_loss=0.126]\u001b[A\n","Epoch 4:  40%|████      | 42/105 [17:40<26:06, 24.87s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  41%|████      | 43/105 [17:40<25:13, 24.42s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  41%|████      | 43/105 [18:05<25:13, 24.42s/it, training_loss=0.179]\u001b[A\n","Epoch 4:  42%|████▏     | 44/105 [18:05<25:03, 24.64s/it, training_loss=0.179]\u001b[A\n","Epoch 4:  42%|████▏     | 44/105 [18:30<25:03, 24.64s/it, training_loss=0.367]\u001b[A\n","Epoch 4:  43%|████▎     | 45/105 [18:30<24:49, 24.83s/it, training_loss=0.367]\u001b[A\n","Epoch 4:  43%|████▎     | 45/105 [18:54<24:49, 24.83s/it, training_loss=0.571]\u001b[A\n","Epoch 4:  44%|████▍     | 46/105 [18:54<24:00, 24.42s/it, training_loss=0.571]\u001b[A\n","Epoch 4:  44%|████▍     | 46/105 [19:19<24:00, 24.42s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  45%|████▍     | 47/105 [19:19<23:50, 24.66s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  45%|████▍     | 47/105 [19:44<23:50, 24.66s/it, training_loss=0.111]\u001b[A\n","Epoch 4:  46%|████▌     | 48/105 [19:44<23:35, 24.84s/it, training_loss=0.111]\u001b[A\n","Epoch 4:  46%|████▌     | 48/105 [20:09<23:35, 24.84s/it, training_loss=0.263]\u001b[A\n","Epoch 4:  47%|████▋     | 49/105 [20:09<23:01, 24.67s/it, training_loss=0.263]\u001b[A\n","Epoch 4:  47%|████▋     | 49/105 [20:33<23:01, 24.67s/it, training_loss=0.306]\u001b[A\n","Epoch 4:  48%|████▊     | 50/105 [20:33<22:29, 24.53s/it, training_loss=0.306]\u001b[A\n","Epoch 4:  48%|████▊     | 50/105 [20:58<22:29, 24.53s/it, training_loss=0.198]\u001b[A\n","Epoch 4:  49%|████▊     | 51/105 [20:58<22:22, 24.87s/it, training_loss=0.198]\u001b[A\n","Epoch 4:  49%|████▊     | 51/105 [21:24<22:22, 24.87s/it, training_loss=0.230]\u001b[A\n","Epoch 4:  50%|████▉     | 52/105 [21:24<22:05, 25.00s/it, training_loss=0.230]\u001b[A\n","Epoch 4:  50%|████▉     | 52/105 [21:47<22:05, 25.00s/it, training_loss=0.637]\u001b[A\n","Epoch 4:  50%|█████     | 53/105 [21:47<21:15, 24.52s/it, training_loss=0.637]\u001b[A\n","Epoch 4:  50%|█████     | 53/105 [22:12<21:15, 24.52s/it, training_loss=0.212]\u001b[A\n","Epoch 4:  51%|█████▏    | 54/105 [22:12<21:02, 24.75s/it, training_loss=0.212]\u001b[A\n","Epoch 4:  51%|█████▏    | 54/105 [22:38<21:02, 24.75s/it, training_loss=0.315]\u001b[A\n","Epoch 4:  52%|█████▏    | 55/105 [22:38<20:45, 24.91s/it, training_loss=0.315]\u001b[A\n","Epoch 4:  52%|█████▏    | 55/105 [23:02<20:45, 24.91s/it, training_loss=0.235]\u001b[A\n","Epoch 4:  53%|█████▎    | 56/105 [23:02<20:05, 24.60s/it, training_loss=0.235]\u001b[A\n","Epoch 4:  53%|█████▎    | 56/105 [23:26<20:05, 24.60s/it, training_loss=0.186]\u001b[A\n","Epoch 4:  54%|█████▍    | 57/105 [23:26<19:40, 24.59s/it, training_loss=0.186]\u001b[A\n","Epoch 4:  54%|█████▍    | 57/105 [23:52<19:40, 24.59s/it, training_loss=0.199]\u001b[A\n","Epoch 4:  55%|█████▌    | 58/105 [23:52<19:26, 24.82s/it, training_loss=0.199]\u001b[A\n","Epoch 4:  55%|█████▌    | 58/105 [24:16<19:26, 24.82s/it, training_loss=0.062]\u001b[A\n","Epoch 4:  56%|█████▌    | 59/105 [24:16<19:02, 24.85s/it, training_loss=0.062]\u001b[A\n","Epoch 4:  56%|█████▌    | 59/105 [24:40<19:02, 24.85s/it, training_loss=0.239]\u001b[A\n","Epoch 4:  57%|█████▋    | 60/105 [24:40<18:21, 24.47s/it, training_loss=0.239]\u001b[A\n","Epoch 4:  57%|█████▋    | 60/105 [25:05<18:21, 24.47s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  58%|█████▊    | 61/105 [25:05<18:06, 24.70s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  58%|█████▊    | 61/105 [25:31<18:06, 24.70s/it, training_loss=0.100]\u001b[A\n","Epoch 4:  59%|█████▉    | 62/105 [25:31<17:49, 24.87s/it, training_loss=0.100]\u001b[A\n","Epoch 4:  59%|█████▉    | 62/105 [25:54<17:49, 24.87s/it, training_loss=0.134]\u001b[A\n","Epoch 4:  60%|██████    | 63/105 [25:54<17:06, 24.43s/it, training_loss=0.134]\u001b[A\n","Epoch 4:  60%|██████    | 63/105 [26:19<17:06, 24.43s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  61%|██████    | 64/105 [26:19<16:51, 24.67s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  61%|██████    | 64/105 [26:44<16:51, 24.67s/it, training_loss=0.449]\u001b[A\n","Epoch 4:  62%|██████▏   | 65/105 [26:44<16:33, 24.84s/it, training_loss=0.449]\u001b[A\n","Epoch 4:  62%|██████▏   | 65/105 [27:08<16:33, 24.84s/it, training_loss=0.159]\u001b[A\n","Epoch 4:  63%|██████▎   | 66/105 [27:08<15:55, 24.49s/it, training_loss=0.159]\u001b[A\n","Epoch 4:  63%|██████▎   | 66/105 [27:33<15:55, 24.49s/it, training_loss=0.099]\u001b[A\n","Epoch 4:  64%|██████▍   | 67/105 [27:33<15:32, 24.55s/it, training_loss=0.099]\u001b[A\n","Epoch 4:  64%|██████▍   | 67/105 [27:58<15:32, 24.55s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  65%|██████▍   | 68/105 [27:58<15:16, 24.76s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  65%|██████▍   | 68/105 [28:23<15:16, 24.76s/it, training_loss=0.198]\u001b[A\n","Epoch 4:  66%|██████▌   | 69/105 [28:23<14:51, 24.75s/it, training_loss=0.198]\u001b[A\n","Epoch 4:  66%|██████▌   | 69/105 [28:47<14:51, 24.75s/it, training_loss=0.084]\u001b[A\n","Epoch 4:  67%|██████▋   | 70/105 [28:47<14:15, 24.45s/it, training_loss=0.084]\u001b[A\n","Epoch 4:  67%|██████▋   | 70/105 [29:12<14:15, 24.45s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  68%|██████▊   | 71/105 [29:12<14:00, 24.71s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  68%|██████▊   | 71/105 [29:37<14:00, 24.71s/it, training_loss=0.199]\u001b[A\n","Epoch 4:  69%|██████▊   | 72/105 [29:37<13:40, 24.87s/it, training_loss=0.199]\u001b[A\n","Epoch 4:  69%|██████▊   | 72/105 [30:00<13:40, 24.87s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  70%|██████▉   | 73/105 [30:00<13:01, 24.41s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  70%|██████▉   | 73/105 [30:26<13:01, 24.41s/it, training_loss=0.254]\u001b[A\n","Epoch 4:  70%|███████   | 74/105 [30:26<12:44, 24.67s/it, training_loss=0.254]\u001b[A\n","Epoch 4:  70%|███████   | 74/105 [30:51<12:44, 24.67s/it, training_loss=0.167]\u001b[A\n","Epoch 4:  71%|███████▏  | 75/105 [30:51<12:24, 24.82s/it, training_loss=0.167]\u001b[A\n","Epoch 4:  71%|███████▏  | 75/105 [31:14<12:24, 24.82s/it, training_loss=0.139]\u001b[A\n","Epoch 4:  72%|███████▏  | 76/105 [31:14<11:48, 24.42s/it, training_loss=0.139]\u001b[A\n","Epoch 4:  72%|███████▏  | 76/105 [31:39<11:48, 24.42s/it, training_loss=0.170]\u001b[A\n","Epoch 4:  73%|███████▎  | 77/105 [31:39<11:26, 24.53s/it, training_loss=0.170]\u001b[A\n","Epoch 4:  73%|███████▎  | 77/105 [32:04<11:26, 24.53s/it, training_loss=0.149]\u001b[A\n","Epoch 4:  74%|███████▍  | 78/105 [32:04<11:07, 24.72s/it, training_loss=0.149]\u001b[A\n","Epoch 4:  74%|███████▍  | 78/105 [32:29<11:07, 24.72s/it, training_loss=0.152]\u001b[A\n","Epoch 4:  75%|███████▌  | 79/105 [32:29<10:39, 24.59s/it, training_loss=0.152]\u001b[A\n","Epoch 4:  75%|███████▌  | 79/105 [32:53<10:39, 24.59s/it, training_loss=0.388]\u001b[A\n","Epoch 4:  76%|███████▌  | 80/105 [32:53<10:10, 24.42s/it, training_loss=0.388]\u001b[A\n","Epoch 4:  76%|███████▌  | 80/105 [33:18<10:10, 24.42s/it, training_loss=0.308]\u001b[A\n","Epoch 4:  77%|███████▋  | 81/105 [33:18<09:51, 24.64s/it, training_loss=0.308]\u001b[A\n","Epoch 4:  77%|███████▋  | 81/105 [33:43<09:51, 24.64s/it, training_loss=0.132]\u001b[A\n","Epoch 4:  78%|███████▊  | 82/105 [33:43<09:30, 24.81s/it, training_loss=0.132]\u001b[A\n","Epoch 4:  78%|███████▊  | 82/105 [34:06<09:30, 24.81s/it, training_loss=0.205]\u001b[A\n","Epoch 4:  79%|███████▉  | 83/105 [34:06<08:56, 24.39s/it, training_loss=0.205]\u001b[A\n","Epoch 4:  79%|███████▉  | 83/105 [34:32<08:56, 24.39s/it, training_loss=0.149]\u001b[A\n","Epoch 4:  80%|████████  | 84/105 [34:32<08:37, 24.65s/it, training_loss=0.149]\u001b[A\n","Epoch 4:  80%|████████  | 84/105 [34:57<08:37, 24.65s/it, training_loss=0.143]\u001b[A\n","Epoch 4:  81%|████████  | 85/105 [34:57<08:17, 24.87s/it, training_loss=0.143]\u001b[A\n","Epoch 4:  81%|████████  | 85/105 [35:21<08:17, 24.87s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  82%|████████▏ | 86/105 [35:21<07:49, 24.71s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  82%|████████▏ | 86/105 [35:46<07:49, 24.71s/it, training_loss=0.281]\u001b[A\n","Epoch 4:  83%|████████▎ | 87/105 [35:46<07:24, 24.70s/it, training_loss=0.281]\u001b[A\n","Epoch 4:  83%|████████▎ | 87/105 [36:11<07:24, 24.70s/it, training_loss=0.150]\u001b[A\n","Epoch 4:  84%|████████▍ | 88/105 [36:11<07:02, 24.84s/it, training_loss=0.150]\u001b[A\n","Epoch 4:  84%|████████▍ | 88/105 [36:36<07:02, 24.84s/it, training_loss=0.174]\u001b[A\n","Epoch 4:  85%|████████▍ | 89/105 [36:36<06:35, 24.75s/it, training_loss=0.174]\u001b[A\n","Epoch 4:  85%|████████▍ | 89/105 [37:00<06:35, 24.75s/it, training_loss=0.446]\u001b[A\n","Epoch 4:  86%|████████▌ | 90/105 [37:00<06:07, 24.47s/it, training_loss=0.446]\u001b[A\n","Epoch 4:  86%|████████▌ | 90/105 [37:25<06:07, 24.47s/it, training_loss=0.137]\u001b[A\n","Epoch 4:  87%|████████▋ | 91/105 [37:25<05:46, 24.73s/it, training_loss=0.137]\u001b[A\n","Epoch 4:  87%|████████▋ | 91/105 [37:50<05:46, 24.73s/it, training_loss=0.278]\u001b[A\n","Epoch 4:  88%|████████▊ | 92/105 [37:50<05:23, 24.87s/it, training_loss=0.278]\u001b[A\n","Epoch 4:  88%|████████▊ | 92/105 [38:13<05:23, 24.87s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  89%|████████▊ | 93/105 [38:13<04:52, 24.41s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  89%|████████▊ | 93/105 [38:39<04:52, 24.41s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  90%|████████▉ | 94/105 [38:39<04:31, 24.68s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  90%|████████▉ | 94/105 [39:04<04:31, 24.68s/it, training_loss=0.135]\u001b[A\n","Epoch 4:  90%|█████████ | 95/105 [39:04<04:08, 24.84s/it, training_loss=0.135]\u001b[A\n","Epoch 4:  90%|█████████ | 95/105 [39:27<04:08, 24.84s/it, training_loss=0.371]\u001b[A\n","Epoch 4:  91%|█████████▏| 96/105 [39:27<03:39, 24.43s/it, training_loss=0.371]\u001b[A\n","Epoch 4:  91%|█████████▏| 96/105 [39:53<03:39, 24.43s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  92%|█████████▏| 97/105 [39:53<03:17, 24.64s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  92%|█████████▏| 97/105 [40:18<03:17, 24.64s/it, training_loss=0.122]\u001b[A\n","Epoch 4:  93%|█████████▎| 98/105 [40:18<02:53, 24.81s/it, training_loss=0.122]\u001b[A\n","Epoch 4:  93%|█████████▎| 98/105 [40:42<02:53, 24.81s/it, training_loss=0.379]\u001b[A\n","Epoch 4:  94%|█████████▍| 99/105 [40:42<02:27, 24.63s/it, training_loss=0.379]\u001b[A\n","Epoch 4:  94%|█████████▍| 99/105 [41:06<02:27, 24.63s/it, training_loss=0.345]\u001b[A\n","Epoch 4:  95%|█████████▌| 100/105 [41:06<02:02, 24.51s/it, training_loss=0.345]\u001b[A\n","Epoch 4:  95%|█████████▌| 100/105 [41:32<02:02, 24.51s/it, training_loss=0.104]\u001b[A\n","Epoch 4:  96%|█████████▌| 101/105 [41:32<01:38, 24.75s/it, training_loss=0.104]\u001b[A\n","Epoch 4:  96%|█████████▌| 101/105 [41:57<01:38, 24.75s/it, training_loss=0.293]\u001b[A\n","Epoch 4:  97%|█████████▋| 102/105 [41:57<01:14, 24.91s/it, training_loss=0.293]\u001b[A\n","Epoch 4:  97%|█████████▋| 102/105 [42:20<01:14, 24.91s/it, training_loss=0.158]\u001b[A\n","Epoch 4:  98%|█████████▊| 103/105 [42:20<00:48, 24.44s/it, training_loss=0.158]\u001b[A\n","Epoch 4:  98%|█████████▊| 103/105 [42:45<00:48, 24.44s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  99%|█████████▉| 104/105 [42:45<00:24, 24.67s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  99%|█████████▉| 104/105 [43:11<00:24, 24.67s/it, training_loss=0.270]\u001b[A\n","Epoch 4: 100%|██████████| 105/105 [43:11<00:00, 24.84s/it, training_loss=0.270]\u001b[A\n"," 75%|███████▌  | 3/4 [3:03:52<46:52, 2812.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 0.8007021657058171\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [3:07:36<00:00, 2814.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 0.9117189491236651\n","F1 Score (Weighted): 0.5849602865514738\n","QWK Score: 0.48821128995692586\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import pandas as pd\n","\n","path_dir = '/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Teknologi'\n","list_dir = os.listdir(path_dir)\n","\n","list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","\n","for m in list_pre_trained_model:\n","    print(m)\n","    for idx, ele in enumerate(list_dir):\n","        df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                               sheet_name='Soal',\n","                               header=1,\n","                               index_col=0,\n","                               usecols='B:D')\n","\n","        list_final = []\n","\n","        for i in df_raw.itertuples():\n","            list_final.append(\n","                {\n","                    'soal': i[1],\n","                    'jawaban': i[2],\n","                    'nilai': 100,\n","                    'tipe': 'train'\n","                }\n","            )\n","            df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","            df_tmp = df_tmp.dropna()\n","            for j in df_tmp.itertuples():\n","                list_final.append(\n","                    {\n","                        'soal': i[1],\n","                        'jawaban': j[2],\n","                        'nilai': j[12],\n","                        'tipe': 'test'\n","                    }\n","                )\n","        if idx == 0:\n","            df_final = pd.DataFrame(list_final)\n","        else:\n","            df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","        print(' '.join(ele.rstrip('.xslx').split('_')))\n","        train_eval(df_final, m)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_L2EdYIAAYkI","executionInfo":{"status":"ok","timestamp":1680448271743,"user_tz":-420,"elapsed":614,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["def train_eval_raw(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False, duplicates='drop')\n","\n","    # concatenate soal and jawaban\n","    df_final['soal-jawaban'] = df_final['soal']+df_final['jawaban']\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","        torch.save(model.state_dict(), f'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Teknologi_Save/finetuned_BERT_raw_epoch_{epoch}.model')\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')\n"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","path_dir = '/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Teknologi'\n","list_dir = os.listdir(path_dir)\n","\n","list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","\n","for m in list_pre_trained_model:\n","    print(m)\n","    for idx, ele in enumerate(list_dir):\n","        df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                               sheet_name='Soal',\n","                               header=1,\n","                               index_col=0,\n","                               usecols='B:D')\n","\n","        list_final = []\n","\n","        for i in df_raw.itertuples():\n","            list_final.append(\n","                {\n","                    'soal': i[1],\n","                    'jawaban': i[2],\n","                    'nilai': 100,\n","                    'tipe': 'train'\n","                }\n","            )\n","            df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","            df_tmp = df_tmp.dropna()\n","            for j in df_tmp.itertuples():\n","                list_final.append(\n","                    {\n","                        'soal': i[1],\n","                        'jawaban': j[2],\n","                        'nilai': j[12],\n","                        'tipe': 'test'\n","                    }\n","                )\n","        if idx == 0:\n","            df_final = pd.DataFrame(list_final)\n","        else:\n","            df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","        print(' '.join(ele.rstrip('.xslx').split('_')))\n","        train_eval_raw(df_final, m)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2d_WTRKLFo4O","executionInfo":{"status":"ok","timestamp":1680464201873,"user_tz":-420,"elapsed":10339178,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"ce528b59-c51a-4847-cc28-023583576e2b"},"execution_count":19,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["indobenchmark/indobert-lite-base-p2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Analisis Essay Grading Teknologi\n"]},{"output_type":"stream","name":"stderr","text":["You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'pooler.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.3.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'classifier.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/105 [00:43<?, ?it/s, training_loss=0.556]\u001b[A\n","Epoch 1:   1%|          | 1/105 [00:43<1:16:15, 44.00s/it, training_loss=0.556]\u001b[A\n","Epoch 1:   1%|          | 1/105 [01:10<1:16:15, 44.00s/it, training_loss=0.733]\u001b[A\n","Epoch 1:   2%|▏         | 2/105 [01:10<57:49, 33.69s/it, training_loss=0.733]  \u001b[A\n","Epoch 1:   2%|▏         | 2/105 [01:36<57:49, 33.69s/it, training_loss=0.874]\u001b[A\n","Epoch 1:   3%|▎         | 3/105 [01:36<51:01, 30.01s/it, training_loss=0.874]\u001b[A\n","Epoch 1:   3%|▎         | 3/105 [01:59<51:01, 30.01s/it, training_loss=0.627]\u001b[A\n","Epoch 1:   4%|▍         | 4/105 [01:59<46:23, 27.56s/it, training_loss=0.627]\u001b[A\n","Epoch 1:   4%|▍         | 4/105 [02:27<46:23, 27.56s/it, training_loss=0.525]\u001b[A\n","Epoch 1:   5%|▍         | 5/105 [02:27<45:47, 27.47s/it, training_loss=0.525]\u001b[A\n","Epoch 1:   5%|▍         | 5/105 [02:52<45:47, 27.47s/it, training_loss=0.598]\u001b[A\n","Epoch 1:   6%|▌         | 6/105 [02:52<44:07, 26.74s/it, training_loss=0.598]\u001b[A\n","Epoch 1:   6%|▌         | 6/105 [03:17<44:07, 26.74s/it, training_loss=0.565]\u001b[A\n","Epoch 1:   7%|▋         | 7/105 [03:17<42:35, 26.07s/it, training_loss=0.565]\u001b[A\n","Epoch 1:   7%|▋         | 7/105 [03:41<42:35, 26.07s/it, training_loss=0.637]\u001b[A\n","Epoch 1:   8%|▊         | 8/105 [03:41<41:08, 25.45s/it, training_loss=0.637]\u001b[A\n","Epoch 1:   8%|▊         | 8/105 [04:06<41:08, 25.45s/it, training_loss=0.669]\u001b[A\n","Epoch 1:   9%|▊         | 9/105 [04:06<40:45, 25.47s/it, training_loss=0.669]\u001b[A\n","Epoch 1:   9%|▊         | 9/105 [04:32<40:45, 25.47s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  10%|▉         | 10/105 [04:32<40:18, 25.46s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  10%|▉         | 10/105 [04:55<40:18, 25.46s/it, training_loss=0.461]\u001b[A\n","Epoch 1:  10%|█         | 11/105 [04:55<39:00, 24.90s/it, training_loss=0.461]\u001b[A\n","Epoch 1:  10%|█         | 11/105 [05:21<39:00, 24.90s/it, training_loss=0.564]\u001b[A\n","Epoch 1:  11%|█▏        | 12/105 [05:21<38:47, 25.03s/it, training_loss=0.564]\u001b[A\n","Epoch 1:  11%|█▏        | 12/105 [05:46<38:47, 25.03s/it, training_loss=0.607]\u001b[A\n","Epoch 1:  12%|█▏        | 13/105 [05:46<38:28, 25.09s/it, training_loss=0.607]\u001b[A\n","Epoch 1:  12%|█▏        | 13/105 [06:11<38:28, 25.09s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  13%|█▎        | 14/105 [06:11<37:55, 25.00s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  13%|█▎        | 14/105 [06:34<37:55, 25.00s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  14%|█▍        | 15/105 [06:34<36:44, 24.50s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  14%|█▍        | 15/105 [06:59<36:44, 24.50s/it, training_loss=0.447]\u001b[A\n","Epoch 1:  15%|█▌        | 16/105 [06:59<36:31, 24.63s/it, training_loss=0.447]\u001b[A\n","Epoch 1:  15%|█▌        | 16/105 [07:24<36:31, 24.63s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  16%|█▌        | 17/105 [07:24<36:12, 24.69s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  16%|█▌        | 17/105 [07:49<36:12, 24.69s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  17%|█▋        | 18/105 [07:49<35:51, 24.73s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  17%|█▋        | 18/105 [08:12<35:51, 24.73s/it, training_loss=0.680]\u001b[A\n","Epoch 1:  18%|█▊        | 19/105 [08:12<34:50, 24.30s/it, training_loss=0.680]\u001b[A\n","Epoch 1:  18%|█▊        | 19/105 [08:37<34:50, 24.30s/it, training_loss=0.646]\u001b[A\n","Epoch 1:  19%|█▉        | 20/105 [08:37<34:36, 24.43s/it, training_loss=0.646]\u001b[A\n","Epoch 1:  19%|█▉        | 20/105 [09:02<34:36, 24.43s/it, training_loss=0.476]\u001b[A\n","Epoch 1:  20%|██        | 21/105 [09:02<34:21, 24.55s/it, training_loss=0.476]\u001b[A\n","Epoch 1:  20%|██        | 21/105 [09:27<34:21, 24.55s/it, training_loss=0.509]\u001b[A\n","Epoch 1:  21%|██        | 22/105 [09:27<34:08, 24.68s/it, training_loss=0.509]\u001b[A\n","Epoch 1:  21%|██        | 22/105 [09:50<34:08, 24.68s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  22%|██▏       | 23/105 [09:50<33:15, 24.34s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  22%|██▏       | 23/105 [10:15<33:15, 24.34s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  23%|██▎       | 24/105 [10:15<32:54, 24.38s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  23%|██▎       | 24/105 [10:39<32:54, 24.38s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  24%|██▍       | 25/105 [10:39<32:42, 24.53s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  24%|██▍       | 25/105 [11:04<32:42, 24.53s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  25%|██▍       | 26/105 [11:04<32:25, 24.63s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  25%|██▍       | 26/105 [11:28<32:25, 24.63s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  26%|██▌       | 27/105 [11:28<31:36, 24.32s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  26%|██▌       | 27/105 [11:52<31:36, 24.32s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  27%|██▋       | 28/105 [11:52<31:08, 24.27s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  27%|██▋       | 28/105 [12:17<31:08, 24.27s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  28%|██▊       | 29/105 [12:17<30:57, 24.44s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  28%|██▊       | 29/105 [12:42<30:57, 24.44s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  29%|██▊       | 30/105 [12:42<30:42, 24.56s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  29%|██▊       | 30/105 [13:06<30:42, 24.56s/it, training_loss=0.604]\u001b[A\n","Epoch 1:  30%|██▉       | 31/105 [13:06<30:09, 24.46s/it, training_loss=0.604]\u001b[A\n","Epoch 1:  30%|██▉       | 31/105 [13:30<30:09, 24.46s/it, training_loss=0.454]\u001b[A\n","Epoch 1:  30%|███       | 32/105 [13:30<29:30, 24.25s/it, training_loss=0.454]\u001b[A\n","Epoch 1:  30%|███       | 32/105 [13:55<29:30, 24.25s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  31%|███▏      | 33/105 [13:55<29:18, 24.42s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  31%|███▏      | 33/105 [14:19<29:18, 24.42s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  32%|███▏      | 34/105 [14:19<29:04, 24.57s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  32%|███▏      | 34/105 [14:44<29:04, 24.57s/it, training_loss=0.627]\u001b[A\n","Epoch 1:  33%|███▎      | 35/105 [14:44<28:40, 24.58s/it, training_loss=0.627]\u001b[A\n","Epoch 1:  33%|███▎      | 35/105 [15:08<28:40, 24.58s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  34%|███▍      | 36/105 [15:08<27:54, 24.26s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  34%|███▍      | 36/105 [15:32<27:54, 24.26s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  35%|███▌      | 37/105 [15:32<27:41, 24.43s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  35%|███▌      | 37/105 [15:57<27:41, 24.43s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  36%|███▌      | 38/105 [15:57<27:25, 24.56s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  36%|███▌      | 38/105 [16:22<27:25, 24.56s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  37%|███▋      | 39/105 [16:22<27:06, 24.64s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  37%|███▋      | 39/105 [16:45<27:06, 24.64s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  38%|███▊      | 40/105 [16:45<26:13, 24.21s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  38%|███▊      | 40/105 [17:10<26:13, 24.21s/it, training_loss=0.627]\u001b[A\n","Epoch 1:  39%|███▉      | 41/105 [17:10<26:02, 24.41s/it, training_loss=0.627]\u001b[A\n","Epoch 1:  39%|███▉      | 41/105 [17:35<26:02, 24.41s/it, training_loss=0.510]\u001b[A\n","Epoch 1:  40%|████      | 42/105 [17:35<25:45, 24.53s/it, training_loss=0.510]\u001b[A\n","Epoch 1:  40%|████      | 42/105 [18:00<25:45, 24.53s/it, training_loss=0.453]\u001b[A\n","Epoch 1:  41%|████      | 43/105 [18:00<25:26, 24.61s/it, training_loss=0.453]\u001b[A\n","Epoch 1:  41%|████      | 43/105 [18:23<25:26, 24.61s/it, training_loss=0.601]\u001b[A\n","Epoch 1:  42%|████▏     | 44/105 [18:23<24:37, 24.23s/it, training_loss=0.601]\u001b[A\n","Epoch 1:  42%|████▏     | 44/105 [18:48<24:37, 24.23s/it, training_loss=0.601]\u001b[A\n","Epoch 1:  43%|████▎     | 45/105 [18:48<24:23, 24.39s/it, training_loss=0.601]\u001b[A\n","Epoch 1:  43%|████▎     | 45/105 [19:13<24:23, 24.39s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  44%|████▍     | 46/105 [19:13<24:06, 24.51s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  44%|████▍     | 46/105 [19:38<24:06, 24.51s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  45%|████▍     | 47/105 [19:38<23:46, 24.60s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  45%|████▍     | 47/105 [20:01<23:46, 24.60s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  46%|████▌     | 48/105 [20:01<23:03, 24.27s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  46%|████▌     | 48/105 [20:25<23:03, 24.27s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  47%|████▋     | 49/105 [20:25<22:41, 24.32s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  47%|████▋     | 49/105 [20:50<22:41, 24.32s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  48%|████▊     | 50/105 [20:50<22:25, 24.46s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  48%|████▊     | 50/105 [21:15<22:25, 24.46s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  49%|████▊     | 51/105 [21:15<22:08, 24.60s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  49%|████▊     | 51/105 [21:39<22:08, 24.60s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  50%|████▉     | 52/105 [21:39<21:30, 24.35s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  50%|████▉     | 52/105 [22:03<21:30, 24.35s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  50%|█████     | 53/105 [22:03<21:00, 24.24s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  50%|█████     | 53/105 [22:28<21:00, 24.24s/it, training_loss=0.467]\u001b[A\n","Epoch 1:  51%|█████▏    | 54/105 [22:28<20:45, 24.43s/it, training_loss=0.467]\u001b[A\n","Epoch 1:  51%|█████▏    | 54/105 [22:53<20:45, 24.43s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  52%|█████▏    | 55/105 [22:53<20:27, 24.55s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  52%|█████▏    | 55/105 [23:17<20:27, 24.55s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  53%|█████▎    | 56/105 [23:17<19:54, 24.39s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  53%|█████▎    | 56/105 [23:40<19:54, 24.39s/it, training_loss=0.491]\u001b[A\n","Epoch 1:  54%|█████▍    | 57/105 [23:40<19:22, 24.21s/it, training_loss=0.491]\u001b[A\n","Epoch 1:  54%|█████▍    | 57/105 [24:05<19:22, 24.21s/it, training_loss=0.418]\u001b[A\n","Epoch 1:  55%|█████▌    | 58/105 [24:05<19:06, 24.40s/it, training_loss=0.418]\u001b[A\n","Epoch 1:  55%|█████▌    | 58/105 [24:30<19:06, 24.40s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  56%|█████▌    | 59/105 [24:30<18:48, 24.53s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  56%|█████▌    | 59/105 [24:54<18:48, 24.53s/it, training_loss=0.675]\u001b[A\n","Epoch 1:  57%|█████▋    | 60/105 [24:54<18:21, 24.48s/it, training_loss=0.675]\u001b[A\n","Epoch 1:  57%|█████▋    | 60/105 [25:18<18:21, 24.48s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  58%|█████▊    | 61/105 [25:18<17:44, 24.20s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  58%|█████▊    | 61/105 [25:43<17:44, 24.20s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  59%|█████▉    | 62/105 [25:43<17:27, 24.37s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  59%|█████▉    | 62/105 [26:08<17:27, 24.37s/it, training_loss=0.565]\u001b[A\n","Epoch 1:  60%|██████    | 63/105 [26:08<17:08, 24.49s/it, training_loss=0.565]\u001b[A\n","Epoch 1:  60%|██████    | 63/105 [26:32<17:08, 24.49s/it, training_loss=0.717]\u001b[A\n","Epoch 1:  61%|██████    | 64/105 [26:32<16:44, 24.50s/it, training_loss=0.717]\u001b[A\n","Epoch 1:  61%|██████    | 64/105 [26:55<16:44, 24.50s/it, training_loss=0.509]\u001b[A\n","Epoch 1:  62%|██████▏   | 65/105 [26:55<16:07, 24.18s/it, training_loss=0.509]\u001b[A\n","Epoch 1:  62%|██████▏   | 65/105 [27:20<16:07, 24.18s/it, training_loss=0.708]\u001b[A\n","Epoch 1:  63%|██████▎   | 66/105 [27:20<15:49, 24.35s/it, training_loss=0.708]\u001b[A\n","Epoch 1:  63%|██████▎   | 66/105 [27:45<15:49, 24.35s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  64%|██████▍   | 67/105 [27:45<15:28, 24.43s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  64%|██████▍   | 67/105 [28:09<15:28, 24.43s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  65%|██████▍   | 68/105 [28:09<15:04, 24.44s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  65%|██████▍   | 68/105 [28:33<15:04, 24.44s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  66%|██████▌   | 69/105 [28:33<14:28, 24.11s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  66%|██████▌   | 69/105 [28:57<14:28, 24.11s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  67%|██████▋   | 70/105 [28:57<14:10, 24.31s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  67%|██████▋   | 70/105 [29:22<14:10, 24.31s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  68%|██████▊   | 71/105 [29:22<13:50, 24.44s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  68%|██████▊   | 71/105 [29:47<13:50, 24.44s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  69%|██████▊   | 72/105 [29:47<13:28, 24.51s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  69%|██████▊   | 72/105 [30:10<13:28, 24.51s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  70%|██████▉   | 73/105 [30:10<12:52, 24.16s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  70%|██████▉   | 73/105 [30:35<12:52, 24.16s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  70%|███████   | 74/105 [30:35<12:34, 24.33s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  70%|███████   | 74/105 [31:00<12:34, 24.33s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  71%|███████▏  | 75/105 [31:00<12:12, 24.43s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  71%|███████▏  | 75/105 [31:26<12:12, 24.43s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  72%|███████▏  | 76/105 [31:26<12:03, 24.96s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  72%|███████▏  | 76/105 [31:49<12:03, 24.96s/it, training_loss=0.559]\u001b[A\n","Epoch 1:  73%|███████▎  | 77/105 [31:49<11:23, 24.42s/it, training_loss=0.559]\u001b[A\n","Epoch 1:  73%|███████▎  | 77/105 [32:14<11:23, 24.42s/it, training_loss=0.461]\u001b[A\n","Epoch 1:  74%|███████▍  | 78/105 [32:14<11:02, 24.55s/it, training_loss=0.461]\u001b[A\n","Epoch 1:  74%|███████▍  | 78/105 [32:39<11:02, 24.55s/it, training_loss=0.533]\u001b[A\n","Epoch 1:  75%|███████▌  | 79/105 [32:39<10:40, 24.62s/it, training_loss=0.533]\u001b[A\n","Epoch 1:  75%|███████▌  | 79/105 [33:03<10:40, 24.62s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  76%|███████▌  | 80/105 [33:03<10:16, 24.66s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  76%|███████▌  | 80/105 [33:27<10:16, 24.66s/it, training_loss=0.533]\u001b[A\n","Epoch 1:  77%|███████▋  | 81/105 [33:27<09:41, 24.25s/it, training_loss=0.533]\u001b[A\n","Epoch 1:  77%|███████▋  | 81/105 [33:51<09:41, 24.25s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  78%|███████▊  | 82/105 [33:51<09:20, 24.36s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  78%|███████▊  | 82/105 [34:16<09:20, 24.36s/it, training_loss=0.614]\u001b[A\n","Epoch 1:  79%|███████▉  | 83/105 [34:16<08:58, 24.48s/it, training_loss=0.614]\u001b[A\n","Epoch 1:  79%|███████▉  | 83/105 [34:41<08:58, 24.48s/it, training_loss=0.421]\u001b[A\n","Epoch 1:  80%|████████  | 84/105 [34:41<08:35, 24.56s/it, training_loss=0.421]\u001b[A\n","Epoch 1:  80%|████████  | 84/105 [35:04<08:35, 24.56s/it, training_loss=0.480]\u001b[A\n","Epoch 1:  81%|████████  | 85/105 [35:04<08:04, 24.21s/it, training_loss=0.480]\u001b[A\n","Epoch 1:  81%|████████  | 85/105 [35:29<08:04, 24.21s/it, training_loss=0.467]\u001b[A\n","Epoch 1:  82%|████████▏ | 86/105 [35:29<07:41, 24.28s/it, training_loss=0.467]\u001b[A\n","Epoch 1:  82%|████████▏ | 86/105 [35:53<07:41, 24.28s/it, training_loss=0.440]\u001b[A\n","Epoch 1:  83%|████████▎ | 87/105 [35:53<07:20, 24.45s/it, training_loss=0.440]\u001b[A\n","Epoch 1:  83%|████████▎ | 87/105 [36:18<07:20, 24.45s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  84%|████████▍ | 88/105 [36:18<06:57, 24.58s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  84%|████████▍ | 88/105 [36:42<06:57, 24.58s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  85%|████████▍ | 89/105 [36:42<06:28, 24.27s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  85%|████████▍ | 89/105 [37:06<06:28, 24.27s/it, training_loss=0.383]\u001b[A\n","Epoch 1:  86%|████████▌ | 90/105 [37:06<06:03, 24.24s/it, training_loss=0.383]\u001b[A\n","Epoch 1:  86%|████████▌ | 90/105 [37:31<06:03, 24.24s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  87%|████████▋ | 91/105 [37:31<05:41, 24.41s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  87%|████████▋ | 91/105 [37:56<05:41, 24.41s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  88%|████████▊ | 92/105 [37:56<05:18, 24.52s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  88%|████████▊ | 92/105 [38:19<05:18, 24.52s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  89%|████████▊ | 93/105 [38:19<04:51, 24.28s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  89%|████████▊ | 93/105 [38:43<04:51, 24.28s/it, training_loss=0.585]\u001b[A\n","Epoch 1:  90%|████████▉ | 94/105 [38:43<04:25, 24.16s/it, training_loss=0.585]\u001b[A\n","Epoch 1:  90%|████████▉ | 94/105 [39:08<04:25, 24.16s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  90%|█████████ | 95/105 [39:08<04:03, 24.35s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  90%|█████████ | 95/105 [39:33<04:03, 24.35s/it, training_loss=0.401]\u001b[A\n","Epoch 1:  91%|█████████▏| 96/105 [39:33<03:40, 24.48s/it, training_loss=0.401]\u001b[A\n","Epoch 1:  91%|█████████▏| 96/105 [39:57<03:40, 24.48s/it, training_loss=0.358]\u001b[A\n","Epoch 1:  92%|█████████▏| 97/105 [39:57<03:14, 24.35s/it, training_loss=0.358]\u001b[A\n","Epoch 1:  92%|█████████▏| 97/105 [40:20<03:14, 24.35s/it, training_loss=0.400]\u001b[A\n","Epoch 1:  93%|█████████▎| 98/105 [40:20<02:49, 24.15s/it, training_loss=0.400]\u001b[A\n","Epoch 1:  93%|█████████▎| 98/105 [40:45<02:49, 24.15s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  94%|█████████▍| 99/105 [40:45<02:25, 24.30s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  94%|█████████▍| 99/105 [41:10<02:25, 24.30s/it, training_loss=0.427]\u001b[A\n","Epoch 1:  95%|█████████▌| 100/105 [41:10<02:02, 24.43s/it, training_loss=0.427]\u001b[A\n","Epoch 1:  95%|█████████▌| 100/105 [41:34<02:02, 24.43s/it, training_loss=0.373]\u001b[A\n","Epoch 1:  96%|█████████▌| 101/105 [41:34<01:37, 24.32s/it, training_loss=0.373]\u001b[A\n","Epoch 1:  96%|█████████▌| 101/105 [41:58<01:37, 24.32s/it, training_loss=0.409]\u001b[A\n","Epoch 1:  97%|█████████▋| 102/105 [41:58<01:12, 24.12s/it, training_loss=0.409]\u001b[A\n","Epoch 1:  97%|█████████▋| 102/105 [42:22<01:12, 24.12s/it, training_loss=0.440]\u001b[A\n","Epoch 1:  98%|█████████▊| 103/105 [42:22<00:48, 24.28s/it, training_loss=0.440]\u001b[A\n","Epoch 1:  98%|█████████▊| 103/105 [42:47<00:48, 24.28s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  99%|█████████▉| 104/105 [42:47<00:24, 24.42s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  99%|█████████▉| 104/105 [43:11<00:24, 24.42s/it, training_loss=0.571]\u001b[A\n","Epoch 1: 100%|██████████| 105/105 [43:11<00:00, 24.38s/it, training_loss=0.571]\u001b[A\n","  0%|          | 0/4 [43:13<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.6421009109133766\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [46:43<2:20:11, 2803.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.3253429509975292\n","F1 Score (Weighted): 0.19848155799212527\n","QWK Score: 0.151074151074151\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/105 [00:24<?, ?it/s, training_loss=0.509]\u001b[A\n","Epoch 2:   1%|          | 1/105 [00:24<41:42, 24.07s/it, training_loss=0.509]\u001b[A\n","Epoch 2:   1%|          | 1/105 [00:47<41:42, 24.07s/it, training_loss=0.825]\u001b[A\n","Epoch 2:   2%|▏         | 2/105 [00:47<40:56, 23.85s/it, training_loss=0.825]\u001b[A\n","Epoch 2:   2%|▏         | 2/105 [01:12<40:56, 23.85s/it, training_loss=0.561]\u001b[A\n","Epoch 2:   3%|▎         | 3/105 [01:12<41:13, 24.25s/it, training_loss=0.561]\u001b[A\n","Epoch 2:   3%|▎         | 3/105 [01:37<41:13, 24.25s/it, training_loss=0.560]\u001b[A\n","Epoch 2:   4%|▍         | 4/105 [01:37<41:08, 24.44s/it, training_loss=0.560]\u001b[A\n","Epoch 2:   4%|▍         | 4/105 [02:01<41:08, 24.44s/it, training_loss=0.730]\u001b[A\n","Epoch 2:   5%|▍         | 5/105 [02:01<40:32, 24.32s/it, training_loss=0.730]\u001b[A\n","Epoch 2:   5%|▍         | 5/105 [02:25<40:32, 24.32s/it, training_loss=0.662]\u001b[A\n","Epoch 2:   6%|▌         | 6/105 [02:25<39:48, 24.12s/it, training_loss=0.662]\u001b[A\n","Epoch 2:   6%|▌         | 6/105 [02:49<39:48, 24.12s/it, training_loss=0.428]\u001b[A\n","Epoch 2:   7%|▋         | 7/105 [02:49<39:45, 24.34s/it, training_loss=0.428]\u001b[A\n","Epoch 2:   7%|▋         | 7/105 [03:14<39:45, 24.34s/it, training_loss=0.569]\u001b[A\n","Epoch 2:   8%|▊         | 8/105 [03:14<39:34, 24.48s/it, training_loss=0.569]\u001b[A\n","Epoch 2:   8%|▊         | 8/105 [03:39<39:34, 24.48s/it, training_loss=0.501]\u001b[A\n","Epoch 2:   9%|▊         | 9/105 [03:39<39:06, 24.44s/it, training_loss=0.501]\u001b[A\n","Epoch 2:   9%|▊         | 9/105 [04:02<39:06, 24.44s/it, training_loss=0.292]\u001b[A\n","Epoch 2:  10%|▉         | 10/105 [04:02<38:13, 24.14s/it, training_loss=0.292]\u001b[A\n","Epoch 2:  10%|▉         | 10/105 [04:27<38:13, 24.14s/it, training_loss=0.468]\u001b[A\n","Epoch 2:  10%|█         | 11/105 [04:27<38:06, 24.32s/it, training_loss=0.468]\u001b[A\n","Epoch 2:  10%|█         | 11/105 [04:51<38:06, 24.32s/it, training_loss=0.600]\u001b[A\n","Epoch 2:  11%|█▏        | 12/105 [04:51<37:54, 24.46s/it, training_loss=0.600]\u001b[A\n","Epoch 2:  11%|█▏        | 12/105 [05:16<37:54, 24.46s/it, training_loss=0.462]\u001b[A\n","Epoch 2:  12%|█▏        | 13/105 [05:16<37:34, 24.51s/it, training_loss=0.462]\u001b[A\n","Epoch 2:  12%|█▏        | 13/105 [05:39<37:34, 24.51s/it, training_loss=0.371]\u001b[A\n","Epoch 2:  13%|█▎        | 14/105 [05:39<36:37, 24.14s/it, training_loss=0.371]\u001b[A\n","Epoch 2:  13%|█▎        | 14/105 [06:04<36:37, 24.14s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  14%|█▍        | 15/105 [06:04<36:32, 24.37s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  14%|█▍        | 15/105 [06:29<36:32, 24.37s/it, training_loss=0.430]\u001b[A\n","Epoch 2:  15%|█▌        | 16/105 [06:29<36:20, 24.50s/it, training_loss=0.430]\u001b[A\n","Epoch 2:  15%|█▌        | 16/105 [06:54<36:20, 24.50s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  16%|█▌        | 17/105 [06:54<36:01, 24.56s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  16%|█▌        | 17/105 [07:17<36:01, 24.56s/it, training_loss=0.336]\u001b[A\n","Epoch 2:  17%|█▋        | 18/105 [07:17<34:59, 24.14s/it, training_loss=0.336]\u001b[A\n","Epoch 2:  17%|█▋        | 18/105 [07:42<34:59, 24.14s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  18%|█▊        | 19/105 [07:42<34:51, 24.32s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  18%|█▊        | 19/105 [08:07<34:51, 24.32s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  19%|█▉        | 20/105 [08:07<34:40, 24.48s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  19%|█▉        | 20/105 [08:31<34:40, 24.48s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  20%|██        | 21/105 [08:31<34:24, 24.58s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  20%|██        | 21/105 [08:55<34:24, 24.58s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  21%|██        | 22/105 [08:55<33:30, 24.22s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  21%|██        | 22/105 [09:19<33:30, 24.22s/it, training_loss=0.387]\u001b[A\n","Epoch 2:  22%|██▏       | 23/105 [09:19<33:16, 24.35s/it, training_loss=0.387]\u001b[A\n","Epoch 2:  22%|██▏       | 23/105 [09:44<33:16, 24.35s/it, training_loss=0.351]\u001b[A\n","Epoch 2:  23%|██▎       | 24/105 [09:44<33:03, 24.49s/it, training_loss=0.351]\u001b[A\n","Epoch 2:  23%|██▎       | 24/105 [10:09<33:03, 24.49s/it, training_loss=0.357]\u001b[A\n","Epoch 2:  24%|██▍       | 25/105 [10:09<32:44, 24.56s/it, training_loss=0.357]\u001b[A\n","Epoch 2:  24%|██▍       | 25/105 [10:32<32:44, 24.56s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  25%|██▍       | 26/105 [10:32<31:50, 24.19s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  25%|██▍       | 26/105 [10:57<31:50, 24.19s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  26%|██▌       | 27/105 [10:57<31:37, 24.33s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  26%|██▌       | 27/105 [11:22<31:37, 24.33s/it, training_loss=0.313]\u001b[A\n","Epoch 2:  27%|██▋       | 28/105 [11:22<31:24, 24.47s/it, training_loss=0.313]\u001b[A\n","Epoch 2:  27%|██▋       | 28/105 [11:46<31:24, 24.47s/it, training_loss=0.751]\u001b[A\n","Epoch 2:  28%|██▊       | 29/105 [11:46<31:04, 24.53s/it, training_loss=0.751]\u001b[A\n","Epoch 2:  28%|██▊       | 29/105 [12:10<31:04, 24.53s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  29%|██▊       | 30/105 [12:10<30:12, 24.17s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  29%|██▊       | 30/105 [12:34<30:12, 24.17s/it, training_loss=0.458]\u001b[A\n","Epoch 2:  30%|██▉       | 31/105 [12:34<29:53, 24.24s/it, training_loss=0.458]\u001b[A\n","Epoch 2:  30%|██▉       | 31/105 [12:59<29:53, 24.24s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  30%|███       | 32/105 [12:59<29:43, 24.43s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  30%|███       | 32/105 [13:24<29:43, 24.43s/it, training_loss=0.539]\u001b[A\n","Epoch 2:  31%|███▏      | 33/105 [13:24<29:26, 24.53s/it, training_loss=0.539]\u001b[A\n","Epoch 2:  31%|███▏      | 33/105 [13:47<29:26, 24.53s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  32%|███▏      | 34/105 [13:47<28:40, 24.23s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  32%|███▏      | 34/105 [14:11<28:40, 24.23s/it, training_loss=0.484]\u001b[A\n","Epoch 2:  33%|███▎      | 35/105 [14:11<28:15, 24.22s/it, training_loss=0.484]\u001b[A\n","Epoch 2:  33%|███▎      | 35/105 [14:36<28:15, 24.22s/it, training_loss=0.348]\u001b[A\n","Epoch 2:  34%|███▍      | 36/105 [14:36<28:01, 24.38s/it, training_loss=0.348]\u001b[A\n","Epoch 2:  34%|███▍      | 36/105 [15:01<28:01, 24.38s/it, training_loss=0.271]\u001b[A\n","Epoch 2:  35%|███▌      | 37/105 [15:01<27:44, 24.47s/it, training_loss=0.271]\u001b[A\n","Epoch 2:  35%|███▌      | 37/105 [15:25<27:44, 24.47s/it, training_loss=0.247]\u001b[A\n","Epoch 2:  36%|███▌      | 38/105 [15:25<27:07, 24.29s/it, training_loss=0.247]\u001b[A\n","Epoch 2:  36%|███▌      | 38/105 [15:49<27:07, 24.29s/it, training_loss=0.446]\u001b[A\n","Epoch 2:  37%|███▋      | 39/105 [15:49<26:32, 24.13s/it, training_loss=0.446]\u001b[A\n","Epoch 2:  37%|███▋      | 39/105 [16:13<26:32, 24.13s/it, training_loss=0.563]\u001b[A\n","Epoch 2:  38%|███▊      | 40/105 [16:13<26:22, 24.35s/it, training_loss=0.563]\u001b[A\n","Epoch 2:  38%|███▊      | 40/105 [16:38<26:22, 24.35s/it, training_loss=0.247]\u001b[A\n","Epoch 2:  39%|███▉      | 41/105 [16:38<26:05, 24.47s/it, training_loss=0.247]\u001b[A\n","Epoch 2:  39%|███▉      | 41/105 [17:02<26:05, 24.47s/it, training_loss=0.578]\u001b[A\n","Epoch 2:  40%|████      | 42/105 [17:02<25:33, 24.35s/it, training_loss=0.578]\u001b[A\n","Epoch 2:  40%|████      | 42/105 [17:26<25:33, 24.35s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  41%|████      | 43/105 [17:26<24:58, 24.18s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  41%|████      | 43/105 [17:51<24:58, 24.18s/it, training_loss=0.446]\u001b[A\n","Epoch 2:  42%|████▏     | 44/105 [17:51<24:45, 24.35s/it, training_loss=0.446]\u001b[A\n","Epoch 2:  42%|████▏     | 44/105 [18:15<24:45, 24.35s/it, training_loss=0.281]\u001b[A\n","Epoch 2:  43%|████▎     | 45/105 [18:15<24:27, 24.45s/it, training_loss=0.281]\u001b[A\n","Epoch 2:  43%|████▎     | 45/105 [18:40<24:27, 24.45s/it, training_loss=0.351]\u001b[A\n","Epoch 2:  44%|████▍     | 46/105 [18:40<23:57, 24.37s/it, training_loss=0.351]\u001b[A\n","Epoch 2:  44%|████▍     | 46/105 [19:03<23:57, 24.37s/it, training_loss=0.506]\u001b[A\n","Epoch 2:  45%|████▍     | 47/105 [19:03<23:21, 24.16s/it, training_loss=0.506]\u001b[A\n","Epoch 2:  45%|████▍     | 47/105 [19:28<23:21, 24.16s/it, training_loss=0.375]\u001b[A\n","Epoch 2:  46%|████▌     | 48/105 [19:28<23:07, 24.35s/it, training_loss=0.375]\u001b[A\n","Epoch 2:  46%|████▌     | 48/105 [19:53<23:07, 24.35s/it, training_loss=0.485]\u001b[A\n","Epoch 2:  47%|████▋     | 49/105 [19:53<22:50, 24.47s/it, training_loss=0.485]\u001b[A\n","Epoch 2:  47%|████▋     | 49/105 [20:17<22:50, 24.47s/it, training_loss=0.470]\u001b[A\n","Epoch 2:  48%|████▊     | 50/105 [20:17<22:26, 24.48s/it, training_loss=0.470]\u001b[A\n","Epoch 2:  48%|████▊     | 50/105 [20:41<22:26, 24.48s/it, training_loss=0.198]\u001b[A\n","Epoch 2:  49%|████▊     | 51/105 [20:41<21:47, 24.21s/it, training_loss=0.198]\u001b[A\n","Epoch 2:  49%|████▊     | 51/105 [21:06<21:47, 24.21s/it, training_loss=0.491]\u001b[A\n","Epoch 2:  50%|████▉     | 52/105 [21:06<21:32, 24.39s/it, training_loss=0.491]\u001b[A\n","Epoch 2:  50%|████▉     | 52/105 [21:32<21:32, 24.39s/it, training_loss=0.261]\u001b[A\n","Epoch 2:  50%|█████     | 53/105 [21:32<21:39, 25.00s/it, training_loss=0.261]\u001b[A\n","Epoch 2:  50%|█████     | 53/105 [21:57<21:39, 25.00s/it, training_loss=0.106]\u001b[A\n","Epoch 2:  51%|█████▏    | 54/105 [21:57<21:10, 24.91s/it, training_loss=0.106]\u001b[A\n","Epoch 2:  51%|█████▏    | 54/105 [22:20<21:10, 24.91s/it, training_loss=0.266]\u001b[A\n","Epoch 2:  52%|█████▏    | 55/105 [22:20<20:25, 24.52s/it, training_loss=0.266]\u001b[A\n","Epoch 2:  52%|█████▏    | 55/105 [22:45<20:25, 24.52s/it, training_loss=0.363]\u001b[A\n","Epoch 2:  53%|█████▎    | 56/105 [22:45<19:54, 24.38s/it, training_loss=0.363]\u001b[A\n","Epoch 2:  53%|█████▎    | 56/105 [23:09<19:54, 24.38s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  54%|█████▍    | 57/105 [23:09<19:36, 24.51s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  54%|█████▍    | 57/105 [23:34<19:36, 24.51s/it, training_loss=0.583]\u001b[A\n","Epoch 2:  55%|█████▌    | 58/105 [23:34<19:17, 24.62s/it, training_loss=0.583]\u001b[A\n","Epoch 2:  55%|█████▌    | 58/105 [23:58<19:17, 24.62s/it, training_loss=0.393]\u001b[A\n","Epoch 2:  56%|█████▌    | 59/105 [23:58<18:43, 24.41s/it, training_loss=0.393]\u001b[A\n","Epoch 2:  56%|█████▌    | 59/105 [24:22<18:43, 24.41s/it, training_loss=0.360]\u001b[A\n","Epoch 2:  57%|█████▋    | 60/105 [24:22<18:08, 24.20s/it, training_loss=0.360]\u001b[A\n","Epoch 2:  57%|█████▋    | 60/105 [24:47<18:08, 24.20s/it, training_loss=0.395]\u001b[A\n","Epoch 2:  58%|█████▊    | 61/105 [24:47<17:52, 24.38s/it, training_loss=0.395]\u001b[A\n","Epoch 2:  58%|█████▊    | 61/105 [25:13<17:52, 24.38s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  59%|█████▉    | 62/105 [25:13<17:52, 24.95s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  59%|█████▉    | 62/105 [25:38<17:52, 24.95s/it, training_loss=0.322]\u001b[A\n","Epoch 2:  60%|██████    | 63/105 [25:38<17:25, 24.88s/it, training_loss=0.322]\u001b[A\n","Epoch 2:  60%|██████    | 63/105 [26:01<17:25, 24.88s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  61%|██████    | 64/105 [26:01<16:39, 24.38s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  61%|██████    | 64/105 [26:26<16:39, 24.38s/it, training_loss=0.326]\u001b[A\n","Epoch 2:  62%|██████▏   | 65/105 [26:26<16:20, 24.50s/it, training_loss=0.326]\u001b[A\n","Epoch 2:  62%|██████▏   | 65/105 [26:50<16:20, 24.50s/it, training_loss=0.275]\u001b[A\n","Epoch 2:  63%|██████▎   | 66/105 [26:50<15:59, 24.60s/it, training_loss=0.275]\u001b[A\n","Epoch 2:  63%|██████▎   | 66/105 [27:15<15:59, 24.60s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  64%|██████▍   | 67/105 [27:15<15:36, 24.65s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  64%|██████▍   | 67/105 [27:39<15:36, 24.65s/it, training_loss=0.296]\u001b[A\n","Epoch 2:  65%|██████▍   | 68/105 [27:39<14:57, 24.25s/it, training_loss=0.296]\u001b[A\n","Epoch 2:  65%|██████▍   | 68/105 [28:03<14:57, 24.25s/it, training_loss=0.242]\u001b[A\n","Epoch 2:  66%|██████▌   | 69/105 [28:03<14:37, 24.37s/it, training_loss=0.242]\u001b[A\n","Epoch 2:  66%|██████▌   | 69/105 [28:30<14:37, 24.37s/it, training_loss=0.339]\u001b[A\n","Epoch 2:  67%|██████▋   | 70/105 [28:30<14:34, 24.98s/it, training_loss=0.339]\u001b[A\n","Epoch 2:  67%|██████▋   | 70/105 [28:54<14:34, 24.98s/it, training_loss=0.189]\u001b[A\n","Epoch 2:  68%|██████▊   | 71/105 [28:54<14:07, 24.93s/it, training_loss=0.189]\u001b[A\n","Epoch 2:  68%|██████▊   | 71/105 [29:18<14:07, 24.93s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  69%|██████▊   | 72/105 [29:18<13:27, 24.47s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  69%|██████▊   | 72/105 [29:42<13:27, 24.47s/it, training_loss=0.191]\u001b[A\n","Epoch 2:  70%|██████▉   | 73/105 [29:42<13:03, 24.49s/it, training_loss=0.191]\u001b[A\n","Epoch 2:  70%|██████▉   | 73/105 [30:07<13:03, 24.49s/it, training_loss=0.623]\u001b[A\n","Epoch 2:  70%|███████   | 74/105 [30:07<12:40, 24.54s/it, training_loss=0.623]\u001b[A\n","Epoch 2:  70%|███████   | 74/105 [30:32<12:40, 24.54s/it, training_loss=0.310]\u001b[A\n","Epoch 2:  71%|███████▏  | 75/105 [30:32<12:17, 24.59s/it, training_loss=0.310]\u001b[A\n","Epoch 2:  71%|███████▏  | 75/105 [30:55<12:17, 24.59s/it, training_loss=0.211]\u001b[A\n","Epoch 2:  72%|███████▏  | 76/105 [30:55<11:42, 24.23s/it, training_loss=0.211]\u001b[A\n","Epoch 2:  72%|███████▏  | 76/105 [31:20<11:42, 24.23s/it, training_loss=0.435]\u001b[A\n","Epoch 2:  73%|███████▎  | 77/105 [31:20<11:19, 24.28s/it, training_loss=0.435]\u001b[A\n","Epoch 2:  73%|███████▎  | 77/105 [31:44<11:19, 24.28s/it, training_loss=0.178]\u001b[A\n","Epoch 2:  74%|███████▍  | 78/105 [31:44<10:59, 24.42s/it, training_loss=0.178]\u001b[A\n","Epoch 2:  74%|███████▍  | 78/105 [32:11<10:59, 24.42s/it, training_loss=0.511]\u001b[A\n","Epoch 2:  75%|███████▌  | 79/105 [32:11<10:50, 25.00s/it, training_loss=0.511]\u001b[A\n","Epoch 2:  75%|███████▌  | 79/105 [32:34<10:50, 25.00s/it, training_loss=0.776]\u001b[A\n","Epoch 2:  76%|███████▌  | 80/105 [32:34<10:14, 24.57s/it, training_loss=0.776]\u001b[A\n","Epoch 2:  76%|███████▌  | 80/105 [32:59<10:14, 24.57s/it, training_loss=0.532]\u001b[A\n","Epoch 2:  77%|███████▋  | 81/105 [32:59<09:48, 24.51s/it, training_loss=0.532]\u001b[A\n","Epoch 2:  77%|███████▋  | 81/105 [33:23<09:48, 24.51s/it, training_loss=0.369]\u001b[A\n","Epoch 2:  78%|███████▊  | 82/105 [33:23<09:25, 24.61s/it, training_loss=0.369]\u001b[A\n","Epoch 2:  78%|███████▊  | 82/105 [33:48<09:25, 24.61s/it, training_loss=0.421]\u001b[A\n","Epoch 2:  79%|███████▉  | 83/105 [33:48<09:02, 24.64s/it, training_loss=0.421]\u001b[A\n","Epoch 2:  79%|███████▉  | 83/105 [34:12<09:02, 24.64s/it, training_loss=0.465]\u001b[A\n","Epoch 2:  80%|████████  | 84/105 [34:12<08:31, 24.35s/it, training_loss=0.465]\u001b[A\n","Epoch 2:  80%|████████  | 84/105 [34:36<08:31, 24.35s/it, training_loss=0.492]\u001b[A\n","Epoch 2:  81%|████████  | 85/105 [34:36<08:04, 24.25s/it, training_loss=0.492]\u001b[A\n","Epoch 2:  81%|████████  | 85/105 [35:00<08:04, 24.25s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  82%|████████▏ | 86/105 [35:00<07:43, 24.38s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  82%|████████▏ | 86/105 [35:27<07:43, 24.38s/it, training_loss=0.697]\u001b[A\n","Epoch 2:  83%|████████▎ | 87/105 [35:27<07:28, 24.94s/it, training_loss=0.697]\u001b[A\n","Epoch 2:  83%|████████▎ | 87/105 [35:51<07:28, 24.94s/it, training_loss=0.599]\u001b[A\n","Epoch 2:  84%|████████▍ | 88/105 [35:51<07:02, 24.88s/it, training_loss=0.599]\u001b[A\n","Epoch 2:  84%|████████▍ | 88/105 [36:15<07:02, 24.88s/it, training_loss=0.660]\u001b[A\n","Epoch 2:  85%|████████▍ | 89/105 [36:15<06:30, 24.38s/it, training_loss=0.660]\u001b[A\n","Epoch 2:  85%|████████▍ | 89/105 [36:39<06:30, 24.38s/it, training_loss=0.292]\u001b[A\n","Epoch 2:  86%|████████▌ | 90/105 [36:39<06:07, 24.47s/it, training_loss=0.292]\u001b[A\n","Epoch 2:  86%|████████▌ | 90/105 [37:04<06:07, 24.47s/it, training_loss=0.597]\u001b[A\n","Epoch 2:  87%|████████▋ | 91/105 [37:04<05:43, 24.55s/it, training_loss=0.597]\u001b[A\n","Epoch 2:  87%|████████▋ | 91/105 [37:29<05:43, 24.55s/it, training_loss=0.343]\u001b[A\n","Epoch 2:  88%|████████▊ | 92/105 [37:29<05:19, 24.61s/it, training_loss=0.343]\u001b[A\n","Epoch 2:  88%|████████▊ | 92/105 [37:52<05:19, 24.61s/it, training_loss=0.195]\u001b[A\n","Epoch 2:  89%|████████▊ | 93/105 [37:52<04:50, 24.24s/it, training_loss=0.195]\u001b[A\n","Epoch 2:  89%|████████▊ | 93/105 [38:17<04:50, 24.24s/it, training_loss=0.409]\u001b[A\n","Epoch 2:  90%|████████▉ | 94/105 [38:17<04:28, 24.38s/it, training_loss=0.409]\u001b[A\n","Epoch 2:  90%|████████▉ | 94/105 [38:42<04:28, 24.38s/it, training_loss=0.172]\u001b[A\n","Epoch 2:  90%|█████████ | 95/105 [38:42<04:05, 24.52s/it, training_loss=0.172]\u001b[A\n","Epoch 2:  90%|█████████ | 95/105 [39:08<04:05, 24.52s/it, training_loss=0.253]\u001b[A\n","Epoch 2:  91%|█████████▏| 96/105 [39:08<03:45, 25.09s/it, training_loss=0.253]\u001b[A\n","Epoch 2:  91%|█████████▏| 96/105 [39:33<03:45, 25.09s/it, training_loss=0.260]\u001b[A\n","Epoch 2:  92%|█████████▏| 97/105 [39:33<03:19, 24.94s/it, training_loss=0.260]\u001b[A\n","Epoch 2:  92%|█████████▏| 97/105 [39:57<03:19, 24.94s/it, training_loss=0.363]\u001b[A\n","Epoch 2:  93%|█████████▎| 98/105 [39:57<02:53, 24.82s/it, training_loss=0.363]\u001b[A\n","Epoch 2:  93%|█████████▎| 98/105 [40:22<02:53, 24.82s/it, training_loss=0.251]\u001b[A\n","Epoch 2:  94%|█████████▍| 99/105 [40:22<02:28, 24.83s/it, training_loss=0.251]\u001b[A\n","Epoch 2:  94%|█████████▍| 99/105 [40:47<02:28, 24.83s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  95%|█████████▌| 100/105 [40:47<02:04, 24.82s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  95%|█████████▌| 100/105 [41:12<02:04, 24.82s/it, training_loss=0.273]\u001b[A\n","Epoch 2:  96%|█████████▌| 101/105 [41:12<01:39, 24.81s/it, training_loss=0.273]\u001b[A\n","Epoch 2:  96%|█████████▌| 101/105 [41:35<01:39, 24.81s/it, training_loss=0.208]\u001b[A\n","Epoch 2:  97%|█████████▋| 102/105 [41:35<01:13, 24.40s/it, training_loss=0.208]\u001b[A\n","Epoch 2:  97%|█████████▋| 102/105 [42:00<01:13, 24.40s/it, training_loss=0.432]\u001b[A\n","Epoch 2:  98%|█████████▊| 103/105 [42:00<00:48, 24.41s/it, training_loss=0.432]\u001b[A\n","Epoch 2:  98%|█████████▊| 103/105 [42:26<00:48, 24.41s/it, training_loss=0.452]\u001b[A\n","Epoch 2:  99%|█████████▉| 104/105 [42:26<00:24, 24.99s/it, training_loss=0.452]\u001b[A\n","Epoch 2:  99%|█████████▉| 104/105 [42:51<00:24, 24.99s/it, training_loss=0.214]\u001b[A\n","Epoch 2: 100%|██████████| 105/105 [42:51<00:00, 24.94s/it, training_loss=0.214]\u001b[A\n"," 25%|██▌       | 1/4 [1:29:36<2:20:11, 2803.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.2356790429069882\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [1:33:10<1:33:07, 2793.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 0.9726158159750479\n","F1 Score (Weighted): 0.5172555628404685\n","QWK Score: 0.4951923076923077\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/105 [00:24<?, ?it/s, training_loss=0.261]\u001b[A\n","Epoch 3:   1%|          | 1/105 [00:24<43:17, 24.98s/it, training_loss=0.261]\u001b[A\n","Epoch 3:   1%|          | 1/105 [00:49<43:17, 24.98s/it, training_loss=0.493]\u001b[A\n","Epoch 3:   2%|▏         | 2/105 [00:49<42:14, 24.61s/it, training_loss=0.493]\u001b[A\n","Epoch 3:   2%|▏         | 2/105 [01:12<42:14, 24.61s/it, training_loss=0.589]\u001b[A\n","Epoch 3:   3%|▎         | 3/105 [01:12<41:03, 24.15s/it, training_loss=0.589]\u001b[A\n","Epoch 3:   3%|▎         | 3/105 [01:37<41:03, 24.15s/it, training_loss=0.459]\u001b[A\n","Epoch 3:   4%|▍         | 4/105 [01:37<41:04, 24.40s/it, training_loss=0.459]\u001b[A\n","Epoch 3:   4%|▍         | 4/105 [02:02<41:04, 24.40s/it, training_loss=0.602]\u001b[A\n","Epoch 3:   5%|▍         | 5/105 [02:02<41:01, 24.62s/it, training_loss=0.602]\u001b[A\n","Epoch 3:   5%|▍         | 5/105 [02:27<41:01, 24.62s/it, training_loss=0.210]\u001b[A\n","Epoch 3:   6%|▌         | 6/105 [02:27<40:42, 24.67s/it, training_loss=0.210]\u001b[A\n","Epoch 3:   6%|▌         | 6/105 [02:52<40:42, 24.67s/it, training_loss=0.678]\u001b[A\n","Epoch 3:   7%|▋         | 7/105 [02:52<40:28, 24.78s/it, training_loss=0.678]\u001b[A\n","Epoch 3:   7%|▋         | 7/105 [03:16<40:28, 24.78s/it, training_loss=0.261]\u001b[A\n","Epoch 3:   8%|▊         | 8/105 [03:16<39:53, 24.67s/it, training_loss=0.261]\u001b[A\n","Epoch 3:   8%|▊         | 8/105 [03:41<39:53, 24.67s/it, training_loss=0.213]\u001b[A\n","Epoch 3:   9%|▊         | 9/105 [03:41<39:29, 24.68s/it, training_loss=0.213]\u001b[A\n","Epoch 3:   9%|▊         | 9/105 [04:06<39:29, 24.68s/it, training_loss=0.419]\u001b[A\n","Epoch 3:  10%|▉         | 10/105 [04:06<39:07, 24.71s/it, training_loss=0.419]\u001b[A\n","Epoch 3:  10%|▉         | 10/105 [04:30<39:07, 24.71s/it, training_loss=0.253]\u001b[A\n","Epoch 3:  10%|█         | 11/105 [04:30<38:11, 24.38s/it, training_loss=0.253]\u001b[A\n","Epoch 3:  10%|█         | 11/105 [04:54<38:11, 24.38s/it, training_loss=0.260]\u001b[A\n","Epoch 3:  11%|█▏        | 12/105 [04:54<37:42, 24.33s/it, training_loss=0.260]\u001b[A\n","Epoch 3:  11%|█▏        | 12/105 [05:19<37:42, 24.33s/it, training_loss=0.247]\u001b[A\n","Epoch 3:  12%|█▏        | 13/105 [05:19<37:30, 24.46s/it, training_loss=0.247]\u001b[A\n","Epoch 3:  12%|█▏        | 13/105 [05:43<37:30, 24.46s/it, training_loss=0.374]\u001b[A\n","Epoch 3:  13%|█▎        | 14/105 [05:43<37:14, 24.55s/it, training_loss=0.374]\u001b[A\n","Epoch 3:  13%|█▎        | 14/105 [06:08<37:14, 24.55s/it, training_loss=0.410]\u001b[A\n","Epoch 3:  14%|█▍        | 15/105 [06:08<37:03, 24.70s/it, training_loss=0.410]\u001b[A\n","Epoch 3:  14%|█▍        | 15/105 [06:33<37:03, 24.70s/it, training_loss=0.185]\u001b[A\n","Epoch 3:  15%|█▌        | 16/105 [06:33<36:28, 24.59s/it, training_loss=0.185]\u001b[A\n","Epoch 3:  15%|█▌        | 16/105 [06:57<36:28, 24.59s/it, training_loss=0.194]\u001b[A\n","Epoch 3:  16%|█▌        | 17/105 [06:57<36:08, 24.64s/it, training_loss=0.194]\u001b[A\n","Epoch 3:  16%|█▌        | 17/105 [07:22<36:08, 24.64s/it, training_loss=0.210]\u001b[A\n","Epoch 3:  17%|█▋        | 18/105 [07:22<35:49, 24.70s/it, training_loss=0.210]\u001b[A\n","Epoch 3:  17%|█▋        | 18/105 [07:46<35:49, 24.70s/it, training_loss=0.277]\u001b[A\n","Epoch 3:  18%|█▊        | 19/105 [07:46<34:56, 24.37s/it, training_loss=0.277]\u001b[A\n","Epoch 3:  18%|█▊        | 19/105 [08:10<34:56, 24.37s/it, training_loss=0.262]\u001b[A\n","Epoch 3:  19%|█▉        | 20/105 [08:10<34:26, 24.31s/it, training_loss=0.262]\u001b[A\n","Epoch 3:  19%|█▉        | 20/105 [08:35<34:26, 24.31s/it, training_loss=0.180]\u001b[A\n","Epoch 3:  20%|██        | 21/105 [08:35<34:12, 24.44s/it, training_loss=0.180]\u001b[A\n","Epoch 3:  20%|██        | 21/105 [09:00<34:12, 24.44s/it, training_loss=0.403]\u001b[A\n","Epoch 3:  21%|██        | 22/105 [09:00<34:13, 24.74s/it, training_loss=0.403]\u001b[A\n","Epoch 3:  21%|██        | 22/105 [09:27<34:13, 24.74s/it, training_loss=0.481]\u001b[A\n","Epoch 3:  22%|██▏       | 23/105 [09:27<34:29, 25.24s/it, training_loss=0.481]\u001b[A\n","Epoch 3:  22%|██▏       | 23/105 [09:50<34:29, 25.24s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  23%|██▎       | 24/105 [09:50<33:16, 24.65s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  23%|██▎       | 24/105 [10:15<33:16, 24.65s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  24%|██▍       | 25/105 [10:15<32:54, 24.68s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  24%|██▍       | 25/105 [10:39<32:54, 24.68s/it, training_loss=0.384]\u001b[A\n","Epoch 3:  25%|██▍       | 26/105 [10:39<32:32, 24.71s/it, training_loss=0.384]\u001b[A\n","Epoch 3:  25%|██▍       | 26/105 [11:04<32:32, 24.71s/it, training_loss=0.458]\u001b[A\n","Epoch 3:  26%|██▌       | 27/105 [11:04<32:10, 24.75s/it, training_loss=0.458]\u001b[A\n","Epoch 3:  26%|██▌       | 27/105 [11:28<32:10, 24.75s/it, training_loss=0.518]\u001b[A\n","Epoch 3:  27%|██▋       | 28/105 [11:28<31:13, 24.33s/it, training_loss=0.518]\u001b[A\n","Epoch 3:  27%|██▋       | 28/105 [11:52<31:13, 24.33s/it, training_loss=0.395]\u001b[A\n","Epoch 3:  28%|██▊       | 29/105 [11:52<30:50, 24.34s/it, training_loss=0.395]\u001b[A\n","Epoch 3:  28%|██▊       | 29/105 [12:17<30:50, 24.34s/it, training_loss=0.191]\u001b[A\n","Epoch 3:  29%|██▊       | 30/105 [12:17<30:34, 24.46s/it, training_loss=0.191]\u001b[A\n","Epoch 3:  29%|██▊       | 30/105 [12:43<30:34, 24.46s/it, training_loss=0.193]\u001b[A\n","Epoch 3:  30%|██▉       | 31/105 [12:43<30:47, 24.97s/it, training_loss=0.193]\u001b[A\n","Epoch 3:  30%|██▉       | 31/105 [13:07<30:47, 24.97s/it, training_loss=0.201]\u001b[A\n","Epoch 3:  30%|███       | 32/105 [13:07<29:55, 24.59s/it, training_loss=0.201]\u001b[A\n","Epoch 3:  30%|███       | 32/105 [13:31<29:55, 24.59s/it, training_loss=0.421]\u001b[A\n","Epoch 3:  31%|███▏      | 33/105 [13:31<29:35, 24.66s/it, training_loss=0.421]\u001b[A\n","Epoch 3:  31%|███▏      | 33/105 [13:56<29:35, 24.66s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  32%|███▏      | 34/105 [13:56<29:15, 24.72s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  32%|███▏      | 34/105 [14:21<29:15, 24.72s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  33%|███▎      | 35/105 [14:21<28:52, 24.74s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  33%|███▎      | 35/105 [14:44<28:52, 24.74s/it, training_loss=0.193]\u001b[A\n","Epoch 3:  34%|███▍      | 36/105 [14:44<27:59, 24.33s/it, training_loss=0.193]\u001b[A\n","Epoch 3:  34%|███▍      | 36/105 [15:09<27:59, 24.33s/it, training_loss=0.591]\u001b[A\n","Epoch 3:  35%|███▌      | 37/105 [15:09<27:43, 24.46s/it, training_loss=0.591]\u001b[A\n","Epoch 3:  35%|███▌      | 37/105 [15:34<27:43, 24.46s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  36%|███▌      | 38/105 [15:34<27:24, 24.55s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  36%|███▌      | 38/105 [15:59<27:24, 24.55s/it, training_loss=0.324]\u001b[A\n","Epoch 3:  37%|███▋      | 39/105 [15:59<27:08, 24.67s/it, training_loss=0.324]\u001b[A\n","Epoch 3:  37%|███▋      | 39/105 [16:25<27:08, 24.67s/it, training_loss=0.299]\u001b[A\n","Epoch 3:  38%|███▊      | 40/105 [16:25<27:05, 25.00s/it, training_loss=0.299]\u001b[A\n","Epoch 3:  38%|███▊      | 40/105 [16:48<27:05, 25.00s/it, training_loss=0.170]\u001b[A\n","Epoch 3:  39%|███▉      | 41/105 [16:48<26:08, 24.52s/it, training_loss=0.170]\u001b[A\n","Epoch 3:  39%|███▉      | 41/105 [17:13<26:08, 24.52s/it, training_loss=0.632]\u001b[A\n","Epoch 3:  40%|████      | 42/105 [17:13<25:49, 24.60s/it, training_loss=0.632]\u001b[A\n","Epoch 3:  40%|████      | 42/105 [17:38<25:49, 24.60s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  41%|████      | 43/105 [17:38<25:26, 24.63s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  41%|████      | 43/105 [18:02<25:26, 24.63s/it, training_loss=0.134]\u001b[A\n","Epoch 3:  42%|████▏     | 44/105 [18:02<25:02, 24.63s/it, training_loss=0.134]\u001b[A\n","Epoch 3:  42%|████▏     | 44/105 [18:26<25:02, 24.63s/it, training_loss=0.362]\u001b[A\n","Epoch 3:  43%|████▎     | 45/105 [18:26<24:14, 24.25s/it, training_loss=0.362]\u001b[A\n","Epoch 3:  43%|████▎     | 45/105 [18:50<24:14, 24.25s/it, training_loss=0.209]\u001b[A\n","Epoch 3:  44%|████▍     | 46/105 [18:50<24:01, 24.43s/it, training_loss=0.209]\u001b[A\n","Epoch 3:  44%|████▍     | 46/105 [19:15<24:01, 24.43s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  45%|████▍     | 47/105 [19:15<23:41, 24.51s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  45%|████▍     | 47/105 [19:41<23:41, 24.51s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  46%|████▌     | 48/105 [19:41<23:46, 25.02s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  46%|████▌     | 48/105 [20:05<23:46, 25.02s/it, training_loss=0.299]\u001b[A\n","Epoch 3:  47%|████▋     | 49/105 [20:05<22:58, 24.62s/it, training_loss=0.299]\u001b[A\n","Epoch 3:  47%|████▋     | 49/105 [20:29<22:58, 24.62s/it, training_loss=0.282]\u001b[A\n","Epoch 3:  48%|████▊     | 50/105 [20:29<22:26, 24.47s/it, training_loss=0.282]\u001b[A\n","Epoch 3:  48%|████▊     | 50/105 [20:54<22:26, 24.47s/it, training_loss=0.242]\u001b[A\n","Epoch 3:  49%|████▊     | 51/105 [20:54<22:07, 24.58s/it, training_loss=0.242]\u001b[A\n","Epoch 3:  49%|████▊     | 51/105 [21:19<22:07, 24.58s/it, training_loss=0.429]\u001b[A\n","Epoch 3:  50%|████▉     | 52/105 [21:19<21:44, 24.62s/it, training_loss=0.429]\u001b[A\n","Epoch 3:  50%|████▉     | 52/105 [21:43<21:44, 24.62s/it, training_loss=0.314]\u001b[A\n","Epoch 3:  50%|█████     | 53/105 [21:43<21:12, 24.47s/it, training_loss=0.314]\u001b[A\n","Epoch 3:  50%|█████     | 53/105 [22:07<21:12, 24.47s/it, training_loss=0.597]\u001b[A\n","Epoch 3:  51%|█████▏    | 54/105 [22:07<20:36, 24.24s/it, training_loss=0.597]\u001b[A\n","Epoch 3:  51%|█████▏    | 54/105 [22:33<20:36, 24.24s/it, training_loss=0.341]\u001b[A\n","Epoch 3:  52%|█████▏    | 55/105 [22:33<20:39, 24.78s/it, training_loss=0.341]\u001b[A\n","Epoch 3:  52%|█████▏    | 55/105 [22:59<20:39, 24.78s/it, training_loss=0.634]\u001b[A\n","Epoch 3:  53%|█████▎    | 56/105 [22:59<20:37, 25.25s/it, training_loss=0.634]\u001b[A\n","Epoch 3:  53%|█████▎    | 56/105 [23:23<20:37, 25.25s/it, training_loss=0.277]\u001b[A\n","Epoch 3:  54%|█████▍    | 57/105 [23:23<19:53, 24.86s/it, training_loss=0.277]\u001b[A\n","Epoch 3:  54%|█████▍    | 57/105 [23:47<19:53, 24.86s/it, training_loss=0.195]\u001b[A\n","Epoch 3:  55%|█████▌    | 58/105 [23:47<19:13, 24.55s/it, training_loss=0.195]\u001b[A\n","Epoch 3:  55%|█████▌    | 58/105 [24:11<19:13, 24.55s/it, training_loss=0.214]\u001b[A\n","Epoch 3:  56%|█████▌    | 59/105 [24:11<18:51, 24.60s/it, training_loss=0.214]\u001b[A\n","Epoch 3:  56%|█████▌    | 59/105 [24:36<18:51, 24.60s/it, training_loss=0.196]\u001b[A\n","Epoch 3:  57%|█████▋    | 60/105 [24:36<18:28, 24.63s/it, training_loss=0.196]\u001b[A\n","Epoch 3:  57%|█████▋    | 60/105 [25:00<18:28, 24.63s/it, training_loss=0.187]\u001b[A\n","Epoch 3:  58%|█████▊    | 61/105 [25:00<17:58, 24.52s/it, training_loss=0.187]\u001b[A\n","Epoch 3:  58%|█████▊    | 61/105 [25:24<17:58, 24.52s/it, training_loss=0.422]\u001b[A\n","Epoch 3:  59%|█████▉    | 62/105 [25:24<17:21, 24.22s/it, training_loss=0.422]\u001b[A\n","Epoch 3:  59%|█████▉    | 62/105 [25:49<17:21, 24.22s/it, training_loss=0.248]\u001b[A\n","Epoch 3:  60%|██████    | 63/105 [25:49<17:05, 24.41s/it, training_loss=0.248]\u001b[A\n","Epoch 3:  60%|██████    | 63/105 [26:15<17:05, 24.41s/it, training_loss=0.203]\u001b[A\n","Epoch 3:  61%|██████    | 64/105 [26:15<17:06, 25.03s/it, training_loss=0.203]\u001b[A\n","Epoch 3:  61%|██████    | 64/105 [26:39<17:06, 25.03s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  62%|██████▏   | 65/105 [26:39<16:22, 24.56s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  62%|██████▏   | 65/105 [27:03<16:22, 24.56s/it, training_loss=0.399]\u001b[A\n","Epoch 3:  63%|██████▎   | 66/105 [27:03<15:55, 24.50s/it, training_loss=0.399]\u001b[A\n","Epoch 3:  63%|██████▎   | 66/105 [27:28<15:55, 24.50s/it, training_loss=0.199]\u001b[A\n","Epoch 3:  64%|██████▍   | 67/105 [27:28<15:34, 24.59s/it, training_loss=0.199]\u001b[A\n","Epoch 3:  64%|██████▍   | 67/105 [27:53<15:34, 24.59s/it, training_loss=0.496]\u001b[A\n","Epoch 3:  65%|██████▍   | 68/105 [27:53<15:11, 24.63s/it, training_loss=0.496]\u001b[A\n","Epoch 3:  65%|██████▍   | 68/105 [28:16<15:11, 24.63s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  66%|██████▌   | 69/105 [28:16<14:35, 24.33s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  66%|██████▌   | 69/105 [28:40<14:35, 24.33s/it, training_loss=0.409]\u001b[A\n","Epoch 3:  67%|██████▋   | 70/105 [28:40<14:10, 24.29s/it, training_loss=0.409]\u001b[A\n","Epoch 3:  67%|██████▋   | 70/105 [29:05<14:10, 24.29s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  68%|██████▊   | 71/105 [29:05<13:51, 24.46s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  68%|██████▊   | 71/105 [29:32<13:51, 24.46s/it, training_loss=0.895]\u001b[A\n","Epoch 3:  69%|██████▊   | 72/105 [29:32<13:46, 25.05s/it, training_loss=0.895]\u001b[A\n","Epoch 3:  69%|██████▊   | 72/105 [29:55<13:46, 25.05s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  70%|██████▉   | 73/105 [29:55<13:07, 24.60s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  70%|██████▉   | 73/105 [30:19<13:07, 24.60s/it, training_loss=0.236]\u001b[A\n","Epoch 3:  70%|███████   | 74/105 [30:19<12:39, 24.50s/it, training_loss=0.236]\u001b[A\n","Epoch 3:  70%|███████   | 74/105 [30:44<12:39, 24.50s/it, training_loss=0.238]\u001b[A\n","Epoch 3:  71%|███████▏  | 75/105 [30:44<12:18, 24.61s/it, training_loss=0.238]\u001b[A\n","Epoch 3:  71%|███████▏  | 75/105 [31:09<12:18, 24.61s/it, training_loss=0.736]\u001b[A\n","Epoch 3:  72%|███████▏  | 76/105 [31:09<11:55, 24.66s/it, training_loss=0.736]\u001b[A\n","Epoch 3:  72%|███████▏  | 76/105 [31:33<11:55, 24.66s/it, training_loss=0.390]\u001b[A\n","Epoch 3:  73%|███████▎  | 77/105 [31:33<11:22, 24.36s/it, training_loss=0.390]\u001b[A\n","Epoch 3:  73%|███████▎  | 77/105 [31:57<11:22, 24.36s/it, training_loss=0.242]\u001b[A\n","Epoch 3:  74%|███████▍  | 78/105 [31:57<10:54, 24.23s/it, training_loss=0.242]\u001b[A\n","Epoch 3:  74%|███████▍  | 78/105 [32:21<10:54, 24.23s/it, training_loss=0.495]\u001b[A\n","Epoch 3:  75%|███████▌  | 79/105 [32:21<10:33, 24.38s/it, training_loss=0.495]\u001b[A\n","Epoch 3:  75%|███████▌  | 79/105 [32:48<10:33, 24.38s/it, training_loss=0.484]\u001b[A\n","Epoch 3:  76%|███████▌  | 80/105 [32:48<10:24, 25.00s/it, training_loss=0.484]\u001b[A\n","Epoch 3:  76%|███████▌  | 80/105 [33:11<10:24, 25.00s/it, training_loss=0.223]\u001b[A\n","Epoch 3:  77%|███████▋  | 81/105 [33:11<09:49, 24.56s/it, training_loss=0.223]\u001b[A\n","Epoch 3:  77%|███████▋  | 81/105 [33:36<09:49, 24.56s/it, training_loss=0.264]\u001b[A\n","Epoch 3:  78%|███████▊  | 82/105 [33:36<09:22, 24.46s/it, training_loss=0.264]\u001b[A\n","Epoch 3:  78%|███████▊  | 82/105 [34:00<09:22, 24.46s/it, training_loss=0.170]\u001b[A\n","Epoch 3:  79%|███████▉  | 83/105 [34:00<09:00, 24.56s/it, training_loss=0.170]\u001b[A\n","Epoch 3:  79%|███████▉  | 83/105 [34:25<09:00, 24.56s/it, training_loss=0.298]\u001b[A\n","Epoch 3:  80%|████████  | 84/105 [34:25<08:37, 24.65s/it, training_loss=0.298]\u001b[A\n","Epoch 3:  80%|████████  | 84/105 [34:49<08:37, 24.65s/it, training_loss=0.203]\u001b[A\n","Epoch 3:  81%|████████  | 85/105 [34:49<08:08, 24.42s/it, training_loss=0.203]\u001b[A\n","Epoch 3:  81%|████████  | 85/105 [35:13<08:08, 24.42s/it, training_loss=0.155]\u001b[A\n","Epoch 3:  82%|████████▏ | 86/105 [35:13<07:40, 24.23s/it, training_loss=0.155]\u001b[A\n","Epoch 3:  82%|████████▏ | 86/105 [35:38<07:40, 24.23s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  83%|████████▎ | 87/105 [35:38<07:18, 24.37s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  83%|████████▎ | 87/105 [36:04<07:18, 24.37s/it, training_loss=0.132]\u001b[A\n","Epoch 3:  84%|████████▍ | 88/105 [36:04<07:04, 24.96s/it, training_loss=0.132]\u001b[A\n","Epoch 3:  84%|████████▍ | 88/105 [36:27<07:04, 24.96s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  85%|████████▍ | 89/105 [36:27<06:30, 24.42s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  85%|████████▍ | 89/105 [36:52<06:30, 24.42s/it, training_loss=0.626]\u001b[A\n","Epoch 3:  86%|████████▌ | 90/105 [36:52<06:07, 24.53s/it, training_loss=0.626]\u001b[A\n","Epoch 3:  86%|████████▌ | 90/105 [37:17<06:07, 24.53s/it, training_loss=0.194]\u001b[A\n","Epoch 3:  87%|████████▋ | 91/105 [37:17<05:44, 24.60s/it, training_loss=0.194]\u001b[A\n","Epoch 3:  87%|████████▋ | 91/105 [37:41<05:44, 24.60s/it, training_loss=0.291]\u001b[A\n","Epoch 3:  88%|████████▊ | 92/105 [37:41<05:20, 24.64s/it, training_loss=0.291]\u001b[A\n","Epoch 3:  88%|████████▊ | 92/105 [38:05<05:20, 24.64s/it, training_loss=0.138]\u001b[A\n","Epoch 3:  89%|████████▊ | 93/105 [38:05<04:50, 24.19s/it, training_loss=0.138]\u001b[A\n","Epoch 3:  89%|████████▊ | 93/105 [38:30<04:50, 24.19s/it, training_loss=0.199]\u001b[A\n","Epoch 3:  90%|████████▉ | 94/105 [38:30<04:30, 24.59s/it, training_loss=0.199]\u001b[A\n","Epoch 3:  90%|████████▉ | 94/105 [38:55<04:30, 24.59s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  90%|█████████ | 95/105 [38:55<04:06, 24.64s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  90%|█████████ | 95/105 [39:22<04:06, 24.64s/it, training_loss=0.216]\u001b[A\n","Epoch 3:  91%|█████████▏| 96/105 [39:22<03:47, 25.25s/it, training_loss=0.216]\u001b[A\n","Epoch 3:  91%|█████████▏| 96/105 [39:46<03:47, 25.25s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  92%|█████████▏| 97/105 [39:46<03:19, 24.92s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  92%|█████████▏| 97/105 [40:09<03:19, 24.92s/it, training_loss=0.417]\u001b[A\n","Epoch 3:  93%|█████████▎| 98/105 [40:09<02:51, 24.57s/it, training_loss=0.417]\u001b[A\n","Epoch 3:  93%|█████████▎| 98/105 [40:34<02:51, 24.57s/it, training_loss=0.262]\u001b[A\n","Epoch 3:  94%|█████████▍| 99/105 [40:34<02:27, 24.62s/it, training_loss=0.262]\u001b[A\n","Epoch 3:  94%|█████████▍| 99/105 [40:59<02:27, 24.62s/it, training_loss=0.416]\u001b[A\n","Epoch 3:  95%|█████████▌| 100/105 [40:59<02:03, 24.68s/it, training_loss=0.416]\u001b[A\n","Epoch 3:  95%|█████████▌| 100/105 [41:23<02:03, 24.68s/it, training_loss=0.457]\u001b[A\n","Epoch 3:  96%|█████████▌| 101/105 [41:23<01:38, 24.52s/it, training_loss=0.457]\u001b[A\n","Epoch 3:  96%|█████████▌| 101/105 [41:47<01:38, 24.52s/it, training_loss=0.333]\u001b[A\n","Epoch 3:  97%|█████████▋| 102/105 [41:47<01:12, 24.26s/it, training_loss=0.333]\u001b[A\n","Epoch 3:  97%|█████████▋| 102/105 [42:12<01:12, 24.26s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  98%|█████████▊| 103/105 [42:12<00:48, 24.47s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  98%|█████████▊| 103/105 [42:38<00:48, 24.47s/it, training_loss=0.564]\u001b[A\n","Epoch 3:  99%|█████████▉| 104/105 [42:38<00:24, 24.92s/it, training_loss=0.564]\u001b[A\n","Epoch 3:  99%|█████████▉| 104/105 [43:02<00:24, 24.92s/it, training_loss=0.222]\u001b[A\n","Epoch 3: 100%|██████████| 105/105 [43:02<00:00, 24.85s/it, training_loss=0.222]\u001b[A\n"," 50%|█████     | 2/4 [2:16:15<1:33:07, 2793.58s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 1.0227106764203027\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [2:19:47<46:35, 2795.40s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 0.9193787712741781\n","F1 Score (Weighted): 0.5202714769507223\n","QWK Score: 0.48107379534988204\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/105 [00:24<?, ?it/s, training_loss=0.321]\u001b[A\n","Epoch 4:   1%|          | 1/105 [00:24<43:01, 24.82s/it, training_loss=0.321]\u001b[A\n","Epoch 4:   1%|          | 1/105 [00:49<43:01, 24.82s/it, training_loss=0.093]\u001b[A\n","Epoch 4:   2%|▏         | 2/105 [00:49<42:39, 24.85s/it, training_loss=0.093]\u001b[A\n","Epoch 4:   2%|▏         | 2/105 [01:13<42:39, 24.85s/it, training_loss=0.450]\u001b[A\n","Epoch 4:   3%|▎         | 3/105 [01:13<41:04, 24.16s/it, training_loss=0.450]\u001b[A\n","Epoch 4:   3%|▎         | 3/105 [01:37<41:04, 24.16s/it, training_loss=0.457]\u001b[A\n","Epoch 4:   4%|▍         | 4/105 [01:37<40:50, 24.26s/it, training_loss=0.457]\u001b[A\n","Epoch 4:   4%|▍         | 4/105 [02:02<40:50, 24.26s/it, training_loss=0.501]\u001b[A\n","Epoch 4:   5%|▍         | 5/105 [02:02<40:45, 24.46s/it, training_loss=0.501]\u001b[A\n","Epoch 4:   5%|▍         | 5/105 [02:28<40:45, 24.46s/it, training_loss=0.356]\u001b[A\n","Epoch 4:   6%|▌         | 6/105 [02:28<41:15, 25.01s/it, training_loss=0.356]\u001b[A\n","Epoch 4:   6%|▌         | 6/105 [02:52<41:15, 25.01s/it, training_loss=0.120]\u001b[A\n","Epoch 4:   7%|▋         | 7/105 [02:52<40:39, 24.89s/it, training_loss=0.120]\u001b[A\n","Epoch 4:   7%|▋         | 7/105 [03:16<40:39, 24.89s/it, training_loss=0.290]\u001b[A\n","Epoch 4:   8%|▊         | 8/105 [03:16<39:22, 24.36s/it, training_loss=0.290]\u001b[A\n","Epoch 4:   8%|▊         | 8/105 [03:40<39:22, 24.36s/it, training_loss=0.304]\u001b[A\n","Epoch 4:   9%|▊         | 9/105 [03:40<39:11, 24.49s/it, training_loss=0.304]\u001b[A\n","Epoch 4:   9%|▊         | 9/105 [04:05<39:11, 24.49s/it, training_loss=0.220]\u001b[A\n","Epoch 4:  10%|▉         | 10/105 [04:05<38:56, 24.60s/it, training_loss=0.220]\u001b[A\n","Epoch 4:  10%|▉         | 10/105 [04:30<38:56, 24.60s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  10%|█         | 11/105 [04:30<38:39, 24.68s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  10%|█         | 11/105 [04:53<38:39, 24.68s/it, training_loss=0.570]\u001b[A\n","Epoch 4:  11%|█▏        | 12/105 [04:53<37:35, 24.25s/it, training_loss=0.570]\u001b[A\n","Epoch 4:  11%|█▏        | 12/105 [05:20<37:35, 24.25s/it, training_loss=0.449]\u001b[A\n","Epoch 4:  12%|█▏        | 13/105 [05:20<38:09, 24.89s/it, training_loss=0.449]\u001b[A\n","Epoch 4:  12%|█▏        | 13/105 [05:45<38:09, 24.89s/it, training_loss=0.210]\u001b[A\n","Epoch 4:  13%|█▎        | 14/105 [05:45<37:41, 24.85s/it, training_loss=0.210]\u001b[A\n","Epoch 4:  13%|█▎        | 14/105 [06:09<37:41, 24.85s/it, training_loss=0.226]\u001b[A\n","Epoch 4:  14%|█▍        | 15/105 [06:09<37:15, 24.84s/it, training_loss=0.226]\u001b[A\n","Epoch 4:  14%|█▍        | 15/105 [06:33<37:15, 24.84s/it, training_loss=0.325]\u001b[A\n","Epoch 4:  15%|█▌        | 16/105 [06:33<36:28, 24.59s/it, training_loss=0.325]\u001b[A\n","Epoch 4:  15%|█▌        | 16/105 [06:57<36:28, 24.59s/it, training_loss=0.153]\u001b[A\n","Epoch 4:  16%|█▌        | 17/105 [06:57<35:41, 24.33s/it, training_loss=0.153]\u001b[A\n","Epoch 4:  16%|█▌        | 17/105 [07:23<35:41, 24.33s/it, training_loss=0.319]\u001b[A\n","Epoch 4:  17%|█▋        | 18/105 [07:23<35:55, 24.77s/it, training_loss=0.319]\u001b[A\n","Epoch 4:  17%|█▋        | 18/105 [07:49<35:55, 24.77s/it, training_loss=0.300]\u001b[A\n","Epoch 4:  18%|█▊        | 19/105 [07:49<36:06, 25.20s/it, training_loss=0.300]\u001b[A\n","Epoch 4:  18%|█▊        | 19/105 [08:14<36:06, 25.20s/it, training_loss=0.256]\u001b[A\n","Epoch 4:  19%|█▉        | 20/105 [08:14<35:38, 25.16s/it, training_loss=0.256]\u001b[A\n","Epoch 4:  19%|█▉        | 20/105 [08:41<35:38, 25.16s/it, training_loss=0.234]\u001b[A\n","Epoch 4:  20%|██        | 21/105 [08:41<35:43, 25.51s/it, training_loss=0.234]\u001b[A\n","Epoch 4:  20%|██        | 21/105 [09:04<35:43, 25.51s/it, training_loss=0.090]\u001b[A\n","Epoch 4:  21%|██        | 22/105 [09:04<34:20, 24.82s/it, training_loss=0.090]\u001b[A\n","Epoch 4:  21%|██        | 22/105 [09:28<34:20, 24.82s/it, training_loss=0.343]\u001b[A\n","Epoch 4:  22%|██▏       | 23/105 [09:29<33:54, 24.81s/it, training_loss=0.343]\u001b[A\n","Epoch 4:  22%|██▏       | 23/105 [09:53<33:54, 24.81s/it, training_loss=0.590]\u001b[A\n","Epoch 4:  23%|██▎       | 24/105 [09:53<33:27, 24.78s/it, training_loss=0.590]\u001b[A\n","Epoch 4:  23%|██▎       | 24/105 [10:18<33:27, 24.78s/it, training_loss=0.238]\u001b[A\n","Epoch 4:  24%|██▍       | 25/105 [10:18<33:05, 24.82s/it, training_loss=0.238]\u001b[A\n","Epoch 4:  24%|██▍       | 25/105 [10:42<33:05, 24.82s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  25%|██▍       | 26/105 [10:42<32:07, 24.40s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  25%|██▍       | 26/105 [11:06<32:07, 24.40s/it, training_loss=0.290]\u001b[A\n","Epoch 4:  26%|██▌       | 27/105 [11:06<31:43, 24.40s/it, training_loss=0.290]\u001b[A\n","Epoch 4:  26%|██▌       | 27/105 [11:31<31:43, 24.40s/it, training_loss=0.170]\u001b[A\n","Epoch 4:  27%|██▋       | 28/105 [11:31<31:25, 24.49s/it, training_loss=0.170]\u001b[A\n","Epoch 4:  27%|██▋       | 28/105 [11:57<31:25, 24.49s/it, training_loss=0.178]\u001b[A\n","Epoch 4:  28%|██▊       | 29/105 [11:57<31:44, 25.06s/it, training_loss=0.178]\u001b[A\n","Epoch 4:  28%|██▊       | 29/105 [12:20<31:44, 25.06s/it, training_loss=0.803]\u001b[A\n","Epoch 4:  29%|██▊       | 30/105 [12:20<30:36, 24.49s/it, training_loss=0.803]\u001b[A\n","Epoch 4:  29%|██▊       | 30/105 [12:45<30:36, 24.49s/it, training_loss=0.029]\u001b[A\n","Epoch 4:  30%|██▉       | 31/105 [12:45<30:18, 24.58s/it, training_loss=0.029]\u001b[A\n","Epoch 4:  30%|██▉       | 31/105 [13:10<30:18, 24.58s/it, training_loss=0.288]\u001b[A\n","Epoch 4:  30%|███       | 32/105 [13:10<29:58, 24.64s/it, training_loss=0.288]\u001b[A\n","Epoch 4:  30%|███       | 32/105 [13:35<29:58, 24.64s/it, training_loss=0.196]\u001b[A\n","Epoch 4:  31%|███▏      | 33/105 [13:35<29:37, 24.68s/it, training_loss=0.196]\u001b[A\n","Epoch 4:  31%|███▏      | 33/105 [13:58<29:37, 24.68s/it, training_loss=0.277]\u001b[A\n","Epoch 4:  32%|███▏      | 34/105 [13:58<28:42, 24.26s/it, training_loss=0.277]\u001b[A\n","Epoch 4:  32%|███▏      | 34/105 [14:22<28:42, 24.26s/it, training_loss=0.380]\u001b[A\n","Epoch 4:  33%|███▎      | 35/105 [14:22<28:26, 24.37s/it, training_loss=0.380]\u001b[A\n","Epoch 4:  33%|███▎      | 35/105 [14:49<28:26, 24.37s/it, training_loss=0.554]\u001b[A\n","Epoch 4:  34%|███▍      | 36/105 [14:49<28:41, 24.94s/it, training_loss=0.554]\u001b[A\n","Epoch 4:  34%|███▍      | 36/105 [15:13<28:41, 24.94s/it, training_loss=0.107]\u001b[A\n","Epoch 4:  35%|███▌      | 37/105 [15:13<28:11, 24.88s/it, training_loss=0.107]\u001b[A\n","Epoch 4:  35%|███▌      | 37/105 [15:38<28:11, 24.88s/it, training_loss=0.125]\u001b[A\n","Epoch 4:  36%|███▌      | 38/105 [15:38<27:43, 24.83s/it, training_loss=0.125]\u001b[A\n","Epoch 4:  36%|███▌      | 38/105 [16:01<27:43, 24.83s/it, training_loss=0.159]\u001b[A\n","Epoch 4:  37%|███▋      | 39/105 [16:01<26:48, 24.37s/it, training_loss=0.159]\u001b[A\n","Epoch 4:  37%|███▋      | 39/105 [16:26<26:48, 24.37s/it, training_loss=0.273]\u001b[A\n","Epoch 4:  38%|███▊      | 40/105 [16:26<26:31, 24.48s/it, training_loss=0.273]\u001b[A\n","Epoch 4:  38%|███▊      | 40/105 [16:51<26:31, 24.48s/it, training_loss=0.713]\u001b[A\n","Epoch 4:  39%|███▉      | 41/105 [16:51<26:13, 24.58s/it, training_loss=0.713]\u001b[A\n","Epoch 4:  39%|███▉      | 41/105 [17:16<26:13, 24.58s/it, training_loss=0.252]\u001b[A\n","Epoch 4:  40%|████      | 42/105 [17:16<25:50, 24.61s/it, training_loss=0.252]\u001b[A\n","Epoch 4:  40%|████      | 42/105 [17:39<25:50, 24.61s/it, training_loss=0.440]\u001b[A\n","Epoch 4:  41%|████      | 43/105 [17:39<24:58, 24.17s/it, training_loss=0.440]\u001b[A\n","Epoch 4:  41%|████      | 43/105 [18:05<24:58, 24.17s/it, training_loss=0.443]\u001b[A\n","Epoch 4:  42%|████▏     | 44/105 [18:05<25:15, 24.84s/it, training_loss=0.443]\u001b[A\n","Epoch 4:  42%|████▏     | 44/105 [18:30<25:15, 24.84s/it, training_loss=0.098]\u001b[A\n","Epoch 4:  43%|████▎     | 45/105 [18:30<24:49, 24.83s/it, training_loss=0.098]\u001b[A\n","Epoch 4:  43%|████▎     | 45/105 [18:55<24:49, 24.83s/it, training_loss=0.838]\u001b[A\n","Epoch 4:  44%|████▍     | 46/105 [18:55<24:21, 24.77s/it, training_loss=0.838]\u001b[A\n","Epoch 4:  44%|████▍     | 46/105 [19:18<24:21, 24.77s/it, training_loss=0.552]\u001b[A\n","Epoch 4:  45%|████▍     | 47/105 [19:18<23:31, 24.34s/it, training_loss=0.552]\u001b[A\n","Epoch 4:  45%|████▍     | 47/105 [19:43<23:31, 24.34s/it, training_loss=0.326]\u001b[A\n","Epoch 4:  46%|████▌     | 48/105 [19:43<23:15, 24.49s/it, training_loss=0.326]\u001b[A\n","Epoch 4:  46%|████▌     | 48/105 [20:08<23:15, 24.49s/it, training_loss=0.319]\u001b[A\n","Epoch 4:  47%|████▋     | 49/105 [20:08<23:01, 24.66s/it, training_loss=0.319]\u001b[A\n","Epoch 4:  47%|████▋     | 49/105 [20:33<23:01, 24.66s/it, training_loss=0.135]\u001b[A\n","Epoch 4:  48%|████▊     | 50/105 [20:33<22:40, 24.73s/it, training_loss=0.135]\u001b[A\n","Epoch 4:  48%|████▊     | 50/105 [20:56<22:40, 24.73s/it, training_loss=0.375]\u001b[A\n","Epoch 4:  49%|████▊     | 51/105 [20:56<21:57, 24.39s/it, training_loss=0.375]\u001b[A\n","Epoch 4:  49%|████▊     | 51/105 [21:22<21:57, 24.39s/it, training_loss=0.384]\u001b[A\n","Epoch 4:  50%|████▉     | 52/105 [21:22<21:53, 24.78s/it, training_loss=0.384]\u001b[A\n","Epoch 4:  50%|████▉     | 52/105 [21:47<21:53, 24.78s/it, training_loss=0.120]\u001b[A\n","Epoch 4:  50%|█████     | 53/105 [21:47<21:26, 24.74s/it, training_loss=0.120]\u001b[A\n","Epoch 4:  50%|█████     | 53/105 [22:12<21:26, 24.74s/it, training_loss=0.462]\u001b[A\n","Epoch 4:  51%|█████▏    | 54/105 [22:12<21:01, 24.74s/it, training_loss=0.462]\u001b[A\n","Epoch 4:  51%|█████▏    | 54/105 [22:36<21:01, 24.74s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  52%|█████▏    | 55/105 [22:36<20:38, 24.78s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  52%|█████▏    | 55/105 [23:00<20:38, 24.78s/it, training_loss=0.589]\u001b[A\n","Epoch 4:  53%|█████▎    | 56/105 [23:00<19:50, 24.29s/it, training_loss=0.589]\u001b[A\n","Epoch 4:  53%|█████▎    | 56/105 [23:24<19:50, 24.29s/it, training_loss=0.124]\u001b[A\n","Epoch 4:  54%|█████▍    | 57/105 [23:24<19:33, 24.44s/it, training_loss=0.124]\u001b[A\n","Epoch 4:  54%|█████▍    | 57/105 [23:49<19:33, 24.44s/it, training_loss=0.479]\u001b[A\n","Epoch 4:  55%|█████▌    | 58/105 [23:49<19:12, 24.51s/it, training_loss=0.479]\u001b[A\n","Epoch 4:  55%|█████▌    | 58/105 [24:15<19:12, 24.51s/it, training_loss=0.206]\u001b[A\n","Epoch 4:  56%|█████▌    | 59/105 [24:15<19:14, 25.10s/it, training_loss=0.206]\u001b[A\n","Epoch 4:  56%|█████▌    | 59/105 [24:39<19:14, 25.10s/it, training_loss=0.353]\u001b[A\n","Epoch 4:  57%|█████▋    | 60/105 [24:39<18:24, 24.55s/it, training_loss=0.353]\u001b[A\n","Epoch 4:  57%|█████▋    | 60/105 [25:04<18:24, 24.55s/it, training_loss=0.606]\u001b[A\n","Epoch 4:  58%|█████▊    | 61/105 [25:04<18:06, 24.69s/it, training_loss=0.606]\u001b[A\n","Epoch 4:  58%|█████▊    | 61/105 [25:29<18:06, 24.69s/it, training_loss=0.252]\u001b[A\n","Epoch 4:  59%|█████▉    | 62/105 [25:29<17:43, 24.74s/it, training_loss=0.252]\u001b[A\n","Epoch 4:  59%|█████▉    | 62/105 [25:53<17:43, 24.74s/it, training_loss=0.329]\u001b[A\n","Epoch 4:  60%|██████    | 63/105 [25:53<17:19, 24.75s/it, training_loss=0.329]\u001b[A\n","Epoch 4:  60%|██████    | 63/105 [26:17<17:19, 24.75s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  61%|██████    | 64/105 [26:17<16:39, 24.37s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  61%|██████    | 64/105 [26:41<16:39, 24.37s/it, training_loss=0.469]\u001b[A\n","Epoch 4:  62%|██████▏   | 65/105 [26:41<16:14, 24.35s/it, training_loss=0.469]\u001b[A\n","Epoch 4:  62%|██████▏   | 65/105 [27:06<16:14, 24.35s/it, training_loss=0.370]\u001b[A\n","Epoch 4:  63%|██████▎   | 66/105 [27:06<15:55, 24.49s/it, training_loss=0.370]\u001b[A\n","Epoch 4:  63%|██████▎   | 66/105 [27:31<15:55, 24.49s/it, training_loss=0.187]\u001b[A\n","Epoch 4:  64%|██████▍   | 67/105 [27:31<15:34, 24.58s/it, training_loss=0.187]\u001b[A\n","Epoch 4:  64%|██████▍   | 67/105 [27:55<15:34, 24.58s/it, training_loss=0.132]\u001b[A\n","Epoch 4:  65%|██████▍   | 68/105 [27:55<15:02, 24.39s/it, training_loss=0.132]\u001b[A\n","Epoch 4:  65%|██████▍   | 68/105 [28:19<15:02, 24.39s/it, training_loss=0.242]\u001b[A\n","Epoch 4:  66%|██████▌   | 69/105 [28:19<14:32, 24.23s/it, training_loss=0.242]\u001b[A\n","Epoch 4:  66%|██████▌   | 69/105 [28:43<14:32, 24.23s/it, training_loss=0.240]\u001b[A\n","Epoch 4:  67%|██████▋   | 70/105 [28:43<14:13, 24.40s/it, training_loss=0.240]\u001b[A\n","Epoch 4:  67%|██████▋   | 70/105 [29:08<14:13, 24.40s/it, training_loss=0.274]\u001b[A\n","Epoch 4:  68%|██████▊   | 71/105 [29:08<13:54, 24.54s/it, training_loss=0.274]\u001b[A\n","Epoch 4:  68%|██████▊   | 71/105 [29:32<13:54, 24.54s/it, training_loss=0.240]\u001b[A\n","Epoch 4:  69%|██████▊   | 72/105 [29:32<13:26, 24.45s/it, training_loss=0.240]\u001b[A\n","Epoch 4:  69%|██████▊   | 72/105 [29:56<13:26, 24.45s/it, training_loss=0.225]\u001b[A\n","Epoch 4:  70%|██████▉   | 73/105 [29:56<12:55, 24.24s/it, training_loss=0.225]\u001b[A\n","Epoch 4:  70%|██████▉   | 73/105 [30:21<12:55, 24.24s/it, training_loss=0.614]\u001b[A\n","Epoch 4:  70%|███████   | 74/105 [30:21<12:37, 24.42s/it, training_loss=0.614]\u001b[A\n","Epoch 4:  70%|███████   | 74/105 [30:46<12:37, 24.42s/it, training_loss=0.204]\u001b[A\n","Epoch 4:  71%|███████▏  | 75/105 [30:46<12:16, 24.54s/it, training_loss=0.204]\u001b[A\n","Epoch 4:  71%|███████▏  | 75/105 [31:10<12:16, 24.54s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  72%|███████▏  | 76/105 [31:10<11:51, 24.55s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  72%|███████▏  | 76/105 [31:34<11:51, 24.55s/it, training_loss=0.159]\u001b[A\n","Epoch 4:  73%|███████▎  | 77/105 [31:34<11:18, 24.24s/it, training_loss=0.159]\u001b[A\n","Epoch 4:  73%|███████▎  | 77/105 [32:00<11:18, 24.24s/it, training_loss=0.383]\u001b[A\n","Epoch 4:  74%|███████▍  | 78/105 [32:00<11:07, 24.70s/it, training_loss=0.383]\u001b[A\n","Epoch 4:  74%|███████▍  | 78/105 [32:25<11:07, 24.70s/it, training_loss=0.165]\u001b[A\n","Epoch 4:  75%|███████▌  | 79/105 [32:25<10:42, 24.72s/it, training_loss=0.165]\u001b[A\n","Epoch 4:  75%|███████▌  | 79/105 [32:49<10:42, 24.72s/it, training_loss=0.273]\u001b[A\n","Epoch 4:  76%|███████▌  | 80/105 [32:49<10:18, 24.76s/it, training_loss=0.273]\u001b[A\n","Epoch 4:  76%|███████▌  | 80/105 [33:13<10:18, 24.76s/it, training_loss=0.134]\u001b[A\n","Epoch 4:  77%|███████▋  | 81/105 [33:13<09:44, 24.35s/it, training_loss=0.134]\u001b[A\n","Epoch 4:  77%|███████▋  | 81/105 [33:37<09:44, 24.35s/it, training_loss=0.126]\u001b[A\n","Epoch 4:  78%|███████▊  | 82/105 [33:37<09:21, 24.40s/it, training_loss=0.126]\u001b[A\n","Epoch 4:  78%|███████▊  | 82/105 [34:02<09:21, 24.40s/it, training_loss=0.098]\u001b[A\n","Epoch 4:  79%|███████▉  | 83/105 [34:02<08:59, 24.51s/it, training_loss=0.098]\u001b[A\n","Epoch 4:  79%|███████▉  | 83/105 [34:27<08:59, 24.51s/it, training_loss=0.165]\u001b[A\n","Epoch 4:  80%|████████  | 84/105 [34:27<08:35, 24.57s/it, training_loss=0.165]\u001b[A\n","Epoch 4:  80%|████████  | 84/105 [34:50<08:35, 24.57s/it, training_loss=0.079]\u001b[A\n","Epoch 4:  81%|████████  | 85/105 [34:50<08:05, 24.29s/it, training_loss=0.079]\u001b[A\n","Epoch 4:  81%|████████  | 85/105 [35:14<08:05, 24.29s/it, training_loss=0.187]\u001b[A\n","Epoch 4:  82%|████████▏ | 86/105 [35:14<07:39, 24.21s/it, training_loss=0.187]\u001b[A\n","Epoch 4:  82%|████████▏ | 86/105 [35:39<07:39, 24.21s/it, training_loss=0.376]\u001b[A\n","Epoch 4:  83%|████████▎ | 87/105 [35:39<07:18, 24.37s/it, training_loss=0.376]\u001b[A\n","Epoch 4:  83%|████████▎ | 87/105 [36:04<07:18, 24.37s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  84%|████████▍ | 88/105 [36:04<06:56, 24.50s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  84%|████████▍ | 88/105 [36:28<06:56, 24.50s/it, training_loss=0.264]\u001b[A\n","Epoch 4:  85%|████████▍ | 89/105 [36:28<06:29, 24.34s/it, training_loss=0.264]\u001b[A\n","Epoch 4:  85%|████████▍ | 89/105 [36:52<06:29, 24.34s/it, training_loss=0.287]\u001b[A\n","Epoch 4:  86%|████████▌ | 90/105 [36:52<06:03, 24.20s/it, training_loss=0.287]\u001b[A\n","Epoch 4:  86%|████████▌ | 90/105 [37:17<06:03, 24.20s/it, training_loss=0.202]\u001b[A\n","Epoch 4:  87%|████████▋ | 91/105 [37:17<05:41, 24.37s/it, training_loss=0.202]\u001b[A\n","Epoch 4:  87%|████████▋ | 91/105 [37:41<05:41, 24.37s/it, training_loss=0.117]\u001b[A\n","Epoch 4:  88%|████████▊ | 92/105 [37:41<05:18, 24.49s/it, training_loss=0.117]\u001b[A\n","Epoch 4:  88%|████████▊ | 92/105 [38:06<05:18, 24.49s/it, training_loss=0.303]\u001b[A\n","Epoch 4:  89%|████████▊ | 93/105 [38:06<04:52, 24.40s/it, training_loss=0.303]\u001b[A\n","Epoch 4:  89%|████████▊ | 93/105 [38:29<04:52, 24.40s/it, training_loss=0.158]\u001b[A\n","Epoch 4:  90%|████████▉ | 94/105 [38:29<04:25, 24.16s/it, training_loss=0.158]\u001b[A\n","Epoch 4:  90%|████████▉ | 94/105 [38:54<04:25, 24.16s/it, training_loss=0.369]\u001b[A\n","Epoch 4:  90%|█████████ | 95/105 [38:54<04:03, 24.37s/it, training_loss=0.369]\u001b[A\n","Epoch 4:  90%|█████████ | 95/105 [39:19<04:03, 24.37s/it, training_loss=0.308]\u001b[A\n","Epoch 4:  91%|█████████▏| 96/105 [39:19<03:40, 24.51s/it, training_loss=0.308]\u001b[A\n","Epoch 4:  91%|█████████▏| 96/105 [39:43<03:40, 24.51s/it, training_loss=0.057]\u001b[A\n","Epoch 4:  92%|█████████▏| 97/105 [39:43<03:16, 24.54s/it, training_loss=0.057]\u001b[A\n","Epoch 4:  92%|█████████▏| 97/105 [40:07<03:16, 24.54s/it, training_loss=0.414]\u001b[A\n","Epoch 4:  93%|█████████▎| 98/105 [40:07<02:49, 24.22s/it, training_loss=0.414]\u001b[A\n","Epoch 4:  93%|█████████▎| 98/105 [40:32<02:49, 24.22s/it, training_loss=0.418]\u001b[A\n","Epoch 4:  94%|█████████▍| 99/105 [40:32<02:26, 24.42s/it, training_loss=0.418]\u001b[A\n","Epoch 4:  94%|█████████▍| 99/105 [40:57<02:26, 24.42s/it, training_loss=0.219]\u001b[A\n","Epoch 4:  95%|█████████▌| 100/105 [40:57<02:02, 24.53s/it, training_loss=0.219]\u001b[A\n","Epoch 4:  95%|█████████▌| 100/105 [41:21<02:02, 24.53s/it, training_loss=0.101]\u001b[A\n","Epoch 4:  96%|█████████▌| 101/105 [41:21<01:38, 24.58s/it, training_loss=0.101]\u001b[A\n","Epoch 4:  96%|█████████▌| 101/105 [41:44<01:38, 24.58s/it, training_loss=0.260]\u001b[A\n","Epoch 4:  97%|█████████▋| 102/105 [41:44<01:12, 24.16s/it, training_loss=0.260]\u001b[A\n","Epoch 4:  97%|█████████▋| 102/105 [42:09<01:12, 24.16s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  98%|█████████▊| 103/105 [42:09<00:48, 24.34s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  98%|█████████▊| 103/105 [42:34<00:48, 24.34s/it, training_loss=0.394]\u001b[A\n","Epoch 4:  99%|█████████▉| 104/105 [42:34<00:24, 24.49s/it, training_loss=0.394]\u001b[A\n","Epoch 4:  99%|█████████▉| 104/105 [42:59<00:24, 24.49s/it, training_loss=0.181]\u001b[A\n","Epoch 4: 100%|██████████| 105/105 [42:59<00:00, 24.56s/it, training_loss=0.181]\u001b[A\n"," 75%|███████▌  | 3/4 [3:02:48<46:35, 2795.40s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 0.8979638443106697\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [3:06:19<00:00, 2794.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 0.9063561390395518\n","F1 Score (Weighted): 0.48922658294086874\n","QWK Score: 0.43472409152086133\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["while 1:\n","  print(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"axRE4aZbZBm0","executionInfo":{"status":"error","timestamp":1680453016629,"user_tz":-420,"elapsed":642634,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"4637788f-2684-456e-fd0b-9100ebdd481a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-0c462dd19bad>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"Hau1JnUPj_Jt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyNM9waj89xv8bTzwfO+mY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00093a7738e44be5a726da8720cfedc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_417da303ef7941f5880cf6240053d4a6","IPY_MODEL_ca3dfb9047c042a5a2c52f1dc421f6ca","IPY_MODEL_252a6ca0efe44a3b895cf2aecc6c483b"],"layout":"IPY_MODEL_16942d7c125646b1a3c4cebab6c73085"}},"417da303ef7941f5880cf6240053d4a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e79de76a257417884df569d052ecc58","placeholder":"​","style":"IPY_MODEL_2b6ed3a4aefb430babcc0e869438a842","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"ca3dfb9047c042a5a2c52f1dc421f6ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_189ef25f48554471b2f6290399964e61","max":224974,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1741bdf6811f42cab7680580d4286b9f","value":224974}},"252a6ca0efe44a3b895cf2aecc6c483b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_822216ea942744a793a25c5e5162df1e","placeholder":"​","style":"IPY_MODEL_b85fab09e1424cfda1907a75a6584d63","value":" 225k/225k [00:00&lt;00:00, 3.13MB/s]"}},"16942d7c125646b1a3c4cebab6c73085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e79de76a257417884df569d052ecc58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b6ed3a4aefb430babcc0e869438a842":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"189ef25f48554471b2f6290399964e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1741bdf6811f42cab7680580d4286b9f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"822216ea942744a793a25c5e5162df1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b85fab09e1424cfda1907a75a6584d63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3af26c7c61644084942f3ce6bebecffc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68850496b75445ef9048bc8db7753475","IPY_MODEL_370281fbb45542a4b374c25ead1e38bc","IPY_MODEL_efa3e5b4244242389d3d855b99a9c067"],"layout":"IPY_MODEL_235353f0f83a4bcfae39713b56963711"}},"68850496b75445ef9048bc8db7753475":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4490cf6e1e4745178051a04e65412b73","placeholder":"​","style":"IPY_MODEL_5ee1620e22ad497fada8dee819920e1b","value":"Downloading (…)cial_tokens_map.json: 100%"}},"370281fbb45542a4b374c25ead1e38bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fd954d56b3741d29f06f9ea8df0a4a1","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38a75ad10b4d40fda6bc7f63f42f9f6b","value":112}},"efa3e5b4244242389d3d855b99a9c067":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5317c2721dc84323b2eddf0a322c6ba9","placeholder":"​","style":"IPY_MODEL_2b67e710394643a98ad3a2994966c68b","value":" 112/112 [00:00&lt;00:00, 3.18kB/s]"}},"235353f0f83a4bcfae39713b56963711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4490cf6e1e4745178051a04e65412b73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ee1620e22ad497fada8dee819920e1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fd954d56b3741d29f06f9ea8df0a4a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38a75ad10b4d40fda6bc7f63f42f9f6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5317c2721dc84323b2eddf0a322c6ba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b67e710394643a98ad3a2994966c68b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4903585dc5884c1587fe030489318546":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6521369110ce47daa3609879aede00fb","IPY_MODEL_e2e0eda571e24470abebfaa3f8dca047","IPY_MODEL_bbee9f37246645848d5d7a4a114e1114"],"layout":"IPY_MODEL_85e3d84e07694cd8b313dd1d8832ec91"}},"6521369110ce47daa3609879aede00fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb01501f49e04c3580534ebc8b425ca4","placeholder":"​","style":"IPY_MODEL_86249bff82b04da7bb25f251b35f1db3","value":"Downloading (…)okenizer_config.json: 100%"}},"e2e0eda571e24470abebfaa3f8dca047":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b58541e936e94ad09b919696c8c2c35e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46d17e86ab574419a98a4f07be11c8d5","value":2}},"bbee9f37246645848d5d7a4a114e1114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a41a4105a2814334a9ca804b42f478de","placeholder":"​","style":"IPY_MODEL_612f4e06b09949eb9722144b409f6d8c","value":" 2.00/2.00 [00:00&lt;00:00, 73.0B/s]"}},"85e3d84e07694cd8b313dd1d8832ec91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb01501f49e04c3580534ebc8b425ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86249bff82b04da7bb25f251b35f1db3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b58541e936e94ad09b919696c8c2c35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46d17e86ab574419a98a4f07be11c8d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a41a4105a2814334a9ca804b42f478de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"612f4e06b09949eb9722144b409f6d8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50561c2392a6483da84891df594e7a0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_153d2b7cceb14082b8e113ae0facb246","IPY_MODEL_3eb7525bfcb342808f59cec9112d0b91","IPY_MODEL_b34004ee5f3340fda946db85bb4543d6"],"layout":"IPY_MODEL_b92f0c98b36a49b3a64daa95f3aae2dc"}},"153d2b7cceb14082b8e113ae0facb246":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c2d63a624f448f89af1656ea5b912c3","placeholder":"​","style":"IPY_MODEL_eca65f23d0444457b09fa563ba24405d","value":"Downloading (…)lve/main/config.json: 100%"}},"3eb7525bfcb342808f59cec9112d0b91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf0f1ed09ac44f18931a0c0bdb164a1f","max":1542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_385694d10b7f40409ef70c152b99111e","value":1542}},"b34004ee5f3340fda946db85bb4543d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1ce6f9c1ac1427bbcceefd3fbb754d2","placeholder":"​","style":"IPY_MODEL_78b2c606a73e44e9a350d53e832aedf1","value":" 1.54k/1.54k [00:00&lt;00:00, 70.4kB/s]"}},"b92f0c98b36a49b3a64daa95f3aae2dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c2d63a624f448f89af1656ea5b912c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eca65f23d0444457b09fa563ba24405d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf0f1ed09ac44f18931a0c0bdb164a1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"385694d10b7f40409ef70c152b99111e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1ce6f9c1ac1427bbcceefd3fbb754d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78b2c606a73e44e9a350d53e832aedf1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ff5fd193356486797114dea880c2d1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efcbe723dc9c4ab49c4851c112a7699a","IPY_MODEL_5b4818ecacd64e68abaad6981e938b58","IPY_MODEL_661f9b5b145d43f989b24127c57a996f"],"layout":"IPY_MODEL_c920a52c755745dc904ffb62c5757788"}},"efcbe723dc9c4ab49c4851c112a7699a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9231e25cdae4ef1a5273ef454e1ca0d","placeholder":"​","style":"IPY_MODEL_d852a055bf7a474aa98aab34ff3a93ad","value":"Downloading pytorch_model.bin: 100%"}},"5b4818ecacd64e68abaad6981e938b58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d93c8a6e2c034aaa8b2d98341505d3bf","max":46739879,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2772b1ad0fde48a9a37ecb8ec5ecdcbb","value":46739879}},"661f9b5b145d43f989b24127c57a996f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2697a5c1d84143edb59ef63003242b56","placeholder":"​","style":"IPY_MODEL_9a515ea53654401289d150000d16f8e9","value":" 46.7M/46.7M [00:00&lt;00:00, 49.1MB/s]"}},"c920a52c755745dc904ffb62c5757788":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9231e25cdae4ef1a5273ef454e1ca0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d852a055bf7a474aa98aab34ff3a93ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d93c8a6e2c034aaa8b2d98341505d3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2772b1ad0fde48a9a37ecb8ec5ecdcbb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2697a5c1d84143edb59ef63003242b56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a515ea53654401289d150000d16f8e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}