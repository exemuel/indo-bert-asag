{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3143,"status":"ok","timestamp":1680434655732,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"50S27W_Vj_Bi","outputId":"32ff3814-9eda-4dfd-92d9-c517eb85ae42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17616,"status":"ok","timestamp":1680434673343,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"frHag4z7kGdZ","outputId":"2c557d25-a5cc-4971-9074-94cde4f049b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n"]}],"source":["pip install sastrawi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7553,"status":"ok","timestamp":1680434680888,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"kk8ilth6kH1d","outputId":"356fc46a-04db-42b8-e3c9-a9fa89fd5984"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk) (1.16.0)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3790,"status":"ok","timestamp":1680434684673,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"Ph17gJD0kKb4","outputId":"e80be054-6dc8-494e-acc6-9631a7355b66"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680434684674,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"gs4oMdsrkL3E","outputId":"0956660d-66df-4f97-b0f3-700ebef312c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9247,"status":"ok","timestamp":1680434693917,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"OGmxzhivkNRJ","outputId":"5c2da2c3-1032-4879-ab85-d8af40073f60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nlp_id in /usr/local/lib/python3.9/dist-packages (0.1.13.0)\n","Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.4.5)\n","Requirement already satisfied: scikit-learn==1.1.0 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (1.1.0)\n","Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.4.5->nlp_id) (1.16.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.22.4)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.10.1)\n"]}],"source":["pip install nlp_id"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15495,"status":"ok","timestamp":1680434709402,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"K9ZXuJrokX-x","outputId":"1034a75d-bc51-4829-d975-0e9f9eade5a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"LEM8axq7kjkZ","executionInfo":{"status":"ok","timestamp":1680434727483,"user_tz":-420,"elapsed":18086,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["import re\n","import random\n","import pandas as pd\n","import torch\n","import tensorflow as tf\n","import numpy as np\n","\n","from nlp_id.lemmatizer import Lemmatizer\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.metrics import f1_score, cohen_kappa_score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from nltk.corpus import stopwords\n","\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def qwk_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return cohen_kappa_score(labels_flat, preds_flat)\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","\n","def evaluate(dataloader_val, device, model):\n","\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_val:\n","\n","        batch = tuple(b.to(device) for b in batch)\n","\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total/len(dataloader_val)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals\n","\n","def train_eval(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False, duplicates='drop')\n","\n","    # concatenate soal and jawaban\n","    df_final['soal-jawaban'] = df_final['soal']+df_final['jawaban']\n","\n","    # preprocessing\n","    # lowercasing\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: x.lower())\n","    # lemmatization\n","    lemmatizer = Lemmatizer()\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: lemmatizer.lemmatize(x))\n","    # stopword removal\n","    list_stopwords = set(stopwords.words('indonesian'))\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: ' '.join([item for item in x.split() if item not in list_stopwords]))\n","    # punctuation removal\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwIDxQ2UklHF","executionInfo":{"status":"ok","timestamp":1680441279004,"user_tz":-420,"elapsed":6551534,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"d9b81510-40b7-4d86-bf3b-1bec4908fba1"},"outputs":[{"output_type":"stream","name":"stdout","text":["indobenchmark/indobert-lite-base-p2\n","Analisis Essay Grading Olahraga\n"]},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'pooler.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/111 [00:58<?, ?it/s, training_loss=0.562]\u001b[A\n","Epoch 1:   1%|          | 1/111 [00:58<1:46:41, 58.20s/it, training_loss=0.562]\u001b[A\n","Epoch 1:   1%|          | 1/111 [01:37<1:46:41, 58.20s/it, training_loss=0.605]\u001b[A\n","Epoch 1:   2%|▏         | 2/111 [01:37<1:25:25, 47.02s/it, training_loss=0.605]\u001b[A\n","Epoch 1:   2%|▏         | 2/111 [01:52<1:25:25, 47.02s/it, training_loss=1.033]\u001b[A\n","Epoch 1:   3%|▎         | 3/111 [01:52<58:10, 32.32s/it, training_loss=1.033]  \u001b[A\n","Epoch 1:   3%|▎         | 3/111 [02:05<58:10, 32.32s/it, training_loss=0.980]\u001b[A\n","Epoch 1:   4%|▎         | 4/111 [02:05<44:28, 24.94s/it, training_loss=0.980]\u001b[A\n","Epoch 1:   4%|▎         | 4/111 [02:17<44:28, 24.94s/it, training_loss=0.673]\u001b[A\n","Epoch 1:   5%|▍         | 5/111 [02:17<35:42, 20.21s/it, training_loss=0.673]\u001b[A\n","Epoch 1:   5%|▍         | 5/111 [02:34<35:42, 20.21s/it, training_loss=0.525]\u001b[A\n","Epoch 1:   5%|▌         | 6/111 [02:34<33:28, 19.13s/it, training_loss=0.525]\u001b[A\n","Epoch 1:   5%|▌         | 6/111 [02:49<33:28, 19.13s/it, training_loss=0.615]\u001b[A\n","Epoch 1:   6%|▋         | 7/111 [02:49<30:43, 17.72s/it, training_loss=0.615]\u001b[A\n","Epoch 1:   6%|▋         | 7/111 [03:03<30:43, 17.72s/it, training_loss=0.582]\u001b[A\n","Epoch 1:   7%|▋         | 8/111 [03:03<28:32, 16.63s/it, training_loss=0.582]\u001b[A\n","Epoch 1:   7%|▋         | 8/111 [03:15<28:32, 16.63s/it, training_loss=0.567]\u001b[A\n","Epoch 1:   8%|▊         | 9/111 [03:15<25:37, 15.08s/it, training_loss=0.567]\u001b[A\n","Epoch 1:   8%|▊         | 9/111 [03:29<25:37, 15.08s/it, training_loss=0.520]\u001b[A\n","Epoch 1:   9%|▉         | 10/111 [03:29<24:59, 14.84s/it, training_loss=0.520]\u001b[A\n","Epoch 1:   9%|▉         | 10/111 [03:44<24:59, 14.84s/it, training_loss=0.583]\u001b[A\n","Epoch 1:  10%|▉         | 11/111 [03:44<24:29, 14.70s/it, training_loss=0.583]\u001b[A\n","Epoch 1:  10%|▉         | 11/111 [03:57<24:29, 14.70s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  11%|█         | 12/111 [04:09<23:21, 14.16s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  12%|█▏        | 13/111 [04:09<22:14, 13.62s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  12%|█▏        | 13/111 [04:26<22:14, 13.62s/it, training_loss=0.895]\u001b[A\n","Epoch 1:  13%|█▎        | 14/111 [04:26<23:54, 14.79s/it, training_loss=0.895]\u001b[A\n","Epoch 1:  13%|█▎        | 14/111 [04:41<23:54, 14.79s/it, training_loss=0.470]\u001b[A\n","Epoch 1:  14%|█▎        | 15/111 [04:41<23:23, 14.62s/it, training_loss=0.470]\u001b[A\n","Epoch 1:  14%|█▎        | 15/111 [04:56<23:23, 14.62s/it, training_loss=0.533]\u001b[A\n","Epoch 1:  14%|█▍        | 16/111 [04:56<23:26, 14.80s/it, training_loss=0.533]\u001b[A\n","Epoch 1:  14%|█▍        | 16/111 [05:08<23:26, 14.80s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  15%|█▌        | 17/111 [05:08<22:01, 14.06s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  15%|█▌        | 17/111 [05:21<22:01, 14.06s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  16%|█▌        | 18/111 [05:21<21:03, 13.59s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  16%|█▌        | 18/111 [05:35<21:03, 13.59s/it, training_loss=0.712]\u001b[A\n","Epoch 1:  17%|█▋        | 19/111 [05:35<20:58, 13.68s/it, training_loss=0.712]\u001b[A\n","Epoch 1:  17%|█▋        | 19/111 [05:49<20:58, 13.68s/it, training_loss=0.794]\u001b[A\n","Epoch 1:  18%|█▊        | 20/111 [05:49<20:57, 13.82s/it, training_loss=0.794]\u001b[A\n","Epoch 1:  18%|█▊        | 20/111 [06:02<20:57, 13.82s/it, training_loss=0.756]\u001b[A\n","Epoch 1:  19%|█▉        | 21/111 [06:02<20:32, 13.69s/it, training_loss=0.756]\u001b[A\n","Epoch 1:  19%|█▉        | 21/111 [06:17<20:32, 13.69s/it, training_loss=0.644]\u001b[A\n","Epoch 1:  20%|█▉        | 22/111 [06:17<20:37, 13.91s/it, training_loss=0.644]\u001b[A\n","Epoch 1:  20%|█▉        | 22/111 [06:30<20:37, 13.91s/it, training_loss=0.487]\u001b[A\n","Epoch 1:  21%|██        | 23/111 [06:30<20:11, 13.76s/it, training_loss=0.487]\u001b[A\n","Epoch 1:  21%|██        | 23/111 [06:44<20:11, 13.76s/it, training_loss=0.664]\u001b[A\n","Epoch 1:  22%|██▏       | 24/111 [06:44<20:13, 13.94s/it, training_loss=0.664]\u001b[A\n","Epoch 1:  22%|██▏       | 24/111 [06:59<20:13, 13.94s/it, training_loss=0.501]\u001b[A\n","Epoch 1:  23%|██▎       | 25/111 [06:59<20:09, 14.07s/it, training_loss=0.501]\u001b[A\n","Epoch 1:  23%|██▎       | 25/111 [07:12<20:09, 14.07s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  23%|██▎       | 26/111 [07:12<19:26, 13.73s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  23%|██▎       | 26/111 [07:24<19:26, 13.73s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  24%|██▍       | 27/111 [07:24<18:42, 13.36s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  24%|██▍       | 27/111 [07:38<18:42, 13.36s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  25%|██▌       | 28/111 [07:38<18:48, 13.59s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  25%|██▌       | 28/111 [07:53<18:48, 13.59s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  26%|██▌       | 29/111 [07:53<18:51, 13.80s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  26%|██▌       | 29/111 [08:06<18:51, 13.80s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  27%|██▋       | 30/111 [08:06<18:33, 13.75s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  27%|██▋       | 30/111 [08:18<18:33, 13.75s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  28%|██▊       | 31/111 [08:18<17:36, 13.21s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  28%|██▊       | 31/111 [08:32<17:36, 13.21s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  29%|██▉       | 32/111 [08:32<17:46, 13.50s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  29%|██▉       | 32/111 [08:47<17:46, 13.50s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  30%|██▉       | 33/111 [08:47<17:55, 13.79s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  30%|██▉       | 33/111 [09:04<17:55, 13.79s/it, training_loss=0.696]\u001b[A\n","Epoch 1:  31%|███       | 34/111 [09:04<19:00, 14.82s/it, training_loss=0.696]\u001b[A\n","Epoch 1:  31%|███       | 34/111 [09:17<19:00, 14.82s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  32%|███▏      | 35/111 [09:17<17:59, 14.20s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  32%|███▏      | 35/111 [09:29<17:59, 14.20s/it, training_loss=0.479]\u001b[A\n","Epoch 1:  32%|███▏      | 36/111 [09:29<17:10, 13.74s/it, training_loss=0.479]\u001b[A\n","Epoch 1:  32%|███▏      | 36/111 [09:44<17:10, 13.74s/it, training_loss=0.733]\u001b[A\n","Epoch 1:  33%|███▎      | 37/111 [09:44<17:10, 13.92s/it, training_loss=0.733]\u001b[A\n","Epoch 1:  33%|███▎      | 37/111 [09:58<17:10, 13.92s/it, training_loss=0.495]\u001b[A\n","Epoch 1:  34%|███▍      | 38/111 [09:58<17:04, 14.04s/it, training_loss=0.495]\u001b[A\n","Epoch 1:  34%|███▍      | 38/111 [10:12<17:04, 14.04s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  35%|███▌      | 39/111 [10:12<16:48, 14.00s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  35%|███▌      | 39/111 [10:24<16:48, 14.00s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  36%|███▌      | 40/111 [10:24<15:47, 13.35s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  36%|███▌      | 40/111 [10:38<15:47, 13.35s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  37%|███▋      | 41/111 [10:38<15:43, 13.47s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  37%|███▋      | 41/111 [10:52<15:43, 13.47s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  38%|███▊      | 42/111 [10:52<15:48, 13.75s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  38%|███▊      | 42/111 [11:06<15:48, 13.75s/it, training_loss=0.748]\u001b[A\n","Epoch 1:  39%|███▊      | 43/111 [11:06<15:49, 13.96s/it, training_loss=0.748]\u001b[A\n","Epoch 1:  39%|███▊      | 43/111 [11:19<15:49, 13.96s/it, training_loss=0.589]\u001b[A\n","Epoch 1:  40%|███▉      | 44/111 [11:19<14:57, 13.39s/it, training_loss=0.589]\u001b[A\n","Epoch 1:  40%|███▉      | 44/111 [11:31<14:57, 13.39s/it, training_loss=0.794]\u001b[A\n","Epoch 1:  41%|████      | 45/111 [11:31<14:34, 13.25s/it, training_loss=0.794]\u001b[A\n","Epoch 1:  41%|████      | 45/111 [11:46<14:34, 13.25s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  41%|████▏     | 46/111 [11:46<14:43, 13.59s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  41%|████▏     | 46/111 [12:00<14:43, 13.59s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  42%|████▏     | 47/111 [12:00<14:43, 13.81s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  42%|████▏     | 47/111 [12:12<14:43, 13.81s/it, training_loss=0.437]\u001b[A\n","Epoch 1:  43%|████▎     | 48/111 [12:12<13:57, 13.29s/it, training_loss=0.437]\u001b[A\n","Epoch 1:  43%|████▎     | 48/111 [12:25<13:57, 13.29s/it, training_loss=0.525]\u001b[A\n","Epoch 1:  44%|████▍     | 49/111 [12:25<13:34, 13.14s/it, training_loss=0.525]\u001b[A\n","Epoch 1:  44%|████▍     | 49/111 [12:39<13:34, 13.14s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  45%|████▌     | 50/111 [12:39<13:45, 13.54s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  45%|████▌     | 50/111 [12:54<13:45, 13.54s/it, training_loss=0.608]\u001b[A\n","Epoch 1:  46%|████▌     | 51/111 [12:54<13:51, 13.85s/it, training_loss=0.608]\u001b[A\n","Epoch 1:  46%|████▌     | 51/111 [13:07<13:51, 13.85s/it, training_loss=0.468]\u001b[A\n","Epoch 1:  47%|████▋     | 52/111 [13:07<13:18, 13.53s/it, training_loss=0.468]\u001b[A\n","Epoch 1:  47%|████▋     | 52/111 [13:19<13:18, 13.53s/it, training_loss=0.583]\u001b[A\n","Epoch 1:  48%|████▊     | 53/111 [13:19<12:43, 13.16s/it, training_loss=0.583]\u001b[A\n","Epoch 1:  48%|████▊     | 53/111 [13:33<12:43, 13.16s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  49%|████▊     | 54/111 [13:33<12:43, 13.40s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  49%|████▊     | 54/111 [13:47<12:43, 13.40s/it, training_loss=0.504]\u001b[A\n","Epoch 1:  50%|████▉     | 55/111 [13:47<12:45, 13.67s/it, training_loss=0.504]\u001b[A\n","Epoch 1:  50%|████▉     | 55/111 [14:01<12:45, 13.67s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  50%|█████     | 56/111 [14:01<12:25, 13.56s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  50%|█████     | 56/111 [14:13<12:25, 13.56s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  51%|█████▏    | 57/111 [14:13<11:49, 13.14s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  51%|█████▏    | 57/111 [14:27<11:49, 13.14s/it, training_loss=0.558]\u001b[A\n","Epoch 1:  52%|█████▏    | 58/111 [14:27<11:54, 13.49s/it, training_loss=0.558]\u001b[A\n","Epoch 1:  52%|█████▏    | 58/111 [14:42<11:54, 13.49s/it, training_loss=0.629]\u001b[A\n","Epoch 1:  53%|█████▎    | 59/111 [14:42<11:54, 13.75s/it, training_loss=0.629]\u001b[A\n","Epoch 1:  53%|█████▎    | 59/111 [14:56<11:54, 13.75s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  54%|█████▍    | 60/111 [14:56<11:48, 13.88s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  54%|█████▍    | 60/111 [15:08<11:48, 13.88s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  55%|█████▍    | 61/111 [15:08<11:06, 13.33s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  55%|█████▍    | 61/111 [15:22<11:06, 13.33s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  56%|█████▌    | 62/111 [15:22<11:02, 13.51s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  56%|█████▌    | 62/111 [15:36<11:02, 13.51s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  57%|█████▋    | 63/111 [15:36<11:02, 13.80s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  57%|█████▋    | 63/111 [15:51<11:02, 13.80s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  58%|█████▊    | 64/111 [15:51<10:58, 14.01s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  58%|█████▊    | 64/111 [16:03<10:58, 14.01s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  59%|█████▊    | 65/111 [16:03<10:25, 13.59s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  59%|█████▊    | 65/111 [16:16<10:25, 13.59s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  59%|█████▉    | 66/111 [16:16<10:01, 13.36s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  59%|█████▉    | 66/111 [16:31<10:01, 13.36s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  60%|██████    | 67/111 [16:31<10:03, 13.72s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  60%|██████    | 67/111 [16:45<10:03, 13.72s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  61%|██████▏   | 68/111 [16:45<09:59, 13.95s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  61%|██████▏   | 68/111 [16:58<09:59, 13.95s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  62%|██████▏   | 69/111 [16:58<09:33, 13.64s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  62%|██████▏   | 69/111 [17:10<09:33, 13.64s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  63%|██████▎   | 70/111 [17:10<09:01, 13.22s/it, training_loss=0.486]\u001b[A\n","Epoch 1:  63%|██████▎   | 70/111 [17:24<09:01, 13.22s/it, training_loss=0.540]\u001b[A\n","Epoch 1:  64%|██████▍   | 71/111 [17:24<09:00, 13.51s/it, training_loss=0.540]\u001b[A\n","Epoch 1:  64%|██████▍   | 71/111 [17:39<09:00, 13.51s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  65%|██████▍   | 72/111 [17:39<08:59, 13.84s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  65%|██████▍   | 72/111 [17:53<08:59, 13.84s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  66%|██████▌   | 73/111 [17:53<08:43, 13.77s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  66%|██████▌   | 73/111 [18:05<08:43, 13.77s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  67%|██████▋   | 74/111 [18:05<08:12, 13.31s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  67%|██████▋   | 74/111 [18:19<08:12, 13.31s/it, training_loss=0.423]\u001b[A\n","Epoch 1:  68%|██████▊   | 75/111 [18:19<08:11, 13.65s/it, training_loss=0.423]\u001b[A\n","Epoch 1:  68%|██████▊   | 75/111 [18:34<08:11, 13.65s/it, training_loss=0.474]\u001b[A\n","Epoch 1:  68%|██████▊   | 76/111 [18:34<08:03, 13.83s/it, training_loss=0.474]\u001b[A\n","Epoch 1:  68%|██████▊   | 76/111 [18:47<08:03, 13.83s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  69%|██████▉   | 77/111 [18:47<07:50, 13.83s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  69%|██████▉   | 77/111 [19:01<07:50, 13.83s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  70%|███████   | 78/111 [19:01<07:34, 13.79s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  70%|███████   | 78/111 [19:16<07:34, 13.79s/it, training_loss=0.474]\u001b[A\n","Epoch 1:  71%|███████   | 79/111 [19:16<07:28, 14.03s/it, training_loss=0.474]\u001b[A\n","Epoch 1:  71%|███████   | 79/111 [19:30<07:28, 14.03s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  72%|███████▏  | 80/111 [19:30<07:18, 14.14s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  72%|███████▏  | 80/111 [19:45<07:18, 14.14s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  73%|███████▎  | 81/111 [19:45<07:06, 14.22s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  73%|███████▎  | 81/111 [19:58<07:06, 14.22s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  74%|███████▍  | 82/111 [19:58<06:44, 13.95s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  74%|███████▍  | 82/111 [20:10<06:44, 13.95s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  75%|███████▍  | 83/111 [20:10<06:15, 13.42s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  75%|███████▍  | 83/111 [20:24<06:15, 13.42s/it, training_loss=0.481]\u001b[A\n","Epoch 1:  76%|███████▌  | 84/111 [20:24<06:09, 13.68s/it, training_loss=0.481]\u001b[A\n","Epoch 1:  76%|███████▌  | 84/111 [20:39<06:09, 13.68s/it, training_loss=0.678]\u001b[A\n","Epoch 1:  77%|███████▋  | 85/111 [20:39<06:01, 13.89s/it, training_loss=0.678]\u001b[A\n","Epoch 1:  77%|███████▋  | 85/111 [20:53<06:01, 13.89s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  77%|███████▋  | 86/111 [20:53<05:48, 13.93s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  77%|███████▋  | 86/111 [21:05<05:48, 13.93s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  78%|███████▊  | 87/111 [21:05<05:20, 13.36s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  78%|███████▊  | 87/111 [21:19<05:20, 13.36s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  79%|███████▉  | 88/111 [21:19<05:10, 13.48s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  79%|███████▉  | 88/111 [21:33<05:10, 13.48s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  80%|████████  | 89/111 [21:33<05:01, 13.72s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  80%|████████  | 89/111 [21:47<05:01, 13.72s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  81%|████████  | 90/111 [21:47<04:50, 13.83s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  81%|████████  | 90/111 [21:59<04:50, 13.83s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  82%|████████▏ | 91/111 [21:59<04:27, 13.36s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  82%|████████▏ | 91/111 [22:12<04:27, 13.36s/it, training_loss=0.457]\u001b[A\n","Epoch 1:  83%|████████▎ | 92/111 [22:12<04:11, 13.25s/it, training_loss=0.457]\u001b[A\n","Epoch 1:  83%|████████▎ | 92/111 [22:26<04:11, 13.25s/it, training_loss=0.448]\u001b[A\n","Epoch 1:  84%|████████▍ | 93/111 [22:26<04:03, 13.55s/it, training_loss=0.448]\u001b[A\n","Epoch 1:  84%|████████▍ | 93/111 [22:41<04:03, 13.55s/it, training_loss=0.674]\u001b[A\n","Epoch 1:  85%|████████▍ | 94/111 [22:41<03:53, 13.75s/it, training_loss=0.674]\u001b[A\n","Epoch 1:  85%|████████▍ | 94/111 [22:53<03:53, 13.75s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  86%|████████▌ | 95/111 [22:53<03:34, 13.40s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  86%|████████▌ | 95/111 [23:06<03:34, 13.40s/it, training_loss=0.537]\u001b[A\n","Epoch 1:  86%|████████▋ | 96/111 [23:06<03:17, 13.19s/it, training_loss=0.537]\u001b[A\n","Epoch 1:  86%|████████▋ | 96/111 [23:20<03:17, 13.19s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  87%|████████▋ | 97/111 [23:20<03:09, 13.53s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  87%|████████▋ | 97/111 [23:35<03:09, 13.53s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  88%|████████▊ | 98/111 [23:35<02:59, 13.81s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  88%|████████▊ | 98/111 [23:48<02:59, 13.81s/it, training_loss=0.568]\u001b[A\n","Epoch 1:  89%|████████▉ | 99/111 [23:48<02:45, 13.81s/it, training_loss=0.568]\u001b[A\n","Epoch 1:  89%|████████▉ | 99/111 [24:01<02:45, 13.81s/it, training_loss=0.608]\u001b[A\n","Epoch 1:  90%|█████████ | 100/111 [24:01<02:26, 13.28s/it, training_loss=0.608]\u001b[A\n","Epoch 1:  90%|█████████ | 100/111 [24:14<02:26, 13.28s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  91%|█████████ | 101/111 [24:14<02:14, 13.44s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  91%|█████████ | 101/111 [24:28<02:14, 13.44s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  92%|█████████▏| 102/111 [24:28<02:02, 13.63s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  92%|█████████▏| 102/111 [24:42<02:02, 13.63s/it, training_loss=0.565]\u001b[A\n","Epoch 1:  93%|█████████▎| 103/111 [24:42<01:49, 13.71s/it, training_loss=0.565]\u001b[A\n","Epoch 1:  93%|█████████▎| 103/111 [24:54<01:49, 13.71s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  94%|█████████▎| 104/111 [24:54<01:32, 13.20s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  94%|█████████▎| 104/111 [25:08<01:32, 13.20s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  95%|█████████▍| 105/111 [25:08<01:20, 13.41s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  95%|█████████▍| 105/111 [25:22<01:20, 13.41s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  95%|█████████▌| 106/111 [25:22<01:08, 13.67s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  95%|█████████▌| 106/111 [25:37<01:08, 13.67s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  96%|█████████▋| 107/111 [25:37<00:55, 13.84s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  96%|█████████▋| 107/111 [25:49<00:55, 13.84s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  97%|█████████▋| 108/111 [25:49<00:40, 13.36s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  97%|█████████▋| 108/111 [26:02<00:40, 13.36s/it, training_loss=0.567]\u001b[A\n","Epoch 1:  98%|█████████▊| 109/111 [26:02<00:26, 13.28s/it, training_loss=0.567]\u001b[A\n","Epoch 1:  98%|█████████▊| 109/111 [26:16<00:26, 13.28s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  99%|█████████▉| 110/111 [26:16<00:13, 13.56s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  99%|█████████▉| 110/111 [26:27<00:13, 13.56s/it, training_loss=0.497]\u001b[A\n","Epoch 1: 100%|██████████| 111/111 [26:27<00:00, 12.75s/it, training_loss=0.497]\u001b[A\n","  0%|          | 0/4 [26:27<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.723011159682059\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [28:20<1:25:01, 1700.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.5680969485214777\n","F1 Score (Weighted): 0.20524370524370522\n","QWK Score: 0.13690944881889755\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/111 [00:14<?, ?it/s, training_loss=0.445]\u001b[A\n","Epoch 2:   1%|          | 1/111 [00:14<26:03, 14.21s/it, training_loss=0.445]\u001b[A\n","Epoch 2:   1%|          | 1/111 [00:26<26:03, 14.21s/it, training_loss=0.542]\u001b[A\n","Epoch 2:   2%|▏         | 2/111 [00:26<24:06, 13.27s/it, training_loss=0.542]\u001b[A\n","Epoch 2:   2%|▏         | 2/111 [00:39<24:06, 13.27s/it, training_loss=0.406]\u001b[A\n","Epoch 2:   3%|▎         | 3/111 [00:39<23:16, 12.93s/it, training_loss=0.406]\u001b[A\n","Epoch 2:   3%|▎         | 3/111 [00:53<23:16, 12.93s/it, training_loss=0.669]\u001b[A\n","Epoch 2:   4%|▎         | 4/111 [00:53<23:55, 13.42s/it, training_loss=0.669]\u001b[A\n","Epoch 2:   4%|▎         | 4/111 [01:07<23:55, 13.42s/it, training_loss=0.521]\u001b[A\n","Epoch 2:   5%|▍         | 5/111 [01:07<24:01, 13.60s/it, training_loss=0.521]\u001b[A\n","Epoch 2:   5%|▍         | 5/111 [01:19<24:01, 13.60s/it, training_loss=0.578]\u001b[A\n","Epoch 2:   5%|▌         | 6/111 [01:19<23:06, 13.20s/it, training_loss=0.578]\u001b[A\n","Epoch 2:   5%|▌         | 6/111 [01:32<23:06, 13.20s/it, training_loss=0.539]\u001b[A\n","Epoch 2:   6%|▋         | 7/111 [01:32<22:17, 12.86s/it, training_loss=0.539]\u001b[A\n","Epoch 2:   6%|▋         | 7/111 [01:45<22:17, 12.86s/it, training_loss=0.602]\u001b[A\n","Epoch 2:   7%|▋         | 8/111 [01:45<22:36, 13.17s/it, training_loss=0.602]\u001b[A\n","Epoch 2:   7%|▋         | 8/111 [01:59<22:36, 13.17s/it, training_loss=0.646]\u001b[A\n","Epoch 2:   8%|▊         | 9/111 [02:00<22:54, 13.48s/it, training_loss=0.646]\u001b[A\n","Epoch 2:   8%|▊         | 9/111 [02:12<22:54, 13.48s/it, training_loss=0.539]\u001b[A\n","Epoch 2:   9%|▉         | 10/111 [02:12<22:18, 13.25s/it, training_loss=0.539]\u001b[A\n","Epoch 2:   9%|▉         | 10/111 [02:24<22:18, 13.25s/it, training_loss=0.430]\u001b[A\n","Epoch 2:  10%|▉         | 11/111 [02:24<21:32, 12.93s/it, training_loss=0.430]\u001b[A\n","Epoch 2:  10%|▉         | 11/111 [02:38<21:32, 12.93s/it, training_loss=0.422]\u001b[A\n","Epoch 2:  11%|█         | 12/111 [02:38<21:53, 13.26s/it, training_loss=0.422]\u001b[A\n","Epoch 2:  11%|█         | 12/111 [02:53<21:53, 13.26s/it, training_loss=0.562]\u001b[A\n","Epoch 2:  12%|█▏        | 13/111 [02:53<22:06, 13.54s/it, training_loss=0.562]\u001b[A\n","Epoch 2:  12%|█▏        | 13/111 [03:06<22:06, 13.54s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  13%|█▎        | 14/111 [03:06<21:45, 13.46s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  13%|█▎        | 14/111 [03:18<21:45, 13.46s/it, training_loss=0.576]\u001b[A\n","Epoch 2:  14%|█▎        | 15/111 [03:18<20:46, 12.99s/it, training_loss=0.576]\u001b[A\n","Epoch 2:  14%|█▎        | 15/111 [03:32<20:46, 12.99s/it, training_loss=0.625]\u001b[A\n","Epoch 2:  14%|█▍        | 16/111 [03:32<20:55, 13.22s/it, training_loss=0.625]\u001b[A\n","Epoch 2:  14%|█▍        | 16/111 [03:46<20:55, 13.22s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  15%|█▌        | 17/111 [03:46<21:05, 13.46s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  15%|█▌        | 17/111 [03:59<21:05, 13.46s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  16%|█▌        | 18/111 [03:59<20:51, 13.45s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  16%|█▌        | 18/111 [04:11<20:51, 13.45s/it, training_loss=0.493]\u001b[A\n","Epoch 2:  17%|█▋        | 19/111 [04:11<19:48, 12.92s/it, training_loss=0.493]\u001b[A\n","Epoch 2:  17%|█▋        | 19/111 [04:24<19:48, 12.92s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  18%|█▊        | 20/111 [04:24<19:51, 13.09s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  18%|█▊        | 20/111 [04:38<19:51, 13.09s/it, training_loss=0.758]\u001b[A\n","Epoch 2:  19%|█▉        | 21/111 [04:38<20:08, 13.43s/it, training_loss=0.758]\u001b[A\n","Epoch 2:  19%|█▉        | 21/111 [04:52<20:08, 13.43s/it, training_loss=0.577]\u001b[A\n","Epoch 2:  20%|█▉        | 22/111 [04:52<20:01, 13.50s/it, training_loss=0.577]\u001b[A\n","Epoch 2:  20%|█▉        | 22/111 [05:04<20:01, 13.50s/it, training_loss=0.518]\u001b[A\n","Epoch 2:  21%|██        | 23/111 [05:04<19:07, 13.03s/it, training_loss=0.518]\u001b[A\n","Epoch 2:  21%|██        | 23/111 [05:18<19:07, 13.03s/it, training_loss=0.507]\u001b[A\n","Epoch 2:  22%|██▏       | 24/111 [05:18<19:07, 13.19s/it, training_loss=0.507]\u001b[A\n","Epoch 2:  22%|██▏       | 24/111 [05:32<19:07, 13.19s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  23%|██▎       | 25/111 [05:32<19:16, 13.45s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  23%|██▎       | 25/111 [05:45<19:16, 13.45s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  23%|██▎       | 26/111 [05:45<19:06, 13.49s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  23%|██▎       | 26/111 [05:57<19:06, 13.49s/it, training_loss=0.463]\u001b[A\n","Epoch 2:  24%|██▍       | 27/111 [05:57<18:08, 12.95s/it, training_loss=0.463]\u001b[A\n","Epoch 2:  24%|██▍       | 27/111 [06:11<18:08, 12.95s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  25%|██▌       | 28/111 [06:11<18:11, 13.15s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  25%|██▌       | 28/111 [06:24<18:11, 13.15s/it, training_loss=0.500]\u001b[A\n","Epoch 2:  26%|██▌       | 29/111 [06:24<18:17, 13.38s/it, training_loss=0.500]\u001b[A\n","Epoch 2:  26%|██▌       | 29/111 [06:39<18:17, 13.38s/it, training_loss=0.381]\u001b[A\n","Epoch 2:  27%|██▋       | 30/111 [06:39<18:21, 13.59s/it, training_loss=0.381]\u001b[A\n","Epoch 2:  27%|██▋       | 30/111 [06:50<18:21, 13.59s/it, training_loss=0.542]\u001b[A\n","Epoch 2:  28%|██▊       | 31/111 [06:50<17:10, 12.88s/it, training_loss=0.542]\u001b[A\n","Epoch 2:  28%|██▊       | 31/111 [07:04<17:10, 12.88s/it, training_loss=0.530]\u001b[A\n","Epoch 2:  29%|██▉       | 32/111 [07:04<17:19, 13.16s/it, training_loss=0.530]\u001b[A\n","Epoch 2:  29%|██▉       | 32/111 [07:18<17:19, 13.16s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  30%|██▉       | 33/111 [07:18<17:36, 13.54s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  30%|██▉       | 33/111 [07:32<17:36, 13.54s/it, training_loss=0.610]\u001b[A\n","Epoch 2:  31%|███       | 34/111 [07:32<17:39, 13.76s/it, training_loss=0.610]\u001b[A\n","Epoch 2:  31%|███       | 34/111 [07:44<17:39, 13.76s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  32%|███▏      | 35/111 [07:44<16:48, 13.27s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  32%|███▏      | 35/111 [07:57<16:48, 13.27s/it, training_loss=0.338]\u001b[A\n","Epoch 2:  32%|███▏      | 36/111 [07:57<16:23, 13.11s/it, training_loss=0.338]\u001b[A\n","Epoch 2:  32%|███▏      | 36/111 [08:12<16:23, 13.11s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  33%|███▎      | 37/111 [08:12<16:38, 13.49s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  33%|███▎      | 37/111 [08:26<16:38, 13.49s/it, training_loss=0.617]\u001b[A\n","Epoch 2:  34%|███▍      | 38/111 [08:26<16:43, 13.75s/it, training_loss=0.617]\u001b[A\n","Epoch 2:  34%|███▍      | 38/111 [08:38<16:43, 13.75s/it, training_loss=0.230]\u001b[A\n","Epoch 2:  35%|███▌      | 39/111 [08:38<16:03, 13.39s/it, training_loss=0.230]\u001b[A\n","Epoch 2:  35%|███▌      | 39/111 [08:51<16:03, 13.39s/it, training_loss=0.428]\u001b[A\n","Epoch 2:  36%|███▌      | 40/111 [08:51<15:37, 13.20s/it, training_loss=0.428]\u001b[A\n","Epoch 2:  36%|███▌      | 40/111 [09:06<15:37, 13.20s/it, training_loss=0.456]\u001b[A\n","Epoch 2:  37%|███▋      | 41/111 [09:06<15:50, 13.58s/it, training_loss=0.456]\u001b[A\n","Epoch 2:  37%|███▋      | 41/111 [09:20<15:50, 13.58s/it, training_loss=0.127]\u001b[A\n","Epoch 2:  38%|███▊      | 42/111 [09:20<15:53, 13.82s/it, training_loss=0.127]\u001b[A\n","Epoch 2:  38%|███▊      | 42/111 [09:33<15:53, 13.82s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  39%|███▊      | 43/111 [09:33<15:30, 13.68s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  39%|███▊      | 43/111 [09:45<15:30, 13.68s/it, training_loss=0.352]\u001b[A\n","Epoch 2:  40%|███▉      | 44/111 [09:45<14:42, 13.18s/it, training_loss=0.352]\u001b[A\n","Epoch 2:  40%|███▉      | 44/111 [10:00<14:42, 13.18s/it, training_loss=0.379]\u001b[A\n","Epoch 2:  41%|████      | 45/111 [10:00<14:50, 13.49s/it, training_loss=0.379]\u001b[A\n","Epoch 2:  41%|████      | 45/111 [10:14<14:50, 13.49s/it, training_loss=0.479]\u001b[A\n","Epoch 2:  41%|████▏     | 46/111 [10:14<14:53, 13.75s/it, training_loss=0.479]\u001b[A\n","Epoch 2:  41%|████▏     | 46/111 [10:28<14:53, 13.75s/it, training_loss=0.284]\u001b[A\n","Epoch 2:  42%|████▏     | 47/111 [10:28<14:39, 13.74s/it, training_loss=0.284]\u001b[A\n","Epoch 2:  42%|████▏     | 47/111 [10:40<14:39, 13.74s/it, training_loss=0.341]\u001b[A\n","Epoch 2:  43%|████▎     | 48/111 [10:40<13:52, 13.21s/it, training_loss=0.341]\u001b[A\n","Epoch 2:  43%|████▎     | 48/111 [10:53<13:52, 13.21s/it, training_loss=0.516]\u001b[A\n","Epoch 2:  44%|████▍     | 49/111 [10:53<13:45, 13.32s/it, training_loss=0.516]\u001b[A\n","Epoch 2:  44%|████▍     | 49/111 [11:08<13:45, 13.32s/it, training_loss=0.415]\u001b[A\n","Epoch 2:  45%|████▌     | 50/111 [11:08<13:50, 13.61s/it, training_loss=0.415]\u001b[A\n","Epoch 2:  45%|████▌     | 50/111 [11:22<13:50, 13.61s/it, training_loss=0.469]\u001b[A\n","Epoch 2:  46%|████▌     | 51/111 [11:22<13:46, 13.77s/it, training_loss=0.469]\u001b[A\n","Epoch 2:  46%|████▌     | 51/111 [11:34<13:46, 13.77s/it, training_loss=0.402]\u001b[A\n","Epoch 2:  47%|████▋     | 52/111 [11:34<13:01, 13.25s/it, training_loss=0.402]\u001b[A\n","Epoch 2:  47%|████▋     | 52/111 [11:47<13:01, 13.25s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  48%|████▊     | 53/111 [11:47<12:42, 13.14s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  48%|████▊     | 53/111 [12:01<12:42, 13.14s/it, training_loss=0.576]\u001b[A\n","Epoch 2:  49%|████▊     | 54/111 [12:01<12:45, 13.43s/it, training_loss=0.576]\u001b[A\n","Epoch 2:  49%|████▊     | 54/111 [12:15<12:45, 13.43s/it, training_loss=0.648]\u001b[A\n","Epoch 2:  50%|████▉     | 55/111 [12:15<12:41, 13.59s/it, training_loss=0.648]\u001b[A\n","Epoch 2:  50%|████▉     | 55/111 [12:27<12:41, 13.59s/it, training_loss=0.582]\u001b[A\n","Epoch 2:  50%|█████     | 56/111 [12:27<12:10, 13.29s/it, training_loss=0.582]\u001b[A\n","Epoch 2:  50%|█████     | 56/111 [12:40<12:10, 13.29s/it, training_loss=0.398]\u001b[A\n","Epoch 2:  51%|█████▏    | 57/111 [12:40<11:47, 13.10s/it, training_loss=0.398]\u001b[A\n","Epoch 2:  51%|█████▏    | 57/111 [12:54<11:47, 13.10s/it, training_loss=0.524]\u001b[A\n","Epoch 2:  52%|█████▏    | 58/111 [12:54<11:53, 13.47s/it, training_loss=0.524]\u001b[A\n","Epoch 2:  52%|█████▏    | 58/111 [13:08<11:53, 13.47s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  53%|█████▎    | 59/111 [13:08<11:52, 13.69s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  53%|█████▎    | 59/111 [13:22<11:52, 13.69s/it, training_loss=0.364]\u001b[A\n","Epoch 2:  54%|█████▍    | 60/111 [13:22<11:35, 13.63s/it, training_loss=0.364]\u001b[A\n","Epoch 2:  54%|█████▍    | 60/111 [13:34<11:35, 13.63s/it, training_loss=0.340]\u001b[A\n","Epoch 2:  55%|█████▍    | 61/111 [13:34<10:55, 13.11s/it, training_loss=0.340]\u001b[A\n","Epoch 2:  55%|█████▍    | 61/111 [13:48<10:55, 13.11s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  56%|█████▌    | 62/111 [13:48<10:59, 13.46s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  56%|█████▌    | 62/111 [14:02<10:59, 13.46s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  57%|█████▋    | 63/111 [14:02<10:58, 13.73s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  57%|█████▋    | 63/111 [14:16<10:58, 13.73s/it, training_loss=0.520]\u001b[A\n","Epoch 2:  58%|█████▊    | 64/111 [14:16<10:46, 13.75s/it, training_loss=0.520]\u001b[A\n","Epoch 2:  58%|█████▊    | 64/111 [14:28<10:46, 13.75s/it, training_loss=0.391]\u001b[A\n","Epoch 2:  59%|█████▊    | 65/111 [14:28<10:08, 13.23s/it, training_loss=0.391]\u001b[A\n","Epoch 2:  59%|█████▊    | 65/111 [14:42<10:08, 13.23s/it, training_loss=0.395]\u001b[A\n","Epoch 2:  59%|█████▉    | 66/111 [14:42<10:04, 13.43s/it, training_loss=0.395]\u001b[A\n","Epoch 2:  59%|█████▉    | 66/111 [14:56<10:04, 13.43s/it, training_loss=0.518]\u001b[A\n","Epoch 2:  60%|██████    | 67/111 [14:56<10:00, 13.66s/it, training_loss=0.518]\u001b[A\n","Epoch 2:  60%|██████    | 67/111 [15:11<10:00, 13.66s/it, training_loss=0.408]\u001b[A\n","Epoch 2:  61%|██████▏   | 68/111 [15:11<09:56, 13.87s/it, training_loss=0.408]\u001b[A\n","Epoch 2:  61%|██████▏   | 68/111 [15:23<09:56, 13.87s/it, training_loss=0.488]\u001b[A\n","Epoch 2:  62%|██████▏   | 69/111 [15:23<09:17, 13.27s/it, training_loss=0.488]\u001b[A\n","Epoch 2:  62%|██████▏   | 69/111 [15:36<09:17, 13.27s/it, training_loss=0.567]\u001b[A\n","Epoch 2:  63%|██████▎   | 70/111 [15:36<09:03, 13.25s/it, training_loss=0.567]\u001b[A\n","Epoch 2:  63%|██████▎   | 70/111 [15:50<09:03, 13.25s/it, training_loss=0.386]\u001b[A\n","Epoch 2:  64%|██████▍   | 71/111 [15:50<09:01, 13.53s/it, training_loss=0.386]\u001b[A\n","Epoch 2:  64%|██████▍   | 71/111 [16:04<09:01, 13.53s/it, training_loss=0.453]\u001b[A\n","Epoch 2:  65%|██████▍   | 72/111 [16:04<08:56, 13.76s/it, training_loss=0.453]\u001b[A\n","Epoch 2:  65%|██████▍   | 72/111 [16:17<08:56, 13.76s/it, training_loss=0.354]\u001b[A\n","Epoch 2:  66%|██████▌   | 73/111 [16:17<08:27, 13.35s/it, training_loss=0.354]\u001b[A\n","Epoch 2:  66%|██████▌   | 73/111 [16:29<08:27, 13.35s/it, training_loss=0.384]\u001b[A\n","Epoch 2:  67%|██████▋   | 74/111 [16:29<08:07, 13.17s/it, training_loss=0.384]\u001b[A\n","Epoch 2:  67%|██████▋   | 74/111 [16:44<08:07, 13.17s/it, training_loss=0.471]\u001b[A\n","Epoch 2:  68%|██████▊   | 75/111 [16:44<08:05, 13.49s/it, training_loss=0.471]\u001b[A\n","Epoch 2:  68%|██████▊   | 75/111 [16:58<08:05, 13.49s/it, training_loss=0.231]\u001b[A\n","Epoch 2:  68%|██████▊   | 76/111 [16:58<08:01, 13.76s/it, training_loss=0.231]\u001b[A\n","Epoch 2:  68%|██████▊   | 76/111 [17:11<08:01, 13.76s/it, training_loss=0.368]\u001b[A\n","Epoch 2:  69%|██████▉   | 77/111 [17:11<07:38, 13.49s/it, training_loss=0.368]\u001b[A\n","Epoch 2:  69%|██████▉   | 77/111 [17:23<07:38, 13.49s/it, training_loss=0.136]\u001b[A\n","Epoch 2:  70%|███████   | 78/111 [17:23<07:14, 13.17s/it, training_loss=0.136]\u001b[A\n","Epoch 2:  70%|███████   | 78/111 [17:37<07:14, 13.17s/it, training_loss=0.529]\u001b[A\n","Epoch 2:  71%|███████   | 79/111 [17:37<07:08, 13.39s/it, training_loss=0.529]\u001b[A\n","Epoch 2:  71%|███████   | 79/111 [17:51<07:08, 13.39s/it, training_loss=0.150]\u001b[A\n","Epoch 2:  72%|███████▏  | 80/111 [17:51<06:57, 13.48s/it, training_loss=0.150]\u001b[A\n","Epoch 2:  72%|███████▏  | 80/111 [18:03<06:57, 13.48s/it, training_loss=0.447]\u001b[A\n","Epoch 2:  73%|███████▎  | 81/111 [18:03<06:35, 13.19s/it, training_loss=0.447]\u001b[A\n","Epoch 2:  73%|███████▎  | 81/111 [18:16<06:35, 13.19s/it, training_loss=0.134]\u001b[A\n","Epoch 2:  74%|███████▍  | 82/111 [18:16<06:13, 12.87s/it, training_loss=0.134]\u001b[A\n","Epoch 2:  74%|███████▍  | 82/111 [18:29<06:13, 12.87s/it, training_loss=0.293]\u001b[A\n","Epoch 2:  75%|███████▍  | 83/111 [18:29<06:08, 13.16s/it, training_loss=0.293]\u001b[A\n","Epoch 2:  75%|███████▍  | 83/111 [18:44<06:08, 13.16s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  76%|███████▌  | 84/111 [18:44<06:05, 13.54s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  76%|███████▌  | 84/111 [18:57<06:05, 13.54s/it, training_loss=0.176]\u001b[A\n","Epoch 2:  77%|███████▋  | 85/111 [18:57<05:48, 13.39s/it, training_loss=0.176]\u001b[A\n","Epoch 2:  77%|███████▋  | 85/111 [19:09<05:48, 13.39s/it, training_loss=0.565]\u001b[A\n","Epoch 2:  77%|███████▋  | 86/111 [19:09<05:25, 13.00s/it, training_loss=0.565]\u001b[A\n","Epoch 2:  77%|███████▋  | 86/111 [19:23<05:25, 13.00s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  78%|███████▊  | 87/111 [19:23<05:18, 13.25s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  78%|███████▊  | 87/111 [19:37<05:18, 13.25s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  79%|███████▉  | 88/111 [19:37<05:10, 13.49s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  79%|███████▉  | 88/111 [19:50<05:10, 13.49s/it, training_loss=0.490]\u001b[A\n","Epoch 2:  80%|████████  | 89/111 [19:50<04:51, 13.27s/it, training_loss=0.490]\u001b[A\n","Epoch 2:  80%|████████  | 89/111 [20:01<04:51, 13.27s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  81%|████████  | 90/111 [20:01<04:27, 12.75s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  81%|████████  | 90/111 [20:15<04:27, 12.75s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  82%|████████▏ | 91/111 [20:15<04:23, 13.16s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  82%|████████▏ | 91/111 [20:29<04:23, 13.16s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  83%|████████▎ | 92/111 [20:29<04:14, 13.39s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  83%|████████▎ | 92/111 [20:42<04:14, 13.39s/it, training_loss=0.661]\u001b[A\n","Epoch 2:  84%|████████▍ | 93/111 [20:42<03:55, 13.11s/it, training_loss=0.661]\u001b[A\n","Epoch 2:  84%|████████▍ | 93/111 [20:54<03:55, 13.11s/it, training_loss=0.249]\u001b[A\n","Epoch 2:  85%|████████▍ | 94/111 [20:54<03:39, 12.93s/it, training_loss=0.249]\u001b[A\n","Epoch 2:  85%|████████▍ | 94/111 [21:08<03:39, 12.93s/it, training_loss=0.077]\u001b[A\n","Epoch 2:  86%|████████▌ | 95/111 [21:08<03:32, 13.28s/it, training_loss=0.077]\u001b[A\n","Epoch 2:  86%|████████▌ | 95/111 [21:22<03:32, 13.28s/it, training_loss=0.651]\u001b[A\n","Epoch 2:  86%|████████▋ | 96/111 [21:22<03:21, 13.46s/it, training_loss=0.651]\u001b[A\n","Epoch 2:  86%|████████▋ | 96/111 [21:34<03:21, 13.46s/it, training_loss=0.416]\u001b[A\n","Epoch 2:  87%|████████▋ | 97/111 [21:34<03:02, 13.06s/it, training_loss=0.416]\u001b[A\n","Epoch 2:  87%|████████▋ | 97/111 [21:47<03:02, 13.06s/it, training_loss=0.601]\u001b[A\n","Epoch 2:  88%|████████▊ | 98/111 [21:47<02:48, 12.96s/it, training_loss=0.601]\u001b[A\n","Epoch 2:  88%|████████▊ | 98/111 [22:01<02:48, 12.96s/it, training_loss=0.156]\u001b[A\n","Epoch 2:  89%|████████▉ | 99/111 [22:01<02:38, 13.24s/it, training_loss=0.156]\u001b[A\n","Epoch 2:  89%|████████▉ | 99/111 [22:15<02:38, 13.24s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  90%|█████████ | 100/111 [22:15<02:27, 13.45s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  90%|█████████ | 100/111 [22:27<02:27, 13.45s/it, training_loss=0.427]\u001b[A\n","Epoch 2:  91%|█████████ | 101/111 [22:27<02:11, 13.12s/it, training_loss=0.427]\u001b[A\n","Epoch 2:  91%|█████████ | 101/111 [22:40<02:11, 13.12s/it, training_loss=0.324]\u001b[A\n","Epoch 2:  92%|█████████▏| 102/111 [22:40<01:56, 12.96s/it, training_loss=0.324]\u001b[A\n","Epoch 2:  92%|█████████▏| 102/111 [22:54<01:56, 12.96s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  93%|█████████▎| 103/111 [22:54<01:45, 13.24s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  93%|█████████▎| 103/111 [23:08<01:45, 13.24s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  94%|█████████▎| 104/111 [23:08<01:34, 13.55s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  94%|█████████▎| 104/111 [23:21<01:34, 13.55s/it, training_loss=0.490]\u001b[A\n","Epoch 2:  95%|█████████▍| 105/111 [23:21<01:19, 13.32s/it, training_loss=0.490]\u001b[A\n","Epoch 2:  95%|█████████▍| 105/111 [23:33<01:19, 13.32s/it, training_loss=0.234]\u001b[A\n","Epoch 2:  95%|█████████▌| 106/111 [23:33<01:04, 12.89s/it, training_loss=0.234]\u001b[A\n","Epoch 2:  95%|█████████▌| 106/111 [23:47<01:04, 12.89s/it, training_loss=0.479]\u001b[A\n","Epoch 2:  96%|█████████▋| 107/111 [23:47<00:52, 13.20s/it, training_loss=0.479]\u001b[A\n","Epoch 2:  96%|█████████▋| 107/111 [24:01<00:52, 13.20s/it, training_loss=0.401]\u001b[A\n","Epoch 2:  97%|█████████▋| 108/111 [24:01<00:40, 13.50s/it, training_loss=0.401]\u001b[A\n","Epoch 2:  97%|█████████▋| 108/111 [24:14<00:40, 13.50s/it, training_loss=0.267]\u001b[A\n","Epoch 2:  98%|█████████▊| 109/111 [24:14<00:26, 13.33s/it, training_loss=0.267]\u001b[A\n","Epoch 2:  98%|█████████▊| 109/111 [24:26<00:26, 13.33s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  99%|█████████▉| 110/111 [24:26<00:12, 12.99s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  99%|█████████▉| 110/111 [24:38<00:12, 12.99s/it, training_loss=0.308]\u001b[A\n","Epoch 2: 100%|██████████| 111/111 [24:38<00:00, 12.60s/it, training_loss=0.308]\u001b[A\n"," 25%|██▌       | 1/4 [52:58<1:25:01, 1700.36s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.3276719990614299\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [54:51<54:32, 1636.40s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.0651129462889262\n","F1 Score (Weighted): 0.42947805640652764\n","QWK Score: 0.3579976067012365\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/111 [00:13<?, ?it/s, training_loss=0.146]\u001b[A\n","Epoch 3:   1%|          | 1/111 [00:13<25:30, 13.92s/it, training_loss=0.146]\u001b[A\n","Epoch 3:   1%|          | 1/111 [00:28<25:30, 13.92s/it, training_loss=0.274]\u001b[A\n","Epoch 3:   2%|▏         | 2/111 [00:28<25:32, 14.06s/it, training_loss=0.274]\u001b[A\n","Epoch 3:   2%|▏         | 2/111 [00:42<25:32, 14.06s/it, training_loss=0.424]\u001b[A\n","Epoch 3:   3%|▎         | 3/111 [00:42<25:14, 14.02s/it, training_loss=0.424]\u001b[A\n","Epoch 3:   3%|▎         | 3/111 [00:53<25:14, 14.02s/it, training_loss=0.174]\u001b[A\n","Epoch 3:   4%|▎         | 4/111 [00:53<23:08, 12.98s/it, training_loss=0.174]\u001b[A\n","Epoch 3:   4%|▎         | 4/111 [01:06<23:08, 12.98s/it, training_loss=0.371]\u001b[A\n","Epoch 3:   5%|▍         | 5/111 [01:06<23:10, 13.12s/it, training_loss=0.371]\u001b[A\n","Epoch 3:   5%|▍         | 5/111 [01:20<23:10, 13.12s/it, training_loss=0.241]\u001b[A\n","Epoch 3:   5%|▌         | 6/111 [01:20<23:34, 13.47s/it, training_loss=0.241]\u001b[A\n","Epoch 3:   5%|▌         | 6/111 [01:34<23:34, 13.47s/it, training_loss=0.289]\u001b[A\n","Epoch 3:   6%|▋         | 7/111 [01:34<23:32, 13.59s/it, training_loss=0.289]\u001b[A\n","Epoch 3:   6%|▋         | 7/111 [01:46<23:32, 13.59s/it, training_loss=0.633]\u001b[A\n","Epoch 3:   7%|▋         | 8/111 [01:46<22:19, 13.00s/it, training_loss=0.633]\u001b[A\n","Epoch 3:   7%|▋         | 8/111 [02:00<22:19, 13.00s/it, training_loss=0.128]\u001b[A\n","Epoch 3:   8%|▊         | 9/111 [02:00<22:27, 13.21s/it, training_loss=0.128]\u001b[A\n","Epoch 3:   8%|▊         | 9/111 [02:14<22:27, 13.21s/it, training_loss=0.400]\u001b[A\n","Epoch 3:   9%|▉         | 10/111 [02:14<22:47, 13.54s/it, training_loss=0.400]\u001b[A\n","Epoch 3:   9%|▉         | 10/111 [02:28<22:47, 13.54s/it, training_loss=0.214]\u001b[A\n","Epoch 3:  10%|▉         | 11/111 [02:28<22:46, 13.67s/it, training_loss=0.214]\u001b[A\n","Epoch 3:  10%|▉         | 11/111 [02:40<22:46, 13.67s/it, training_loss=0.198]\u001b[A\n","Epoch 3:  11%|█         | 12/111 [02:40<21:43, 13.16s/it, training_loss=0.198]\u001b[A\n","Epoch 3:  11%|█         | 12/111 [02:53<21:43, 13.16s/it, training_loss=0.257]\u001b[A\n","Epoch 3:  12%|█▏        | 13/111 [02:53<21:28, 13.15s/it, training_loss=0.257]\u001b[A\n","Epoch 3:  12%|█▏        | 13/111 [03:07<21:28, 13.15s/it, training_loss=0.186]\u001b[A\n","Epoch 3:  13%|█▎        | 14/111 [03:07<21:41, 13.42s/it, training_loss=0.186]\u001b[A\n","Epoch 3:  13%|█▎        | 14/111 [03:21<21:41, 13.42s/it, training_loss=0.183]\u001b[A\n","Epoch 3:  14%|█▎        | 15/111 [03:21<21:54, 13.69s/it, training_loss=0.183]\u001b[A\n","Epoch 3:  14%|█▎        | 15/111 [03:34<21:54, 13.69s/it, training_loss=0.253]\u001b[A\n","Epoch 3:  14%|█▍        | 16/111 [03:34<21:21, 13.49s/it, training_loss=0.253]\u001b[A\n","Epoch 3:  14%|█▍        | 16/111 [03:47<21:21, 13.49s/it, training_loss=0.416]\u001b[A\n","Epoch 3:  15%|█▌        | 17/111 [03:47<20:34, 13.13s/it, training_loss=0.416]\u001b[A\n","Epoch 3:  15%|█▌        | 17/111 [04:01<20:34, 13.13s/it, training_loss=0.377]\u001b[A\n","Epoch 3:  16%|█▌        | 18/111 [04:01<20:53, 13.48s/it, training_loss=0.377]\u001b[A\n","Epoch 3:  16%|█▌        | 18/111 [04:15<20:53, 13.48s/it, training_loss=0.328]\u001b[A\n","Epoch 3:  17%|█▋        | 19/111 [04:15<21:03, 13.74s/it, training_loss=0.328]\u001b[A\n","Epoch 3:  17%|█▋        | 19/111 [04:29<21:03, 13.74s/it, training_loss=0.389]\u001b[A\n","Epoch 3:  18%|█▊        | 20/111 [04:29<20:47, 13.71s/it, training_loss=0.389]\u001b[A\n","Epoch 3:  18%|█▊        | 20/111 [04:41<20:47, 13.71s/it, training_loss=0.473]\u001b[A\n","Epoch 3:  19%|█▉        | 21/111 [04:41<19:44, 13.16s/it, training_loss=0.473]\u001b[A\n","Epoch 3:  19%|█▉        | 21/111 [04:55<19:44, 13.16s/it, training_loss=0.295]\u001b[A\n","Epoch 3:  20%|█▉        | 22/111 [04:55<19:58, 13.47s/it, training_loss=0.295]\u001b[A\n","Epoch 3:  20%|█▉        | 22/111 [05:09<19:58, 13.47s/it, training_loss=0.490]\u001b[A\n","Epoch 3:  21%|██        | 23/111 [05:09<20:05, 13.70s/it, training_loss=0.490]\u001b[A\n","Epoch 3:  21%|██        | 23/111 [05:23<20:05, 13.70s/it, training_loss=0.877]\u001b[A\n","Epoch 3:  22%|██▏       | 24/111 [05:23<19:58, 13.78s/it, training_loss=0.877]\u001b[A\n","Epoch 3:  22%|██▏       | 24/111 [05:35<19:58, 13.78s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  23%|██▎       | 25/111 [05:35<18:54, 13.19s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  23%|██▎       | 25/111 [05:49<18:54, 13.19s/it, training_loss=0.392]\u001b[A\n","Epoch 3:  23%|██▎       | 26/111 [05:49<18:50, 13.31s/it, training_loss=0.392]\u001b[A\n","Epoch 3:  23%|██▎       | 26/111 [06:03<18:50, 13.31s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  24%|██▍       | 27/111 [06:03<19:00, 13.58s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  24%|██▍       | 27/111 [06:17<19:00, 13.58s/it, training_loss=0.551]\u001b[A\n","Epoch 3:  25%|██▌       | 28/111 [06:17<19:05, 13.80s/it, training_loss=0.551]\u001b[A\n","Epoch 3:  25%|██▌       | 28/111 [06:30<19:05, 13.80s/it, training_loss=0.105]\u001b[A\n","Epoch 3:  26%|██▌       | 29/111 [06:30<18:26, 13.49s/it, training_loss=0.105]\u001b[A\n","Epoch 3:  26%|██▌       | 29/111 [06:43<18:26, 13.49s/it, training_loss=0.330]\u001b[A\n","Epoch 3:  27%|██▋       | 30/111 [06:43<17:49, 13.21s/it, training_loss=0.330]\u001b[A\n","Epoch 3:  27%|██▋       | 30/111 [06:57<17:49, 13.21s/it, training_loss=0.328]\u001b[A\n","Epoch 3:  28%|██▊       | 31/111 [06:57<18:02, 13.53s/it, training_loss=0.328]\u001b[A\n","Epoch 3:  28%|██▊       | 31/111 [07:11<18:02, 13.53s/it, training_loss=0.385]\u001b[A\n","Epoch 3:  29%|██▉       | 32/111 [07:11<18:05, 13.73s/it, training_loss=0.385]\u001b[A\n","Epoch 3:  29%|██▉       | 32/111 [07:25<18:05, 13.73s/it, training_loss=0.111]\u001b[A\n","Epoch 3:  30%|██▉       | 33/111 [07:25<17:49, 13.71s/it, training_loss=0.111]\u001b[A\n","Epoch 3:  30%|██▉       | 33/111 [07:37<17:49, 13.71s/it, training_loss=0.379]\u001b[A\n","Epoch 3:  31%|███       | 34/111 [07:37<16:56, 13.20s/it, training_loss=0.379]\u001b[A\n","Epoch 3:  31%|███       | 34/111 [07:51<16:56, 13.20s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  32%|███▏      | 35/111 [07:51<17:02, 13.45s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  32%|███▏      | 35/111 [08:05<17:02, 13.45s/it, training_loss=0.021]\u001b[A\n","Epoch 3:  32%|███▏      | 36/111 [08:05<17:08, 13.71s/it, training_loss=0.021]\u001b[A\n","Epoch 3:  32%|███▏      | 36/111 [08:19<17:08, 13.71s/it, training_loss=0.551]\u001b[A\n","Epoch 3:  33%|███▎      | 37/111 [08:19<17:07, 13.89s/it, training_loss=0.551]\u001b[A\n","Epoch 3:  33%|███▎      | 37/111 [08:31<17:07, 13.89s/it, training_loss=0.461]\u001b[A\n","Epoch 3:  34%|███▍      | 38/111 [08:31<16:11, 13.30s/it, training_loss=0.461]\u001b[A\n","Epoch 3:  34%|███▍      | 38/111 [08:45<16:11, 13.30s/it, training_loss=0.204]\u001b[A\n","Epoch 3:  35%|███▌      | 39/111 [08:45<15:56, 13.29s/it, training_loss=0.204]\u001b[A\n","Epoch 3:  35%|███▌      | 39/111 [08:59<15:56, 13.29s/it, training_loss=0.704]\u001b[A\n","Epoch 3:  36%|███▌      | 40/111 [08:59<16:06, 13.61s/it, training_loss=0.704]\u001b[A\n","Epoch 3:  36%|███▌      | 40/111 [09:13<16:06, 13.61s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  37%|███▋      | 41/111 [09:13<16:10, 13.86s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  37%|███▋      | 41/111 [09:26<16:10, 13.86s/it, training_loss=0.414]\u001b[A\n","Epoch 3:  38%|███▊      | 42/111 [09:26<15:38, 13.60s/it, training_loss=0.414]\u001b[A\n","Epoch 3:  38%|███▊      | 42/111 [09:39<15:38, 13.60s/it, training_loss=0.304]\u001b[A\n","Epoch 3:  39%|███▊      | 43/111 [09:39<15:02, 13.28s/it, training_loss=0.304]\u001b[A\n","Epoch 3:  39%|███▊      | 43/111 [09:53<15:02, 13.28s/it, training_loss=0.430]\u001b[A\n","Epoch 3:  40%|███▉      | 44/111 [09:53<15:11, 13.61s/it, training_loss=0.430]\u001b[A\n","Epoch 3:  40%|███▉      | 44/111 [10:08<15:11, 13.61s/it, training_loss=0.401]\u001b[A\n","Epoch 3:  41%|████      | 45/111 [10:08<15:13, 13.85s/it, training_loss=0.401]\u001b[A\n","Epoch 3:  41%|████      | 45/111 [10:22<15:13, 13.85s/it, training_loss=0.274]\u001b[A\n","Epoch 3:  41%|████▏     | 46/111 [10:22<15:04, 13.91s/it, training_loss=0.274]\u001b[A\n","Epoch 3:  41%|████▏     | 46/111 [10:34<15:04, 13.91s/it, training_loss=0.284]\u001b[A\n","Epoch 3:  42%|████▏     | 47/111 [10:34<14:12, 13.33s/it, training_loss=0.284]\u001b[A\n","Epoch 3:  42%|████▏     | 47/111 [10:48<14:12, 13.33s/it, training_loss=0.271]\u001b[A\n","Epoch 3:  43%|████▎     | 48/111 [10:48<14:09, 13.49s/it, training_loss=0.271]\u001b[A\n","Epoch 3:  43%|████▎     | 48/111 [11:02<14:09, 13.49s/it, training_loss=0.133]\u001b[A\n","Epoch 3:  44%|████▍     | 49/111 [11:02<14:15, 13.79s/it, training_loss=0.133]\u001b[A\n","Epoch 3:  44%|████▍     | 49/111 [11:16<14:15, 13.79s/it, training_loss=0.654]\u001b[A\n","Epoch 3:  45%|████▌     | 50/111 [11:17<14:13, 13.99s/it, training_loss=0.654]\u001b[A\n","Epoch 3:  45%|████▌     | 50/111 [11:29<14:13, 13.99s/it, training_loss=0.273]\u001b[A\n","Epoch 3:  46%|████▌     | 51/111 [11:29<13:32, 13.54s/it, training_loss=0.273]\u001b[A\n","Epoch 3:  46%|████▌     | 51/111 [11:42<13:32, 13.54s/it, training_loss=0.178]\u001b[A\n","Epoch 3:  47%|████▋     | 52/111 [11:42<13:06, 13.34s/it, training_loss=0.178]\u001b[A\n","Epoch 3:  47%|████▋     | 52/111 [11:57<13:06, 13.34s/it, training_loss=0.387]\u001b[A\n","Epoch 3:  48%|████▊     | 53/111 [11:57<13:16, 13.74s/it, training_loss=0.387]\u001b[A\n","Epoch 3:  48%|████▊     | 53/111 [12:11<13:16, 13.74s/it, training_loss=0.363]\u001b[A\n","Epoch 3:  49%|████▊     | 54/111 [12:11<13:18, 14.01s/it, training_loss=0.363]\u001b[A\n","Epoch 3:  49%|████▊     | 54/111 [12:25<13:18, 14.01s/it, training_loss=0.669]\u001b[A\n","Epoch 3:  50%|████▉     | 55/111 [12:25<13:03, 14.00s/it, training_loss=0.669]\u001b[A\n","Epoch 3:  50%|████▉     | 55/111 [12:37<13:03, 14.00s/it, training_loss=0.353]\u001b[A\n","Epoch 3:  50%|█████     | 56/111 [12:37<12:22, 13.50s/it, training_loss=0.353]\u001b[A\n","Epoch 3:  50%|█████     | 56/111 [12:52<12:22, 13.50s/it, training_loss=0.296]\u001b[A\n","Epoch 3:  51%|█████▏    | 57/111 [12:52<12:22, 13.74s/it, training_loss=0.296]\u001b[A\n","Epoch 3:  51%|█████▏    | 57/111 [13:06<12:22, 13.74s/it, training_loss=0.587]\u001b[A\n","Epoch 3:  52%|█████▏    | 58/111 [13:06<12:19, 13.95s/it, training_loss=0.587]\u001b[A\n","Epoch 3:  52%|█████▏    | 58/111 [13:21<12:19, 13.95s/it, training_loss=0.466]\u001b[A\n","Epoch 3:  53%|█████▎    | 59/111 [13:21<12:10, 14.06s/it, training_loss=0.466]\u001b[A\n","Epoch 3:  53%|█████▎    | 59/111 [13:32<12:10, 14.06s/it, training_loss=0.461]\u001b[A\n","Epoch 3:  54%|█████▍    | 60/111 [13:32<11:24, 13.43s/it, training_loss=0.461]\u001b[A\n","Epoch 3:  54%|█████▍    | 60/111 [13:46<11:24, 13.43s/it, training_loss=0.208]\u001b[A\n","Epoch 3:  55%|█████▍    | 61/111 [13:46<11:11, 13.44s/it, training_loss=0.208]\u001b[A\n","Epoch 3:  55%|█████▍    | 61/111 [14:00<11:11, 13.44s/it, training_loss=0.491]\u001b[A\n","Epoch 3:  56%|█████▌    | 62/111 [14:00<11:10, 13.68s/it, training_loss=0.491]\u001b[A\n","Epoch 3:  56%|█████▌    | 62/111 [14:14<11:10, 13.68s/it, training_loss=0.441]\u001b[A\n","Epoch 3:  57%|█████▋    | 63/111 [14:14<11:05, 13.86s/it, training_loss=0.441]\u001b[A\n","Epoch 3:  57%|█████▋    | 63/111 [14:27<11:05, 13.86s/it, training_loss=0.470]\u001b[A\n","Epoch 3:  58%|█████▊    | 64/111 [14:27<10:35, 13.52s/it, training_loss=0.470]\u001b[A\n","Epoch 3:  58%|█████▊    | 64/111 [14:40<10:35, 13.52s/it, training_loss=0.183]\u001b[A\n","Epoch 3:  59%|█████▊    | 65/111 [14:40<10:12, 13.31s/it, training_loss=0.183]\u001b[A\n","Epoch 3:  59%|█████▊    | 65/111 [14:54<10:12, 13.31s/it, training_loss=0.491]\u001b[A\n","Epoch 3:  59%|█████▉    | 66/111 [14:54<10:09, 13.54s/it, training_loss=0.491]\u001b[A\n","Epoch 3:  59%|█████▉    | 66/111 [15:09<10:09, 13.54s/it, training_loss=0.430]\u001b[A\n","Epoch 3:  60%|██████    | 67/111 [15:09<10:07, 13.81s/it, training_loss=0.430]\u001b[A\n","Epoch 3:  60%|██████    | 67/111 [15:22<10:07, 13.81s/it, training_loss=0.229]\u001b[A\n","Epoch 3:  61%|██████▏   | 68/111 [15:22<09:48, 13.69s/it, training_loss=0.229]\u001b[A\n","Epoch 3:  61%|██████▏   | 68/111 [15:34<09:48, 13.69s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  62%|██████▏   | 69/111 [15:34<09:17, 13.27s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  62%|██████▏   | 69/111 [15:49<09:17, 13.27s/it, training_loss=0.637]\u001b[A\n","Epoch 3:  63%|██████▎   | 70/111 [15:49<09:17, 13.60s/it, training_loss=0.637]\u001b[A\n","Epoch 3:  63%|██████▎   | 70/111 [16:03<09:17, 13.60s/it, training_loss=0.493]\u001b[A\n","Epoch 3:  64%|██████▍   | 71/111 [16:03<09:16, 13.90s/it, training_loss=0.493]\u001b[A\n","Epoch 3:  64%|██████▍   | 71/111 [16:17<09:16, 13.90s/it, training_loss=0.907]\u001b[A\n","Epoch 3:  65%|██████▍   | 72/111 [16:17<09:01, 13.89s/it, training_loss=0.907]\u001b[A\n","Epoch 3:  65%|██████▍   | 72/111 [16:29<09:01, 13.89s/it, training_loss=0.429]\u001b[A\n","Epoch 3:  66%|██████▌   | 73/111 [16:29<08:26, 13.33s/it, training_loss=0.429]\u001b[A\n","Epoch 3:  66%|██████▌   | 73/111 [16:43<08:26, 13.33s/it, training_loss=0.114]\u001b[A\n","Epoch 3:  67%|██████▋   | 74/111 [16:43<08:15, 13.40s/it, training_loss=0.114]\u001b[A\n","Epoch 3:  67%|██████▋   | 74/111 [16:57<08:15, 13.40s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  68%|██████▊   | 75/111 [16:57<08:12, 13.68s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  68%|██████▊   | 75/111 [17:11<08:12, 13.68s/it, training_loss=0.292]\u001b[A\n","Epoch 3:  68%|██████▊   | 76/111 [17:11<08:06, 13.90s/it, training_loss=0.292]\u001b[A\n","Epoch 3:  68%|██████▊   | 76/111 [17:24<08:06, 13.90s/it, training_loss=0.302]\u001b[A\n","Epoch 3:  69%|██████▉   | 77/111 [17:24<07:38, 13.50s/it, training_loss=0.302]\u001b[A\n","Epoch 3:  69%|██████▉   | 77/111 [17:37<07:38, 13.50s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  70%|███████   | 78/111 [17:37<07:20, 13.34s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  70%|███████   | 78/111 [17:51<07:20, 13.34s/it, training_loss=0.482]\u001b[A\n","Epoch 3:  71%|███████   | 79/111 [17:51<07:16, 13.64s/it, training_loss=0.482]\u001b[A\n","Epoch 3:  71%|███████   | 79/111 [18:06<07:16, 13.64s/it, training_loss=0.346]\u001b[A\n","Epoch 3:  72%|███████▏  | 80/111 [18:06<07:09, 13.85s/it, training_loss=0.346]\u001b[A\n","Epoch 3:  72%|███████▏  | 80/111 [18:19<07:09, 13.85s/it, training_loss=0.309]\u001b[A\n","Epoch 3:  73%|███████▎  | 81/111 [18:19<06:51, 13.71s/it, training_loss=0.309]\u001b[A\n","Epoch 3:  73%|███████▎  | 81/111 [18:31<06:51, 13.71s/it, training_loss=0.330]\u001b[A\n","Epoch 3:  74%|███████▍  | 82/111 [18:31<06:21, 13.17s/it, training_loss=0.330]\u001b[A\n","Epoch 3:  74%|███████▍  | 82/111 [18:45<06:21, 13.17s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  75%|███████▍  | 83/111 [18:45<06:18, 13.53s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  75%|███████▍  | 83/111 [19:00<06:18, 13.53s/it, training_loss=0.263]\u001b[A\n","Epoch 3:  76%|███████▌  | 84/111 [19:00<06:12, 13.79s/it, training_loss=0.263]\u001b[A\n","Epoch 3:  76%|███████▌  | 84/111 [19:14<06:12, 13.79s/it, training_loss=0.412]\u001b[A\n","Epoch 3:  77%|███████▋  | 85/111 [19:14<05:59, 13.84s/it, training_loss=0.412]\u001b[A\n","Epoch 3:  77%|███████▋  | 85/111 [19:26<05:59, 13.84s/it, training_loss=0.408]\u001b[A\n","Epoch 3:  77%|███████▋  | 86/111 [19:26<05:31, 13.27s/it, training_loss=0.408]\u001b[A\n","Epoch 3:  77%|███████▋  | 86/111 [19:39<05:31, 13.27s/it, training_loss=0.284]\u001b[A\n","Epoch 3:  78%|███████▊  | 87/111 [19:39<05:20, 13.34s/it, training_loss=0.284]\u001b[A\n","Epoch 3:  78%|███████▊  | 87/111 [19:54<05:20, 13.34s/it, training_loss=0.206]\u001b[A\n","Epoch 3:  79%|███████▉  | 88/111 [19:54<05:14, 13.68s/it, training_loss=0.206]\u001b[A\n","Epoch 3:  79%|███████▉  | 88/111 [20:08<05:14, 13.68s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  80%|████████  | 89/111 [20:08<05:06, 13.93s/it, training_loss=0.266]\u001b[A\n","Epoch 3:  80%|████████  | 89/111 [20:20<05:06, 13.93s/it, training_loss=0.304]\u001b[A\n","Epoch 3:  81%|████████  | 90/111 [20:20<04:41, 13.41s/it, training_loss=0.304]\u001b[A\n","Epoch 3:  81%|████████  | 90/111 [20:33<04:41, 13.41s/it, training_loss=0.341]\u001b[A\n","Epoch 3:  82%|████████▏ | 91/111 [20:33<04:24, 13.24s/it, training_loss=0.341]\u001b[A\n","Epoch 3:  82%|████████▏ | 91/111 [20:48<04:24, 13.24s/it, training_loss=0.163]\u001b[A\n","Epoch 3:  83%|████████▎ | 92/111 [20:48<04:18, 13.59s/it, training_loss=0.163]\u001b[A\n","Epoch 3:  83%|████████▎ | 92/111 [21:02<04:18, 13.59s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  84%|████████▍ | 93/111 [21:02<04:08, 13.81s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  84%|████████▍ | 93/111 [21:15<04:08, 13.81s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  85%|████████▍ | 94/111 [21:15<03:50, 13.55s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  85%|████████▍ | 94/111 [21:27<03:50, 13.55s/it, training_loss=0.315]\u001b[A\n","Epoch 3:  86%|████████▌ | 95/111 [21:27<03:31, 13.20s/it, training_loss=0.315]\u001b[A\n","Epoch 3:  86%|████████▌ | 95/111 [21:41<03:31, 13.20s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  86%|████████▋ | 96/111 [21:41<03:23, 13.54s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  86%|████████▋ | 96/111 [21:56<03:23, 13.54s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  87%|████████▋ | 97/111 [21:56<03:13, 13.79s/it, training_loss=0.290]\u001b[A\n","Epoch 3:  87%|████████▋ | 97/111 [22:10<03:13, 13.79s/it, training_loss=0.269]\u001b[A\n","Epoch 3:  88%|████████▊ | 98/111 [22:10<02:59, 13.80s/it, training_loss=0.269]\u001b[A\n","Epoch 3:  88%|████████▊ | 98/111 [22:22<02:59, 13.80s/it, training_loss=0.132]\u001b[A\n","Epoch 3:  89%|████████▉ | 99/111 [22:22<02:39, 13.32s/it, training_loss=0.132]\u001b[A\n","Epoch 3:  89%|████████▉ | 99/111 [22:36<02:39, 13.32s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  90%|█████████ | 100/111 [22:36<02:29, 13.58s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  90%|█████████ | 100/111 [22:50<02:29, 13.58s/it, training_loss=0.218]\u001b[A\n","Epoch 3:  91%|█████████ | 101/111 [22:50<02:17, 13.74s/it, training_loss=0.218]\u001b[A\n","Epoch 3:  91%|█████████ | 101/111 [23:04<02:17, 13.74s/it, training_loss=0.387]\u001b[A\n","Epoch 3:  92%|█████████▏| 102/111 [23:04<02:03, 13.72s/it, training_loss=0.387]\u001b[A\n","Epoch 3:  92%|█████████▏| 102/111 [23:16<02:03, 13.72s/it, training_loss=0.390]\u001b[A\n","Epoch 3:  93%|█████████▎| 103/111 [23:16<01:45, 13.15s/it, training_loss=0.390]\u001b[A\n","Epoch 3:  93%|█████████▎| 103/111 [23:30<01:45, 13.15s/it, training_loss=0.239]\u001b[A\n","Epoch 3:  94%|█████████▎| 104/111 [23:30<01:33, 13.37s/it, training_loss=0.239]\u001b[A\n","Epoch 3:  94%|█████████▎| 104/111 [23:44<01:33, 13.37s/it, training_loss=0.190]\u001b[A\n","Epoch 3:  95%|█████████▍| 105/111 [23:44<01:21, 13.59s/it, training_loss=0.190]\u001b[A\n","Epoch 3:  95%|█████████▍| 105/111 [23:58<01:21, 13.59s/it, training_loss=0.275]\u001b[A\n","Epoch 3:  95%|█████████▌| 106/111 [23:58<01:08, 13.72s/it, training_loss=0.275]\u001b[A\n","Epoch 3:  95%|█████████▌| 106/111 [24:09<01:08, 13.72s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  96%|█████████▋| 107/111 [24:09<00:52, 13.13s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  96%|█████████▋| 107/111 [24:23<00:52, 13.13s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  97%|█████████▋| 108/111 [24:23<00:39, 13.23s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  97%|█████████▋| 108/111 [24:37<00:39, 13.23s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  98%|█████████▊| 109/111 [24:37<00:27, 13.53s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  98%|█████████▊| 109/111 [24:51<00:27, 13.53s/it, training_loss=0.410]\u001b[A\n","Epoch 3:  99%|█████████▉| 110/111 [24:51<00:13, 13.77s/it, training_loss=0.410]\u001b[A\n","Epoch 3:  99%|█████████▉| 110/111 [25:00<00:13, 13.77s/it, training_loss=0.206]\u001b[A\n","Epoch 3: 100%|██████████| 111/111 [25:00<00:00, 12.27s/it, training_loss=0.206]\u001b[A\n"," 50%|█████     | 2/4 [1:19:52<54:32, 1636.40s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 1.0350464442828755\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [1:21:49<27:07, 1627.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.1078839350624807\n","F1 Score (Weighted): 0.45682146457627565\n","QWK Score: 0.3884921444603142\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/111 [00:13<?, ?it/s, training_loss=0.192]\u001b[A\n","Epoch 4:   1%|          | 1/111 [00:13<25:20, 13.82s/it, training_loss=0.192]\u001b[A\n","Epoch 4:   1%|          | 1/111 [00:26<25:20, 13.82s/it, training_loss=0.307]\u001b[A\n","Epoch 4:   2%|▏         | 2/111 [00:26<23:22, 12.87s/it, training_loss=0.307]\u001b[A\n","Epoch 4:   2%|▏         | 2/111 [00:39<23:22, 12.87s/it, training_loss=0.530]\u001b[A\n","Epoch 4:   3%|▎         | 3/111 [00:39<23:58, 13.32s/it, training_loss=0.530]\u001b[A\n","Epoch 4:   3%|▎         | 3/111 [00:54<23:58, 13.32s/it, training_loss=0.248]\u001b[A\n","Epoch 4:   4%|▎         | 4/111 [00:54<24:24, 13.69s/it, training_loss=0.248]\u001b[A\n","Epoch 4:   4%|▎         | 4/111 [01:08<24:24, 13.69s/it, training_loss=0.340]\u001b[A\n","Epoch 4:   5%|▍         | 5/111 [01:08<24:30, 13.87s/it, training_loss=0.340]\u001b[A\n","Epoch 4:   5%|▍         | 5/111 [01:20<24:30, 13.87s/it, training_loss=0.787]\u001b[A\n","Epoch 4:   5%|▌         | 6/111 [01:20<23:11, 13.25s/it, training_loss=0.787]\u001b[A\n","Epoch 4:   5%|▌         | 6/111 [01:33<23:11, 13.25s/it, training_loss=0.045]\u001b[A\n","Epoch 4:   6%|▋         | 7/111 [01:33<22:54, 13.22s/it, training_loss=0.045]\u001b[A\n","Epoch 4:   6%|▋         | 7/111 [01:47<22:54, 13.22s/it, training_loss=0.177]\u001b[A\n","Epoch 4:   7%|▋         | 8/111 [01:47<23:13, 13.53s/it, training_loss=0.177]\u001b[A\n","Epoch 4:   7%|▋         | 8/111 [02:01<23:13, 13.53s/it, training_loss=0.382]\u001b[A\n","Epoch 4:   8%|▊         | 9/111 [02:01<23:18, 13.71s/it, training_loss=0.382]\u001b[A\n","Epoch 4:   8%|▊         | 9/111 [02:14<23:18, 13.71s/it, training_loss=0.112]\u001b[A\n","Epoch 4:   9%|▉         | 10/111 [02:14<22:25, 13.32s/it, training_loss=0.112]\u001b[A\n","Epoch 4:   9%|▉         | 10/111 [02:26<22:25, 13.32s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  10%|▉         | 11/111 [02:26<21:45, 13.06s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  10%|▉         | 11/111 [02:40<21:45, 13.06s/it, training_loss=0.191]\u001b[A\n","Epoch 4:  11%|█         | 12/111 [02:40<22:07, 13.41s/it, training_loss=0.191]\u001b[A\n","Epoch 4:  11%|█         | 12/111 [02:55<22:07, 13.41s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  12%|█▏        | 13/111 [02:55<22:20, 13.68s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  12%|█▏        | 13/111 [03:08<22:20, 13.68s/it, training_loss=0.095]\u001b[A\n","Epoch 4:  13%|█▎        | 14/111 [03:08<22:03, 13.64s/it, training_loss=0.095]\u001b[A\n","Epoch 4:  13%|█▎        | 14/111 [03:20<22:03, 13.64s/it, training_loss=0.199]\u001b[A\n","Epoch 4:  14%|█▎        | 15/111 [03:20<20:55, 13.08s/it, training_loss=0.199]\u001b[A\n","Epoch 4:  14%|█▎        | 15/111 [03:34<20:55, 13.08s/it, training_loss=0.424]\u001b[A\n","Epoch 4:  14%|█▍        | 16/111 [03:34<21:12, 13.39s/it, training_loss=0.424]\u001b[A\n","Epoch 4:  14%|█▍        | 16/111 [03:49<21:12, 13.39s/it, training_loss=0.471]\u001b[A\n","Epoch 4:  15%|█▌        | 17/111 [03:49<21:27, 13.70s/it, training_loss=0.471]\u001b[A\n","Epoch 4:  15%|█▌        | 17/111 [04:03<21:27, 13.70s/it, training_loss=0.461]\u001b[A\n","Epoch 4:  16%|█▌        | 18/111 [04:03<21:23, 13.80s/it, training_loss=0.461]\u001b[A\n","Epoch 4:  16%|█▌        | 18/111 [04:14<21:23, 13.80s/it, training_loss=0.310]\u001b[A\n","Epoch 4:  17%|█▋        | 19/111 [04:14<20:14, 13.20s/it, training_loss=0.310]\u001b[A\n","Epoch 4:  17%|█▋        | 19/111 [04:28<20:14, 13.20s/it, training_loss=0.387]\u001b[A\n","Epoch 4:  18%|█▊        | 20/111 [04:28<20:07, 13.27s/it, training_loss=0.387]\u001b[A\n","Epoch 4:  18%|█▊        | 20/111 [04:42<20:07, 13.27s/it, training_loss=0.205]\u001b[A\n","Epoch 4:  19%|█▉        | 21/111 [04:42<20:19, 13.55s/it, training_loss=0.205]\u001b[A\n","Epoch 4:  19%|█▉        | 21/111 [04:56<20:19, 13.55s/it, training_loss=0.350]\u001b[A\n","Epoch 4:  20%|█▉        | 22/111 [04:56<20:23, 13.75s/it, training_loss=0.350]\u001b[A\n","Epoch 4:  20%|█▉        | 22/111 [05:09<20:23, 13.75s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  21%|██        | 23/111 [05:09<19:32, 13.32s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  21%|██        | 23/111 [05:21<19:32, 13.32s/it, training_loss=0.362]\u001b[A\n","Epoch 4:  22%|██▏       | 24/111 [05:21<19:00, 13.11s/it, training_loss=0.362]\u001b[A\n","Epoch 4:  22%|██▏       | 24/111 [05:35<19:00, 13.11s/it, training_loss=0.177]\u001b[A\n","Epoch 4:  23%|██▎       | 25/111 [05:35<19:14, 13.43s/it, training_loss=0.177]\u001b[A\n","Epoch 4:  23%|██▎       | 25/111 [05:50<19:14, 13.43s/it, training_loss=0.331]\u001b[A\n","Epoch 4:  23%|██▎       | 26/111 [05:50<19:20, 13.65s/it, training_loss=0.331]\u001b[A\n","Epoch 4:  23%|██▎       | 26/111 [06:02<19:20, 13.65s/it, training_loss=0.581]\u001b[A\n","Epoch 4:  24%|██▍       | 27/111 [06:02<18:42, 13.36s/it, training_loss=0.581]\u001b[A\n","Epoch 4:  24%|██▍       | 27/111 [06:15<18:42, 13.36s/it, training_loss=0.497]\u001b[A\n","Epoch 4:  25%|██▌       | 28/111 [06:15<18:02, 13.04s/it, training_loss=0.497]\u001b[A\n","Epoch 4:  25%|██▌       | 28/111 [06:29<18:02, 13.04s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  26%|██▌       | 29/111 [06:29<18:16, 13.38s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  26%|██▌       | 29/111 [06:43<18:16, 13.38s/it, training_loss=0.585]\u001b[A\n","Epoch 4:  27%|██▋       | 30/111 [06:43<18:24, 13.64s/it, training_loss=0.585]\u001b[A\n","Epoch 4:  27%|██▋       | 30/111 [06:57<18:24, 13.64s/it, training_loss=0.325]\u001b[A\n","Epoch 4:  28%|██▊       | 31/111 [06:57<18:11, 13.64s/it, training_loss=0.325]\u001b[A\n","Epoch 4:  28%|██▊       | 31/111 [07:08<18:11, 13.64s/it, training_loss=0.433]\u001b[A\n","Epoch 4:  29%|██▉       | 32/111 [07:08<17:12, 13.07s/it, training_loss=0.433]\u001b[A\n","Epoch 4:  29%|██▉       | 32/111 [07:22<17:12, 13.07s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  30%|██▉       | 33/111 [07:22<17:19, 13.33s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  30%|██▉       | 33/111 [07:36<17:19, 13.33s/it, training_loss=0.449]\u001b[A\n","Epoch 4:  31%|███       | 34/111 [07:36<17:24, 13.56s/it, training_loss=0.449]\u001b[A\n","Epoch 4:  31%|███       | 34/111 [07:50<17:24, 13.56s/it, training_loss=0.090]\u001b[A\n","Epoch 4:  32%|███▏      | 35/111 [07:50<17:12, 13.59s/it, training_loss=0.090]\u001b[A\n","Epoch 4:  32%|███▏      | 35/111 [08:02<17:12, 13.59s/it, training_loss=0.230]\u001b[A\n","Epoch 4:  32%|███▏      | 36/111 [08:02<16:19, 13.06s/it, training_loss=0.230]\u001b[A\n","Epoch 4:  32%|███▏      | 36/111 [08:16<16:19, 13.06s/it, training_loss=0.248]\u001b[A\n","Epoch 4:  33%|███▎      | 37/111 [08:16<16:21, 13.27s/it, training_loss=0.248]\u001b[A\n","Epoch 4:  33%|███▎      | 37/111 [08:30<16:21, 13.27s/it, training_loss=0.218]\u001b[A\n","Epoch 4:  34%|███▍      | 38/111 [08:30<16:33, 13.61s/it, training_loss=0.218]\u001b[A\n","Epoch 4:  34%|███▍      | 38/111 [08:44<16:33, 13.61s/it, training_loss=0.116]\u001b[A\n","Epoch 4:  35%|███▌      | 39/111 [08:44<16:29, 13.74s/it, training_loss=0.116]\u001b[A\n","Epoch 4:  35%|███▌      | 39/111 [08:56<16:29, 13.74s/it, training_loss=0.663]\u001b[A\n","Epoch 4:  36%|███▌      | 40/111 [08:56<15:35, 13.18s/it, training_loss=0.663]\u001b[A\n","Epoch 4:  36%|███▌      | 40/111 [09:09<15:35, 13.18s/it, training_loss=0.311]\u001b[A\n","Epoch 4:  37%|███▋      | 41/111 [09:09<15:22, 13.17s/it, training_loss=0.311]\u001b[A\n","Epoch 4:  37%|███▋      | 41/111 [09:23<15:22, 13.17s/it, training_loss=0.757]\u001b[A\n","Epoch 4:  38%|███▊      | 42/111 [09:23<15:26, 13.42s/it, training_loss=0.757]\u001b[A\n","Epoch 4:  38%|███▊      | 42/111 [09:37<15:26, 13.42s/it, training_loss=0.182]\u001b[A\n","Epoch 4:  39%|███▊      | 43/111 [09:37<15:22, 13.56s/it, training_loss=0.182]\u001b[A\n","Epoch 4:  39%|███▊      | 43/111 [09:49<15:22, 13.56s/it, training_loss=0.478]\u001b[A\n","Epoch 4:  40%|███▉      | 44/111 [09:49<14:37, 13.10s/it, training_loss=0.478]\u001b[A\n","Epoch 4:  40%|███▉      | 44/111 [10:02<14:37, 13.10s/it, training_loss=0.255]\u001b[A\n","Epoch 4:  41%|████      | 45/111 [10:02<14:18, 13.01s/it, training_loss=0.255]\u001b[A\n","Epoch 4:  41%|████      | 45/111 [10:16<14:18, 13.01s/it, training_loss=0.249]\u001b[A\n","Epoch 4:  41%|████▏     | 46/111 [10:16<14:23, 13.28s/it, training_loss=0.249]\u001b[A\n","Epoch 4:  41%|████▏     | 46/111 [10:30<14:23, 13.28s/it, training_loss=0.198]\u001b[A\n","Epoch 4:  42%|████▏     | 47/111 [10:30<14:27, 13.56s/it, training_loss=0.198]\u001b[A\n","Epoch 4:  42%|████▏     | 47/111 [10:43<14:27, 13.56s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  43%|████▎     | 48/111 [10:43<13:58, 13.31s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  43%|████▎     | 48/111 [10:55<13:58, 13.31s/it, training_loss=0.272]\u001b[A\n","Epoch 4:  44%|████▍     | 49/111 [10:55<13:28, 13.05s/it, training_loss=0.272]\u001b[A\n","Epoch 4:  44%|████▍     | 49/111 [11:09<13:28, 13.05s/it, training_loss=0.463]\u001b[A\n","Epoch 4:  45%|████▌     | 50/111 [11:09<13:38, 13.42s/it, training_loss=0.463]\u001b[A\n","Epoch 4:  45%|████▌     | 50/111 [11:24<13:38, 13.42s/it, training_loss=0.411]\u001b[A\n","Epoch 4:  46%|████▌     | 51/111 [11:24<13:42, 13.70s/it, training_loss=0.411]\u001b[A\n","Epoch 4:  46%|████▌     | 51/111 [11:38<13:42, 13.70s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  47%|████▋     | 52/111 [11:38<13:30, 13.73s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  47%|████▋     | 52/111 [11:50<13:30, 13.73s/it, training_loss=0.248]\u001b[A\n","Epoch 4:  48%|████▊     | 53/111 [11:50<12:45, 13.21s/it, training_loss=0.248]\u001b[A\n","Epoch 4:  48%|████▊     | 53/111 [12:03<12:45, 13.21s/it, training_loss=0.317]\u001b[A\n","Epoch 4:  49%|████▊     | 54/111 [12:03<12:44, 13.41s/it, training_loss=0.317]\u001b[A\n","Epoch 4:  49%|████▊     | 54/111 [12:18<12:44, 13.41s/it, training_loss=0.241]\u001b[A\n","Epoch 4:  50%|████▉     | 55/111 [12:18<12:46, 13.68s/it, training_loss=0.241]\u001b[A\n","Epoch 4:  50%|████▉     | 55/111 [12:32<12:46, 13.68s/it, training_loss=0.225]\u001b[A\n","Epoch 4:  50%|█████     | 56/111 [12:32<12:45, 13.92s/it, training_loss=0.225]\u001b[A\n","Epoch 4:  50%|█████     | 56/111 [12:44<12:45, 13.92s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  51%|█████▏    | 57/111 [12:44<12:04, 13.41s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  51%|█████▏    | 57/111 [12:57<12:04, 13.41s/it, training_loss=0.388]\u001b[A\n","Epoch 4:  52%|█████▏    | 58/111 [12:57<11:44, 13.28s/it, training_loss=0.388]\u001b[A\n","Epoch 4:  52%|█████▏    | 58/111 [13:12<11:44, 13.28s/it, training_loss=0.291]\u001b[A\n","Epoch 4:  53%|█████▎    | 59/111 [13:12<11:49, 13.64s/it, training_loss=0.291]\u001b[A\n","Epoch 4:  53%|█████▎    | 59/111 [13:26<11:49, 13.64s/it, training_loss=0.369]\u001b[A\n","Epoch 4:  54%|█████▍    | 60/111 [13:26<11:49, 13.91s/it, training_loss=0.369]\u001b[A\n","Epoch 4:  54%|█████▍    | 60/111 [13:40<11:49, 13.91s/it, training_loss=0.339]\u001b[A\n","Epoch 4:  55%|█████▍    | 61/111 [13:40<11:27, 13.74s/it, training_loss=0.339]\u001b[A\n","Epoch 4:  55%|█████▍    | 61/111 [13:52<11:27, 13.74s/it, training_loss=0.258]\u001b[A\n","Epoch 4:  56%|█████▌    | 62/111 [13:52<10:54, 13.35s/it, training_loss=0.258]\u001b[A\n","Epoch 4:  56%|█████▌    | 62/111 [14:07<10:54, 13.35s/it, training_loss=0.317]\u001b[A\n","Epoch 4:  57%|█████▋    | 63/111 [14:07<10:57, 13.71s/it, training_loss=0.317]\u001b[A\n","Epoch 4:  57%|█████▋    | 63/111 [14:21<10:57, 13.71s/it, training_loss=0.181]\u001b[A\n","Epoch 4:  58%|█████▊    | 64/111 [14:21<10:57, 13.98s/it, training_loss=0.181]\u001b[A\n","Epoch 4:  58%|█████▊    | 64/111 [14:35<10:57, 13.98s/it, training_loss=0.338]\u001b[A\n","Epoch 4:  59%|█████▊    | 65/111 [14:35<10:44, 14.02s/it, training_loss=0.338]\u001b[A\n","Epoch 4:  59%|█████▊    | 65/111 [14:47<10:44, 14.02s/it, training_loss=0.447]\u001b[A\n","Epoch 4:  59%|█████▉    | 66/111 [14:47<10:02, 13.39s/it, training_loss=0.447]\u001b[A\n","Epoch 4:  59%|█████▉    | 66/111 [15:01<10:02, 13.39s/it, training_loss=0.072]\u001b[A\n","Epoch 4:  60%|██████    | 67/111 [15:01<09:50, 13.42s/it, training_loss=0.072]\u001b[A\n","Epoch 4:  60%|██████    | 67/111 [15:15<09:50, 13.42s/it, training_loss=0.327]\u001b[A\n","Epoch 4:  61%|██████▏   | 68/111 [15:15<09:51, 13.75s/it, training_loss=0.327]\u001b[A\n","Epoch 4:  61%|██████▏   | 68/111 [15:30<09:51, 13.75s/it, training_loss=0.515]\u001b[A\n","Epoch 4:  62%|██████▏   | 69/111 [15:30<09:44, 13.92s/it, training_loss=0.515]\u001b[A\n","Epoch 4:  62%|██████▏   | 69/111 [15:42<09:44, 13.92s/it, training_loss=0.389]\u001b[A\n","Epoch 4:  63%|██████▎   | 70/111 [15:42<09:10, 13.42s/it, training_loss=0.389]\u001b[A\n","Epoch 4:  63%|██████▎   | 70/111 [15:55<09:10, 13.42s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  64%|██████▍   | 71/111 [15:55<08:55, 13.38s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  64%|██████▍   | 71/111 [16:10<08:55, 13.38s/it, training_loss=0.690]\u001b[A\n","Epoch 4:  65%|██████▍   | 72/111 [16:10<08:55, 13.74s/it, training_loss=0.690]\u001b[A\n","Epoch 4:  65%|██████▍   | 72/111 [16:24<08:55, 13.74s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  66%|██████▌   | 73/111 [16:24<08:50, 13.97s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  66%|██████▌   | 73/111 [16:38<08:50, 13.97s/it, training_loss=0.176]\u001b[A\n","Epoch 4:  67%|██████▋   | 74/111 [16:38<08:30, 13.79s/it, training_loss=0.176]\u001b[A\n","Epoch 4:  67%|██████▋   | 74/111 [16:50<08:30, 13.79s/it, training_loss=0.241]\u001b[A\n","Epoch 4:  68%|██████▊   | 75/111 [16:50<08:00, 13.36s/it, training_loss=0.241]\u001b[A\n","Epoch 4:  68%|██████▊   | 75/111 [17:05<08:00, 13.36s/it, training_loss=0.331]\u001b[A\n","Epoch 4:  68%|██████▊   | 76/111 [17:05<07:59, 13.71s/it, training_loss=0.331]\u001b[A\n","Epoch 4:  68%|██████▊   | 76/111 [17:19<07:59, 13.71s/it, training_loss=0.387]\u001b[A\n","Epoch 4:  69%|██████▉   | 77/111 [17:19<07:53, 13.92s/it, training_loss=0.387]\u001b[A\n","Epoch 4:  69%|██████▉   | 77/111 [17:33<07:53, 13.92s/it, training_loss=0.590]\u001b[A\n","Epoch 4:  70%|███████   | 78/111 [17:33<07:37, 13.86s/it, training_loss=0.590]\u001b[A\n","Epoch 4:  70%|███████   | 78/111 [17:45<07:37, 13.86s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  71%|███████   | 79/111 [17:45<07:08, 13.38s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  71%|███████   | 79/111 [17:59<07:08, 13.38s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  72%|███████▏  | 80/111 [17:59<07:03, 13.66s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  72%|███████▏  | 80/111 [18:14<07:03, 13.66s/it, training_loss=0.254]\u001b[A\n","Epoch 4:  73%|███████▎  | 81/111 [18:14<06:57, 13.90s/it, training_loss=0.254]\u001b[A\n","Epoch 4:  73%|███████▎  | 81/111 [18:28<06:57, 13.90s/it, training_loss=0.496]\u001b[A\n","Epoch 4:  74%|███████▍  | 82/111 [18:28<06:47, 14.06s/it, training_loss=0.496]\u001b[A\n","Epoch 4:  74%|███████▍  | 82/111 [18:41<06:47, 14.06s/it, training_loss=0.248]\u001b[A\n","Epoch 4:  75%|███████▍  | 83/111 [18:41<06:20, 13.60s/it, training_loss=0.248]\u001b[A\n","Epoch 4:  75%|███████▍  | 83/111 [18:54<06:20, 13.60s/it, training_loss=0.351]\u001b[A\n","Epoch 4:  76%|███████▌  | 84/111 [18:54<06:05, 13.55s/it, training_loss=0.351]\u001b[A\n","Epoch 4:  76%|███████▌  | 84/111 [19:09<06:05, 13.55s/it, training_loss=0.142]\u001b[A\n","Epoch 4:  77%|███████▋  | 85/111 [19:09<06:01, 13.90s/it, training_loss=0.142]\u001b[A\n","Epoch 4:  77%|███████▋  | 85/111 [19:24<06:01, 13.90s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  77%|███████▋  | 86/111 [19:24<05:53, 14.13s/it, training_loss=0.302]\u001b[A\n","Epoch 4:  77%|███████▋  | 86/111 [19:37<05:53, 14.13s/it, training_loss=0.370]\u001b[A\n","Epoch 4:  78%|███████▊  | 87/111 [19:37<05:34, 13.94s/it, training_loss=0.370]\u001b[A\n","Epoch 4:  78%|███████▊  | 87/111 [19:49<05:34, 13.94s/it, training_loss=0.169]\u001b[A\n","Epoch 4:  79%|███████▉  | 88/111 [19:49<05:09, 13.47s/it, training_loss=0.169]\u001b[A\n","Epoch 4:  79%|███████▉  | 88/111 [20:04<05:09, 13.47s/it, training_loss=0.184]\u001b[A\n","Epoch 4:  80%|████████  | 89/111 [20:04<05:01, 13.71s/it, training_loss=0.184]\u001b[A\n","Epoch 4:  80%|████████  | 89/111 [20:18<05:01, 13.71s/it, training_loss=0.283]\u001b[A\n","Epoch 4:  81%|████████  | 90/111 [20:18<04:52, 13.91s/it, training_loss=0.283]\u001b[A\n","Epoch 4:  81%|████████  | 90/111 [20:32<04:52, 13.91s/it, training_loss=0.179]\u001b[A\n","Epoch 4:  82%|████████▏ | 91/111 [20:32<04:37, 13.87s/it, training_loss=0.179]\u001b[A\n","Epoch 4:  82%|████████▏ | 91/111 [20:44<04:37, 13.87s/it, training_loss=0.164]\u001b[A\n","Epoch 4:  83%|████████▎ | 92/111 [20:44<04:15, 13.45s/it, training_loss=0.164]\u001b[A\n","Epoch 4:  83%|████████▎ | 92/111 [20:59<04:15, 13.45s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  84%|████████▍ | 93/111 [20:59<04:07, 13.73s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  84%|████████▍ | 93/111 [21:13<04:07, 13.73s/it, training_loss=0.485]\u001b[A\n","Epoch 4:  85%|████████▍ | 94/111 [21:13<03:56, 13.94s/it, training_loss=0.485]\u001b[A\n","Epoch 4:  85%|████████▍ | 94/111 [21:27<03:56, 13.94s/it, training_loss=0.391]\u001b[A\n","Epoch 4:  86%|████████▌ | 95/111 [21:27<03:43, 13.97s/it, training_loss=0.391]\u001b[A\n","Epoch 4:  86%|████████▌ | 95/111 [21:39<03:43, 13.97s/it, training_loss=0.293]\u001b[A\n","Epoch 4:  86%|████████▋ | 96/111 [21:39<03:19, 13.32s/it, training_loss=0.293]\u001b[A\n","Epoch 4:  86%|████████▋ | 96/111 [21:53<03:19, 13.32s/it, training_loss=0.264]\u001b[A\n","Epoch 4:  87%|████████▋ | 97/111 [21:53<03:08, 13.48s/it, training_loss=0.264]\u001b[A\n","Epoch 4:  87%|████████▋ | 97/111 [22:07<03:08, 13.48s/it, training_loss=0.184]\u001b[A\n","Epoch 4:  88%|████████▊ | 98/111 [22:07<02:58, 13.73s/it, training_loss=0.184]\u001b[A\n","Epoch 4:  88%|████████▊ | 98/111 [22:29<02:58, 13.73s/it, training_loss=0.093]\u001b[A\n","Epoch 4:  89%|████████▉ | 99/111 [22:29<03:14, 16.20s/it, training_loss=0.093]\u001b[A\n","Epoch 4:  89%|████████▉ | 99/111 [22:46<03:14, 16.20s/it, training_loss=0.290]\u001b[A\n","Epoch 4:  90%|█████████ | 100/111 [22:46<03:01, 16.50s/it, training_loss=0.290]\u001b[A\n","Epoch 4:  90%|█████████ | 100/111 [23:01<03:01, 16.50s/it, training_loss=0.458]\u001b[A\n","Epoch 4:  91%|█████████ | 101/111 [23:01<02:39, 15.94s/it, training_loss=0.458]\u001b[A\n","Epoch 4:  91%|█████████ | 101/111 [23:15<02:39, 15.94s/it, training_loss=0.157]\u001b[A\n","Epoch 4:  92%|█████████▏| 102/111 [23:15<02:17, 15.29s/it, training_loss=0.157]\u001b[A\n","Epoch 4:  92%|█████████▏| 102/111 [23:27<02:17, 15.29s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  93%|█████████▎| 103/111 [23:27<01:55, 14.46s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  93%|█████████▎| 103/111 [23:42<01:55, 14.46s/it, training_loss=0.182]\u001b[A\n","Epoch 4:  94%|█████████▎| 104/111 [23:42<01:40, 14.43s/it, training_loss=0.182]\u001b[A\n","Epoch 4:  94%|█████████▎| 104/111 [23:56<01:40, 14.43s/it, training_loss=0.297]\u001b[A\n","Epoch 4:  95%|█████████▍| 105/111 [23:56<01:26, 14.39s/it, training_loss=0.297]\u001b[A\n","Epoch 4:  95%|█████████▍| 105/111 [24:10<01:26, 14.39s/it, training_loss=0.280]\u001b[A\n","Epoch 4:  95%|█████████▌| 106/111 [24:10<01:11, 14.33s/it, training_loss=0.280]\u001b[A\n","Epoch 4:  95%|█████████▌| 106/111 [24:22<01:11, 14.33s/it, training_loss=0.325]\u001b[A\n","Epoch 4:  96%|█████████▋| 107/111 [24:22<00:54, 13.55s/it, training_loss=0.325]\u001b[A\n","Epoch 4:  96%|█████████▋| 107/111 [24:36<00:54, 13.55s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  97%|█████████▋| 108/111 [24:36<00:40, 13.64s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  97%|█████████▋| 108/111 [24:50<00:40, 13.64s/it, training_loss=0.161]\u001b[A\n","Epoch 4:  98%|█████████▊| 109/111 [24:50<00:27, 13.95s/it, training_loss=0.161]\u001b[A\n","Epoch 4:  98%|█████████▊| 109/111 [25:05<00:27, 13.95s/it, training_loss=0.133]\u001b[A\n","Epoch 4:  99%|█████████▉| 110/111 [25:05<00:14, 14.13s/it, training_loss=0.133]\u001b[A\n","Epoch 4:  99%|█████████▉| 110/111 [25:14<00:14, 14.13s/it, training_loss=0.279]\u001b[A\n","Epoch 4: 100%|██████████| 111/111 [25:14<00:00, 12.65s/it, training_loss=0.279]\u001b[A\n"," 75%|███████▌  | 3/4 [1:47:03<27:07, 1627.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 0.9310684742422791\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [1:49:01<00:00, 1635.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 0.9394558890323553\n","F1 Score (Weighted): 0.5671569812180358\n","QWK Score: 0.47318994244168433\n"]}],"source":["import os\n","import pandas as pd\n","\n","path_dir = '/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Olahraga'\n","list_dir = os.listdir(path_dir)\n","\n","list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","\n","for m in list_pre_trained_model:\n","    print(m)\n","    for idx, ele in enumerate(list_dir):\n","        df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                               sheet_name='Soal',\n","                               header=1,\n","                               index_col=0,\n","                               usecols='B:D')\n","\n","        list_final = []\n","\n","        for i in df_raw.itertuples():\n","            list_final.append(\n","                {\n","                    'soal': i[1],\n","                    'jawaban': i[2],\n","                    'nilai': 100,\n","                    'tipe': 'train'\n","                }\n","            )\n","            df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","            df_tmp = df_tmp.dropna()\n","            for j in df_tmp.itertuples():\n","                list_final.append(\n","                    {\n","                        'soal': i[1],\n","                        'jawaban': j[2],\n","                        'nilai': j[12],\n","                        'tipe': 'test'\n","                    }\n","                )\n","        if idx == 0:\n","            df_final = pd.DataFrame(list_final)\n","        else:\n","            df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","        print(' '.join(ele.rstrip('.xslx').split('_')))\n","        train_eval(df_final, m)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_L2EdYIAAYkI","executionInfo":{"status":"ok","timestamp":1680445901967,"user_tz":-420,"elapsed":574,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["def train_eval_raw(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False, duplicates='drop')\n","\n","    # concatenate soal and jawaban\n","    df_final['soal-jawaban'] = df_final['soal']+df_final['jawaban']\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","        torch.save(model.state_dict(), f'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Olahraga_Save/finetuned_BERT_raw_epoch_{epoch}.model')\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')\n"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","path_dir = '/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Olahraga'\n","list_dir = os.listdir(path_dir)\n","\n","list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","\n","for m in list_pre_trained_model:\n","    print(m)\n","    for idx, ele in enumerate(list_dir):\n","        df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                               sheet_name='Soal',\n","                               header=1,\n","                               index_col=0,\n","                               usecols='B:D')\n","\n","        list_final = []\n","\n","        for i in df_raw.itertuples():\n","            list_final.append(\n","                {\n","                    'soal': i[1],\n","                    'jawaban': i[2],\n","                    'nilai': 100,\n","                    'tipe': 'train'\n","                }\n","            )\n","            df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","            df_tmp = df_tmp.dropna()\n","            for j in df_tmp.itertuples():\n","                list_final.append(\n","                    {\n","                        'soal': i[1],\n","                        'jawaban': j[2],\n","                        'nilai': j[12],\n","                        'tipe': 'test'\n","                    }\n","                )\n","        if idx == 0:\n","            df_final = pd.DataFrame(list_final)\n","        else:\n","            df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","        print(' '.join(ele.rstrip('.xslx').split('_')))\n","        train_eval_raw(df_final, m)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ore_C6ipFmSl","executionInfo":{"status":"ok","timestamp":1680459223118,"user_tz":-420,"elapsed":5403880,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"248c4c52-573c-47d3-c38e-f037d393991b"},"execution_count":17,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["indobenchmark/indobert-lite-base-p2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Analisis Essay Grading Olahraga\n"]},{"output_type":"stream","name":"stderr","text":["You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'pooler.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/111 [00:14<?, ?it/s, training_loss=0.592]\u001b[A\n","Epoch 1:   1%|          | 1/111 [00:14<27:23, 14.94s/it, training_loss=0.592]\u001b[A\n","Epoch 1:   1%|          | 1/111 [00:28<27:23, 14.94s/it, training_loss=0.780]\u001b[A\n","Epoch 1:   2%|▏         | 2/111 [00:28<25:48, 14.21s/it, training_loss=0.780]\u001b[A\n","Epoch 1:   2%|▏         | 2/111 [00:42<25:48, 14.21s/it, training_loss=0.690]\u001b[A\n","Epoch 1:   3%|▎         | 3/111 [00:42<25:27, 14.14s/it, training_loss=0.690]\u001b[A\n","Epoch 1:   3%|▎         | 3/111 [00:56<25:27, 14.14s/it, training_loss=1.057]\u001b[A\n","Epoch 1:   4%|▎         | 4/111 [00:56<25:00, 14.03s/it, training_loss=1.057]\u001b[A\n","Epoch 1:   4%|▎         | 4/111 [01:08<25:00, 14.03s/it, training_loss=0.572]\u001b[A\n","Epoch 1:   5%|▍         | 5/111 [01:08<23:26, 13.27s/it, training_loss=0.572]\u001b[A\n","Epoch 1:   5%|▍         | 5/111 [01:20<23:26, 13.27s/it, training_loss=0.588]\u001b[A\n","Epoch 1:   5%|▌         | 6/111 [01:20<22:42, 12.98s/it, training_loss=0.588]\u001b[A\n","Epoch 1:   5%|▌         | 6/111 [01:34<22:42, 12.98s/it, training_loss=0.576]\u001b[A\n","Epoch 1:   6%|▋         | 7/111 [01:34<22:44, 13.12s/it, training_loss=0.576]\u001b[A\n","Epoch 1:   6%|▋         | 7/111 [01:47<22:44, 13.12s/it, training_loss=0.627]\u001b[A\n","Epoch 1:   7%|▋         | 8/111 [01:47<22:49, 13.30s/it, training_loss=0.627]\u001b[A\n","Epoch 1:   7%|▋         | 8/111 [02:00<22:49, 13.30s/it, training_loss=0.578]\u001b[A\n","Epoch 1:   8%|▊         | 9/111 [02:00<22:17, 13.11s/it, training_loss=0.578]\u001b[A\n","Epoch 1:   8%|▊         | 9/111 [02:12<22:17, 13.11s/it, training_loss=0.509]\u001b[A\n","Epoch 1:   9%|▉         | 10/111 [02:12<21:25, 12.73s/it, training_loss=0.509]\u001b[A\n","Epoch 1:   9%|▉         | 10/111 [02:26<21:25, 12.73s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  10%|▉         | 11/111 [02:26<21:43, 13.03s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  10%|▉         | 11/111 [02:39<21:43, 13.03s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  11%|█         | 12/111 [02:39<21:41, 13.15s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  11%|█         | 12/111 [02:53<21:41, 13.15s/it, training_loss=0.476]\u001b[A\n","Epoch 1:  12%|█▏        | 13/111 [02:53<21:40, 13.27s/it, training_loss=0.476]\u001b[A\n","Epoch 1:  12%|█▏        | 13/111 [03:04<21:40, 13.27s/it, training_loss=0.509]\u001b[A\n","Epoch 1:  13%|█▎        | 14/111 [03:04<20:25, 12.63s/it, training_loss=0.509]\u001b[A\n","Epoch 1:  13%|█▎        | 14/111 [03:17<20:25, 12.63s/it, training_loss=0.470]\u001b[A\n","Epoch 1:  14%|█▎        | 15/111 [03:17<20:24, 12.75s/it, training_loss=0.470]\u001b[A\n","Epoch 1:  14%|█▎        | 15/111 [03:30<20:24, 12.75s/it, training_loss=0.646]\u001b[A\n","Epoch 1:  14%|█▍        | 16/111 [03:30<20:29, 12.94s/it, training_loss=0.646]\u001b[A\n","Epoch 1:  14%|█▍        | 16/111 [03:44<20:29, 12.94s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  15%|█▌        | 17/111 [03:44<20:35, 13.14s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  15%|█▌        | 17/111 [03:57<20:35, 13.14s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  16%|█▌        | 18/111 [03:57<20:08, 12.99s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  16%|█▌        | 18/111 [04:08<20:08, 12.99s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  17%|█▋        | 19/111 [04:09<19:26, 12.68s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  17%|█▋        | 19/111 [04:22<19:26, 12.68s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  18%|█▊        | 20/111 [04:22<19:35, 12.92s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  18%|█▊        | 20/111 [04:36<19:35, 12.92s/it, training_loss=0.440]\u001b[A\n","Epoch 1:  19%|█▉        | 21/111 [04:36<19:40, 13.12s/it, training_loss=0.440]\u001b[A\n","Epoch 1:  19%|█▉        | 21/111 [04:49<19:40, 13.12s/it, training_loss=0.536]\u001b[A\n","Epoch 1:  20%|█▉        | 22/111 [04:49<19:35, 13.21s/it, training_loss=0.536]\u001b[A\n","Epoch 1:  20%|█▉        | 22/111 [05:01<19:35, 13.21s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  21%|██        | 23/111 [05:01<18:37, 12.70s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  21%|██        | 23/111 [05:13<18:37, 12.70s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  22%|██▏       | 24/111 [05:13<18:26, 12.72s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  22%|██▏       | 24/111 [05:27<18:26, 12.72s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  23%|██▎       | 25/111 [05:27<18:32, 12.94s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  23%|██▎       | 25/111 [05:40<18:32, 12.94s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  23%|██▎       | 26/111 [05:40<18:32, 13.09s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  23%|██▎       | 26/111 [05:53<18:32, 13.09s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  24%|██▍       | 27/111 [05:53<18:08, 12.96s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  24%|██▍       | 27/111 [06:04<18:08, 12.96s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  25%|██▌       | 28/111 [06:04<17:23, 12.57s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  25%|██▌       | 28/111 [06:18<17:23, 12.57s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  26%|██▌       | 29/111 [06:18<17:36, 12.88s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  26%|██▌       | 29/111 [06:32<17:36, 12.88s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  27%|██▋       | 30/111 [06:32<17:37, 13.05s/it, training_loss=0.469]\u001b[A\n","Epoch 1:  27%|██▋       | 30/111 [06:45<17:37, 13.05s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  28%|██▊       | 31/111 [06:45<17:32, 13.16s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  28%|██▊       | 31/111 [06:56<17:32, 13.16s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  29%|██▉       | 32/111 [06:56<16:41, 12.68s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  29%|██▉       | 32/111 [07:09<16:41, 12.68s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  30%|██▉       | 33/111 [07:09<16:28, 12.68s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  30%|██▉       | 33/111 [07:23<16:28, 12.68s/it, training_loss=0.628]\u001b[A\n","Epoch 1:  31%|███       | 34/111 [07:23<16:37, 12.95s/it, training_loss=0.628]\u001b[A\n","Epoch 1:  31%|███       | 34/111 [07:36<16:37, 12.95s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  32%|███▏      | 35/111 [07:36<16:40, 13.16s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  32%|███▏      | 35/111 [07:49<16:40, 13.16s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  32%|███▏      | 36/111 [07:49<16:23, 13.11s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  32%|███▏      | 36/111 [08:01<16:23, 13.11s/it, training_loss=0.590]\u001b[A\n","Epoch 1:  33%|███▎      | 37/111 [08:01<15:43, 12.75s/it, training_loss=0.590]\u001b[A\n","Epoch 1:  33%|███▎      | 37/111 [08:15<15:43, 12.75s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  34%|███▍      | 38/111 [08:15<15:45, 12.95s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  34%|███▍      | 38/111 [08:28<15:45, 12.95s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  35%|███▌      | 39/111 [08:28<15:44, 13.12s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  35%|███▌      | 39/111 [08:42<15:44, 13.12s/it, training_loss=0.553]\u001b[A\n","Epoch 1:  36%|███▌      | 40/111 [08:42<15:38, 13.22s/it, training_loss=0.553]\u001b[A\n","Epoch 1:  36%|███▌      | 40/111 [08:54<15:38, 13.22s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  37%|███▋      | 41/111 [08:54<15:05, 12.94s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  37%|███▋      | 41/111 [09:06<15:05, 12.94s/it, training_loss=0.472]\u001b[A\n","Epoch 1:  38%|███▊      | 42/111 [09:06<14:32, 12.64s/it, training_loss=0.472]\u001b[A\n","Epoch 1:  38%|███▊      | 42/111 [09:19<14:32, 12.64s/it, training_loss=0.512]\u001b[A\n","Epoch 1:  39%|███▊      | 43/111 [09:19<14:36, 12.89s/it, training_loss=0.512]\u001b[A\n","Epoch 1:  39%|███▊      | 43/111 [09:33<14:36, 12.89s/it, training_loss=0.477]\u001b[A\n","Epoch 1:  40%|███▉      | 44/111 [09:33<14:33, 13.04s/it, training_loss=0.477]\u001b[A\n","Epoch 1:  40%|███▉      | 44/111 [09:46<14:33, 13.04s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  41%|████      | 45/111 [09:46<14:24, 13.09s/it, training_loss=0.506]\u001b[A\n","Epoch 1:  41%|████      | 45/111 [09:57<14:24, 13.09s/it, training_loss=0.680]\u001b[A\n","Epoch 1:  41%|████▏     | 46/111 [09:57<13:36, 12.57s/it, training_loss=0.680]\u001b[A\n","Epoch 1:  41%|████▏     | 46/111 [10:13<13:36, 12.57s/it, training_loss=0.699]\u001b[A\n","Epoch 1:  42%|████▏     | 47/111 [10:13<14:21, 13.46s/it, training_loss=0.699]\u001b[A\n","Epoch 1:  42%|████▏     | 47/111 [10:26<14:21, 13.46s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  43%|████▎     | 48/111 [10:26<14:10, 13.50s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  43%|████▎     | 48/111 [10:40<14:10, 13.50s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  44%|████▍     | 49/111 [10:40<13:55, 13.47s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  44%|████▍     | 49/111 [10:53<13:55, 13.47s/it, training_loss=0.391]\u001b[A\n","Epoch 1:  45%|████▌     | 50/111 [10:53<13:42, 13.48s/it, training_loss=0.391]\u001b[A\n","Epoch 1:  45%|████▌     | 50/111 [11:05<13:42, 13.48s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  46%|████▌     | 51/111 [11:05<13:00, 13.02s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  46%|████▌     | 51/111 [11:18<13:00, 13.02s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  47%|████▋     | 52/111 [11:18<12:34, 12.78s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  47%|████▋     | 52/111 [11:31<12:34, 12.78s/it, training_loss=0.449]\u001b[A\n","Epoch 1:  48%|████▊     | 53/111 [11:31<12:33, 13.00s/it, training_loss=0.449]\u001b[A\n","Epoch 1:  48%|████▊     | 53/111 [11:45<12:33, 13.00s/it, training_loss=0.463]\u001b[A\n","Epoch 1:  49%|████▊     | 54/111 [11:45<12:28, 13.14s/it, training_loss=0.463]\u001b[A\n","Epoch 1:  49%|████▊     | 54/111 [11:58<12:28, 13.14s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  50%|████▉     | 55/111 [11:58<12:14, 13.12s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  50%|████▉     | 55/111 [12:09<12:14, 13.12s/it, training_loss=0.323]\u001b[A\n","Epoch 1:  50%|█████     | 56/111 [12:09<11:31, 12.58s/it, training_loss=0.323]\u001b[A\n","Epoch 1:  50%|█████     | 56/111 [12:22<11:31, 12.58s/it, training_loss=0.433]\u001b[A\n","Epoch 1:  51%|█████▏    | 57/111 [12:22<11:33, 12.85s/it, training_loss=0.433]\u001b[A\n","Epoch 1:  51%|█████▏    | 57/111 [12:36<11:33, 12.85s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  52%|█████▏    | 58/111 [12:36<11:34, 13.10s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  52%|█████▏    | 58/111 [12:50<11:34, 13.10s/it, training_loss=0.458]\u001b[A\n","Epoch 1:  53%|█████▎    | 59/111 [12:50<11:28, 13.23s/it, training_loss=0.458]\u001b[A\n","Epoch 1:  53%|█████▎    | 59/111 [13:02<11:28, 13.23s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  54%|█████▍    | 60/111 [13:02<10:59, 12.93s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  54%|█████▍    | 60/111 [13:14<10:59, 12.93s/it, training_loss=0.409]\u001b[A\n","Epoch 1:  55%|█████▍    | 61/111 [13:14<10:33, 12.66s/it, training_loss=0.409]\u001b[A\n","Epoch 1:  55%|█████▍    | 61/111 [13:28<10:33, 12.66s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  56%|█████▌    | 62/111 [13:28<10:34, 12.95s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  56%|█████▌    | 62/111 [13:41<10:34, 12.95s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  57%|█████▋    | 63/111 [13:41<10:30, 13.13s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  57%|█████▋    | 63/111 [13:55<10:30, 13.13s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  58%|█████▊    | 64/111 [13:55<10:22, 13.25s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  58%|█████▊    | 64/111 [14:06<10:22, 13.25s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  59%|█████▊    | 65/111 [14:06<09:45, 12.73s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  59%|█████▊    | 65/111 [14:19<09:45, 12.73s/it, training_loss=0.313]\u001b[A\n","Epoch 1:  59%|█████▉    | 66/111 [14:19<09:35, 12.80s/it, training_loss=0.313]\u001b[A\n","Epoch 1:  59%|█████▉    | 66/111 [14:33<09:35, 12.80s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  60%|██████    | 67/111 [14:33<09:33, 13.04s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  60%|██████    | 67/111 [14:46<09:33, 13.04s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  61%|██████▏   | 68/111 [14:46<09:26, 13.18s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  61%|██████▏   | 68/111 [14:59<09:26, 13.18s/it, training_loss=0.743]\u001b[A\n","Epoch 1:  62%|██████▏   | 69/111 [14:59<09:05, 13.00s/it, training_loss=0.743]\u001b[A\n","Epoch 1:  62%|██████▏   | 69/111 [15:10<09:05, 13.00s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  63%|██████▎   | 70/111 [15:10<08:34, 12.54s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  63%|██████▎   | 70/111 [15:24<08:34, 12.54s/it, training_loss=0.460]\u001b[A\n","Epoch 1:  64%|██████▍   | 71/111 [15:24<08:30, 12.77s/it, training_loss=0.460]\u001b[A\n","Epoch 1:  64%|██████▍   | 71/111 [15:37<08:30, 12.77s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  65%|██████▍   | 72/111 [15:37<08:26, 12.99s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  65%|██████▍   | 72/111 [15:50<08:26, 12.99s/it, training_loss=0.415]\u001b[A\n","Epoch 1:  66%|██████▌   | 73/111 [15:50<08:12, 12.97s/it, training_loss=0.415]\u001b[A\n","Epoch 1:  66%|██████▌   | 73/111 [16:01<08:12, 12.97s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  67%|██████▋   | 74/111 [16:01<07:39, 12.41s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  67%|██████▋   | 74/111 [16:14<07:39, 12.41s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  68%|██████▊   | 75/111 [16:14<07:35, 12.65s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  68%|██████▊   | 75/111 [16:28<07:35, 12.65s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  68%|██████▊   | 76/111 [16:28<07:32, 12.93s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  68%|██████▊   | 76/111 [16:42<07:32, 12.93s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  69%|██████▉   | 77/111 [16:42<07:27, 13.15s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  69%|██████▉   | 77/111 [16:53<07:27, 13.15s/it, training_loss=0.443]\u001b[A\n","Epoch 1:  70%|███████   | 78/111 [16:53<07:01, 12.78s/it, training_loss=0.443]\u001b[A\n","Epoch 1:  70%|███████   | 78/111 [17:06<07:01, 12.78s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  71%|███████   | 79/111 [17:06<06:42, 12.59s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  71%|███████   | 79/111 [17:19<06:42, 12.59s/it, training_loss=0.332]\u001b[A\n","Epoch 1:  72%|███████▏  | 80/111 [17:19<06:38, 12.85s/it, training_loss=0.332]\u001b[A\n","Epoch 1:  72%|███████▏  | 80/111 [17:32<06:38, 12.85s/it, training_loss=0.407]\u001b[A\n","Epoch 1:  73%|███████▎  | 81/111 [17:32<06:29, 12.99s/it, training_loss=0.407]\u001b[A\n","Epoch 1:  73%|███████▎  | 81/111 [17:45<06:29, 12.99s/it, training_loss=0.790]\u001b[A\n","Epoch 1:  74%|███████▍  | 82/111 [17:45<06:13, 12.89s/it, training_loss=0.790]\u001b[A\n","Epoch 1:  74%|███████▍  | 82/111 [17:56<06:13, 12.89s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  75%|███████▍  | 83/111 [17:56<05:48, 12.46s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  75%|███████▍  | 83/111 [18:10<05:48, 12.46s/it, training_loss=0.866]\u001b[A\n","Epoch 1:  76%|███████▌  | 84/111 [18:10<05:43, 12.72s/it, training_loss=0.866]\u001b[A\n","Epoch 1:  76%|███████▌  | 84/111 [18:23<05:43, 12.72s/it, training_loss=0.657]\u001b[A\n","Epoch 1:  77%|███████▋  | 85/111 [18:23<05:35, 12.92s/it, training_loss=0.657]\u001b[A\n","Epoch 1:  77%|███████▋  | 85/111 [18:37<05:35, 12.92s/it, training_loss=0.512]\u001b[A\n","Epoch 1:  77%|███████▋  | 86/111 [18:37<05:27, 13.11s/it, training_loss=0.512]\u001b[A\n","Epoch 1:  77%|███████▋  | 86/111 [18:48<05:27, 13.11s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  78%|███████▊  | 87/111 [18:48<05:03, 12.63s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  78%|███████▊  | 87/111 [19:01<05:03, 12.63s/it, training_loss=0.349]\u001b[A\n","Epoch 1:  79%|███████▉  | 88/111 [19:01<04:48, 12.54s/it, training_loss=0.349]\u001b[A\n","Epoch 1:  79%|███████▉  | 88/111 [19:14<04:48, 12.54s/it, training_loss=0.540]\u001b[A\n","Epoch 1:  80%|████████  | 89/111 [19:14<04:41, 12.79s/it, training_loss=0.540]\u001b[A\n","Epoch 1:  80%|████████  | 89/111 [19:27<04:41, 12.79s/it, training_loss=0.586]\u001b[A\n","Epoch 1:  81%|████████  | 90/111 [19:27<04:32, 12.99s/it, training_loss=0.586]\u001b[A\n","Epoch 1:  81%|████████  | 90/111 [19:40<04:32, 12.99s/it, training_loss=0.620]\u001b[A\n","Epoch 1:  82%|████████▏ | 91/111 [19:40<04:17, 12.90s/it, training_loss=0.620]\u001b[A\n","Epoch 1:  82%|████████▏ | 91/111 [19:52<04:17, 12.90s/it, training_loss=0.558]\u001b[A\n","Epoch 1:  83%|████████▎ | 92/111 [19:52<03:57, 12.50s/it, training_loss=0.558]\u001b[A\n","Epoch 1:  83%|████████▎ | 92/111 [20:05<03:57, 12.50s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  84%|████████▍ | 93/111 [20:05<03:49, 12.78s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  84%|████████▍ | 93/111 [20:19<03:49, 12.78s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  85%|████████▍ | 94/111 [20:19<03:40, 12.99s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  85%|████████▍ | 94/111 [20:32<03:40, 12.99s/it, training_loss=0.451]\u001b[A\n","Epoch 1:  86%|████████▌ | 95/111 [20:32<03:30, 13.14s/it, training_loss=0.451]\u001b[A\n","Epoch 1:  86%|████████▌ | 95/111 [20:44<03:30, 13.14s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  86%|████████▋ | 96/111 [20:44<03:10, 12.68s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  86%|████████▋ | 96/111 [20:56<03:10, 12.68s/it, training_loss=0.433]\u001b[A\n","Epoch 1:  87%|████████▋ | 97/111 [20:56<02:56, 12.61s/it, training_loss=0.433]\u001b[A\n","Epoch 1:  87%|████████▋ | 97/111 [21:09<02:56, 12.61s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  88%|████████▊ | 98/111 [21:09<02:46, 12.80s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  88%|████████▊ | 98/111 [21:23<02:46, 12.80s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  89%|████████▉ | 99/111 [21:23<02:35, 12.96s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  89%|████████▉ | 99/111 [21:35<02:35, 12.96s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  90%|█████████ | 100/111 [21:35<02:21, 12.85s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  90%|█████████ | 100/111 [21:47<02:21, 12.85s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  91%|█████████ | 101/111 [21:47<02:04, 12.49s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  91%|█████████ | 101/111 [22:01<02:04, 12.49s/it, training_loss=0.397]\u001b[A\n","Epoch 1:  92%|█████████▏| 102/111 [22:01<01:55, 12.84s/it, training_loss=0.397]\u001b[A\n","Epoch 1:  92%|█████████▏| 102/111 [22:14<01:55, 12.84s/it, training_loss=0.579]\u001b[A\n","Epoch 1:  93%|█████████▎| 103/111 [22:14<01:44, 13.05s/it, training_loss=0.579]\u001b[A\n","Epoch 1:  93%|█████████▎| 103/111 [22:28<01:44, 13.05s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  94%|█████████▎| 104/111 [22:28<01:32, 13.19s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  94%|█████████▎| 104/111 [22:39<01:32, 13.19s/it, training_loss=0.346]\u001b[A\n","Epoch 1:  95%|█████████▍| 105/111 [22:39<01:16, 12.78s/it, training_loss=0.346]\u001b[A\n","Epoch 1:  95%|█████████▍| 105/111 [22:52<01:16, 12.78s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  95%|█████████▌| 106/111 [22:52<01:03, 12.65s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  95%|█████████▌| 106/111 [23:05<01:03, 12.65s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  96%|█████████▋| 107/111 [23:05<00:51, 12.84s/it, training_loss=0.596]\u001b[A\n","Epoch 1:  96%|█████████▋| 107/111 [23:19<00:51, 12.84s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  97%|█████████▋| 108/111 [23:19<00:39, 13.03s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  97%|█████████▋| 108/111 [23:31<00:39, 13.03s/it, training_loss=0.458]\u001b[A\n","Epoch 1:  98%|█████████▊| 109/111 [23:31<00:25, 12.98s/it, training_loss=0.458]\u001b[A\n","Epoch 1:  98%|█████████▊| 109/111 [23:43<00:25, 12.98s/it, training_loss=0.445]\u001b[A\n","Epoch 1:  99%|█████████▉| 110/111 [23:43<00:12, 12.55s/it, training_loss=0.445]\u001b[A\n","Epoch 1:  99%|█████████▉| 110/111 [23:54<00:12, 12.55s/it, training_loss=0.501]\u001b[A\n","Epoch 1: 100%|██████████| 111/111 [23:54<00:00, 12.06s/it, training_loss=0.501]\u001b[A\n","  0%|          | 0/4 [23:57<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.6343814580290168\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [25:53<1:17:39, 1553.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.5509571582078934\n","F1 Score (Weighted): 0.24786328536328534\n","QWK Score: 0.18872647176611945\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/111 [00:13<?, ?it/s, training_loss=0.566]\u001b[A\n","Epoch 2:   1%|          | 1/111 [00:13<25:12, 13.75s/it, training_loss=0.566]\u001b[A\n","Epoch 2:   1%|          | 1/111 [00:25<25:12, 13.75s/it, training_loss=0.445]\u001b[A\n","Epoch 2:   2%|▏         | 2/111 [00:25<23:18, 12.83s/it, training_loss=0.445]\u001b[A\n","Epoch 2:   2%|▏         | 2/111 [00:37<23:18, 12.83s/it, training_loss=0.346]\u001b[A\n","Epoch 2:   3%|▎         | 3/111 [00:37<22:23, 12.44s/it, training_loss=0.346]\u001b[A\n","Epoch 2:   3%|▎         | 3/111 [00:51<22:23, 12.44s/it, training_loss=0.323]\u001b[A\n","Epoch 2:   4%|▎         | 4/111 [00:51<23:03, 12.93s/it, training_loss=0.323]\u001b[A\n","Epoch 2:   4%|▎         | 4/111 [01:04<23:03, 12.93s/it, training_loss=0.455]\u001b[A\n","Epoch 2:   5%|▍         | 5/111 [01:05<23:08, 13.10s/it, training_loss=0.455]\u001b[A\n","Epoch 2:   5%|▍         | 5/111 [01:17<23:08, 13.10s/it, training_loss=0.283]\u001b[A\n","Epoch 2:   5%|▌         | 6/111 [01:17<22:46, 13.01s/it, training_loss=0.283]\u001b[A\n","Epoch 2:   5%|▌         | 6/111 [01:28<22:46, 13.01s/it, training_loss=0.518]\u001b[A\n","Epoch 2:   6%|▋         | 7/111 [01:28<21:25, 12.36s/it, training_loss=0.518]\u001b[A\n","Epoch 2:   6%|▋         | 7/111 [01:42<21:25, 12.36s/it, training_loss=0.515]\u001b[A\n","Epoch 2:   7%|▋         | 8/111 [01:42<21:48, 12.70s/it, training_loss=0.515]\u001b[A\n","Epoch 2:   7%|▋         | 8/111 [01:55<21:48, 12.70s/it, training_loss=0.497]\u001b[A\n","Epoch 2:   8%|▊         | 9/111 [01:55<21:50, 12.85s/it, training_loss=0.497]\u001b[A\n","Epoch 2:   8%|▊         | 9/111 [02:08<21:50, 12.85s/it, training_loss=0.366]\u001b[A\n","Epoch 2:   9%|▉         | 10/111 [02:08<21:54, 13.01s/it, training_loss=0.366]\u001b[A\n","Epoch 2:   9%|▉         | 10/111 [02:22<21:54, 13.01s/it, training_loss=0.554]\u001b[A\n","Epoch 2:  10%|▉         | 11/111 [02:22<22:01, 13.22s/it, training_loss=0.554]\u001b[A\n","Epoch 2:  10%|▉         | 11/111 [02:34<22:01, 13.22s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  11%|█         | 12/111 [02:34<21:09, 12.82s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  11%|█         | 12/111 [02:47<21:09, 12.82s/it, training_loss=0.478]\u001b[A\n","Epoch 2:  12%|█▏        | 13/111 [02:47<21:13, 13.00s/it, training_loss=0.478]\u001b[A\n","Epoch 2:  12%|█▏        | 13/111 [03:01<21:13, 13.00s/it, training_loss=0.406]\u001b[A\n","Epoch 2:  13%|█▎        | 14/111 [03:01<21:18, 13.18s/it, training_loss=0.406]\u001b[A\n","Epoch 2:  13%|█▎        | 14/111 [03:14<21:18, 13.18s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  14%|█▎        | 15/111 [03:14<21:04, 13.17s/it, training_loss=0.473]\u001b[A\n","Epoch 2:  14%|█▎        | 15/111 [03:25<21:04, 13.17s/it, training_loss=0.344]\u001b[A\n","Epoch 2:  14%|█▍        | 16/111 [03:25<19:49, 12.52s/it, training_loss=0.344]\u001b[A\n","Epoch 2:  14%|█▍        | 16/111 [03:38<19:49, 12.52s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  15%|█▌        | 17/111 [03:38<19:38, 12.54s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  15%|█▌        | 17/111 [03:51<19:38, 12.54s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  16%|█▌        | 18/111 [03:51<19:47, 12.77s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  16%|█▌        | 18/111 [04:05<19:47, 12.77s/it, training_loss=0.631]\u001b[A\n","Epoch 2:  17%|█▋        | 19/111 [04:05<20:00, 13.05s/it, training_loss=0.631]\u001b[A\n","Epoch 2:  17%|█▋        | 19/111 [04:17<20:00, 13.05s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  18%|█▊        | 20/111 [04:17<19:15, 12.69s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  18%|█▊        | 20/111 [04:28<19:15, 12.69s/it, training_loss=0.309]\u001b[A\n","Epoch 2:  19%|█▉        | 21/111 [04:28<18:40, 12.45s/it, training_loss=0.309]\u001b[A\n","Epoch 2:  19%|█▉        | 21/111 [04:42<18:40, 12.45s/it, training_loss=0.566]\u001b[A\n","Epoch 2:  20%|█▉        | 22/111 [04:42<18:46, 12.66s/it, training_loss=0.566]\u001b[A\n","Epoch 2:  20%|█▉        | 22/111 [04:55<18:46, 12.66s/it, training_loss=0.622]\u001b[A\n","Epoch 2:  21%|██        | 23/111 [04:55<18:48, 12.82s/it, training_loss=0.622]\u001b[A\n","Epoch 2:  21%|██        | 23/111 [05:07<18:48, 12.82s/it, training_loss=0.596]\u001b[A\n","Epoch 2:  22%|██▏       | 24/111 [05:07<18:26, 12.71s/it, training_loss=0.596]\u001b[A\n","Epoch 2:  22%|██▏       | 24/111 [05:19<18:26, 12.71s/it, training_loss=0.451]\u001b[A\n","Epoch 2:  23%|██▎       | 25/111 [05:19<17:45, 12.39s/it, training_loss=0.451]\u001b[A\n","Epoch 2:  23%|██▎       | 25/111 [05:32<17:45, 12.39s/it, training_loss=0.476]\u001b[A\n","Epoch 2:  23%|██▎       | 26/111 [05:32<17:58, 12.68s/it, training_loss=0.476]\u001b[A\n","Epoch 2:  23%|██▎       | 26/111 [05:46<17:58, 12.68s/it, training_loss=0.293]\u001b[A\n","Epoch 2:  24%|██▍       | 27/111 [05:46<18:04, 12.91s/it, training_loss=0.293]\u001b[A\n","Epoch 2:  24%|██▍       | 27/111 [05:58<18:04, 12.91s/it, training_loss=0.364]\u001b[A\n","Epoch 2:  25%|██▌       | 28/111 [05:58<17:46, 12.85s/it, training_loss=0.364]\u001b[A\n","Epoch 2:  25%|██▌       | 28/111 [06:10<17:46, 12.85s/it, training_loss=0.468]\u001b[A\n","Epoch 2:  26%|██▌       | 29/111 [06:10<16:51, 12.33s/it, training_loss=0.468]\u001b[A\n","Epoch 2:  26%|██▌       | 29/111 [06:23<16:51, 12.33s/it, training_loss=0.235]\u001b[A\n","Epoch 2:  27%|██▋       | 30/111 [06:23<17:07, 12.68s/it, training_loss=0.235]\u001b[A\n","Epoch 2:  27%|██▋       | 30/111 [06:37<17:07, 12.68s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  28%|██▊       | 31/111 [06:37<17:20, 13.00s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  28%|██▊       | 31/111 [06:50<17:20, 13.00s/it, training_loss=0.327]\u001b[A\n","Epoch 2:  29%|██▉       | 32/111 [06:50<17:20, 13.17s/it, training_loss=0.327]\u001b[A\n","Epoch 2:  29%|██▉       | 32/111 [07:02<17:20, 13.17s/it, training_loss=0.418]\u001b[A\n","Epoch 2:  30%|██▉       | 33/111 [07:02<16:36, 12.78s/it, training_loss=0.418]\u001b[A\n","Epoch 2:  30%|██▉       | 33/111 [07:15<16:36, 12.78s/it, training_loss=0.644]\u001b[A\n","Epoch 2:  31%|███       | 34/111 [07:15<16:15, 12.67s/it, training_loss=0.644]\u001b[A\n","Epoch 2:  31%|███       | 34/111 [07:28<16:15, 12.67s/it, training_loss=0.678]\u001b[A\n","Epoch 2:  32%|███▏      | 35/111 [07:28<16:23, 12.94s/it, training_loss=0.678]\u001b[A\n","Epoch 2:  32%|███▏      | 35/111 [07:42<16:23, 12.94s/it, training_loss=0.544]\u001b[A\n","Epoch 2:  32%|███▏      | 36/111 [07:42<16:19, 13.07s/it, training_loss=0.544]\u001b[A\n","Epoch 2:  32%|███▏      | 36/111 [07:54<16:19, 13.07s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  33%|███▎      | 37/111 [07:54<16:03, 13.01s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  33%|███▎      | 37/111 [08:06<16:03, 13.01s/it, training_loss=0.401]\u001b[A\n","Epoch 2:  34%|███▍      | 38/111 [08:06<15:23, 12.65s/it, training_loss=0.401]\u001b[A\n","Epoch 2:  34%|███▍      | 38/111 [08:20<15:23, 12.65s/it, training_loss=0.428]\u001b[A\n","Epoch 2:  35%|███▌      | 39/111 [08:20<15:24, 12.84s/it, training_loss=0.428]\u001b[A\n","Epoch 2:  35%|███▌      | 39/111 [08:33<15:24, 12.84s/it, training_loss=0.401]\u001b[A\n","Epoch 2:  36%|███▌      | 40/111 [08:33<15:27, 13.06s/it, training_loss=0.401]\u001b[A\n","Epoch 2:  36%|███▌      | 40/111 [08:47<15:27, 13.06s/it, training_loss=0.512]\u001b[A\n","Epoch 2:  37%|███▋      | 41/111 [08:47<15:22, 13.18s/it, training_loss=0.512]\u001b[A\n","Epoch 2:  37%|███▋      | 41/111 [08:59<15:22, 13.18s/it, training_loss=0.516]\u001b[A\n","Epoch 2:  38%|███▊      | 42/111 [08:59<14:46, 12.84s/it, training_loss=0.516]\u001b[A\n","Epoch 2:  38%|███▊      | 42/111 [09:11<14:46, 12.84s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  39%|███▊      | 43/111 [09:11<14:19, 12.64s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  39%|███▊      | 43/111 [09:24<14:19, 12.64s/it, training_loss=0.235]\u001b[A\n","Epoch 2:  40%|███▉      | 44/111 [09:24<14:27, 12.94s/it, training_loss=0.235]\u001b[A\n","Epoch 2:  40%|███▉      | 44/111 [09:38<14:27, 12.94s/it, training_loss=0.530]\u001b[A\n","Epoch 2:  41%|████      | 45/111 [09:38<14:24, 13.10s/it, training_loss=0.530]\u001b[A\n","Epoch 2:  41%|████      | 45/111 [09:51<14:24, 13.10s/it, training_loss=0.405]\u001b[A\n","Epoch 2:  41%|████▏     | 46/111 [09:51<14:14, 13.14s/it, training_loss=0.405]\u001b[A\n","Epoch 2:  41%|████▏     | 46/111 [10:02<14:14, 13.14s/it, training_loss=0.265]\u001b[A\n","Epoch 2:  42%|████▏     | 47/111 [10:03<13:26, 12.61s/it, training_loss=0.265]\u001b[A\n","Epoch 2:  42%|████▏     | 47/111 [10:16<13:26, 12.61s/it, training_loss=0.346]\u001b[A\n","Epoch 2:  43%|████▎     | 48/111 [10:16<13:25, 12.79s/it, training_loss=0.346]\u001b[A\n","Epoch 2:  43%|████▎     | 48/111 [10:29<13:25, 12.79s/it, training_loss=0.619]\u001b[A\n","Epoch 2:  44%|████▍     | 49/111 [10:29<13:28, 13.04s/it, training_loss=0.619]\u001b[A\n","Epoch 2:  44%|████▍     | 49/111 [10:43<13:28, 13.04s/it, training_loss=0.412]\u001b[A\n","Epoch 2:  45%|████▌     | 50/111 [10:43<13:25, 13.20s/it, training_loss=0.412]\u001b[A\n","Epoch 2:  45%|████▌     | 50/111 [10:55<13:25, 13.20s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  46%|████▌     | 51/111 [10:55<12:58, 12.97s/it, training_loss=0.353]\u001b[A\n","Epoch 2:  46%|████▌     | 51/111 [11:07<12:58, 12.97s/it, training_loss=0.362]\u001b[A\n","Epoch 2:  47%|████▋     | 52/111 [11:07<12:22, 12.59s/it, training_loss=0.362]\u001b[A\n","Epoch 2:  47%|████▋     | 52/111 [11:20<12:22, 12.59s/it, training_loss=0.345]\u001b[A\n","Epoch 2:  48%|████▊     | 53/111 [11:20<12:24, 12.83s/it, training_loss=0.345]\u001b[A\n","Epoch 2:  48%|████▊     | 53/111 [11:34<12:24, 12.83s/it, training_loss=0.661]\u001b[A\n","Epoch 2:  49%|████▊     | 54/111 [11:34<12:20, 13.00s/it, training_loss=0.661]\u001b[A\n","Epoch 2:  49%|████▊     | 54/111 [11:47<12:20, 13.00s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  50%|████▉     | 55/111 [11:47<12:07, 12.99s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  50%|████▉     | 55/111 [11:58<12:07, 12.99s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  50%|█████     | 56/111 [11:58<11:27, 12.50s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  50%|█████     | 56/111 [12:11<11:27, 12.50s/it, training_loss=0.457]\u001b[A\n","Epoch 2:  51%|█████▏    | 57/111 [12:11<11:27, 12.74s/it, training_loss=0.457]\u001b[A\n","Epoch 2:  51%|█████▏    | 57/111 [12:25<11:27, 12.74s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  52%|█████▏    | 58/111 [12:25<11:29, 13.01s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  52%|█████▏    | 58/111 [12:39<11:29, 13.01s/it, training_loss=0.661]\u001b[A\n","Epoch 2:  53%|█████▎    | 59/111 [12:39<11:23, 13.14s/it, training_loss=0.661]\u001b[A\n","Epoch 2:  53%|█████▎    | 59/111 [12:50<11:23, 13.14s/it, training_loss=0.403]\u001b[A\n","Epoch 2:  54%|█████▍    | 60/111 [12:50<10:51, 12.78s/it, training_loss=0.403]\u001b[A\n","Epoch 2:  54%|█████▍    | 60/111 [13:03<10:51, 12.78s/it, training_loss=0.408]\u001b[A\n","Epoch 2:  55%|█████▍    | 61/111 [13:03<10:28, 12.57s/it, training_loss=0.408]\u001b[A\n","Epoch 2:  55%|█████▍    | 61/111 [13:16<10:28, 12.57s/it, training_loss=0.675]\u001b[A\n","Epoch 2:  56%|█████▌    | 62/111 [13:16<10:28, 12.82s/it, training_loss=0.675]\u001b[A\n","Epoch 2:  56%|█████▌    | 62/111 [13:29<10:28, 12.82s/it, training_loss=0.189]\u001b[A\n","Epoch 2:  57%|█████▋    | 63/111 [13:29<10:24, 13.00s/it, training_loss=0.189]\u001b[A\n","Epoch 2:  57%|█████▋    | 63/111 [13:42<10:24, 13.00s/it, training_loss=0.629]\u001b[A\n","Epoch 2:  58%|█████▊    | 64/111 [13:42<10:10, 12.99s/it, training_loss=0.629]\u001b[A\n","Epoch 2:  58%|█████▊    | 64/111 [13:53<10:10, 12.99s/it, training_loss=0.503]\u001b[A\n","Epoch 2:  59%|█████▊    | 65/111 [13:53<09:31, 12.43s/it, training_loss=0.503]\u001b[A\n","Epoch 2:  59%|█████▊    | 65/111 [14:07<09:31, 12.43s/it, training_loss=0.515]\u001b[A\n","Epoch 2:  59%|█████▉    | 66/111 [14:07<09:33, 12.74s/it, training_loss=0.515]\u001b[A\n","Epoch 2:  59%|█████▉    | 66/111 [14:20<09:33, 12.74s/it, training_loss=0.470]\u001b[A\n","Epoch 2:  60%|██████    | 67/111 [14:20<09:31, 12.99s/it, training_loss=0.470]\u001b[A\n","Epoch 2:  60%|██████    | 67/111 [14:34<09:31, 12.99s/it, training_loss=0.795]\u001b[A\n","Epoch 2:  61%|██████▏   | 68/111 [14:34<09:26, 13.17s/it, training_loss=0.795]\u001b[A\n","Epoch 2:  61%|██████▏   | 68/111 [14:46<09:26, 13.17s/it, training_loss=0.415]\u001b[A\n","Epoch 2:  62%|██████▏   | 69/111 [14:46<09:00, 12.86s/it, training_loss=0.415]\u001b[A\n","Epoch 2:  62%|██████▏   | 69/111 [14:58<09:00, 12.86s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  63%|██████▎   | 70/111 [14:58<08:37, 12.62s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  63%|██████▎   | 70/111 [15:12<08:37, 12.62s/it, training_loss=0.323]\u001b[A\n","Epoch 2:  64%|██████▍   | 71/111 [15:12<08:32, 12.81s/it, training_loss=0.323]\u001b[A\n","Epoch 2:  64%|██████▍   | 71/111 [15:25<08:32, 12.81s/it, training_loss=0.435]\u001b[A\n","Epoch 2:  65%|██████▍   | 72/111 [15:25<08:27, 13.00s/it, training_loss=0.435]\u001b[A\n","Epoch 2:  65%|██████▍   | 72/111 [15:38<08:27, 13.00s/it, training_loss=0.427]\u001b[A\n","Epoch 2:  66%|██████▌   | 73/111 [15:38<08:13, 12.98s/it, training_loss=0.427]\u001b[A\n","Epoch 2:  66%|██████▌   | 73/111 [15:49<08:13, 12.98s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  67%|██████▋   | 74/111 [15:49<07:42, 12.51s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  67%|██████▋   | 74/111 [16:03<07:42, 12.51s/it, training_loss=0.378]\u001b[A\n","Epoch 2:  68%|██████▊   | 75/111 [16:03<07:38, 12.72s/it, training_loss=0.378]\u001b[A\n","Epoch 2:  68%|██████▊   | 75/111 [16:16<07:38, 12.72s/it, training_loss=0.466]\u001b[A\n","Epoch 2:  68%|██████▊   | 76/111 [16:16<07:34, 12.98s/it, training_loss=0.466]\u001b[A\n","Epoch 2:  68%|██████▊   | 76/111 [16:30<07:34, 12.98s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  69%|██████▉   | 77/111 [16:30<07:28, 13.18s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  69%|██████▉   | 77/111 [16:42<07:28, 13.18s/it, training_loss=0.359]\u001b[A\n","Epoch 2:  70%|███████   | 78/111 [16:42<07:06, 12.92s/it, training_loss=0.359]\u001b[A\n","Epoch 2:  70%|███████   | 78/111 [16:54<07:06, 12.92s/it, training_loss=0.378]\u001b[A\n","Epoch 2:  71%|███████   | 79/111 [16:54<06:44, 12.63s/it, training_loss=0.378]\u001b[A\n","Epoch 2:  71%|███████   | 79/111 [17:08<06:44, 12.63s/it, training_loss=0.386]\u001b[A\n","Epoch 2:  72%|███████▏  | 80/111 [17:08<06:39, 12.88s/it, training_loss=0.386]\u001b[A\n","Epoch 2:  72%|███████▏  | 80/111 [17:21<06:39, 12.88s/it, training_loss=0.304]\u001b[A\n","Epoch 2:  73%|███████▎  | 81/111 [17:21<06:31, 13.04s/it, training_loss=0.304]\u001b[A\n","Epoch 2:  73%|███████▎  | 81/111 [17:34<06:31, 13.04s/it, training_loss=0.470]\u001b[A\n","Epoch 2:  74%|███████▍  | 82/111 [17:34<06:19, 13.09s/it, training_loss=0.470]\u001b[A\n","Epoch 2:  74%|███████▍  | 82/111 [17:45<06:19, 13.09s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  75%|███████▍  | 83/111 [17:45<05:51, 12.54s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  75%|███████▍  | 83/111 [17:58<05:51, 12.54s/it, training_loss=0.398]\u001b[A\n","Epoch 2:  76%|███████▌  | 84/111 [17:58<05:41, 12.66s/it, training_loss=0.398]\u001b[A\n","Epoch 2:  76%|███████▌  | 84/111 [18:12<05:41, 12.66s/it, training_loss=0.461]\u001b[A\n","Epoch 2:  77%|███████▋  | 85/111 [18:12<05:35, 12.90s/it, training_loss=0.461]\u001b[A\n","Epoch 2:  77%|███████▋  | 85/111 [18:25<05:35, 12.90s/it, training_loss=0.567]\u001b[A\n","Epoch 2:  77%|███████▋  | 86/111 [18:25<05:26, 13.07s/it, training_loss=0.567]\u001b[A\n","Epoch 2:  77%|███████▋  | 86/111 [18:38<05:26, 13.07s/it, training_loss=0.405]\u001b[A\n","Epoch 2:  78%|███████▊  | 87/111 [18:38<05:08, 12.84s/it, training_loss=0.405]\u001b[A\n","Epoch 2:  78%|███████▊  | 87/111 [18:49<05:08, 12.84s/it, training_loss=0.379]\u001b[A\n","Epoch 2:  79%|███████▉  | 88/111 [18:49<04:48, 12.53s/it, training_loss=0.379]\u001b[A\n","Epoch 2:  79%|███████▉  | 88/111 [19:03<04:48, 12.53s/it, training_loss=0.494]\u001b[A\n","Epoch 2:  80%|████████  | 89/111 [19:03<04:40, 12.76s/it, training_loss=0.494]\u001b[A\n","Epoch 2:  80%|████████  | 89/111 [19:16<04:40, 12.76s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  81%|████████  | 90/111 [19:16<04:31, 12.95s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  81%|████████  | 90/111 [19:29<04:31, 12.95s/it, training_loss=0.457]\u001b[A\n","Epoch 2:  82%|████████▏ | 91/111 [19:29<04:20, 13.01s/it, training_loss=0.457]\u001b[A\n","Epoch 2:  82%|████████▏ | 91/111 [19:41<04:20, 13.01s/it, training_loss=0.397]\u001b[A\n","Epoch 2:  83%|████████▎ | 92/111 [19:41<03:57, 12.50s/it, training_loss=0.397]\u001b[A\n","Epoch 2:  83%|████████▎ | 92/111 [19:53<03:57, 12.50s/it, training_loss=0.146]\u001b[A\n","Epoch 2:  84%|████████▍ | 93/111 [19:53<03:46, 12.60s/it, training_loss=0.146]\u001b[A\n","Epoch 2:  84%|████████▍ | 93/111 [20:07<03:46, 12.60s/it, training_loss=0.486]\u001b[A\n","Epoch 2:  85%|████████▍ | 94/111 [20:07<03:38, 12.87s/it, training_loss=0.486]\u001b[A\n","Epoch 2:  85%|████████▍ | 94/111 [20:20<03:38, 12.87s/it, training_loss=0.486]\u001b[A\n","Epoch 2:  86%|████████▌ | 95/111 [20:20<03:29, 13.07s/it, training_loss=0.486]\u001b[A\n","Epoch 2:  86%|████████▌ | 95/111 [20:33<03:29, 13.07s/it, training_loss=0.392]\u001b[A\n","Epoch 2:  86%|████████▋ | 96/111 [20:33<03:12, 12.81s/it, training_loss=0.392]\u001b[A\n","Epoch 2:  86%|████████▋ | 96/111 [20:45<03:12, 12.81s/it, training_loss=0.360]\u001b[A\n","Epoch 2:  87%|████████▋ | 97/111 [20:45<02:56, 12.58s/it, training_loss=0.360]\u001b[A\n","Epoch 2:  87%|████████▋ | 97/111 [20:58<02:56, 12.58s/it, training_loss=0.319]\u001b[A\n","Epoch 2:  88%|████████▊ | 98/111 [20:58<02:46, 12.82s/it, training_loss=0.319]\u001b[A\n","Epoch 2:  88%|████████▊ | 98/111 [21:12<02:46, 12.82s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  89%|████████▉ | 99/111 [21:12<02:36, 13.03s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  89%|████████▉ | 99/111 [21:25<02:36, 13.03s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  90%|█████████ | 100/111 [21:25<02:24, 13.14s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  90%|█████████ | 100/111 [21:36<02:24, 13.14s/it, training_loss=0.359]\u001b[A\n","Epoch 2:  91%|█████████ | 101/111 [21:36<02:05, 12.60s/it, training_loss=0.359]\u001b[A\n","Epoch 2:  91%|█████████ | 101/111 [21:49<02:05, 12.60s/it, training_loss=0.242]\u001b[A\n","Epoch 2:  92%|█████████▏| 102/111 [21:49<01:53, 12.63s/it, training_loss=0.242]\u001b[A\n","Epoch 2:  92%|█████████▏| 102/111 [22:02<01:53, 12.63s/it, training_loss=0.436]\u001b[A\n","Epoch 2:  93%|█████████▎| 103/111 [22:02<01:42, 12.87s/it, training_loss=0.436]\u001b[A\n","Epoch 2:  93%|█████████▎| 103/111 [22:16<01:42, 12.87s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  94%|█████████▎| 104/111 [22:16<01:31, 13.07s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  94%|█████████▎| 104/111 [22:29<01:31, 13.07s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  95%|█████████▍| 105/111 [22:29<01:17, 12.96s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  95%|█████████▍| 105/111 [22:40<01:17, 12.96s/it, training_loss=0.206]\u001b[A\n","Epoch 2:  95%|█████████▌| 106/111 [22:40<01:03, 12.60s/it, training_loss=0.206]\u001b[A\n","Epoch 2:  95%|█████████▌| 106/111 [22:54<01:03, 12.60s/it, training_loss=0.333]\u001b[A\n","Epoch 2:  96%|█████████▋| 107/111 [22:54<00:51, 12.88s/it, training_loss=0.333]\u001b[A\n","Epoch 2:  96%|█████████▋| 107/111 [23:07<00:51, 12.88s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  97%|█████████▋| 108/111 [23:07<00:39, 13.08s/it, training_loss=0.358]\u001b[A\n","Epoch 2:  97%|█████████▋| 108/111 [23:21<00:39, 13.08s/it, training_loss=0.318]\u001b[A\n","Epoch 2:  98%|█████████▊| 109/111 [23:21<00:26, 13.17s/it, training_loss=0.318]\u001b[A\n","Epoch 2:  98%|█████████▊| 109/111 [23:33<00:26, 13.17s/it, training_loss=0.171]\u001b[A\n","Epoch 2:  99%|█████████▉| 110/111 [23:33<00:12, 12.75s/it, training_loss=0.171]\u001b[A\n","Epoch 2:  99%|█████████▉| 110/111 [23:43<00:12, 12.75s/it, training_loss=0.395]\u001b[A\n","Epoch 2: 100%|██████████| 111/111 [23:43<00:00, 11.96s/it, training_loss=0.395]\u001b[A\n"," 25%|██▌       | 1/4 [49:38<1:17:39, 1553.00s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.2967817944449347\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [51:32<51:29, 1544.95s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.1605821219938142\n","F1 Score (Weighted): 0.38636716428282497\n","QWK Score: 0.3204536330790847\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/111 [00:13<?, ?it/s, training_loss=0.129]\u001b[A\n","Epoch 3:   1%|          | 1/111 [00:13<25:03, 13.67s/it, training_loss=0.129]\u001b[A\n","Epoch 3:   1%|          | 1/111 [00:26<25:03, 13.67s/it, training_loss=0.385]\u001b[A\n","Epoch 3:   2%|▏         | 2/111 [00:26<24:04, 13.25s/it, training_loss=0.385]\u001b[A\n","Epoch 3:   2%|▏         | 2/111 [00:38<24:04, 13.25s/it, training_loss=0.452]\u001b[A\n","Epoch 3:   3%|▎         | 3/111 [00:38<22:36, 12.56s/it, training_loss=0.452]\u001b[A\n","Epoch 3:   3%|▎         | 3/111 [00:51<22:36, 12.56s/it, training_loss=0.289]\u001b[A\n","Epoch 3:   4%|▎         | 4/111 [00:51<22:57, 12.88s/it, training_loss=0.289]\u001b[A\n","Epoch 3:   4%|▎         | 4/111 [01:05<22:57, 12.88s/it, training_loss=0.260]\u001b[A\n","Epoch 3:   5%|▍         | 5/111 [01:05<23:07, 13.09s/it, training_loss=0.260]\u001b[A\n","Epoch 3:   5%|▍         | 5/111 [01:18<23:07, 13.09s/it, training_loss=0.391]\u001b[A\n","Epoch 3:   5%|▌         | 6/111 [01:18<23:05, 13.20s/it, training_loss=0.391]\u001b[A\n","Epoch 3:   5%|▌         | 6/111 [01:29<23:05, 13.20s/it, training_loss=0.496]\u001b[A\n","Epoch 3:   6%|▋         | 7/111 [01:29<21:50, 12.60s/it, training_loss=0.496]\u001b[A\n","Epoch 3:   6%|▋         | 7/111 [01:43<21:50, 12.60s/it, training_loss=0.258]\u001b[A\n","Epoch 3:   7%|▋         | 8/111 [01:43<21:55, 12.77s/it, training_loss=0.258]\u001b[A\n","Epoch 3:   7%|▋         | 8/111 [01:57<21:55, 12.77s/it, training_loss=0.502]\u001b[A\n","Epoch 3:   8%|▊         | 9/111 [01:57<22:25, 13.19s/it, training_loss=0.502]\u001b[A\n","Epoch 3:   8%|▊         | 9/111 [02:11<22:25, 13.19s/it, training_loss=0.154]\u001b[A\n","Epoch 3:   9%|▉         | 10/111 [02:11<22:35, 13.42s/it, training_loss=0.154]\u001b[A\n","Epoch 3:   9%|▉         | 10/111 [02:24<22:35, 13.42s/it, training_loss=0.386]\u001b[A\n","Epoch 3:  10%|▉         | 11/111 [02:24<22:26, 13.47s/it, training_loss=0.386]\u001b[A\n","Epoch 3:  10%|▉         | 11/111 [02:36<22:26, 13.47s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  11%|█         | 12/111 [02:36<21:09, 12.83s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  11%|█         | 12/111 [02:49<21:09, 12.83s/it, training_loss=0.159]\u001b[A\n","Epoch 3:  12%|█▏        | 13/111 [02:49<21:04, 12.90s/it, training_loss=0.159]\u001b[A\n","Epoch 3:  12%|█▏        | 13/111 [03:02<21:04, 12.90s/it, training_loss=0.631]\u001b[A\n","Epoch 3:  13%|█▎        | 14/111 [03:02<21:06, 13.05s/it, training_loss=0.631]\u001b[A\n","Epoch 3:  13%|█▎        | 14/111 [03:15<21:06, 13.05s/it, training_loss=0.291]\u001b[A\n","Epoch 3:  14%|█▎        | 15/111 [03:15<21:01, 13.14s/it, training_loss=0.291]\u001b[A\n","Epoch 3:  14%|█▎        | 15/111 [03:27<21:01, 13.14s/it, training_loss=0.492]\u001b[A\n","Epoch 3:  14%|█▍        | 16/111 [03:27<20:17, 12.81s/it, training_loss=0.492]\u001b[A\n","Epoch 3:  14%|█▍        | 16/111 [03:39<20:17, 12.81s/it, training_loss=0.634]\u001b[A\n","Epoch 3:  15%|█▌        | 17/111 [03:39<19:38, 12.53s/it, training_loss=0.634]\u001b[A\n","Epoch 3:  15%|█▌        | 17/111 [03:53<19:38, 12.53s/it, training_loss=0.352]\u001b[A\n","Epoch 3:  16%|█▌        | 18/111 [03:53<19:52, 12.82s/it, training_loss=0.352]\u001b[A\n","Epoch 3:  16%|█▌        | 18/111 [04:06<19:52, 12.82s/it, training_loss=0.341]\u001b[A\n","Epoch 3:  17%|█▋        | 19/111 [04:07<20:02, 13.07s/it, training_loss=0.341]\u001b[A\n","Epoch 3:  17%|█▋        | 19/111 [04:20<20:02, 13.07s/it, training_loss=0.315]\u001b[A\n","Epoch 3:  18%|█▊        | 20/111 [04:20<19:55, 13.14s/it, training_loss=0.315]\u001b[A\n","Epoch 3:  18%|█▊        | 20/111 [04:31<19:55, 13.14s/it, training_loss=0.157]\u001b[A\n","Epoch 3:  19%|█▉        | 21/111 [04:31<19:00, 12.67s/it, training_loss=0.157]\u001b[A\n","Epoch 3:  19%|█▉        | 21/111 [04:45<19:00, 12.67s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  20%|█▉        | 22/111 [04:45<19:07, 12.89s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  20%|█▉        | 22/111 [04:58<19:07, 12.89s/it, training_loss=0.171]\u001b[A\n","Epoch 3:  21%|██        | 23/111 [04:58<19:15, 13.14s/it, training_loss=0.171]\u001b[A\n","Epoch 3:  21%|██        | 23/111 [05:12<19:15, 13.14s/it, training_loss=0.471]\u001b[A\n","Epoch 3:  22%|██▏       | 24/111 [05:12<19:18, 13.32s/it, training_loss=0.471]\u001b[A\n","Epoch 3:  22%|██▏       | 24/111 [05:25<19:18, 13.32s/it, training_loss=0.129]\u001b[A\n","Epoch 3:  23%|██▎       | 25/111 [05:25<19:00, 13.26s/it, training_loss=0.129]\u001b[A\n","Epoch 3:  23%|██▎       | 25/111 [05:37<19:00, 13.26s/it, training_loss=0.414]\u001b[A\n","Epoch 3:  23%|██▎       | 26/111 [05:37<18:08, 12.81s/it, training_loss=0.414]\u001b[A\n","Epoch 3:  23%|██▎       | 26/111 [05:51<18:08, 12.81s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  24%|██▍       | 27/111 [05:51<18:12, 13.00s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  24%|██▍       | 27/111 [06:04<18:12, 13.00s/it, training_loss=0.281]\u001b[A\n","Epoch 3:  25%|██▌       | 28/111 [06:04<18:14, 13.19s/it, training_loss=0.281]\u001b[A\n","Epoch 3:  25%|██▌       | 28/111 [06:18<18:14, 13.19s/it, training_loss=0.211]\u001b[A\n","Epoch 3:  26%|██▌       | 29/111 [06:18<18:12, 13.32s/it, training_loss=0.211]\u001b[A\n","Epoch 3:  26%|██▌       | 29/111 [06:30<18:12, 13.32s/it, training_loss=0.406]\u001b[A\n","Epoch 3:  27%|██▋       | 30/111 [06:30<17:33, 13.01s/it, training_loss=0.406]\u001b[A\n","Epoch 3:  27%|██▋       | 30/111 [06:42<17:33, 13.01s/it, training_loss=0.166]\u001b[A\n","Epoch 3:  28%|██▊       | 31/111 [06:42<17:00, 12.76s/it, training_loss=0.166]\u001b[A\n","Epoch 3:  28%|██▊       | 31/111 [06:56<17:00, 12.76s/it, training_loss=0.228]\u001b[A\n","Epoch 3:  29%|██▉       | 32/111 [06:56<17:06, 13.00s/it, training_loss=0.228]\u001b[A\n","Epoch 3:  29%|██▉       | 32/111 [07:09<17:06, 13.00s/it, training_loss=0.197]\u001b[A\n","Epoch 3:  30%|██▉       | 33/111 [07:09<17:07, 13.17s/it, training_loss=0.197]\u001b[A\n","Epoch 3:  30%|██▉       | 33/111 [07:23<17:07, 13.17s/it, training_loss=0.253]\u001b[A\n","Epoch 3:  31%|███       | 34/111 [07:23<16:59, 13.24s/it, training_loss=0.253]\u001b[A\n","Epoch 3:  31%|███       | 34/111 [07:34<16:59, 13.24s/it, training_loss=0.309]\u001b[A\n","Epoch 3:  32%|███▏      | 35/111 [07:34<16:05, 12.70s/it, training_loss=0.309]\u001b[A\n","Epoch 3:  32%|███▏      | 35/111 [07:47<16:05, 12.70s/it, training_loss=0.289]\u001b[A\n","Epoch 3:  32%|███▏      | 36/111 [07:47<15:56, 12.75s/it, training_loss=0.289]\u001b[A\n","Epoch 3:  32%|███▏      | 36/111 [08:01<15:56, 12.75s/it, training_loss=0.635]\u001b[A\n","Epoch 3:  33%|███▎      | 37/111 [08:01<16:03, 13.02s/it, training_loss=0.635]\u001b[A\n","Epoch 3:  33%|███▎      | 37/111 [08:14<16:03, 13.02s/it, training_loss=0.674]\u001b[A\n","Epoch 3:  34%|███▍      | 38/111 [08:14<16:01, 13.18s/it, training_loss=0.674]\u001b[A\n","Epoch 3:  34%|███▍      | 38/111 [08:27<16:01, 13.18s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  35%|███▌      | 39/111 [08:27<15:41, 13.07s/it, training_loss=0.306]\u001b[A\n","Epoch 3:  35%|███▌      | 39/111 [08:39<15:41, 13.07s/it, training_loss=0.401]\u001b[A\n","Epoch 3:  36%|███▌      | 40/111 [08:39<15:02, 12.71s/it, training_loss=0.401]\u001b[A\n","Epoch 3:  36%|███▌      | 40/111 [08:53<15:02, 12.71s/it, training_loss=0.420]\u001b[A\n","Epoch 3:  37%|███▋      | 41/111 [08:53<15:08, 12.97s/it, training_loss=0.420]\u001b[A\n","Epoch 3:  37%|███▋      | 41/111 [09:06<15:08, 12.97s/it, training_loss=0.398]\u001b[A\n","Epoch 3:  38%|███▊      | 42/111 [09:06<15:08, 13.16s/it, training_loss=0.398]\u001b[A\n","Epoch 3:  38%|███▊      | 42/111 [09:20<15:08, 13.16s/it, training_loss=0.470]\u001b[A\n","Epoch 3:  39%|███▊      | 43/111 [09:20<15:02, 13.27s/it, training_loss=0.470]\u001b[A\n","Epoch 3:  39%|███▊      | 43/111 [09:32<15:02, 13.27s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  40%|███▉      | 44/111 [09:32<14:21, 12.85s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  40%|███▉      | 44/111 [09:44<14:21, 12.85s/it, training_loss=0.575]\u001b[A\n","Epoch 3:  41%|████      | 45/111 [09:44<13:56, 12.67s/it, training_loss=0.575]\u001b[A\n","Epoch 3:  41%|████      | 45/111 [09:57<13:56, 12.67s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  41%|████▏     | 46/111 [09:57<13:56, 12.87s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  41%|████▏     | 46/111 [10:11<13:56, 12.87s/it, training_loss=0.912]\u001b[A\n","Epoch 3:  42%|████▏     | 47/111 [10:11<13:55, 13.06s/it, training_loss=0.912]\u001b[A\n","Epoch 3:  42%|████▏     | 47/111 [10:24<13:55, 13.06s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  43%|████▎     | 48/111 [10:24<13:44, 13.08s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  43%|████▎     | 48/111 [10:35<13:44, 13.08s/it, training_loss=0.378]\u001b[A\n","Epoch 3:  44%|████▍     | 49/111 [10:35<13:00, 12.60s/it, training_loss=0.378]\u001b[A\n","Epoch 3:  44%|████▍     | 49/111 [10:49<13:00, 12.60s/it, training_loss=0.482]\u001b[A\n","Epoch 3:  45%|████▌     | 50/111 [10:49<13:00, 12.80s/it, training_loss=0.482]\u001b[A\n","Epoch 3:  45%|████▌     | 50/111 [11:02<13:00, 12.80s/it, training_loss=0.209]\u001b[A\n","Epoch 3:  46%|████▌     | 51/111 [11:02<13:03, 13.06s/it, training_loss=0.209]\u001b[A\n","Epoch 3:  46%|████▌     | 51/111 [11:16<13:03, 13.06s/it, training_loss=0.620]\u001b[A\n","Epoch 3:  47%|████▋     | 52/111 [11:16<13:00, 13.23s/it, training_loss=0.620]\u001b[A\n","Epoch 3:  47%|████▋     | 52/111 [11:28<13:00, 13.23s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  48%|████▊     | 53/111 [11:28<12:32, 12.98s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  48%|████▊     | 53/111 [11:40<12:32, 12.98s/it, training_loss=0.437]\u001b[A\n","Epoch 3:  49%|████▊     | 54/111 [11:40<11:58, 12.61s/it, training_loss=0.437]\u001b[A\n","Epoch 3:  49%|████▊     | 54/111 [11:53<11:58, 12.61s/it, training_loss=0.438]\u001b[A\n","Epoch 3:  50%|████▉     | 55/111 [11:53<11:57, 12.81s/it, training_loss=0.438]\u001b[A\n","Epoch 3:  50%|████▉     | 55/111 [12:07<11:57, 12.81s/it, training_loss=0.291]\u001b[A\n","Epoch 3:  50%|█████     | 56/111 [12:07<11:54, 12.99s/it, training_loss=0.291]\u001b[A\n","Epoch 3:  50%|█████     | 56/111 [12:20<11:54, 12.99s/it, training_loss=0.633]\u001b[A\n","Epoch 3:  51%|█████▏    | 57/111 [12:20<11:41, 12.98s/it, training_loss=0.633]\u001b[A\n","Epoch 3:  51%|█████▏    | 57/111 [12:31<11:41, 12.98s/it, training_loss=0.594]\u001b[A\n","Epoch 3:  52%|█████▏    | 58/111 [12:31<11:03, 12.51s/it, training_loss=0.594]\u001b[A\n","Epoch 3:  52%|█████▏    | 58/111 [12:44<11:03, 12.51s/it, training_loss=0.176]\u001b[A\n","Epoch 3:  53%|█████▎    | 59/111 [12:44<11:00, 12.70s/it, training_loss=0.176]\u001b[A\n","Epoch 3:  53%|█████▎    | 59/111 [12:58<11:00, 12.70s/it, training_loss=0.324]\u001b[A\n","Epoch 3:  54%|█████▍    | 60/111 [12:58<11:01, 12.96s/it, training_loss=0.324]\u001b[A\n","Epoch 3:  54%|█████▍    | 60/111 [13:11<11:01, 12.96s/it, training_loss=0.413]\u001b[A\n","Epoch 3:  55%|█████▍    | 61/111 [13:11<10:55, 13.11s/it, training_loss=0.413]\u001b[A\n","Epoch 3:  55%|█████▍    | 61/111 [13:23<10:55, 13.11s/it, training_loss=0.272]\u001b[A\n","Epoch 3:  56%|█████▌    | 62/111 [13:23<10:29, 12.85s/it, training_loss=0.272]\u001b[A\n","Epoch 3:  56%|█████▌    | 62/111 [13:35<10:29, 12.85s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  57%|█████▋    | 63/111 [13:35<10:04, 12.59s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  57%|█████▋    | 63/111 [13:49<10:04, 12.59s/it, training_loss=0.191]\u001b[A\n","Epoch 3:  58%|█████▊    | 64/111 [13:49<10:06, 12.91s/it, training_loss=0.191]\u001b[A\n","Epoch 3:  58%|█████▊    | 64/111 [14:03<10:06, 12.91s/it, training_loss=0.194]\u001b[A\n","Epoch 3:  59%|█████▊    | 65/111 [14:03<10:01, 13.07s/it, training_loss=0.194]\u001b[A\n","Epoch 3:  59%|█████▊    | 65/111 [14:16<10:01, 13.07s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  59%|█████▉    | 66/111 [14:16<09:52, 13.16s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  59%|█████▉    | 66/111 [14:27<09:52, 13.16s/it, training_loss=0.319]\u001b[A\n","Epoch 3:  60%|██████    | 67/111 [14:27<09:12, 12.55s/it, training_loss=0.319]\u001b[A\n","Epoch 3:  60%|██████    | 67/111 [14:40<09:12, 12.55s/it, training_loss=0.275]\u001b[A\n","Epoch 3:  61%|██████▏   | 68/111 [14:40<09:07, 12.72s/it, training_loss=0.275]\u001b[A\n","Epoch 3:  61%|██████▏   | 68/111 [14:54<09:07, 12.72s/it, training_loss=0.366]\u001b[A\n","Epoch 3:  62%|██████▏   | 69/111 [14:54<09:04, 12.97s/it, training_loss=0.366]\u001b[A\n","Epoch 3:  62%|██████▏   | 69/111 [15:07<09:04, 12.97s/it, training_loss=0.226]\u001b[A\n","Epoch 3:  63%|██████▎   | 70/111 [15:07<08:59, 13.15s/it, training_loss=0.226]\u001b[A\n","Epoch 3:  63%|██████▎   | 70/111 [15:20<08:59, 13.15s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  64%|██████▍   | 71/111 [15:20<08:40, 13.01s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  64%|██████▍   | 71/111 [15:32<08:40, 13.01s/it, training_loss=0.254]\u001b[A\n","Epoch 3:  65%|██████▍   | 72/111 [15:32<08:11, 12.59s/it, training_loss=0.254]\u001b[A\n","Epoch 3:  65%|██████▍   | 72/111 [15:45<08:11, 12.59s/it, training_loss=0.101]\u001b[A\n","Epoch 3:  66%|██████▌   | 73/111 [15:45<08:07, 12.83s/it, training_loss=0.101]\u001b[A\n","Epoch 3:  66%|██████▌   | 73/111 [15:59<08:07, 12.83s/it, training_loss=0.082]\u001b[A\n","Epoch 3:  67%|██████▋   | 74/111 [15:59<08:02, 13.05s/it, training_loss=0.082]\u001b[A\n","Epoch 3:  67%|██████▋   | 74/111 [16:12<08:02, 13.05s/it, training_loss=0.616]\u001b[A\n","Epoch 3:  68%|██████▊   | 75/111 [16:12<07:54, 13.19s/it, training_loss=0.616]\u001b[A\n","Epoch 3:  68%|██████▊   | 75/111 [16:24<07:54, 13.19s/it, training_loss=0.247]\u001b[A\n","Epoch 3:  68%|██████▊   | 76/111 [16:24<07:24, 12.70s/it, training_loss=0.247]\u001b[A\n","Epoch 3:  68%|██████▊   | 76/111 [16:36<07:24, 12.70s/it, training_loss=0.361]\u001b[A\n","Epoch 3:  69%|██████▉   | 77/111 [16:36<07:12, 12.72s/it, training_loss=0.361]\u001b[A\n","Epoch 3:  69%|██████▉   | 77/111 [16:50<07:12, 12.72s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  70%|███████   | 78/111 [16:50<07:09, 13.00s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  70%|███████   | 78/111 [17:05<07:09, 13.00s/it, training_loss=0.237]\u001b[A\n","Epoch 3:  71%|███████   | 79/111 [17:05<07:18, 13.71s/it, training_loss=0.237]\u001b[A\n","Epoch 3:  71%|███████   | 79/111 [17:17<07:18, 13.71s/it, training_loss=0.332]\u001b[A\n","Epoch 3:  72%|███████▏  | 80/111 [17:17<06:49, 13.21s/it, training_loss=0.332]\u001b[A\n","Epoch 3:  72%|███████▏  | 80/111 [17:31<06:49, 13.21s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  73%|███████▎  | 81/111 [17:31<06:35, 13.17s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  73%|███████▎  | 81/111 [17:44<06:35, 13.17s/it, training_loss=0.235]\u001b[A\n","Epoch 3:  74%|███████▍  | 82/111 [17:44<06:25, 13.28s/it, training_loss=0.235]\u001b[A\n","Epoch 3:  74%|███████▍  | 82/111 [17:58<06:25, 13.28s/it, training_loss=0.321]\u001b[A\n","Epoch 3:  75%|███████▍  | 83/111 [17:58<06:13, 13.36s/it, training_loss=0.321]\u001b[A\n","Epoch 3:  75%|███████▍  | 83/111 [18:10<06:13, 13.36s/it, training_loss=0.227]\u001b[A\n","Epoch 3:  76%|███████▌  | 84/111 [18:10<05:52, 13.05s/it, training_loss=0.227]\u001b[A\n","Epoch 3:  76%|███████▌  | 84/111 [18:22<05:52, 13.05s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  77%|███████▋  | 85/111 [18:22<05:31, 12.76s/it, training_loss=0.449]\u001b[A\n","Epoch 3:  77%|███████▋  | 85/111 [18:36<05:31, 12.76s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  77%|███████▋  | 86/111 [18:36<05:25, 13.04s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  77%|███████▋  | 86/111 [18:49<05:25, 13.04s/it, training_loss=0.513]\u001b[A\n","Epoch 3:  78%|███████▊  | 87/111 [18:49<05:18, 13.26s/it, training_loss=0.513]\u001b[A\n","Epoch 3:  78%|███████▊  | 87/111 [19:03<05:18, 13.26s/it, training_loss=0.332]\u001b[A\n","Epoch 3:  79%|███████▉  | 88/111 [19:03<05:06, 13.33s/it, training_loss=0.332]\u001b[A\n","Epoch 3:  79%|███████▉  | 88/111 [19:15<05:06, 13.33s/it, training_loss=0.348]\u001b[A\n","Epoch 3:  80%|████████  | 89/111 [19:15<04:44, 12.91s/it, training_loss=0.348]\u001b[A\n","Epoch 3:  80%|████████  | 89/111 [19:27<04:44, 12.91s/it, training_loss=0.985]\u001b[A\n","Epoch 3:  81%|████████  | 90/111 [19:27<04:28, 12.77s/it, training_loss=0.985]\u001b[A\n","Epoch 3:  81%|████████  | 90/111 [19:41<04:28, 12.77s/it, training_loss=0.420]\u001b[A\n","Epoch 3:  82%|████████▏ | 91/111 [19:41<04:19, 12.99s/it, training_loss=0.420]\u001b[A\n","Epoch 3:  82%|████████▏ | 91/111 [19:54<04:19, 12.99s/it, training_loss=0.261]\u001b[A\n","Epoch 3:  83%|████████▎ | 92/111 [19:54<04:10, 13.17s/it, training_loss=0.261]\u001b[A\n","Epoch 3:  83%|████████▎ | 92/111 [20:07<04:10, 13.17s/it, training_loss=0.471]\u001b[A\n","Epoch 3:  84%|████████▍ | 93/111 [20:07<03:55, 13.10s/it, training_loss=0.471]\u001b[A\n","Epoch 3:  84%|████████▍ | 93/111 [20:19<03:55, 13.10s/it, training_loss=0.146]\u001b[A\n","Epoch 3:  85%|████████▍ | 94/111 [20:19<03:34, 12.64s/it, training_loss=0.146]\u001b[A\n","Epoch 3:  85%|████████▍ | 94/111 [20:35<03:34, 12.64s/it, training_loss=0.600]\u001b[A\n","Epoch 3:  86%|████████▌ | 95/111 [20:35<03:37, 13.57s/it, training_loss=0.600]\u001b[A\n","Epoch 3:  86%|████████▌ | 95/111 [20:48<03:37, 13.57s/it, training_loss=0.310]\u001b[A\n","Epoch 3:  86%|████████▋ | 96/111 [20:48<03:23, 13.57s/it, training_loss=0.310]\u001b[A\n","Epoch 3:  86%|████████▋ | 96/111 [21:02<03:23, 13.57s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  87%|████████▋ | 97/111 [21:02<03:10, 13.60s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  87%|████████▋ | 97/111 [21:15<03:10, 13.60s/it, training_loss=0.137]\u001b[A\n","Epoch 3:  88%|████████▊ | 98/111 [21:15<02:56, 13.58s/it, training_loss=0.137]\u001b[A\n","Epoch 3:  88%|████████▊ | 98/111 [21:27<02:56, 13.58s/it, training_loss=0.228]\u001b[A\n","Epoch 3:  89%|████████▉ | 99/111 [21:27<02:35, 12.94s/it, training_loss=0.228]\u001b[A\n","Epoch 3:  89%|████████▉ | 99/111 [21:39<02:35, 12.94s/it, training_loss=0.164]\u001b[A\n","Epoch 3:  90%|█████████ | 100/111 [21:40<02:21, 12.84s/it, training_loss=0.164]\u001b[A\n","Epoch 3:  90%|█████████ | 100/111 [21:53<02:21, 12.84s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  91%|█████████ | 101/111 [21:53<02:10, 13.04s/it, training_loss=0.355]\u001b[A\n","Epoch 3:  91%|█████████ | 101/111 [22:06<02:10, 13.04s/it, training_loss=0.362]\u001b[A\n","Epoch 3:  92%|█████████▏| 102/111 [22:06<01:58, 13.17s/it, training_loss=0.362]\u001b[A\n","Epoch 3:  92%|█████████▏| 102/111 [22:19<01:58, 13.17s/it, training_loss=0.434]\u001b[A\n","Epoch 3:  93%|█████████▎| 103/111 [22:19<01:44, 13.05s/it, training_loss=0.434]\u001b[A\n","Epoch 3:  93%|█████████▎| 103/111 [22:31<01:44, 13.05s/it, training_loss=0.316]\u001b[A\n","Epoch 3:  94%|█████████▎| 104/111 [22:31<01:28, 12.63s/it, training_loss=0.316]\u001b[A\n","Epoch 3:  94%|█████████▎| 104/111 [22:44<01:28, 12.63s/it, training_loss=0.224]\u001b[A\n","Epoch 3:  95%|█████████▍| 105/111 [22:44<01:17, 12.91s/it, training_loss=0.224]\u001b[A\n","Epoch 3:  95%|█████████▍| 105/111 [22:58<01:17, 12.91s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  95%|█████████▌| 106/111 [22:58<01:05, 13.05s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  95%|█████████▌| 106/111 [23:11<01:05, 13.05s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  96%|█████████▋| 107/111 [23:11<00:52, 13.16s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  96%|█████████▋| 107/111 [23:23<00:52, 13.16s/it, training_loss=0.376]\u001b[A\n","Epoch 3:  97%|█████████▋| 108/111 [23:23<00:37, 12.65s/it, training_loss=0.376]\u001b[A\n","Epoch 3:  97%|█████████▋| 108/111 [23:35<00:37, 12.65s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  98%|█████████▊| 109/111 [23:35<00:25, 12.63s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  98%|█████████▊| 109/111 [23:49<00:25, 12.63s/it, training_loss=0.186]\u001b[A\n","Epoch 3:  99%|█████████▉| 110/111 [23:49<00:12, 12.89s/it, training_loss=0.186]\u001b[A\n","Epoch 3:  99%|█████████▉| 110/111 [23:59<00:12, 12.89s/it, training_loss=0.293]\u001b[A\n","Epoch 3: 100%|██████████| 111/111 [23:59<00:00, 12.20s/it, training_loss=0.293]\u001b[A\n"," 50%|█████     | 2/4 [1:15:36<51:29, 1544.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 1.068689310335898\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [1:17:31<25:51, 1551.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.1504605391195841\n","F1 Score (Weighted): 0.5150467427392531\n","QWK Score: 0.41907771304433694\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/111 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/111 [00:13<?, ?it/s, training_loss=0.235]\u001b[A\n","Epoch 4:   1%|          | 1/111 [00:13<24:03, 13.12s/it, training_loss=0.235]\u001b[A\n","Epoch 4:   1%|          | 1/111 [00:26<24:03, 13.12s/it, training_loss=0.247]\u001b[A\n","Epoch 4:   2%|▏         | 2/111 [00:26<24:24, 13.44s/it, training_loss=0.247]\u001b[A\n","Epoch 4:   2%|▏         | 2/111 [00:40<24:24, 13.44s/it, training_loss=0.275]\u001b[A\n","Epoch 4:   3%|▎         | 3/111 [00:40<24:15, 13.47s/it, training_loss=0.275]\u001b[A\n","Epoch 4:   3%|▎         | 3/111 [00:52<24:15, 13.47s/it, training_loss=0.131]\u001b[A\n","Epoch 4:   4%|▎         | 4/111 [00:52<23:02, 12.92s/it, training_loss=0.131]\u001b[A\n","Epoch 4:   4%|▎         | 4/111 [01:04<23:02, 12.92s/it, training_loss=0.226]\u001b[A\n","Epoch 4:   5%|▍         | 5/111 [01:04<22:17, 12.62s/it, training_loss=0.226]\u001b[A\n","Epoch 4:   5%|▍         | 5/111 [01:17<22:17, 12.62s/it, training_loss=0.262]\u001b[A\n","Epoch 4:   5%|▌         | 6/111 [01:17<22:38, 12.93s/it, training_loss=0.262]\u001b[A\n","Epoch 4:   5%|▌         | 6/111 [01:32<22:38, 12.93s/it, training_loss=0.551]\u001b[A\n","Epoch 4:   6%|▋         | 7/111 [01:32<23:20, 13.46s/it, training_loss=0.551]\u001b[A\n","Epoch 4:   6%|▋         | 7/111 [01:47<23:20, 13.46s/it, training_loss=0.348]\u001b[A\n","Epoch 4:   7%|▋         | 8/111 [01:47<23:39, 13.78s/it, training_loss=0.348]\u001b[A\n","Epoch 4:   7%|▋         | 8/111 [01:59<23:39, 13.78s/it, training_loss=0.168]\u001b[A\n","Epoch 4:   8%|▊         | 9/111 [01:59<22:37, 13.31s/it, training_loss=0.168]\u001b[A\n","Epoch 4:   8%|▊         | 9/111 [02:11<22:37, 13.31s/it, training_loss=0.169]\u001b[A\n","Epoch 4:   9%|▉         | 10/111 [02:11<21:36, 12.84s/it, training_loss=0.169]\u001b[A\n","Epoch 4:   9%|▉         | 10/111 [02:24<21:36, 12.84s/it, training_loss=0.465]\u001b[A\n","Epoch 4:  10%|▉         | 11/111 [02:24<21:44, 13.05s/it, training_loss=0.465]\u001b[A\n","Epoch 4:  10%|▉         | 11/111 [02:37<21:44, 13.05s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  11%|█         | 12/111 [02:37<21:42, 13.16s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  11%|█         | 12/111 [02:51<21:42, 13.16s/it, training_loss=0.373]\u001b[A\n","Epoch 4:  12%|█▏        | 13/111 [02:51<21:31, 13.17s/it, training_loss=0.373]\u001b[A\n","Epoch 4:  12%|█▏        | 13/111 [03:02<21:31, 13.17s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  13%|█▎        | 14/111 [03:02<20:25, 12.63s/it, training_loss=0.201]\u001b[A\n","Epoch 4:  13%|█▎        | 14/111 [03:15<20:25, 12.63s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  14%|█▎        | 15/111 [03:15<20:24, 12.76s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  14%|█▎        | 15/111 [03:28<20:24, 12.76s/it, training_loss=0.318]\u001b[A\n","Epoch 4:  14%|█▍        | 16/111 [03:28<20:23, 12.88s/it, training_loss=0.318]\u001b[A\n","Epoch 4:  14%|█▍        | 16/111 [03:42<20:23, 12.88s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  15%|█▌        | 17/111 [03:42<20:26, 13.05s/it, training_loss=0.214]\u001b[A\n","Epoch 4:  15%|█▌        | 17/111 [03:53<20:26, 13.05s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  16%|█▌        | 18/111 [03:53<19:32, 12.61s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  16%|█▌        | 18/111 [04:05<19:32, 12.61s/it, training_loss=0.587]\u001b[A\n","Epoch 4:  17%|█▋        | 19/111 [04:05<19:02, 12.42s/it, training_loss=0.587]\u001b[A\n","Epoch 4:  17%|█▋        | 19/111 [04:18<19:02, 12.42s/it, training_loss=0.335]\u001b[A\n","Epoch 4:  18%|█▊        | 20/111 [04:18<19:06, 12.60s/it, training_loss=0.335]\u001b[A\n","Epoch 4:  18%|█▊        | 20/111 [04:32<19:06, 12.60s/it, training_loss=0.301]\u001b[A\n","Epoch 4:  19%|█▉        | 21/111 [04:32<19:15, 12.84s/it, training_loss=0.301]\u001b[A\n","Epoch 4:  19%|█▉        | 21/111 [04:44<19:15, 12.84s/it, training_loss=0.715]\u001b[A\n","Epoch 4:  20%|█▉        | 22/111 [04:44<18:41, 12.60s/it, training_loss=0.715]\u001b[A\n","Epoch 4:  20%|█▉        | 22/111 [04:56<18:41, 12.60s/it, training_loss=0.161]\u001b[A\n","Epoch 4:  21%|██        | 23/111 [04:56<18:09, 12.38s/it, training_loss=0.161]\u001b[A\n","Epoch 4:  21%|██        | 23/111 [05:12<18:09, 12.38s/it, training_loss=0.186]\u001b[A\n","Epoch 4:  22%|██▏       | 24/111 [05:12<19:38, 13.55s/it, training_loss=0.186]\u001b[A\n","Epoch 4:  22%|██▏       | 24/111 [05:25<19:38, 13.55s/it, training_loss=1.023]\u001b[A\n","Epoch 4:  23%|██▎       | 25/111 [05:25<19:21, 13.51s/it, training_loss=1.023]\u001b[A\n","Epoch 4:  23%|██▎       | 25/111 [05:36<19:21, 13.51s/it, training_loss=0.161]\u001b[A\n","Epoch 4:  23%|██▎       | 26/111 [05:36<17:57, 12.68s/it, training_loss=0.161]\u001b[A\n","Epoch 4:  23%|██▎       | 26/111 [05:49<17:57, 12.68s/it, training_loss=0.291]\u001b[A\n","Epoch 4:  24%|██▍       | 27/111 [05:49<17:42, 12.65s/it, training_loss=0.291]\u001b[A\n","Epoch 4:  24%|██▍       | 27/111 [06:02<17:42, 12.65s/it, training_loss=0.511]\u001b[A\n","Epoch 4:  25%|██▌       | 28/111 [06:02<17:47, 12.86s/it, training_loss=0.511]\u001b[A\n","Epoch 4:  25%|██▌       | 28/111 [06:15<17:47, 12.86s/it, training_loss=0.175]\u001b[A\n","Epoch 4:  26%|██▌       | 29/111 [06:15<17:49, 13.04s/it, training_loss=0.175]\u001b[A\n","Epoch 4:  26%|██▌       | 29/111 [06:27<17:49, 13.04s/it, training_loss=0.204]\u001b[A\n","Epoch 4:  27%|██▋       | 30/111 [06:27<17:04, 12.64s/it, training_loss=0.204]\u001b[A\n","Epoch 4:  27%|██▋       | 30/111 [06:39<17:04, 12.64s/it, training_loss=0.046]\u001b[A\n","Epoch 4:  28%|██▊       | 31/111 [06:39<16:39, 12.50s/it, training_loss=0.046]\u001b[A\n","Epoch 4:  28%|██▊       | 31/111 [06:53<16:39, 12.50s/it, training_loss=0.404]\u001b[A\n","Epoch 4:  29%|██▉       | 32/111 [06:53<16:47, 12.75s/it, training_loss=0.404]\u001b[A\n","Epoch 4:  29%|██▉       | 32/111 [07:06<16:47, 12.75s/it, training_loss=0.373]\u001b[A\n","Epoch 4:  30%|██▉       | 33/111 [07:06<16:54, 13.00s/it, training_loss=0.373]\u001b[A\n","Epoch 4:  30%|██▉       | 33/111 [07:19<16:54, 13.00s/it, training_loss=0.424]\u001b[A\n","Epoch 4:  31%|███       | 34/111 [07:19<16:43, 13.03s/it, training_loss=0.424]\u001b[A\n","Epoch 4:  31%|███       | 34/111 [07:31<16:43, 13.03s/it, training_loss=0.209]\u001b[A\n","Epoch 4:  32%|███▏      | 35/111 [07:31<15:54, 12.56s/it, training_loss=0.209]\u001b[A\n","Epoch 4:  32%|███▏      | 35/111 [07:44<15:54, 12.56s/it, training_loss=0.225]\u001b[A\n","Epoch 4:  32%|███▏      | 36/111 [07:44<15:55, 12.74s/it, training_loss=0.225]\u001b[A\n","Epoch 4:  32%|███▏      | 36/111 [07:57<15:55, 12.74s/it, training_loss=0.423]\u001b[A\n","Epoch 4:  33%|███▎      | 37/111 [07:57<15:59, 12.96s/it, training_loss=0.423]\u001b[A\n","Epoch 4:  33%|███▎      | 37/111 [08:11<15:59, 12.96s/it, training_loss=0.218]\u001b[A\n","Epoch 4:  34%|███▍      | 38/111 [08:11<15:54, 13.07s/it, training_loss=0.218]\u001b[A\n","Epoch 4:  34%|███▍      | 38/111 [08:22<15:54, 13.07s/it, training_loss=0.280]\u001b[A\n","Epoch 4:  35%|███▌      | 39/111 [08:22<15:05, 12.57s/it, training_loss=0.280]\u001b[A\n","Epoch 4:  35%|███▌      | 39/111 [08:38<15:05, 12.57s/it, training_loss=0.179]\u001b[A\n","Epoch 4:  36%|███▌      | 40/111 [08:38<15:56, 13.47s/it, training_loss=0.179]\u001b[A\n","Epoch 4:  36%|███▌      | 40/111 [08:51<15:56, 13.47s/it, training_loss=0.178]\u001b[A\n","Epoch 4:  37%|███▋      | 41/111 [08:51<15:47, 13.53s/it, training_loss=0.178]\u001b[A\n","Epoch 4:  37%|███▋      | 41/111 [09:04<15:47, 13.53s/it, training_loss=0.162]\u001b[A\n","Epoch 4:  38%|███▊      | 42/111 [09:04<15:10, 13.19s/it, training_loss=0.162]\u001b[A\n","Epoch 4:  38%|███▊      | 42/111 [09:16<15:10, 13.19s/it, training_loss=0.280]\u001b[A\n","Epoch 4:  39%|███▊      | 43/111 [09:16<14:31, 12.81s/it, training_loss=0.280]\u001b[A\n","Epoch 4:  39%|███▊      | 43/111 [09:29<14:31, 12.81s/it, training_loss=0.396]\u001b[A\n","Epoch 4:  40%|███▉      | 44/111 [09:29<14:30, 12.99s/it, training_loss=0.396]\u001b[A\n","Epoch 4:  40%|███▉      | 44/111 [09:43<14:30, 12.99s/it, training_loss=0.559]\u001b[A\n","Epoch 4:  41%|████      | 45/111 [09:43<14:28, 13.15s/it, training_loss=0.559]\u001b[A\n","Epoch 4:  41%|████      | 45/111 [09:56<14:28, 13.15s/it, training_loss=0.648]\u001b[A\n","Epoch 4:  41%|████▏     | 46/111 [09:56<14:13, 13.13s/it, training_loss=0.648]\u001b[A\n","Epoch 4:  41%|████▏     | 46/111 [10:07<14:13, 13.13s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  42%|████▏     | 47/111 [10:07<13:24, 12.56s/it, training_loss=0.197]\u001b[A\n","Epoch 4:  42%|████▏     | 47/111 [10:20<13:24, 12.56s/it, training_loss=0.366]\u001b[A\n","Epoch 4:  43%|████▎     | 48/111 [10:20<13:24, 12.77s/it, training_loss=0.366]\u001b[A\n","Epoch 4:  43%|████▎     | 48/111 [10:34<13:24, 12.77s/it, training_loss=0.307]\u001b[A\n","Epoch 4:  44%|████▍     | 49/111 [10:34<13:24, 12.97s/it, training_loss=0.307]\u001b[A\n","Epoch 4:  44%|████▍     | 49/111 [10:47<13:24, 12.97s/it, training_loss=0.594]\u001b[A\n","Epoch 4:  45%|████▌     | 50/111 [10:47<13:20, 13.12s/it, training_loss=0.594]\u001b[A\n","Epoch 4:  45%|████▌     | 50/111 [10:59<13:20, 13.12s/it, training_loss=0.254]\u001b[A\n","Epoch 4:  46%|████▌     | 51/111 [10:59<12:49, 12.83s/it, training_loss=0.254]\u001b[A\n","Epoch 4:  46%|████▌     | 51/111 [11:11<12:49, 12.83s/it, training_loss=0.150]\u001b[A\n","Epoch 4:  47%|████▋     | 52/111 [11:11<12:20, 12.55s/it, training_loss=0.150]\u001b[A\n","Epoch 4:  47%|████▋     | 52/111 [11:25<12:20, 12.55s/it, training_loss=0.393]\u001b[A\n","Epoch 4:  48%|████▊     | 53/111 [11:25<12:23, 12.82s/it, training_loss=0.393]\u001b[A\n","Epoch 4:  48%|████▊     | 53/111 [11:38<12:23, 12.82s/it, training_loss=0.284]\u001b[A\n","Epoch 4:  49%|████▊     | 54/111 [11:38<12:20, 12.99s/it, training_loss=0.284]\u001b[A\n","Epoch 4:  49%|████▊     | 54/111 [11:51<12:20, 12.99s/it, training_loss=0.232]\u001b[A\n","Epoch 4:  50%|████▉     | 55/111 [11:51<12:11, 13.05s/it, training_loss=0.232]\u001b[A\n","Epoch 4:  50%|████▉     | 55/111 [12:05<12:11, 13.05s/it, training_loss=0.425]\u001b[A\n","Epoch 4:  50%|█████     | 56/111 [12:05<12:05, 13.20s/it, training_loss=0.425]\u001b[A\n","Epoch 4:  50%|█████     | 56/111 [12:18<12:05, 13.20s/it, training_loss=0.473]\u001b[A\n","Epoch 4:  51%|█████▏    | 57/111 [12:18<11:57, 13.28s/it, training_loss=0.473]\u001b[A\n","Epoch 4:  51%|█████▏    | 57/111 [12:32<11:57, 13.28s/it, training_loss=0.543]\u001b[A\n","Epoch 4:  52%|█████▏    | 58/111 [12:32<11:49, 13.38s/it, training_loss=0.543]\u001b[A\n","Epoch 4:  52%|█████▏    | 58/111 [12:45<11:49, 13.38s/it, training_loss=0.412]\u001b[A\n","Epoch 4:  53%|█████▎    | 59/111 [12:45<11:24, 13.16s/it, training_loss=0.412]\u001b[A\n","Epoch 4:  53%|█████▎    | 59/111 [12:56<11:24, 13.16s/it, training_loss=0.233]\u001b[A\n","Epoch 4:  54%|█████▍    | 60/111 [12:56<10:46, 12.68s/it, training_loss=0.233]\u001b[A\n","Epoch 4:  54%|█████▍    | 60/111 [13:10<10:46, 12.68s/it, training_loss=0.476]\u001b[A\n","Epoch 4:  55%|█████▍    | 61/111 [13:10<10:47, 12.95s/it, training_loss=0.476]\u001b[A\n","Epoch 4:  55%|█████▍    | 61/111 [13:23<10:47, 12.95s/it, training_loss=0.350]\u001b[A\n","Epoch 4:  56%|█████▌    | 62/111 [13:23<10:43, 13.14s/it, training_loss=0.350]\u001b[A\n","Epoch 4:  56%|█████▌    | 62/111 [13:37<10:43, 13.14s/it, training_loss=0.110]\u001b[A\n","Epoch 4:  57%|█████▋    | 63/111 [13:37<10:34, 13.22s/it, training_loss=0.110]\u001b[A\n","Epoch 4:  57%|█████▋    | 63/111 [13:48<10:34, 13.22s/it, training_loss=0.200]\u001b[A\n","Epoch 4:  58%|█████▊    | 64/111 [13:48<09:56, 12.69s/it, training_loss=0.200]\u001b[A\n","Epoch 4:  58%|█████▊    | 64/111 [14:01<09:56, 12.69s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  59%|█████▊    | 65/111 [14:01<09:43, 12.69s/it, training_loss=0.183]\u001b[A\n","Epoch 4:  59%|█████▊    | 65/111 [14:14<09:43, 12.69s/it, training_loss=0.246]\u001b[A\n","Epoch 4:  59%|█████▉    | 66/111 [14:14<09:42, 12.95s/it, training_loss=0.246]\u001b[A\n","Epoch 4:  59%|█████▉    | 66/111 [14:28<09:42, 12.95s/it, training_loss=0.548]\u001b[A\n","Epoch 4:  60%|██████    | 67/111 [14:28<09:38, 13.14s/it, training_loss=0.548]\u001b[A\n","Epoch 4:  60%|██████    | 67/111 [14:41<09:38, 13.14s/it, training_loss=0.380]\u001b[A\n","Epoch 4:  61%|██████▏   | 68/111 [14:41<09:21, 13.05s/it, training_loss=0.380]\u001b[A\n","Epoch 4:  61%|██████▏   | 68/111 [14:53<09:21, 13.05s/it, training_loss=0.139]\u001b[A\n","Epoch 4:  62%|██████▏   | 69/111 [14:53<08:51, 12.66s/it, training_loss=0.139]\u001b[A\n","Epoch 4:  62%|██████▏   | 69/111 [15:07<08:51, 12.66s/it, training_loss=0.216]\u001b[A\n","Epoch 4:  63%|██████▎   | 70/111 [15:07<09:00, 13.17s/it, training_loss=0.216]\u001b[A\n","Epoch 4:  63%|██████▎   | 70/111 [15:23<09:00, 13.17s/it, training_loss=0.273]\u001b[A\n","Epoch 4:  64%|██████▍   | 71/111 [15:23<09:22, 14.06s/it, training_loss=0.273]\u001b[A\n","Epoch 4:  64%|██████▍   | 71/111 [15:36<09:22, 14.06s/it, training_loss=0.259]\u001b[A\n","Epoch 4:  65%|██████▍   | 72/111 [15:36<08:50, 13.61s/it, training_loss=0.259]\u001b[A\n","Epoch 4:  65%|██████▍   | 72/111 [15:47<08:50, 13.61s/it, training_loss=0.310]\u001b[A\n","Epoch 4:  66%|██████▌   | 73/111 [15:47<08:16, 13.08s/it, training_loss=0.310]\u001b[A\n","Epoch 4:  66%|██████▌   | 73/111 [16:01<08:16, 13.08s/it, training_loss=0.113]\u001b[A\n","Epoch 4:  67%|██████▋   | 74/111 [16:01<08:08, 13.19s/it, training_loss=0.113]\u001b[A\n","Epoch 4:  67%|██████▋   | 74/111 [16:14<08:08, 13.19s/it, training_loss=0.457]\u001b[A\n","Epoch 4:  68%|██████▊   | 75/111 [16:14<07:58, 13.29s/it, training_loss=0.457]\u001b[A\n","Epoch 4:  68%|██████▊   | 75/111 [16:28<07:58, 13.29s/it, training_loss=0.135]\u001b[A\n","Epoch 4:  68%|██████▊   | 76/111 [16:28<07:45, 13.30s/it, training_loss=0.135]\u001b[A\n","Epoch 4:  68%|██████▊   | 76/111 [16:39<07:45, 13.30s/it, training_loss=0.447]\u001b[A\n","Epoch 4:  69%|██████▉   | 77/111 [16:39<07:12, 12.72s/it, training_loss=0.447]\u001b[A\n","Epoch 4:  69%|██████▉   | 77/111 [16:52<07:12, 12.72s/it, training_loss=0.283]\u001b[A\n","Epoch 4:  70%|███████   | 78/111 [16:52<06:59, 12.72s/it, training_loss=0.283]\u001b[A\n","Epoch 4:  70%|███████   | 78/111 [17:05<06:59, 12.72s/it, training_loss=0.411]\u001b[A\n","Epoch 4:  71%|███████   | 79/111 [17:05<06:54, 12.96s/it, training_loss=0.411]\u001b[A\n","Epoch 4:  71%|███████   | 79/111 [17:19<06:54, 12.96s/it, training_loss=0.498]\u001b[A\n","Epoch 4:  72%|███████▏  | 80/111 [17:19<06:46, 13.11s/it, training_loss=0.498]\u001b[A\n","Epoch 4:  72%|███████▏  | 80/111 [17:31<06:46, 13.11s/it, training_loss=0.337]\u001b[A\n","Epoch 4:  73%|███████▎  | 81/111 [17:31<06:24, 12.81s/it, training_loss=0.337]\u001b[A\n","Epoch 4:  73%|███████▎  | 81/111 [17:43<06:24, 12.81s/it, training_loss=0.171]\u001b[A\n","Epoch 4:  74%|███████▍  | 82/111 [17:43<06:04, 12.58s/it, training_loss=0.171]\u001b[A\n","Epoch 4:  74%|███████▍  | 82/111 [17:56<06:04, 12.58s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  75%|███████▍  | 83/111 [17:56<05:59, 12.84s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  75%|███████▍  | 83/111 [18:10<05:59, 12.84s/it, training_loss=0.111]\u001b[A\n","Epoch 4:  76%|███████▌  | 84/111 [18:10<05:52, 13.05s/it, training_loss=0.111]\u001b[A\n","Epoch 4:  76%|███████▌  | 84/111 [18:23<05:52, 13.05s/it, training_loss=0.460]\u001b[A\n","Epoch 4:  77%|███████▋  | 85/111 [18:23<05:41, 13.12s/it, training_loss=0.460]\u001b[A\n","Epoch 4:  77%|███████▋  | 85/111 [18:35<05:41, 13.12s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  77%|███████▋  | 86/111 [18:35<05:15, 12.63s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  77%|███████▋  | 86/111 [18:50<05:15, 12.63s/it, training_loss=0.234]\u001b[A\n","Epoch 4:  78%|███████▊  | 87/111 [18:50<05:25, 13.58s/it, training_loss=0.234]\u001b[A\n","Epoch 4:  78%|███████▊  | 87/111 [19:04<05:25, 13.58s/it, training_loss=0.336]\u001b[A\n","Epoch 4:  79%|███████▉  | 88/111 [19:04<05:12, 13.57s/it, training_loss=0.336]\u001b[A\n","Epoch 4:  79%|███████▉  | 88/111 [19:17<05:12, 13.57s/it, training_loss=0.176]\u001b[A\n","Epoch 4:  80%|████████  | 89/111 [19:17<04:53, 13.35s/it, training_loss=0.176]\u001b[A\n","Epoch 4:  80%|████████  | 89/111 [19:28<04:53, 13.35s/it, training_loss=0.667]\u001b[A\n","Epoch 4:  81%|████████  | 90/111 [19:28<04:27, 12.74s/it, training_loss=0.667]\u001b[A\n","Epoch 4:  81%|████████  | 90/111 [19:42<04:27, 12.74s/it, training_loss=0.168]\u001b[A\n","Epoch 4:  82%|████████▏ | 91/111 [19:42<04:19, 12.98s/it, training_loss=0.168]\u001b[A\n","Epoch 4:  82%|████████▏ | 91/111 [19:55<04:19, 12.98s/it, training_loss=0.204]\u001b[A\n","Epoch 4:  83%|████████▎ | 92/111 [19:55<04:09, 13.13s/it, training_loss=0.204]\u001b[A\n","Epoch 4:  83%|████████▎ | 92/111 [20:09<04:09, 13.13s/it, training_loss=0.165]\u001b[A\n","Epoch 4:  84%|████████▍ | 93/111 [20:09<03:58, 13.26s/it, training_loss=0.165]\u001b[A\n","Epoch 4:  84%|████████▍ | 93/111 [20:20<03:58, 13.26s/it, training_loss=0.211]\u001b[A\n","Epoch 4:  85%|████████▍ | 94/111 [20:20<03:36, 12.74s/it, training_loss=0.211]\u001b[A\n","Epoch 4:  85%|████████▍ | 94/111 [20:33<03:36, 12.74s/it, training_loss=0.430]\u001b[A\n","Epoch 4:  86%|████████▌ | 95/111 [20:33<03:23, 12.70s/it, training_loss=0.430]\u001b[A\n","Epoch 4:  86%|████████▌ | 95/111 [20:47<03:23, 12.70s/it, training_loss=0.406]\u001b[A\n","Epoch 4:  86%|████████▋ | 96/111 [20:47<03:14, 12.97s/it, training_loss=0.406]\u001b[A\n","Epoch 4:  86%|████████▋ | 96/111 [21:00<03:14, 12.97s/it, training_loss=0.592]\u001b[A\n","Epoch 4:  87%|████████▋ | 97/111 [21:00<03:04, 13.16s/it, training_loss=0.592]\u001b[A\n","Epoch 4:  87%|████████▋ | 97/111 [21:13<03:04, 13.16s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  88%|████████▊ | 98/111 [21:13<02:49, 13.07s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  88%|████████▊ | 98/111 [21:24<02:49, 13.07s/it, training_loss=0.602]\u001b[A\n","Epoch 4:  89%|████████▉ | 99/111 [21:24<02:30, 12.57s/it, training_loss=0.602]\u001b[A\n","Epoch 4:  89%|████████▉ | 99/111 [21:38<02:30, 12.57s/it, training_loss=0.363]\u001b[A\n","Epoch 4:  90%|█████████ | 100/111 [21:38<02:21, 12.85s/it, training_loss=0.363]\u001b[A\n","Epoch 4:  90%|█████████ | 100/111 [21:51<02:21, 12.85s/it, training_loss=0.015]\u001b[A\n","Epoch 4:  91%|█████████ | 101/111 [21:51<02:10, 13.07s/it, training_loss=0.015]\u001b[A\n","Epoch 4:  91%|█████████ | 101/111 [22:06<02:10, 13.07s/it, training_loss=0.481]\u001b[A\n","Epoch 4:  92%|█████████▏| 102/111 [22:06<02:01, 13.52s/it, training_loss=0.481]\u001b[A\n","Epoch 4:  92%|█████████▏| 102/111 [22:19<02:01, 13.52s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  93%|█████████▎| 103/111 [22:19<01:45, 13.24s/it, training_loss=0.262]\u001b[A\n","Epoch 4:  93%|█████████▎| 103/111 [22:32<01:45, 13.24s/it, training_loss=0.663]\u001b[A\n","Epoch 4:  94%|█████████▎| 104/111 [22:32<01:32, 13.16s/it, training_loss=0.663]\u001b[A\n","Epoch 4:  94%|█████████▎| 104/111 [22:45<01:32, 13.16s/it, training_loss=0.312]\u001b[A\n","Epoch 4:  95%|█████████▍| 105/111 [22:45<01:20, 13.34s/it, training_loss=0.312]\u001b[A\n","Epoch 4:  95%|█████████▍| 105/111 [22:59<01:20, 13.34s/it, training_loss=0.187]\u001b[A\n","Epoch 4:  95%|█████████▌| 106/111 [22:59<01:07, 13.41s/it, training_loss=0.187]\u001b[A\n","Epoch 4:  95%|█████████▌| 106/111 [23:11<01:07, 13.41s/it, training_loss=0.494]\u001b[A\n","Epoch 4:  96%|█████████▋| 107/111 [23:11<00:52, 13.13s/it, training_loss=0.494]\u001b[A\n","Epoch 4:  96%|█████████▋| 107/111 [23:23<00:52, 13.13s/it, training_loss=0.043]\u001b[A\n","Epoch 4:  97%|█████████▋| 108/111 [23:23<00:38, 12.71s/it, training_loss=0.043]\u001b[A\n","Epoch 4:  97%|█████████▋| 108/111 [23:37<00:38, 12.71s/it, training_loss=0.477]\u001b[A\n","Epoch 4:  98%|█████████▊| 109/111 [23:37<00:25, 12.95s/it, training_loss=0.477]\u001b[A\n","Epoch 4:  98%|█████████▊| 109/111 [23:50<00:25, 12.95s/it, training_loss=0.083]\u001b[A\n","Epoch 4:  99%|█████████▉| 110/111 [23:50<00:13, 13.08s/it, training_loss=0.083]\u001b[A\n","Epoch 4:  99%|█████████▉| 110/111 [23:59<00:13, 13.08s/it, training_loss=0.216]\u001b[A\n","Epoch 4: 100%|██████████| 111/111 [23:59<00:00, 11.97s/it, training_loss=0.216]\u001b[A\n"," 75%|███████▌  | 3/4 [1:41:35<25:51, 1551.41s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 0.9496708111585798\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [1:43:32<00:00, 1553.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.0666090010532312\n","F1 Score (Weighted): 0.5567630979395685\n","QWK Score: 0.4657575453725058\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["while 1:\n","  print(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"I4aUgtKqYZ16","executionInfo":{"status":"error","timestamp":1680453005666,"user_tz":-420,"elapsed":4075540,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"110bf19d-f254-435c-bb6a-9464c83c055f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-0c462dd19bad>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"o8L3b-xHj5JE"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNnhAvdf3Sb9CbSHUY296m"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}