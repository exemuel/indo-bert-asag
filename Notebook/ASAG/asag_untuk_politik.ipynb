{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3552,"status":"ok","timestamp":1680434813734,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"50S27W_Vj_Bi","outputId":"43514fb9-7269-423f-afbb-60149ca59d12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7308,"status":"ok","timestamp":1680434821036,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"frHag4z7kGdZ","outputId":"6d8feb2b-b2e6-4c40-c54c-de1c964814fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n"]}],"source":["pip install sastrawi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4921,"status":"ok","timestamp":1680434825953,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"kk8ilth6kH1d","outputId":"89b1ffdc-2dba-469a-b634-b99ce2642f4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk) (1.16.0)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":667,"status":"ok","timestamp":1680434826616,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"Ph17gJD0kKb4","outputId":"5d7d92d1-6a48-442b-e4fb-1af4d6909d94"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":707,"status":"ok","timestamp":1680434827319,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"gs4oMdsrkL3E","outputId":"59ab1c0c-d1e0-43dc-e7d4-c23c61065827"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5414,"status":"ok","timestamp":1680434832730,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"OGmxzhivkNRJ","outputId":"1389a9c7-b774-4a7b-a32c-36033cb47c69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nlp_id in /usr/local/lib/python3.9/dist-packages (0.1.13.0)\n","Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.2)\n","Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.4.5)\n","Requirement already satisfied: scikit-learn==1.1.0 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.4.5->nlp_id) (1.16.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.22.4)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.1.1)\n"]}],"source":["pip install nlp_id"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7251,"status":"ok","timestamp":1680434839977,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"K9ZXuJrokX-x","outputId":"6c6e8dc1-5889-4a44-e882-adad7c947585"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"LEM8axq7kjkZ","executionInfo":{"status":"ok","timestamp":1680434846167,"user_tz":-420,"elapsed":6195,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["import re\n","import random\n","import pandas as pd\n","import torch\n","import tensorflow as tf\n","import numpy as np\n","\n","from nlp_id.lemmatizer import Lemmatizer\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.metrics import f1_score, cohen_kappa_score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from nltk.corpus import stopwords\n","\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def qwk_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return cohen_kappa_score(labels_flat, preds_flat)\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","\n","def evaluate(dataloader_val, device, model):\n","\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_val:\n","\n","        batch = tuple(b.to(device) for b in batch)\n","\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total/len(dataloader_val)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals\n","\n","def train_eval(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False, duplicates='drop')\n","\n","    # concatenate soal and jawaban\n","    df_final['soal-jawaban'] = df_final['soal']+df_final['jawaban']\n","\n","    # preprocessing\n","    # lowercasing\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: x.lower())\n","    # lemmatization\n","    lemmatizer = Lemmatizer()\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: lemmatizer.lemmatize(x))\n","    # stopword removal\n","    list_stopwords = set(stopwords.words('indonesian'))\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: ' '.join([item for item in x.split() if item not in list_stopwords]))\n","    # punctuation removal\n","    df_final['soal-jawaban'] = df_final['soal-jawaban'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cf6b39bc447f484d9671319c26596af8","77cb5a406ff4457a9a5278dfb80be2a0","ad98ad9838e4447abbcf04633395a5ab","535ee4fa2b7346149d9371cb2ee38bee","9bc6b52ee82e424f9fdbfe7f4971b757","b0ae974ec05b417da819850949154e17","f2c5ee9900f24d48b5877064079abe0d","362c3b5b03d743a583bf73690da6a389","4435a68cf50947c3bda90443192e0366","65995a3f023d4d12ba6e0ce5f7891aaf","76ebc46fd67c40709f42cfa5db9a93ef","21cdea9a429f4b368632c6b7ec98cf76","6e7a6896728d4939902ceaa6356a54bf","f94481ee5c314d7f9ff8a6d1d8a39c47","954ab8de3bc849d0a1c1483c57598c19","910083d48d3e4269a3f466032d3c6eeb","201563030b0c4bcead2253698e01cd64","92c7e118883f4244aa0e4060e1a9dd14","decd9456a7f54c62b8e55f2408cd0504","249e92f6680d4393bc66b1c3e1b8ebce","ece0ca3df91b4cefb1db45a29a690bda","6e9e841711344153b9549c21669602ad","2501b901f47e44a5b433b68e57aac24a","c850e17369a94aa4a82056b8869834c4","dfcf3550d47240af8ef79e074c464eca","9a034c290b5542a484a0024e720b9085","fc3aee9ab947445ca301229f7f49c7e9","bed8f438f64946248324e1685357efee","2743b65fa4d747779edcd53b6e883c23","cc9921133ae742c099928b3eb252f888","b3b3a198511c476a84ef92ea51b45565","60e06725b23b40a6a04b5c58a508cc32","625ed921fd4d4e3d98ba4437f370a56e","57074098443042c4babcb99406c27768","6d8464ba294e456ea6500c782ef85ebb","a334fb82881f4f119fe278f91200d741","ecc1a64b417c4f658808731601fefa47","1f5d6e583c0f4d209a17a9eb0b73770a","7e0429881c81450683fd0904f18b3c68","83199933b9a54ba99574c170c3708776","0abcc3227aa547d7b7c0660c885521ca","5e7d807db6e046a88c6b039dbbabb916","f084488020ac4fa4aca86e7aec443d2a","8eb500b779f348c0a385f3e90984abc1","7cbc80fca59341ee8e9fcd22357c4365","28c9d2ad3bd54ee7a78f0f18874ada3f","4cacf3bf87b846ee98c4c5d8f348181b","68fb046afa0e43a589cb67e8af0ebacd","1f6687906fa04d4292ee64769cf4f9f5","5d72c92092094f9abace50f7228eaaa7","63ca50bb7070416ba91005e84072f882","bf468ef261144a8cab0247cd2ddcdd7a","90c0aebbfe364906a4ab85e550e79fba","c7bb924787fe4c86996be33a57c2f038","d095b474b5724c6b863899c8e5834a5f"]},"id":"AwIDxQ2UklHF","executionInfo":{"status":"ok","timestamp":1680440605055,"user_tz":-420,"elapsed":5758894,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"1cdfd3e4-8492-4aee-811e-07f6ed7665cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["indobenchmark/indobert-lite-base-p2\n","Analisis Essay Grading Politik\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6b39bc447f484d9671319c26596af8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21cdea9a429f4b368632c6b7ec98cf76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2501b901f47e44a5b433b68e57aac24a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57074098443042c4babcb99406c27768"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cbc80fca59341ee8e9fcd22357c4365"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['pooler.bias', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'classifier.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/109 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/109 [00:29<?, ?it/s, training_loss=0.561]\u001b[A\n","Epoch 1:   1%|          | 1/109 [00:29<53:27, 29.70s/it, training_loss=0.561]\u001b[A\n","Epoch 1:   1%|          | 1/109 [00:48<53:27, 29.70s/it, training_loss=0.792]\u001b[A\n","Epoch 1:   2%|▏         | 2/109 [00:48<41:21, 23.19s/it, training_loss=0.792]\u001b[A\n","Epoch 1:   2%|▏         | 2/109 [00:59<41:21, 23.19s/it, training_loss=0.972]\u001b[A\n","Epoch 1:   3%|▎         | 3/109 [00:59<31:03, 17.58s/it, training_loss=0.972]\u001b[A\n","Epoch 1:   3%|▎         | 3/109 [01:11<31:03, 17.58s/it, training_loss=0.517]\u001b[A\n","Epoch 1:   4%|▎         | 4/109 [01:11<27:04, 15.47s/it, training_loss=0.517]\u001b[A\n","Epoch 1:   4%|▎         | 4/109 [01:24<27:04, 15.47s/it, training_loss=0.562]\u001b[A\n","Epoch 1:   5%|▍         | 5/109 [01:24<25:18, 14.60s/it, training_loss=0.562]\u001b[A\n","Epoch 1:   5%|▍         | 5/109 [01:36<25:18, 14.60s/it, training_loss=0.481]\u001b[A\n","Epoch 1:   6%|▌         | 6/109 [01:36<23:35, 13.74s/it, training_loss=0.481]\u001b[A\n","Epoch 1:   6%|▌         | 6/109 [01:47<23:35, 13.74s/it, training_loss=0.617]\u001b[A\n","Epoch 1:   6%|▋         | 7/109 [01:47<21:51, 12.86s/it, training_loss=0.617]\u001b[A\n","Epoch 1:   6%|▋         | 7/109 [02:00<21:51, 12.86s/it, training_loss=0.494]\u001b[A\n","Epoch 1:   7%|▋         | 8/109 [02:14<21:40, 12.87s/it, training_loss=0.619]\u001b[A\n","Epoch 1:   8%|▊         | 9/109 [02:14<21:56, 13.16s/it, training_loss=0.619]\u001b[A\n","Epoch 1:   8%|▊         | 9/109 [02:25<21:56, 13.16s/it, training_loss=0.564]\u001b[A\n","Epoch 1:   9%|▉         | 10/109 [02:25<20:35, 12.48s/it, training_loss=0.564]\u001b[A\n","Epoch 1:   9%|▉         | 10/109 [02:38<20:35, 12.48s/it, training_loss=0.641]\u001b[A\n","Epoch 1:  10%|█         | 11/109 [02:38<20:53, 12.79s/it, training_loss=0.641]\u001b[A\n","Epoch 1:  10%|█         | 11/109 [02:51<20:53, 12.79s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  11%|█         | 12/109 [02:51<20:43, 12.82s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  11%|█         | 12/109 [03:04<20:43, 12.82s/it, training_loss=0.797]\u001b[A\n","Epoch 1:  12%|█▏        | 13/109 [03:04<20:34, 12.86s/it, training_loss=0.797]\u001b[A\n","Epoch 1:  12%|█▏        | 13/109 [03:15<20:34, 12.86s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  13%|█▎        | 14/109 [03:15<19:12, 12.13s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  13%|█▎        | 14/109 [03:27<19:12, 12.13s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  14%|█▍        | 15/109 [03:27<19:13, 12.28s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  14%|█▍        | 15/109 [03:40<19:13, 12.28s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  15%|█▍        | 16/109 [03:40<19:19, 12.46s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  15%|█▍        | 16/109 [03:52<19:19, 12.46s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  16%|█▌        | 17/109 [03:52<18:40, 12.18s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  16%|█▌        | 17/109 [04:03<18:40, 12.18s/it, training_loss=0.663]\u001b[A\n","Epoch 1:  17%|█▋        | 18/109 [04:03<18:06, 11.94s/it, training_loss=0.663]\u001b[A\n","Epoch 1:  17%|█▋        | 18/109 [04:16<18:06, 11.94s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  17%|█▋        | 19/109 [04:16<18:21, 12.24s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  17%|█▋        | 19/109 [04:29<18:21, 12.24s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  18%|█▊        | 20/109 [04:29<18:25, 12.42s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  18%|█▊        | 20/109 [04:39<18:25, 12.42s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  19%|█▉        | 21/109 [04:39<17:18, 11.81s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  19%|█▉        | 21/109 [04:52<17:18, 11.81s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  20%|██        | 22/109 [04:52<17:35, 12.13s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  20%|██        | 22/109 [05:05<17:35, 12.13s/it, training_loss=0.628]\u001b[A\n","Epoch 1:  21%|██        | 23/109 [05:05<17:45, 12.39s/it, training_loss=0.628]\u001b[A\n","Epoch 1:  21%|██        | 23/109 [05:16<17:45, 12.39s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  22%|██▏       | 24/109 [05:16<17:07, 12.09s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  22%|██▏       | 24/109 [05:28<17:07, 12.09s/it, training_loss=0.651]\u001b[A\n","Epoch 1:  23%|██▎       | 25/109 [05:28<16:41, 11.93s/it, training_loss=0.651]\u001b[A\n","Epoch 1:  23%|██▎       | 25/109 [05:42<16:41, 11.93s/it, training_loss=0.590]\u001b[A\n","Epoch 1:  24%|██▍       | 26/109 [05:42<17:30, 12.65s/it, training_loss=0.590]\u001b[A\n","Epoch 1:  24%|██▍       | 26/109 [05:55<17:30, 12.65s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  25%|██▍       | 27/109 [05:55<17:30, 12.82s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  25%|██▍       | 27/109 [06:06<17:30, 12.82s/it, training_loss=0.595]\u001b[A\n","Epoch 1:  26%|██▌       | 28/109 [06:06<16:13, 12.02s/it, training_loss=0.595]\u001b[A\n","Epoch 1:  26%|██▌       | 28/109 [06:18<16:13, 12.02s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  27%|██▋       | 29/109 [06:18<16:19, 12.24s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  27%|██▋       | 29/109 [06:32<16:19, 12.24s/it, training_loss=0.543]\u001b[A\n","Epoch 1:  28%|██▊       | 30/109 [06:32<16:28, 12.51s/it, training_loss=0.543]\u001b[A\n","Epoch 1:  28%|██▊       | 30/109 [06:43<16:28, 12.51s/it, training_loss=0.537]\u001b[A\n","Epoch 1:  28%|██▊       | 31/109 [06:43<15:51, 12.20s/it, training_loss=0.537]\u001b[A\n","Epoch 1:  28%|██▊       | 31/109 [06:55<15:51, 12.20s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  29%|██▉       | 32/109 [06:55<15:26, 12.04s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  29%|██▉       | 32/109 [07:08<15:26, 12.04s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  30%|███       | 33/109 [07:08<15:33, 12.28s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  30%|███       | 33/109 [07:20<15:33, 12.28s/it, training_loss=0.458]\u001b[A\n","Epoch 1:  31%|███       | 34/109 [07:20<15:29, 12.40s/it, training_loss=0.458]\u001b[A\n","Epoch 1:  31%|███       | 34/109 [07:31<15:29, 12.40s/it, training_loss=0.487]\u001b[A\n","Epoch 1:  32%|███▏      | 35/109 [07:31<14:31, 11.78s/it, training_loss=0.487]\u001b[A\n","Epoch 1:  32%|███▏      | 35/109 [07:43<14:31, 11.78s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  33%|███▎      | 36/109 [07:43<14:43, 12.11s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  33%|███▎      | 36/109 [07:56<14:43, 12.11s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  34%|███▍      | 37/109 [07:56<14:50, 12.36s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  34%|███▍      | 37/109 [08:07<14:50, 12.36s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  35%|███▍      | 38/109 [08:07<14:09, 11.96s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  35%|███▍      | 38/109 [08:19<14:09, 11.96s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  36%|███▌      | 39/109 [08:19<13:56, 11.94s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  36%|███▌      | 39/109 [08:32<13:56, 11.94s/it, training_loss=0.590]\u001b[A\n","Epoch 1:  37%|███▋      | 40/109 [08:32<14:07, 12.28s/it, training_loss=0.590]\u001b[A\n","Epoch 1:  37%|███▋      | 40/109 [08:45<14:07, 12.28s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  38%|███▊      | 41/109 [08:45<13:54, 12.28s/it, training_loss=0.594]\u001b[A\n","Epoch 1:  38%|███▊      | 41/109 [08:55<13:54, 12.28s/it, training_loss=0.583]\u001b[A\n","Epoch 1:  39%|███▊      | 42/109 [08:55<13:12, 11.82s/it, training_loss=0.583]\u001b[A\n","Epoch 1:  39%|███▊      | 42/109 [09:08<13:12, 11.82s/it, training_loss=0.568]\u001b[A\n","Epoch 1:  39%|███▉      | 43/109 [09:08<13:24, 12.19s/it, training_loss=0.568]\u001b[A\n","Epoch 1:  39%|███▉      | 43/109 [09:21<13:24, 12.19s/it, training_loss=0.648]\u001b[A\n","Epoch 1:  40%|████      | 44/109 [09:21<13:28, 12.43s/it, training_loss=0.648]\u001b[A\n","Epoch 1:  40%|████      | 44/109 [09:32<13:28, 12.43s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  41%|████▏     | 45/109 [09:32<12:39, 11.87s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  41%|████▏     | 45/109 [09:44<12:39, 11.87s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  42%|████▏     | 46/109 [09:44<12:33, 11.95s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  42%|████▏     | 46/109 [09:57<12:33, 11.95s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  43%|████▎     | 47/109 [09:57<12:40, 12.27s/it, training_loss=0.483]\u001b[A\n","Epoch 1:  43%|████▎     | 47/109 [10:09<12:40, 12.27s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  44%|████▍     | 48/109 [10:09<12:18, 12.11s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  44%|████▍     | 48/109 [10:20<12:18, 12.11s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  45%|████▍     | 49/109 [10:20<11:48, 11.81s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  45%|████▍     | 49/109 [10:33<11:48, 11.81s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  46%|████▌     | 50/109 [10:33<11:58, 12.18s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  46%|████▌     | 50/109 [10:46<11:58, 12.18s/it, training_loss=0.475]\u001b[A\n","Epoch 1:  47%|████▋     | 51/109 [10:46<11:59, 12.41s/it, training_loss=0.475]\u001b[A\n","Epoch 1:  47%|████▋     | 51/109 [10:56<11:59, 12.41s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  48%|████▊     | 52/109 [10:56<11:11, 11.78s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  48%|████▊     | 52/109 [11:09<11:11, 11.78s/it, training_loss=0.597]\u001b[A\n","Epoch 1:  49%|████▊     | 53/109 [11:09<11:15, 12.07s/it, training_loss=0.597]\u001b[A\n","Epoch 1:  49%|████▊     | 53/109 [11:22<11:15, 12.07s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  50%|████▉     | 54/109 [11:22<11:21, 12.39s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  50%|████▉     | 54/109 [11:34<11:21, 12.39s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  50%|█████     | 55/109 [11:34<10:53, 12.10s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  50%|█████     | 55/109 [11:45<10:53, 12.10s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  51%|█████▏    | 56/109 [11:45<10:29, 11.88s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  51%|█████▏    | 56/109 [11:58<10:29, 11.88s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  52%|█████▏    | 57/109 [11:58<10:35, 12.23s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  52%|█████▏    | 57/109 [12:11<10:35, 12.23s/it, training_loss=0.595]\u001b[A\n","Epoch 1:  53%|█████▎    | 58/109 [12:11<10:31, 12.38s/it, training_loss=0.595]\u001b[A\n","Epoch 1:  53%|█████▎    | 58/109 [12:21<10:31, 12.38s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  54%|█████▍    | 59/109 [12:21<09:48, 11.77s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  54%|█████▍    | 59/109 [12:34<09:48, 11.77s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  55%|█████▌    | 60/109 [12:34<09:54, 12.14s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  55%|█████▌    | 60/109 [12:47<09:54, 12.14s/it, training_loss=0.507]\u001b[A\n","Epoch 1:  56%|█████▌    | 61/109 [12:47<09:56, 12.42s/it, training_loss=0.507]\u001b[A\n","Epoch 1:  56%|█████▌    | 61/109 [12:58<09:56, 12.42s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  57%|█████▋    | 62/109 [12:58<09:27, 12.08s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  57%|█████▋    | 62/109 [13:10<09:27, 12.08s/it, training_loss=0.553]\u001b[A\n","Epoch 1:  58%|█████▊    | 63/109 [13:10<09:10, 11.97s/it, training_loss=0.553]\u001b[A\n","Epoch 1:  58%|█████▊    | 63/109 [13:23<09:10, 11.97s/it, training_loss=0.355]\u001b[A\n","Epoch 1:  59%|█████▊    | 64/109 [13:23<09:15, 12.33s/it, training_loss=0.355]\u001b[A\n","Epoch 1:  59%|█████▊    | 64/109 [13:36<09:15, 12.33s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  60%|█████▉    | 65/109 [13:36<09:06, 12.41s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  60%|█████▉    | 65/109 [13:46<09:06, 12.41s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  61%|██████    | 66/109 [13:46<08:29, 11.85s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  61%|██████    | 66/109 [13:59<08:29, 11.85s/it, training_loss=0.679]\u001b[A\n","Epoch 1:  61%|██████▏   | 67/109 [13:59<08:32, 12.20s/it, training_loss=0.679]\u001b[A\n","Epoch 1:  61%|██████▏   | 67/109 [14:12<08:32, 12.20s/it, training_loss=0.654]\u001b[A\n","Epoch 1:  62%|██████▏   | 68/109 [14:12<08:29, 12.43s/it, training_loss=0.654]\u001b[A\n","Epoch 1:  62%|██████▏   | 68/109 [14:23<08:29, 12.43s/it, training_loss=0.670]\u001b[A\n","Epoch 1:  63%|██████▎   | 69/109 [14:23<07:59, 11.98s/it, training_loss=0.670]\u001b[A\n","Epoch 1:  63%|██████▎   | 69/109 [14:35<07:59, 11.98s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  64%|██████▍   | 70/109 [14:35<07:47, 11.99s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  64%|██████▍   | 70/109 [14:48<07:47, 11.99s/it, training_loss=0.439]\u001b[A\n","Epoch 1:  65%|██████▌   | 71/109 [14:48<07:46, 12.29s/it, training_loss=0.439]\u001b[A\n","Epoch 1:  65%|██████▌   | 71/109 [15:00<07:46, 12.29s/it, training_loss=0.621]\u001b[A\n","Epoch 1:  66%|██████▌   | 72/109 [15:00<07:32, 12.23s/it, training_loss=0.621]\u001b[A\n","Epoch 1:  66%|██████▌   | 72/109 [15:12<07:32, 12.23s/it, training_loss=0.655]\u001b[A\n","Epoch 1:  67%|██████▋   | 73/109 [15:12<07:07, 11.87s/it, training_loss=0.655]\u001b[A\n","Epoch 1:  67%|██████▋   | 73/109 [15:25<07:07, 11.87s/it, training_loss=0.459]\u001b[A\n","Epoch 1:  68%|██████▊   | 74/109 [15:25<07:09, 12.26s/it, training_loss=0.459]\u001b[A\n","Epoch 1:  68%|██████▊   | 74/109 [15:38<07:09, 12.26s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  69%|██████▉   | 75/109 [15:38<07:05, 12.53s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  69%|██████▉   | 75/109 [15:51<07:05, 12.53s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  70%|██████▉   | 76/109 [15:51<06:58, 12.67s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  70%|██████▉   | 76/109 [16:03<06:58, 12.67s/it, training_loss=0.444]\u001b[A\n","Epoch 1:  71%|███████   | 77/109 [16:03<06:38, 12.44s/it, training_loss=0.444]\u001b[A\n","Epoch 1:  71%|███████   | 77/109 [16:16<06:38, 12.44s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  72%|███████▏  | 78/109 [16:16<06:32, 12.67s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  72%|███████▏  | 78/109 [16:29<06:32, 12.67s/it, training_loss=0.651]\u001b[A\n","Epoch 1:  72%|███████▏  | 79/109 [16:29<06:22, 12.75s/it, training_loss=0.651]\u001b[A\n","Epoch 1:  72%|███████▏  | 79/109 [16:39<06:22, 12.75s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  73%|███████▎  | 80/109 [16:39<05:49, 12.06s/it, training_loss=0.478]\u001b[A\n","Epoch 1:  73%|███████▎  | 80/109 [16:52<05:49, 12.06s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  74%|███████▍  | 81/109 [16:52<05:45, 12.35s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  74%|███████▍  | 81/109 [17:05<05:45, 12.35s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  75%|███████▌  | 82/109 [17:05<05:38, 12.54s/it, training_loss=0.466]\u001b[A\n","Epoch 1:  75%|███████▌  | 82/109 [17:17<05:38, 12.54s/it, training_loss=0.445]\u001b[A\n","Epoch 1:  76%|███████▌  | 83/109 [17:17<05:16, 12.17s/it, training_loss=0.445]\u001b[A\n","Epoch 1:  76%|███████▌  | 83/109 [17:28<05:16, 12.17s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  77%|███████▋  | 84/109 [17:28<05:00, 12.03s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  77%|███████▋  | 84/109 [17:41<05:00, 12.03s/it, training_loss=0.510]\u001b[A\n","Epoch 1:  78%|███████▊  | 85/109 [17:41<04:56, 12.34s/it, training_loss=0.510]\u001b[A\n","Epoch 1:  78%|███████▊  | 85/109 [17:54<04:56, 12.34s/it, training_loss=0.481]\u001b[A\n","Epoch 1:  79%|███████▉  | 86/109 [17:54<04:45, 12.42s/it, training_loss=0.481]\u001b[A\n","Epoch 1:  79%|███████▉  | 86/109 [18:05<04:45, 12.42s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  80%|███████▉  | 87/109 [18:05<04:20, 11.84s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  80%|███████▉  | 87/109 [18:17<04:20, 11.84s/it, training_loss=0.735]\u001b[A\n","Epoch 1:  81%|████████  | 88/109 [18:17<04:15, 12.18s/it, training_loss=0.735]\u001b[A\n","Epoch 1:  81%|████████  | 88/109 [18:31<04:15, 12.18s/it, training_loss=0.528]\u001b[A\n","Epoch 1:  82%|████████▏ | 89/109 [18:31<04:08, 12.44s/it, training_loss=0.528]\u001b[A\n","Epoch 1:  82%|████████▏ | 89/109 [18:42<04:08, 12.44s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  83%|████████▎ | 90/109 [18:42<03:48, 12.01s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  83%|████████▎ | 90/109 [18:54<03:48, 12.01s/it, training_loss=0.567]\u001b[A\n","Epoch 1:  83%|████████▎ | 91/109 [18:54<03:36, 12.01s/it, training_loss=0.567]\u001b[A\n","Epoch 1:  83%|████████▎ | 91/109 [19:07<03:36, 12.01s/it, training_loss=0.553]\u001b[A\n","Epoch 1:  84%|████████▍ | 92/109 [19:07<03:29, 12.32s/it, training_loss=0.553]\u001b[A\n","Epoch 1:  84%|████████▍ | 92/109 [19:19<03:29, 12.32s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  85%|████████▌ | 93/109 [19:19<03:17, 12.34s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  85%|████████▌ | 93/109 [19:30<03:17, 12.34s/it, training_loss=0.461]\u001b[A\n","Epoch 1:  86%|████████▌ | 94/109 [19:30<02:58, 11.88s/it, training_loss=0.461]\u001b[A\n","Epoch 1:  86%|████████▌ | 94/109 [19:43<02:58, 11.88s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  87%|████████▋ | 95/109 [19:43<02:50, 12.19s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  87%|████████▋ | 95/109 [19:56<02:50, 12.19s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  88%|████████▊ | 96/109 [19:56<02:41, 12.44s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  88%|████████▊ | 96/109 [20:07<02:41, 12.44s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  89%|████████▉ | 97/109 [20:07<02:23, 11.95s/it, training_loss=0.639]\u001b[A\n","Epoch 1:  89%|████████▉ | 97/109 [20:19<02:23, 11.95s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  90%|████████▉ | 98/109 [20:19<02:12, 12.03s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  90%|████████▉ | 98/109 [20:32<02:12, 12.03s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  91%|█████████ | 99/109 [20:32<02:03, 12.30s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  91%|█████████ | 99/109 [20:44<02:03, 12.30s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  92%|█████████▏| 100/109 [20:44<01:49, 12.19s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  92%|█████████▏| 100/109 [20:55<01:49, 12.19s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  93%|█████████▎| 101/109 [20:55<01:35, 11.92s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  93%|█████████▎| 101/109 [21:08<01:35, 11.92s/it, training_loss=0.345]\u001b[A\n","Epoch 1:  94%|█████████▎| 102/109 [21:08<01:25, 12.27s/it, training_loss=0.345]\u001b[A\n","Epoch 1:  94%|█████████▎| 102/109 [21:21<01:25, 12.27s/it, training_loss=0.496]\u001b[A\n","Epoch 1:  94%|█████████▍| 103/109 [21:21<01:15, 12.50s/it, training_loss=0.496]\u001b[A\n","Epoch 1:  94%|█████████▍| 103/109 [21:32<01:15, 12.50s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  95%|█████████▌| 104/109 [21:32<00:59, 11.92s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  95%|█████████▌| 104/109 [21:44<00:59, 11.92s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  96%|█████████▋| 105/109 [21:44<00:48, 12.13s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  96%|█████████▋| 105/109 [21:57<00:48, 12.13s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  97%|█████████▋| 106/109 [21:57<00:37, 12.44s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  97%|█████████▋| 106/109 [22:09<00:37, 12.44s/it, training_loss=0.435]\u001b[A\n","Epoch 1:  98%|█████████▊| 107/109 [22:09<00:24, 12.30s/it, training_loss=0.435]\u001b[A\n","Epoch 1:  98%|█████████▊| 107/109 [22:20<00:24, 12.30s/it, training_loss=0.380]\u001b[A\n","Epoch 1:  99%|█████████▉| 108/109 [22:20<00:11, 11.89s/it, training_loss=0.380]\u001b[A\n","Epoch 1:  99%|█████████▉| 108/109 [22:33<00:11, 11.89s/it, training_loss=0.533]\u001b[A\n","Epoch 1: 100%|██████████| 109/109 [22:33<00:00, 12.20s/it, training_loss=0.533]\u001b[A\n","  0%|          | 0/4 [22:33<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.6734430439975283\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [24:17<1:12:52, 1457.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.563721769622394\n","F1 Score (Weighted): 0.22549283941463508\n","QWK Score: 0.11808684965178196\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/109 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/109 [00:13<?, ?it/s, training_loss=0.535]\u001b[A\n","Epoch 2:   1%|          | 1/109 [00:13<23:39, 13.15s/it, training_loss=0.535]\u001b[A\n","Epoch 2:   1%|          | 1/109 [00:23<23:39, 13.15s/it, training_loss=0.482]\u001b[A\n","Epoch 2:   2%|▏         | 2/109 [00:23<20:53, 11.72s/it, training_loss=0.482]\u001b[A\n","Epoch 2:   2%|▏         | 2/109 [00:36<20:53, 11.72s/it, training_loss=0.427]\u001b[A\n","Epoch 2:   3%|▎         | 3/109 [00:36<21:10, 11.99s/it, training_loss=0.427]\u001b[A\n","Epoch 2:   3%|▎         | 3/109 [00:49<21:10, 11.99s/it, training_loss=0.553]\u001b[A\n","Epoch 2:   4%|▎         | 4/109 [00:49<21:45, 12.43s/it, training_loss=0.553]\u001b[A\n","Epoch 2:   4%|▎         | 4/109 [01:01<21:45, 12.43s/it, training_loss=0.413]\u001b[A\n","Epoch 2:   5%|▍         | 5/109 [01:01<21:13, 12.24s/it, training_loss=0.413]\u001b[A\n","Epoch 2:   5%|▍         | 5/109 [01:12<21:13, 12.24s/it, training_loss=0.334]\u001b[A\n","Epoch 2:   6%|▌         | 6/109 [01:12<20:20, 11.85s/it, training_loss=0.334]\u001b[A\n","Epoch 2:   6%|▌         | 6/109 [01:25<20:20, 11.85s/it, training_loss=0.488]\u001b[A\n","Epoch 2:   6%|▋         | 7/109 [01:25<20:45, 12.21s/it, training_loss=0.488]\u001b[A\n","Epoch 2:   6%|▋         | 7/109 [01:38<20:45, 12.21s/it, training_loss=0.499]\u001b[A\n","Epoch 2:   7%|▋         | 8/109 [01:38<21:04, 12.52s/it, training_loss=0.499]\u001b[A\n","Epoch 2:   7%|▋         | 8/109 [01:48<21:04, 12.52s/it, training_loss=0.409]\u001b[A\n","Epoch 2:   8%|▊         | 9/109 [01:48<19:45, 11.85s/it, training_loss=0.409]\u001b[A\n","Epoch 2:   8%|▊         | 9/109 [02:01<19:45, 11.85s/it, training_loss=0.533]\u001b[A\n","Epoch 2:   9%|▉         | 10/109 [02:01<19:53, 12.06s/it, training_loss=0.533]\u001b[A\n","Epoch 2:   9%|▉         | 10/109 [02:14<19:53, 12.06s/it, training_loss=0.397]\u001b[A\n","Epoch 2:  10%|█         | 11/109 [02:14<20:11, 12.36s/it, training_loss=0.397]\u001b[A\n","Epoch 2:  10%|█         | 11/109 [02:25<20:11, 12.36s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  11%|█         | 12/109 [02:26<19:37, 12.14s/it, training_loss=0.441]\u001b[A\n","Epoch 2:  11%|█         | 12/109 [02:37<19:37, 12.14s/it, training_loss=0.331]\u001b[A\n","Epoch 2:  12%|█▏        | 13/109 [02:37<19:07, 11.95s/it, training_loss=0.331]\u001b[A\n","Epoch 2:  12%|█▏        | 13/109 [02:50<19:07, 11.95s/it, training_loss=0.389]\u001b[A\n","Epoch 2:  13%|█▎        | 14/109 [02:50<19:30, 12.32s/it, training_loss=0.389]\u001b[A\n","Epoch 2:  13%|█▎        | 14/109 [03:03<19:30, 12.32s/it, training_loss=0.231]\u001b[A\n","Epoch 2:  14%|█▍        | 15/109 [03:03<19:37, 12.53s/it, training_loss=0.231]\u001b[A\n","Epoch 2:  14%|█▍        | 15/109 [03:14<19:37, 12.53s/it, training_loss=0.376]\u001b[A\n","Epoch 2:  15%|█▍        | 16/109 [03:14<18:28, 11.92s/it, training_loss=0.376]\u001b[A\n","Epoch 2:  15%|█▍        | 16/109 [03:26<18:28, 11.92s/it, training_loss=0.447]\u001b[A\n","Epoch 2:  16%|█▌        | 17/109 [03:26<18:32, 12.09s/it, training_loss=0.447]\u001b[A\n","Epoch 2:  16%|█▌        | 17/109 [03:39<18:32, 12.09s/it, training_loss=0.665]\u001b[A\n","Epoch 2:  17%|█▋        | 18/109 [03:39<18:49, 12.41s/it, training_loss=0.665]\u001b[A\n","Epoch 2:  17%|█▋        | 18/109 [03:51<18:49, 12.41s/it, training_loss=0.397]\u001b[A\n","Epoch 2:  17%|█▋        | 19/109 [03:51<18:16, 12.18s/it, training_loss=0.397]\u001b[A\n","Epoch 2:  17%|█▋        | 19/109 [04:02<18:16, 12.18s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  18%|█▊        | 20/109 [04:02<17:41, 11.92s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  18%|█▊        | 20/109 [04:15<17:41, 11.92s/it, training_loss=0.324]\u001b[A\n","Epoch 2:  19%|█▉        | 21/109 [04:15<17:59, 12.27s/it, training_loss=0.324]\u001b[A\n","Epoch 2:  19%|█▉        | 21/109 [04:28<17:59, 12.27s/it, training_loss=0.335]\u001b[A\n","Epoch 2:  20%|██        | 22/109 [04:28<18:03, 12.46s/it, training_loss=0.335]\u001b[A\n","Epoch 2:  20%|██        | 22/109 [04:39<18:03, 12.46s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  21%|██        | 23/109 [04:39<17:02, 11.88s/it, training_loss=0.400]\u001b[A\n","Epoch 2:  21%|██        | 23/109 [04:52<17:02, 11.88s/it, training_loss=0.428]\u001b[A\n","Epoch 2:  22%|██▏       | 24/109 [04:52<17:15, 12.18s/it, training_loss=0.428]\u001b[A\n","Epoch 2:  22%|██▏       | 24/109 [05:05<17:15, 12.18s/it, training_loss=0.655]\u001b[A\n","Epoch 2:  23%|██▎       | 25/109 [05:05<17:24, 12.44s/it, training_loss=0.655]\u001b[A\n","Epoch 2:  23%|██▎       | 25/109 [05:16<17:24, 12.44s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  24%|██▍       | 26/109 [05:16<16:53, 12.20s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  24%|██▍       | 26/109 [05:28<16:53, 12.20s/it, training_loss=0.394]\u001b[A\n","Epoch 2:  25%|██▍       | 27/109 [05:28<16:21, 11.97s/it, training_loss=0.394]\u001b[A\n","Epoch 2:  25%|██▍       | 27/109 [05:41<16:21, 11.97s/it, training_loss=0.313]\u001b[A\n","Epoch 2:  26%|██▌       | 28/109 [05:41<16:36, 12.30s/it, training_loss=0.313]\u001b[A\n","Epoch 2:  26%|██▌       | 28/109 [05:54<16:36, 12.30s/it, training_loss=0.291]\u001b[A\n","Epoch 2:  27%|██▋       | 29/109 [05:54<16:32, 12.41s/it, training_loss=0.291]\u001b[A\n","Epoch 2:  27%|██▋       | 29/109 [06:04<16:32, 12.41s/it, training_loss=0.272]\u001b[A\n","Epoch 2:  28%|██▊       | 30/109 [06:04<15:31, 11.79s/it, training_loss=0.272]\u001b[A\n","Epoch 2:  28%|██▊       | 30/109 [06:17<15:31, 11.79s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  28%|██▊       | 31/109 [06:17<15:48, 12.16s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  28%|██▊       | 31/109 [06:30<15:48, 12.16s/it, training_loss=0.275]\u001b[A\n","Epoch 2:  29%|██▉       | 32/109 [06:30<15:55, 12.41s/it, training_loss=0.275]\u001b[A\n","Epoch 2:  29%|██▉       | 32/109 [06:41<15:55, 12.41s/it, training_loss=0.432]\u001b[A\n","Epoch 2:  30%|███       | 33/109 [06:41<15:10, 11.98s/it, training_loss=0.432]\u001b[A\n","Epoch 2:  30%|███       | 33/109 [06:53<15:10, 11.98s/it, training_loss=0.602]\u001b[A\n","Epoch 2:  31%|███       | 34/109 [06:53<14:54, 11.93s/it, training_loss=0.602]\u001b[A\n","Epoch 2:  31%|███       | 34/109 [07:06<14:54, 11.93s/it, training_loss=0.417]\u001b[A\n","Epoch 2:  32%|███▏      | 35/109 [07:06<15:03, 12.21s/it, training_loss=0.417]\u001b[A\n","Epoch 2:  32%|███▏      | 35/109 [07:18<15:03, 12.21s/it, training_loss=0.607]\u001b[A\n","Epoch 2:  33%|███▎      | 36/109 [07:18<14:52, 12.22s/it, training_loss=0.607]\u001b[A\n","Epoch 2:  33%|███▎      | 36/109 [07:29<14:52, 12.22s/it, training_loss=0.513]\u001b[A\n","Epoch 2:  34%|███▍      | 37/109 [07:29<14:09, 11.80s/it, training_loss=0.513]\u001b[A\n","Epoch 2:  34%|███▍      | 37/109 [07:42<14:09, 11.80s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  35%|███▍      | 38/109 [07:42<14:24, 12.17s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  35%|███▍      | 38/109 [07:55<14:24, 12.17s/it, training_loss=0.244]\u001b[A\n","Epoch 2:  36%|███▌      | 39/109 [07:55<14:30, 12.44s/it, training_loss=0.244]\u001b[A\n","Epoch 2:  36%|███▌      | 39/109 [08:05<14:30, 12.44s/it, training_loss=0.263]\u001b[A\n","Epoch 2:  37%|███▋      | 40/109 [08:05<13:37, 11.84s/it, training_loss=0.263]\u001b[A\n","Epoch 2:  37%|███▋      | 40/109 [08:18<13:37, 11.84s/it, training_loss=0.381]\u001b[A\n","Epoch 2:  38%|███▊      | 41/109 [08:18<13:39, 12.05s/it, training_loss=0.381]\u001b[A\n","Epoch 2:  38%|███▊      | 41/109 [08:31<13:39, 12.05s/it, training_loss=0.370]\u001b[A\n","Epoch 2:  39%|███▊      | 42/109 [08:31<13:48, 12.37s/it, training_loss=0.370]\u001b[A\n","Epoch 2:  39%|███▊      | 42/109 [08:43<13:48, 12.37s/it, training_loss=0.273]\u001b[A\n","Epoch 2:  39%|███▉      | 43/109 [08:43<13:29, 12.26s/it, training_loss=0.273]\u001b[A\n","Epoch 2:  39%|███▉      | 43/109 [08:54<13:29, 12.26s/it, training_loss=0.394]\u001b[A\n","Epoch 2:  40%|████      | 44/109 [08:54<12:55, 11.93s/it, training_loss=0.394]\u001b[A\n","Epoch 2:  40%|████      | 44/109 [09:07<12:55, 11.93s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  41%|████▏     | 45/109 [09:07<13:05, 12.28s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  41%|████▏     | 45/109 [09:20<13:05, 12.28s/it, training_loss=0.794]\u001b[A\n","Epoch 2:  42%|████▏     | 46/109 [09:20<13:05, 12.47s/it, training_loss=0.794]\u001b[A\n","Epoch 2:  42%|████▏     | 46/109 [09:30<13:05, 12.47s/it, training_loss=0.652]\u001b[A\n","Epoch 2:  43%|████▎     | 47/109 [09:30<12:11, 11.80s/it, training_loss=0.652]\u001b[A\n","Epoch 2:  43%|████▎     | 47/109 [09:43<12:11, 11.80s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  44%|████▍     | 48/109 [09:43<12:19, 12.12s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  44%|████▍     | 48/109 [09:56<12:19, 12.12s/it, training_loss=0.611]\u001b[A\n","Epoch 2:  45%|████▍     | 49/109 [09:56<12:25, 12.43s/it, training_loss=0.611]\u001b[A\n","Epoch 2:  45%|████▍     | 49/109 [10:08<12:25, 12.43s/it, training_loss=0.864]\u001b[A\n","Epoch 2:  46%|████▌     | 50/109 [10:08<11:57, 12.16s/it, training_loss=0.864]\u001b[A\n","Epoch 2:  46%|████▌     | 50/109 [10:19<11:57, 12.16s/it, training_loss=0.503]\u001b[A\n","Epoch 2:  47%|████▋     | 51/109 [10:19<11:31, 11.93s/it, training_loss=0.503]\u001b[A\n","Epoch 2:  47%|████▋     | 51/109 [10:32<11:31, 11.93s/it, training_loss=0.647]\u001b[A\n","Epoch 2:  48%|████▊     | 52/109 [10:32<11:39, 12.26s/it, training_loss=0.647]\u001b[A\n","Epoch 2:  48%|████▊     | 52/109 [10:45<11:39, 12.26s/it, training_loss=0.558]\u001b[A\n","Epoch 2:  49%|████▊     | 53/109 [10:45<11:36, 12.44s/it, training_loss=0.558]\u001b[A\n","Epoch 2:  49%|████▊     | 53/109 [10:55<11:36, 12.44s/it, training_loss=0.359]\u001b[A\n","Epoch 2:  50%|████▉     | 54/109 [10:55<10:49, 11.80s/it, training_loss=0.359]\u001b[A\n","Epoch 2:  50%|████▉     | 54/109 [11:08<10:49, 11.80s/it, training_loss=0.136]\u001b[A\n","Epoch 2:  50%|█████     | 55/109 [11:08<10:54, 12.13s/it, training_loss=0.136]\u001b[A\n","Epoch 2:  50%|█████     | 55/109 [11:21<10:54, 12.13s/it, training_loss=0.368]\u001b[A\n","Epoch 2:  51%|█████▏    | 56/109 [11:21<10:55, 12.38s/it, training_loss=0.368]\u001b[A\n","Epoch 2:  51%|█████▏    | 56/109 [11:33<10:55, 12.38s/it, training_loss=0.446]\u001b[A\n","Epoch 2:  52%|█████▏    | 57/109 [11:33<10:27, 12.06s/it, training_loss=0.446]\u001b[A\n","Epoch 2:  52%|█████▏    | 57/109 [11:45<10:27, 12.06s/it, training_loss=0.221]\u001b[A\n","Epoch 2:  53%|█████▎    | 58/109 [11:45<10:26, 12.28s/it, training_loss=0.221]\u001b[A\n","Epoch 2:  53%|█████▎    | 58/109 [11:59<10:26, 12.28s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  54%|█████▍    | 59/109 [11:59<10:32, 12.65s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  54%|█████▍    | 59/109 [12:12<10:32, 12.65s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  55%|█████▌    | 60/109 [12:12<10:26, 12.79s/it, training_loss=0.252]\u001b[A\n","Epoch 2:  55%|█████▌    | 60/109 [12:22<10:26, 12.79s/it, training_loss=0.627]\u001b[A\n","Epoch 2:  56%|█████▌    | 61/109 [12:22<09:40, 12.09s/it, training_loss=0.627]\u001b[A\n","Epoch 2:  56%|█████▌    | 61/109 [12:35<09:40, 12.09s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  57%|█████▋    | 62/109 [12:35<09:36, 12.26s/it, training_loss=0.373]\u001b[A\n","Epoch 2:  57%|█████▋    | 62/109 [12:48<09:36, 12.26s/it, training_loss=0.730]\u001b[A\n","Epoch 2:  58%|█████▊    | 63/109 [12:48<09:35, 12.51s/it, training_loss=0.730]\u001b[A\n","Epoch 2:  58%|█████▊    | 63/109 [13:00<09:35, 12.51s/it, training_loss=0.600]\u001b[A\n","Epoch 2:  59%|█████▊    | 64/109 [13:00<09:16, 12.37s/it, training_loss=0.600]\u001b[A\n","Epoch 2:  59%|█████▊    | 64/109 [13:11<09:16, 12.37s/it, training_loss=0.387]\u001b[A\n","Epoch 2:  60%|█████▉    | 65/109 [13:11<08:49, 12.03s/it, training_loss=0.387]\u001b[A\n","Epoch 2:  60%|█████▉    | 65/109 [13:24<08:49, 12.03s/it, training_loss=0.562]\u001b[A\n","Epoch 2:  61%|██████    | 66/109 [13:24<08:48, 12.30s/it, training_loss=0.562]\u001b[A\n","Epoch 2:  61%|██████    | 66/109 [13:37<08:48, 12.30s/it, training_loss=0.445]\u001b[A\n","Epoch 2:  61%|██████▏   | 67/109 [13:37<08:43, 12.47s/it, training_loss=0.445]\u001b[A\n","Epoch 2:  61%|██████▏   | 67/109 [13:48<08:43, 12.47s/it, training_loss=0.576]\u001b[A\n","Epoch 2:  62%|██████▏   | 68/109 [13:48<08:04, 11.81s/it, training_loss=0.576]\u001b[A\n","Epoch 2:  62%|██████▏   | 68/109 [14:00<08:04, 11.81s/it, training_loss=0.209]\u001b[A\n","Epoch 2:  63%|██████▎   | 69/109 [14:00<08:04, 12.12s/it, training_loss=0.209]\u001b[A\n","Epoch 2:  63%|██████▎   | 69/109 [14:13<08:04, 12.12s/it, training_loss=0.537]\u001b[A\n","Epoch 2:  64%|██████▍   | 70/109 [14:13<08:03, 12.39s/it, training_loss=0.537]\u001b[A\n","Epoch 2:  64%|██████▍   | 70/109 [14:25<08:03, 12.39s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  65%|██████▌   | 71/109 [14:25<07:38, 12.07s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  65%|██████▌   | 71/109 [14:36<07:38, 12.07s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  66%|██████▌   | 72/109 [14:36<07:21, 11.94s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  66%|██████▌   | 72/109 [14:49<07:21, 11.94s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  67%|██████▋   | 73/109 [14:49<07:22, 12.28s/it, training_loss=0.377]\u001b[A\n","Epoch 2:  67%|██████▋   | 73/109 [15:02<07:22, 12.28s/it, training_loss=0.602]\u001b[A\n","Epoch 2:  68%|██████▊   | 74/109 [15:02<07:12, 12.35s/it, training_loss=0.602]\u001b[A\n","Epoch 2:  68%|██████▊   | 74/109 [15:13<07:12, 12.35s/it, training_loss=0.469]\u001b[A\n","Epoch 2:  69%|██████▉   | 75/109 [15:13<06:42, 11.82s/it, training_loss=0.469]\u001b[A\n","Epoch 2:  69%|██████▉   | 75/109 [15:26<06:42, 11.82s/it, training_loss=0.410]\u001b[A\n","Epoch 2:  70%|██████▉   | 76/109 [15:26<06:42, 12.21s/it, training_loss=0.410]\u001b[A\n","Epoch 2:  70%|██████▉   | 76/109 [15:39<06:42, 12.21s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  71%|███████   | 77/109 [15:39<06:39, 12.47s/it, training_loss=0.472]\u001b[A\n","Epoch 2:  71%|███████   | 77/109 [15:50<06:39, 12.47s/it, training_loss=0.463]\u001b[A\n","Epoch 2:  72%|███████▏  | 78/109 [15:50<06:11, 12.00s/it, training_loss=0.463]\u001b[A\n","Epoch 2:  72%|███████▏  | 78/109 [16:02<06:11, 12.00s/it, training_loss=0.345]\u001b[A\n","Epoch 2:  72%|███████▏  | 79/109 [16:02<05:58, 11.97s/it, training_loss=0.345]\u001b[A\n","Epoch 2:  72%|███████▏  | 79/109 [16:14<05:58, 11.97s/it, training_loss=0.194]\u001b[A\n","Epoch 2:  73%|███████▎  | 80/109 [16:14<05:55, 12.26s/it, training_loss=0.194]\u001b[A\n","Epoch 2:  73%|███████▎  | 80/109 [16:27<05:55, 12.26s/it, training_loss=0.325]\u001b[A\n","Epoch 2:  74%|███████▍  | 81/109 [16:27<05:42, 12.24s/it, training_loss=0.325]\u001b[A\n","Epoch 2:  74%|███████▍  | 81/109 [16:38<05:42, 12.24s/it, training_loss=0.417]\u001b[A\n","Epoch 2:  75%|███████▌  | 82/109 [16:38<05:19, 11.83s/it, training_loss=0.417]\u001b[A\n","Epoch 2:  75%|███████▌  | 82/109 [16:50<05:19, 11.83s/it, training_loss=0.374]\u001b[A\n","Epoch 2:  76%|███████▌  | 83/109 [16:50<05:16, 12.16s/it, training_loss=0.374]\u001b[A\n","Epoch 2:  76%|███████▌  | 83/109 [17:04<05:16, 12.16s/it, training_loss=0.595]\u001b[A\n","Epoch 2:  77%|███████▋  | 84/109 [17:04<05:10, 12.43s/it, training_loss=0.595]\u001b[A\n","Epoch 2:  77%|███████▋  | 84/109 [17:14<05:10, 12.43s/it, training_loss=0.348]\u001b[A\n","Epoch 2:  78%|███████▊  | 85/109 [17:14<04:45, 11.88s/it, training_loss=0.348]\u001b[A\n","Epoch 2:  78%|███████▊  | 85/109 [17:26<04:45, 11.88s/it, training_loss=0.582]\u001b[A\n","Epoch 2:  79%|███████▉  | 86/109 [17:26<04:35, 12.00s/it, training_loss=0.582]\u001b[A\n","Epoch 2:  79%|███████▉  | 86/109 [17:39<04:35, 12.00s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  80%|███████▉  | 87/109 [17:39<04:30, 12.31s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  80%|███████▉  | 87/109 [17:51<04:30, 12.31s/it, training_loss=0.311]\u001b[A\n","Epoch 2:  81%|████████  | 88/109 [17:51<04:16, 12.22s/it, training_loss=0.311]\u001b[A\n","Epoch 2:  81%|████████  | 88/109 [18:03<04:16, 12.22s/it, training_loss=0.678]\u001b[A\n","Epoch 2:  82%|████████▏ | 89/109 [18:03<03:57, 11.88s/it, training_loss=0.678]\u001b[A\n","Epoch 2:  82%|████████▏ | 89/109 [18:16<03:57, 11.88s/it, training_loss=0.382]\u001b[A\n","Epoch 2:  83%|████████▎ | 90/109 [18:16<03:52, 12.25s/it, training_loss=0.382]\u001b[A\n","Epoch 2:  83%|████████▎ | 90/109 [18:29<03:52, 12.25s/it, training_loss=0.447]\u001b[A\n","Epoch 2:  83%|████████▎ | 91/109 [18:29<03:44, 12.47s/it, training_loss=0.447]\u001b[A\n","Epoch 2:  83%|████████▎ | 91/109 [18:39<03:44, 12.47s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  84%|████████▍ | 92/109 [18:39<03:22, 11.90s/it, training_loss=0.294]\u001b[A\n","Epoch 2:  84%|████████▍ | 92/109 [18:52<03:22, 11.90s/it, training_loss=0.239]\u001b[A\n","Epoch 2:  85%|████████▌ | 93/109 [18:52<03:13, 12.09s/it, training_loss=0.239]\u001b[A\n","Epoch 2:  85%|████████▌ | 93/109 [19:05<03:13, 12.09s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  86%|████████▌ | 94/109 [19:05<03:05, 12.36s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  86%|████████▌ | 94/109 [19:16<03:05, 12.36s/it, training_loss=0.437]\u001b[A\n","Epoch 2:  87%|████████▋ | 95/109 [19:16<02:50, 12.15s/it, training_loss=0.437]\u001b[A\n","Epoch 2:  87%|████████▋ | 95/109 [19:28<02:50, 12.15s/it, training_loss=0.567]\u001b[A\n","Epoch 2:  88%|████████▊ | 96/109 [19:28<02:34, 11.87s/it, training_loss=0.567]\u001b[A\n","Epoch 2:  88%|████████▊ | 96/109 [19:41<02:34, 11.87s/it, training_loss=0.465]\u001b[A\n","Epoch 2:  89%|████████▉ | 97/109 [19:41<02:26, 12.21s/it, training_loss=0.465]\u001b[A\n","Epoch 2:  89%|████████▉ | 97/109 [19:54<02:26, 12.21s/it, training_loss=0.241]\u001b[A\n","Epoch 2:  90%|████████▉ | 98/109 [19:54<02:16, 12.44s/it, training_loss=0.241]\u001b[A\n","Epoch 2:  90%|████████▉ | 98/109 [20:04<02:16, 12.44s/it, training_loss=0.351]\u001b[A\n","Epoch 2:  91%|█████████ | 99/109 [20:04<01:58, 11.82s/it, training_loss=0.351]\u001b[A\n","Epoch 2:  91%|█████████ | 99/109 [20:17<01:58, 11.82s/it, training_loss=0.384]\u001b[A\n","Epoch 2:  92%|█████████▏| 100/109 [20:17<01:48, 12.11s/it, training_loss=0.384]\u001b[A\n","Epoch 2:  92%|█████████▏| 100/109 [20:30<01:48, 12.11s/it, training_loss=0.464]\u001b[A\n","Epoch 2:  93%|█████████▎| 101/109 [20:30<01:39, 12.41s/it, training_loss=0.464]\u001b[A\n","Epoch 2:  93%|█████████▎| 101/109 [20:41<01:39, 12.41s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  94%|█████████▎| 102/109 [20:41<01:24, 12.11s/it, training_loss=0.433]\u001b[A\n","Epoch 2:  94%|█████████▎| 102/109 [20:53<01:24, 12.11s/it, training_loss=0.383]\u001b[A\n","Epoch 2:  94%|█████████▍| 103/109 [20:53<01:11, 11.93s/it, training_loss=0.383]\u001b[A\n","Epoch 2:  94%|█████████▍| 103/109 [21:06<01:11, 11.93s/it, training_loss=0.445]\u001b[A\n","Epoch 2:  95%|█████████▌| 104/109 [21:06<01:01, 12.24s/it, training_loss=0.445]\u001b[A\n","Epoch 2:  95%|█████████▌| 104/109 [21:19<01:01, 12.24s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  96%|█████████▋| 105/109 [21:19<00:49, 12.43s/it, training_loss=0.290]\u001b[A\n","Epoch 2:  96%|█████████▋| 105/109 [21:29<00:49, 12.43s/it, training_loss=0.407]\u001b[A\n","Epoch 2:  97%|█████████▋| 106/109 [21:29<00:35, 11.83s/it, training_loss=0.407]\u001b[A\n","Epoch 2:  97%|█████████▋| 106/109 [21:42<00:35, 11.83s/it, training_loss=0.442]\u001b[A\n","Epoch 2:  98%|█████████▊| 107/109 [21:42<00:24, 12.16s/it, training_loss=0.442]\u001b[A\n","Epoch 2:  98%|█████████▊| 107/109 [21:55<00:24, 12.16s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  99%|█████████▉| 108/109 [21:55<00:12, 12.41s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  99%|█████████▉| 108/109 [22:06<00:12, 12.41s/it, training_loss=0.315]\u001b[A\n","Epoch 2: 100%|██████████| 109/109 [22:06<00:00, 11.96s/it, training_loss=0.315]\u001b[A\n"," 25%|██▌       | 1/4 [46:23<1:12:52, 1457.33s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.3278226540722977\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [48:08<48:03, 1441.82s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.2446304112672806\n","F1 Score (Weighted): 0.47566089352470325\n","QWK Score: 0.404809408799748\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/109 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/109 [00:11<?, ?it/s, training_loss=0.315]\u001b[A\n","Epoch 3:   1%|          | 1/109 [00:11<20:16, 11.26s/it, training_loss=0.315]\u001b[A\n","Epoch 3:   1%|          | 1/109 [00:24<20:16, 11.26s/it, training_loss=0.279]\u001b[A\n","Epoch 3:   2%|▏         | 2/109 [00:24<21:50, 12.25s/it, training_loss=0.279]\u001b[A\n","Epoch 3:   2%|▏         | 2/109 [00:37<21:50, 12.25s/it, training_loss=0.378]\u001b[A\n","Epoch 3:   3%|▎         | 3/109 [00:37<22:10, 12.55s/it, training_loss=0.378]\u001b[A\n","Epoch 3:   3%|▎         | 3/109 [00:47<22:10, 12.55s/it, training_loss=0.433]\u001b[A\n","Epoch 3:   4%|▎         | 4/109 [00:47<20:26, 11.68s/it, training_loss=0.433]\u001b[A\n","Epoch 3:   4%|▎         | 4/109 [01:00<20:26, 11.68s/it, training_loss=0.318]\u001b[A\n","Epoch 3:   5%|▍         | 5/109 [01:00<20:55, 12.07s/it, training_loss=0.318]\u001b[A\n","Epoch 3:   5%|▍         | 5/109 [01:13<20:55, 12.07s/it, training_loss=0.512]\u001b[A\n","Epoch 3:   6%|▌         | 6/109 [01:13<21:17, 12.40s/it, training_loss=0.512]\u001b[A\n","Epoch 3:   6%|▌         | 6/109 [01:24<21:17, 12.40s/it, training_loss=0.417]\u001b[A\n","Epoch 3:   6%|▋         | 7/109 [01:24<20:28, 12.04s/it, training_loss=0.417]\u001b[A\n","Epoch 3:   6%|▋         | 7/109 [01:36<20:28, 12.04s/it, training_loss=0.434]\u001b[A\n","Epoch 3:   7%|▋         | 8/109 [01:36<19:58, 11.87s/it, training_loss=0.434]\u001b[A\n","Epoch 3:   7%|▋         | 8/109 [01:49<19:58, 11.87s/it, training_loss=0.347]\u001b[A\n","Epoch 3:   8%|▊         | 9/109 [01:49<20:24, 12.25s/it, training_loss=0.347]\u001b[A\n","Epoch 3:   8%|▊         | 9/109 [02:01<20:24, 12.25s/it, training_loss=0.373]\u001b[A\n","Epoch 3:   9%|▉         | 10/109 [02:01<20:18, 12.31s/it, training_loss=0.373]\u001b[A\n","Epoch 3:   9%|▉         | 10/109 [02:12<20:18, 12.31s/it, training_loss=0.374]\u001b[A\n","Epoch 3:  10%|█         | 11/109 [02:12<19:16, 11.80s/it, training_loss=0.374]\u001b[A\n","Epoch 3:  10%|█         | 11/109 [02:25<19:16, 11.80s/it, training_loss=0.393]\u001b[A\n","Epoch 3:  11%|█         | 12/109 [02:25<19:37, 12.14s/it, training_loss=0.393]\u001b[A\n","Epoch 3:  11%|█         | 12/109 [02:38<19:37, 12.14s/it, training_loss=0.188]\u001b[A\n","Epoch 3:  12%|█▏        | 13/109 [02:38<19:52, 12.43s/it, training_loss=0.188]\u001b[A\n","Epoch 3:  12%|█▏        | 13/109 [02:49<19:52, 12.43s/it, training_loss=0.407]\u001b[A\n","Epoch 3:  13%|█▎        | 14/109 [02:49<19:01, 12.01s/it, training_loss=0.407]\u001b[A\n","Epoch 3:  13%|█▎        | 14/109 [03:01<19:01, 12.01s/it, training_loss=0.354]\u001b[A\n","Epoch 3:  14%|█▍        | 15/109 [03:01<18:47, 12.00s/it, training_loss=0.354]\u001b[A\n","Epoch 3:  14%|█▍        | 15/109 [03:14<18:47, 12.00s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  15%|█▍        | 16/109 [03:14<19:05, 12.31s/it, training_loss=0.329]\u001b[A\n","Epoch 3:  15%|█▍        | 16/109 [03:26<19:05, 12.31s/it, training_loss=0.528]\u001b[A\n","Epoch 3:  16%|█▌        | 17/109 [03:26<18:56, 12.36s/it, training_loss=0.528]\u001b[A\n","Epoch 3:  16%|█▌        | 17/109 [03:37<18:56, 12.36s/it, training_loss=0.202]\u001b[A\n","Epoch 3:  17%|█▋        | 18/109 [03:37<17:59, 11.86s/it, training_loss=0.202]\u001b[A\n","Epoch 3:  17%|█▋        | 18/109 [03:50<17:59, 11.86s/it, training_loss=0.518]\u001b[A\n","Epoch 3:  17%|█▋        | 19/109 [03:50<18:18, 12.21s/it, training_loss=0.518]\u001b[A\n","Epoch 3:  17%|█▋        | 19/109 [04:03<18:18, 12.21s/it, training_loss=0.262]\u001b[A\n","Epoch 3:  18%|█▊        | 20/109 [04:03<18:26, 12.44s/it, training_loss=0.262]\u001b[A\n","Epoch 3:  18%|█▊        | 20/109 [04:14<18:26, 12.44s/it, training_loss=0.255]\u001b[A\n","Epoch 3:  19%|█▉        | 21/109 [04:14<17:32, 11.95s/it, training_loss=0.255]\u001b[A\n","Epoch 3:  19%|█▉        | 21/109 [04:26<17:32, 11.95s/it, training_loss=0.365]\u001b[A\n","Epoch 3:  20%|██        | 22/109 [04:26<17:23, 12.00s/it, training_loss=0.365]\u001b[A\n","Epoch 3:  20%|██        | 22/109 [04:39<17:23, 12.00s/it, training_loss=0.296]\u001b[A\n","Epoch 3:  21%|██        | 23/109 [04:39<17:38, 12.31s/it, training_loss=0.296]\u001b[A\n","Epoch 3:  21%|██        | 23/109 [04:51<17:38, 12.31s/it, training_loss=0.486]\u001b[A\n","Epoch 3:  22%|██▏       | 24/109 [04:51<17:20, 12.24s/it, training_loss=0.486]\u001b[A\n","Epoch 3:  22%|██▏       | 24/109 [05:02<17:20, 12.24s/it, training_loss=0.219]\u001b[A\n","Epoch 3:  23%|██▎       | 25/109 [05:02<16:38, 11.89s/it, training_loss=0.219]\u001b[A\n","Epoch 3:  23%|██▎       | 25/109 [05:15<16:38, 11.89s/it, training_loss=0.261]\u001b[A\n","Epoch 3:  24%|██▍       | 26/109 [05:15<16:56, 12.24s/it, training_loss=0.261]\u001b[A\n","Epoch 3:  24%|██▍       | 26/109 [05:28<16:56, 12.24s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  25%|██▍       | 27/109 [05:28<17:01, 12.46s/it, training_loss=0.317]\u001b[A\n","Epoch 3:  25%|██▍       | 27/109 [05:39<17:01, 12.46s/it, training_loss=0.408]\u001b[A\n","Epoch 3:  26%|██▌       | 28/109 [05:39<16:06, 11.93s/it, training_loss=0.408]\u001b[A\n","Epoch 3:  26%|██▌       | 28/109 [05:51<16:06, 11.93s/it, training_loss=0.788]\u001b[A\n","Epoch 3:  27%|██▋       | 29/109 [05:51<16:04, 12.06s/it, training_loss=0.788]\u001b[A\n","Epoch 3:  27%|██▋       | 29/109 [06:04<16:04, 12.06s/it, training_loss=0.282]\u001b[A\n","Epoch 3:  28%|██▊       | 30/109 [06:04<16:18, 12.38s/it, training_loss=0.282]\u001b[A\n","Epoch 3:  28%|██▊       | 30/109 [06:16<16:18, 12.38s/it, training_loss=0.480]\u001b[A\n","Epoch 3:  28%|██▊       | 31/109 [06:16<15:54, 12.24s/it, training_loss=0.480]\u001b[A\n","Epoch 3:  28%|██▊       | 31/109 [06:27<15:54, 12.24s/it, training_loss=0.388]\u001b[A\n","Epoch 3:  29%|██▉       | 32/109 [06:27<15:14, 11.87s/it, training_loss=0.388]\u001b[A\n","Epoch 3:  29%|██▉       | 32/109 [06:40<15:14, 11.87s/it, training_loss=0.474]\u001b[A\n","Epoch 3:  30%|███       | 33/109 [06:40<15:26, 12.19s/it, training_loss=0.474]\u001b[A\n","Epoch 3:  30%|███       | 33/109 [06:53<15:26, 12.19s/it, training_loss=0.208]\u001b[A\n","Epoch 3:  31%|███       | 34/109 [06:53<15:33, 12.44s/it, training_loss=0.208]\u001b[A\n","Epoch 3:  31%|███       | 34/109 [07:04<15:33, 12.44s/it, training_loss=0.469]\u001b[A\n","Epoch 3:  32%|███▏      | 35/109 [07:04<14:36, 11.85s/it, training_loss=0.469]\u001b[A\n","Epoch 3:  32%|███▏      | 35/109 [07:16<14:36, 11.85s/it, training_loss=0.361]\u001b[A\n","Epoch 3:  33%|███▎      | 36/109 [07:16<14:40, 12.06s/it, training_loss=0.361]\u001b[A\n","Epoch 3:  33%|███▎      | 36/109 [07:29<14:40, 12.06s/it, training_loss=0.496]\u001b[A\n","Epoch 3:  34%|███▍      | 37/109 [07:29<14:47, 12.33s/it, training_loss=0.496]\u001b[A\n","Epoch 3:  34%|███▍      | 37/109 [07:41<14:47, 12.33s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  35%|███▍      | 38/109 [07:41<14:17, 12.07s/it, training_loss=0.350]\u001b[A\n","Epoch 3:  35%|███▍      | 38/109 [07:52<14:17, 12.07s/it, training_loss=0.277]\u001b[A\n","Epoch 3:  36%|███▌      | 39/109 [07:52<13:53, 11.91s/it, training_loss=0.277]\u001b[A\n","Epoch 3:  36%|███▌      | 39/109 [08:05<13:53, 11.91s/it, training_loss=0.267]\u001b[A\n","Epoch 3:  37%|███▋      | 40/109 [08:05<14:05, 12.25s/it, training_loss=0.267]\u001b[A\n","Epoch 3:  37%|███▋      | 40/109 [08:18<14:05, 12.25s/it, training_loss=0.292]\u001b[A\n","Epoch 3:  38%|███▊      | 41/109 [08:18<13:59, 12.34s/it, training_loss=0.292]\u001b[A\n","Epoch 3:  38%|███▊      | 41/109 [08:28<13:59, 12.34s/it, training_loss=0.197]\u001b[A\n","Epoch 3:  39%|███▊      | 42/109 [08:28<13:06, 11.74s/it, training_loss=0.197]\u001b[A\n","Epoch 3:  39%|███▊      | 42/109 [08:41<13:06, 11.74s/it, training_loss=0.229]\u001b[A\n","Epoch 3:  39%|███▉      | 43/109 [08:41<13:19, 12.11s/it, training_loss=0.229]\u001b[A\n","Epoch 3:  39%|███▉      | 43/109 [08:54<13:19, 12.11s/it, training_loss=0.242]\u001b[A\n","Epoch 3:  40%|████      | 44/109 [08:54<13:25, 12.39s/it, training_loss=0.242]\u001b[A\n","Epoch 3:  40%|████      | 44/109 [09:05<13:25, 12.39s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  41%|████▏     | 45/109 [09:05<12:45, 11.96s/it, training_loss=0.305]\u001b[A\n","Epoch 3:  41%|████▏     | 45/109 [09:17<12:45, 11.96s/it, training_loss=0.343]\u001b[A\n","Epoch 3:  42%|████▏     | 46/109 [09:17<12:31, 11.93s/it, training_loss=0.343]\u001b[A\n","Epoch 3:  42%|████▏     | 46/109 [09:30<12:31, 11.93s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  43%|████▎     | 47/109 [09:30<12:38, 12.23s/it, training_loss=0.192]\u001b[A\n","Epoch 3:  43%|████▎     | 47/109 [09:42<12:38, 12.23s/it, training_loss=0.366]\u001b[A\n","Epoch 3:  44%|████▍     | 48/109 [09:42<12:23, 12.18s/it, training_loss=0.366]\u001b[A\n","Epoch 3:  44%|████▍     | 48/109 [09:53<12:23, 12.18s/it, training_loss=0.488]\u001b[A\n","Epoch 3:  45%|████▍     | 49/109 [09:53<11:49, 11.83s/it, training_loss=0.488]\u001b[A\n","Epoch 3:  45%|████▍     | 49/109 [10:06<11:49, 11.83s/it, training_loss=0.269]\u001b[A\n","Epoch 3:  46%|████▌     | 50/109 [10:06<11:59, 12.20s/it, training_loss=0.269]\u001b[A\n","Epoch 3:  46%|████▌     | 50/109 [10:19<11:59, 12.20s/it, training_loss=0.172]\u001b[A\n","Epoch 3:  47%|████▋     | 51/109 [10:19<12:01, 12.44s/it, training_loss=0.172]\u001b[A\n","Epoch 3:  47%|████▋     | 51/109 [10:29<12:01, 12.44s/it, training_loss=0.217]\u001b[A\n","Epoch 3:  48%|████▊     | 52/109 [10:29<11:14, 11.83s/it, training_loss=0.217]\u001b[A\n","Epoch 3:  48%|████▊     | 52/109 [10:42<11:14, 11.83s/it, training_loss=0.603]\u001b[A\n","Epoch 3:  49%|████▊     | 53/109 [10:42<11:12, 12.01s/it, training_loss=0.603]\u001b[A\n","Epoch 3:  49%|████▊     | 53/109 [10:55<11:12, 12.01s/it, training_loss=0.216]\u001b[A\n","Epoch 3:  50%|████▉     | 54/109 [10:55<11:17, 12.32s/it, training_loss=0.216]\u001b[A\n","Epoch 3:  50%|████▉     | 54/109 [11:07<11:17, 12.32s/it, training_loss=0.443]\u001b[A\n","Epoch 3:  50%|█████     | 55/109 [11:07<10:59, 12.21s/it, training_loss=0.443]\u001b[A\n","Epoch 3:  50%|█████     | 55/109 [11:18<10:59, 12.21s/it, training_loss=0.243]\u001b[A\n","Epoch 3:  51%|█████▏    | 56/109 [11:18<10:31, 11.92s/it, training_loss=0.243]\u001b[A\n","Epoch 3:  51%|█████▏    | 56/109 [11:31<10:31, 11.92s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  52%|█████▏    | 57/109 [11:31<10:35, 12.22s/it, training_loss=0.165]\u001b[A\n","Epoch 3:  52%|█████▏    | 57/109 [11:44<10:35, 12.22s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  53%|█████▎    | 58/109 [11:44<10:32, 12.40s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  53%|█████▎    | 58/109 [11:54<10:32, 12.40s/it, training_loss=0.494]\u001b[A\n","Epoch 3:  54%|█████▍    | 59/109 [11:54<09:46, 11.73s/it, training_loss=0.494]\u001b[A\n","Epoch 3:  54%|█████▍    | 59/109 [12:07<09:46, 11.73s/it, training_loss=0.454]\u001b[A\n","Epoch 3:  55%|█████▌    | 60/109 [12:07<09:52, 12.09s/it, training_loss=0.454]\u001b[A\n","Epoch 3:  55%|█████▌    | 60/109 [12:20<09:52, 12.09s/it, training_loss=0.337]\u001b[A\n","Epoch 3:  56%|█████▌    | 61/109 [12:20<09:53, 12.37s/it, training_loss=0.337]\u001b[A\n","Epoch 3:  56%|█████▌    | 61/109 [12:31<09:53, 12.37s/it, training_loss=0.653]\u001b[A\n","Epoch 3:  57%|█████▋    | 62/109 [12:31<09:23, 11.99s/it, training_loss=0.653]\u001b[A\n","Epoch 3:  57%|█████▋    | 62/109 [12:43<09:23, 11.99s/it, training_loss=0.413]\u001b[A\n","Epoch 3:  58%|█████▊    | 63/109 [12:43<09:05, 11.86s/it, training_loss=0.413]\u001b[A\n","Epoch 3:  58%|█████▊    | 63/109 [12:56<09:05, 11.86s/it, training_loss=0.406]\u001b[A\n","Epoch 3:  59%|█████▊    | 64/109 [12:56<09:10, 12.22s/it, training_loss=0.406]\u001b[A\n","Epoch 3:  59%|█████▊    | 64/109 [13:08<09:10, 12.22s/it, training_loss=0.367]\u001b[A\n","Epoch 3:  60%|█████▉    | 65/109 [13:08<09:03, 12.34s/it, training_loss=0.367]\u001b[A\n","Epoch 3:  60%|█████▉    | 65/109 [13:19<09:03, 12.34s/it, training_loss=0.610]\u001b[A\n","Epoch 3:  61%|██████    | 66/109 [13:19<08:26, 11.78s/it, training_loss=0.610]\u001b[A\n","Epoch 3:  61%|██████    | 66/109 [13:32<08:26, 11.78s/it, training_loss=0.299]\u001b[A\n","Epoch 3:  61%|██████▏   | 67/109 [13:32<08:30, 12.16s/it, training_loss=0.299]\u001b[A\n","Epoch 3:  61%|██████▏   | 67/109 [13:45<08:30, 12.16s/it, training_loss=0.211]\u001b[A\n","Epoch 3:  62%|██████▏   | 68/109 [13:45<08:28, 12.41s/it, training_loss=0.211]\u001b[A\n","Epoch 3:  62%|██████▏   | 68/109 [13:56<08:28, 12.41s/it, training_loss=0.232]\u001b[A\n","Epoch 3:  63%|██████▎   | 69/109 [13:56<07:59, 11.99s/it, training_loss=0.232]\u001b[A\n","Epoch 3:  63%|██████▎   | 69/109 [14:08<07:59, 11.99s/it, training_loss=0.099]\u001b[A\n","Epoch 3:  64%|██████▍   | 70/109 [14:08<07:49, 12.03s/it, training_loss=0.099]\u001b[A\n","Epoch 3:  64%|██████▍   | 70/109 [14:21<07:49, 12.03s/it, training_loss=0.548]\u001b[A\n","Epoch 3:  65%|██████▌   | 71/109 [14:21<07:47, 12.31s/it, training_loss=0.548]\u001b[A\n","Epoch 3:  65%|██████▌   | 71/109 [14:33<07:47, 12.31s/it, training_loss=0.217]\u001b[A\n","Epoch 3:  66%|██████▌   | 72/109 [14:33<07:32, 12.24s/it, training_loss=0.217]\u001b[A\n","Epoch 3:  66%|██████▌   | 72/109 [14:44<07:32, 12.24s/it, training_loss=0.249]\u001b[A\n","Epoch 3:  67%|██████▋   | 73/109 [14:44<07:06, 11.85s/it, training_loss=0.249]\u001b[A\n","Epoch 3:  67%|██████▋   | 73/109 [14:57<07:06, 11.85s/it, training_loss=0.231]\u001b[A\n","Epoch 3:  68%|██████▊   | 74/109 [14:57<07:06, 12.19s/it, training_loss=0.231]\u001b[A\n","Epoch 3:  68%|██████▊   | 74/109 [15:10<07:06, 12.19s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  69%|██████▉   | 75/109 [15:10<07:02, 12.44s/it, training_loss=0.283]\u001b[A\n","Epoch 3:  69%|██████▉   | 75/109 [15:20<07:02, 12.44s/it, training_loss=0.780]\u001b[A\n","Epoch 3:  70%|██████▉   | 76/109 [15:20<06:29, 11.81s/it, training_loss=0.780]\u001b[A\n","Epoch 3:  70%|██████▉   | 76/109 [15:33<06:29, 11.81s/it, training_loss=0.508]\u001b[A\n","Epoch 3:  71%|███████   | 77/109 [15:33<06:25, 12.05s/it, training_loss=0.508]\u001b[A\n","Epoch 3:  71%|███████   | 77/109 [15:49<06:25, 12.05s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  72%|███████▏  | 78/109 [15:49<06:50, 13.23s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  72%|███████▏  | 78/109 [16:01<06:50, 13.23s/it, training_loss=0.286]\u001b[A\n","Epoch 3:  72%|███████▏  | 79/109 [16:01<06:30, 13.00s/it, training_loss=0.286]\u001b[A\n","Epoch 3:  72%|███████▏  | 79/109 [16:12<06:30, 13.00s/it, training_loss=0.177]\u001b[A\n","Epoch 3:  73%|███████▎  | 80/109 [16:12<05:55, 12.25s/it, training_loss=0.177]\u001b[A\n","Epoch 3:  73%|███████▎  | 80/109 [16:25<05:55, 12.25s/it, training_loss=0.496]\u001b[A\n","Epoch 3:  74%|███████▍  | 81/109 [16:25<05:48, 12.45s/it, training_loss=0.496]\u001b[A\n","Epoch 3:  74%|███████▍  | 81/109 [16:38<05:48, 12.45s/it, training_loss=0.325]\u001b[A\n","Epoch 3:  75%|███████▌  | 82/109 [16:38<05:40, 12.62s/it, training_loss=0.325]\u001b[A\n","Epoch 3:  75%|███████▌  | 82/109 [16:49<05:40, 12.62s/it, training_loss=0.187]\u001b[A\n","Epoch 3:  76%|███████▌  | 83/109 [16:49<05:14, 12.10s/it, training_loss=0.187]\u001b[A\n","Epoch 3:  76%|███████▌  | 83/109 [17:01<05:14, 12.10s/it, training_loss=0.137]\u001b[A\n","Epoch 3:  77%|███████▋  | 84/109 [17:01<05:02, 12.11s/it, training_loss=0.137]\u001b[A\n","Epoch 3:  77%|███████▋  | 84/109 [17:14<05:02, 12.11s/it, training_loss=0.571]\u001b[A\n","Epoch 3:  78%|███████▊  | 85/109 [17:14<04:57, 12.39s/it, training_loss=0.571]\u001b[A\n","Epoch 3:  78%|███████▊  | 85/109 [17:26<04:57, 12.39s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  79%|███████▉  | 86/109 [17:26<04:42, 12.30s/it, training_loss=0.154]\u001b[A\n","Epoch 3:  79%|███████▉  | 86/109 [17:37<04:42, 12.30s/it, training_loss=0.245]\u001b[A\n","Epoch 3:  80%|███████▉  | 87/109 [17:37<04:23, 11.96s/it, training_loss=0.245]\u001b[A\n","Epoch 3:  80%|███████▉  | 87/109 [17:50<04:23, 11.96s/it, training_loss=0.399]\u001b[A\n","Epoch 3:  81%|████████  | 88/109 [17:50<04:17, 12.26s/it, training_loss=0.399]\u001b[A\n","Epoch 3:  81%|████████  | 88/109 [18:03<04:17, 12.26s/it, training_loss=0.469]\u001b[A\n","Epoch 3:  82%|████████▏ | 89/109 [18:03<04:10, 12.52s/it, training_loss=0.469]\u001b[A\n","Epoch 3:  82%|████████▏ | 89/109 [18:14<04:10, 12.52s/it, training_loss=0.057]\u001b[A\n","Epoch 3:  83%|████████▎ | 90/109 [18:14<03:46, 11.94s/it, training_loss=0.057]\u001b[A\n","Epoch 3:  83%|████████▎ | 90/109 [18:26<03:46, 11.94s/it, training_loss=0.531]\u001b[A\n","Epoch 3:  83%|████████▎ | 91/109 [18:26<03:36, 12.04s/it, training_loss=0.531]\u001b[A\n","Epoch 3:  83%|████████▎ | 91/109 [18:39<03:36, 12.04s/it, training_loss=0.233]\u001b[A\n","Epoch 3:  84%|████████▍ | 92/109 [18:39<03:30, 12.39s/it, training_loss=0.233]\u001b[A\n","Epoch 3:  84%|████████▍ | 92/109 [18:51<03:30, 12.39s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  85%|████████▌ | 93/109 [18:51<03:16, 12.28s/it, training_loss=0.335]\u001b[A\n","Epoch 3:  85%|████████▌ | 93/109 [19:02<03:16, 12.28s/it, training_loss=0.213]\u001b[A\n","Epoch 3:  86%|████████▌ | 94/109 [19:02<02:58, 11.92s/it, training_loss=0.213]\u001b[A\n","Epoch 3:  86%|████████▌ | 94/109 [19:16<02:58, 11.92s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  87%|████████▋ | 95/109 [19:16<02:52, 12.32s/it, training_loss=0.625]\u001b[A\n","Epoch 3:  87%|████████▋ | 95/109 [19:29<02:52, 12.32s/it, training_loss=0.359]\u001b[A\n","Epoch 3:  88%|████████▊ | 96/109 [19:29<02:42, 12.53s/it, training_loss=0.359]\u001b[A\n","Epoch 3:  88%|████████▊ | 96/109 [19:39<02:42, 12.53s/it, training_loss=0.456]\u001b[A\n","Epoch 3:  89%|████████▉ | 97/109 [19:39<02:23, 11.93s/it, training_loss=0.456]\u001b[A\n","Epoch 3:  89%|████████▉ | 97/109 [19:52<02:23, 11.93s/it, training_loss=0.379]\u001b[A\n","Epoch 3:  90%|████████▉ | 98/109 [19:52<02:13, 12.10s/it, training_loss=0.379]\u001b[A\n","Epoch 3:  90%|████████▉ | 98/109 [20:05<02:13, 12.10s/it, training_loss=0.424]\u001b[A\n","Epoch 3:  91%|█████████ | 99/109 [20:05<02:03, 12.39s/it, training_loss=0.424]\u001b[A\n","Epoch 3:  91%|█████████ | 99/109 [20:16<02:03, 12.39s/it, training_loss=0.267]\u001b[A\n","Epoch 3:  92%|█████████▏| 100/109 [20:16<01:49, 12.17s/it, training_loss=0.267]\u001b[A\n","Epoch 3:  92%|█████████▏| 100/109 [20:27<01:49, 12.17s/it, training_loss=0.548]\u001b[A\n","Epoch 3:  93%|█████████▎| 101/109 [20:27<01:34, 11.86s/it, training_loss=0.548]\u001b[A\n","Epoch 3:  93%|█████████▎| 101/109 [20:41<01:34, 11.86s/it, training_loss=0.296]\u001b[A\n","Epoch 3:  94%|█████████▎| 102/109 [20:41<01:25, 12.24s/it, training_loss=0.296]\u001b[A\n","Epoch 3:  94%|█████████▎| 102/109 [20:54<01:25, 12.24s/it, training_loss=0.435]\u001b[A\n","Epoch 3:  94%|█████████▍| 103/109 [20:54<01:14, 12.47s/it, training_loss=0.435]\u001b[A\n","Epoch 3:  94%|█████████▍| 103/109 [21:04<01:14, 12.47s/it, training_loss=0.189]\u001b[A\n","Epoch 3:  95%|█████████▌| 104/109 [21:04<00:59, 11.83s/it, training_loss=0.189]\u001b[A\n","Epoch 3:  95%|█████████▌| 104/109 [21:17<00:59, 11.83s/it, training_loss=0.455]\u001b[A\n","Epoch 3:  96%|█████████▋| 105/109 [21:17<00:48, 12.12s/it, training_loss=0.455]\u001b[A\n","Epoch 3:  96%|█████████▋| 105/109 [21:30<00:48, 12.12s/it, training_loss=0.338]\u001b[A\n","Epoch 3:  97%|█████████▋| 106/109 [21:30<00:37, 12.40s/it, training_loss=0.338]\u001b[A\n","Epoch 3:  97%|█████████▋| 106/109 [21:41<00:37, 12.40s/it, training_loss=0.370]\u001b[A\n","Epoch 3:  98%|█████████▊| 107/109 [21:41<00:24, 12.12s/it, training_loss=0.370]\u001b[A\n","Epoch 3:  98%|█████████▊| 107/109 [21:53<00:24, 12.12s/it, training_loss=0.183]\u001b[A\n","Epoch 3:  99%|█████████▉| 108/109 [21:53<00:11, 11.94s/it, training_loss=0.183]\u001b[A\n","Epoch 3:  99%|█████████▉| 108/109 [22:06<00:11, 11.94s/it, training_loss=0.783]\u001b[A\n","Epoch 3: 100%|██████████| 109/109 [22:06<00:00, 12.29s/it, training_loss=0.783]\u001b[A\n"," 50%|█████     | 2/4 [1:10:14<48:03, 1441.82s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 1.072983389874117\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [1:11:58<23:56, 1436.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.168504349887371\n","F1 Score (Weighted): 0.5125951843338282\n","QWK Score: 0.39016151166473134\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/109 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/109 [00:13<?, ?it/s, training_loss=0.399]\u001b[A\n","Epoch 4:   1%|          | 1/109 [00:13<23:29, 13.05s/it, training_loss=0.399]\u001b[A\n","Epoch 4:   1%|          | 1/109 [00:23<23:29, 13.05s/it, training_loss=0.156]\u001b[A\n","Epoch 4:   2%|▏         | 2/109 [00:23<20:42, 11.61s/it, training_loss=0.156]\u001b[A\n","Epoch 4:   2%|▏         | 2/109 [00:36<20:42, 11.61s/it, training_loss=0.165]\u001b[A\n","Epoch 4:   3%|▎         | 3/109 [00:36<21:11, 12.00s/it, training_loss=0.165]\u001b[A\n","Epoch 4:   3%|▎         | 3/109 [00:49<21:11, 12.00s/it, training_loss=0.467]\u001b[A\n","Epoch 4:   4%|▎         | 4/109 [00:49<21:45, 12.43s/it, training_loss=0.467]\u001b[A\n","Epoch 4:   4%|▎         | 4/109 [01:01<21:45, 12.43s/it, training_loss=0.362]\u001b[A\n","Epoch 4:   5%|▍         | 5/109 [01:01<21:14, 12.26s/it, training_loss=0.362]\u001b[A\n","Epoch 4:   5%|▍         | 5/109 [01:12<21:14, 12.26s/it, training_loss=0.307]\u001b[A\n","Epoch 4:   6%|▌         | 6/109 [01:12<20:24, 11.89s/it, training_loss=0.307]\u001b[A\n","Epoch 4:   6%|▌         | 6/109 [01:25<20:24, 11.89s/it, training_loss=0.247]\u001b[A\n","Epoch 4:   6%|▋         | 7/109 [01:25<20:50, 12.26s/it, training_loss=0.247]\u001b[A\n","Epoch 4:   6%|▋         | 7/109 [01:38<20:50, 12.26s/it, training_loss=0.266]\u001b[A\n","Epoch 4:   7%|▋         | 8/109 [01:38<20:55, 12.43s/it, training_loss=0.266]\u001b[A\n","Epoch 4:   7%|▋         | 8/109 [01:48<20:55, 12.43s/it, training_loss=0.230]\u001b[A\n","Epoch 4:   8%|▊         | 9/109 [01:48<19:42, 11.82s/it, training_loss=0.230]\u001b[A\n","Epoch 4:   8%|▊         | 9/109 [02:01<19:42, 11.82s/it, training_loss=0.146]\u001b[A\n","Epoch 4:   9%|▉         | 10/109 [02:01<19:57, 12.09s/it, training_loss=0.146]\u001b[A\n","Epoch 4:   9%|▉         | 10/109 [02:14<19:57, 12.09s/it, training_loss=0.503]\u001b[A\n","Epoch 4:  10%|█         | 11/109 [02:14<20:11, 12.36s/it, training_loss=0.503]\u001b[A\n","Epoch 4:  10%|█         | 11/109 [02:25<20:11, 12.36s/it, training_loss=0.253]\u001b[A\n","Epoch 4:  11%|█         | 12/109 [02:25<19:31, 12.08s/it, training_loss=0.253]\u001b[A\n","Epoch 4:  11%|█         | 12/109 [02:37<19:31, 12.08s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  12%|█▏        | 13/109 [02:37<18:58, 11.86s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  12%|█▏        | 13/109 [02:50<18:58, 11.86s/it, training_loss=0.809]\u001b[A\n","Epoch 4:  13%|█▎        | 14/109 [02:50<19:20, 12.22s/it, training_loss=0.809]\u001b[A\n","Epoch 4:  13%|█▎        | 14/109 [03:02<19:20, 12.22s/it, training_loss=0.369]\u001b[A\n","Epoch 4:  14%|█▍        | 15/109 [03:02<19:25, 12.40s/it, training_loss=0.369]\u001b[A\n","Epoch 4:  14%|█▍        | 15/109 [03:13<19:25, 12.40s/it, training_loss=0.321]\u001b[A\n","Epoch 4:  15%|█▍        | 16/109 [03:13<18:14, 11.76s/it, training_loss=0.321]\u001b[A\n","Epoch 4:  15%|█▍        | 16/109 [03:26<18:14, 11.76s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  16%|█▌        | 17/109 [03:26<18:38, 12.16s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  16%|█▌        | 17/109 [03:39<18:38, 12.16s/it, training_loss=0.366]\u001b[A\n","Epoch 4:  17%|█▋        | 18/109 [03:39<18:50, 12.43s/it, training_loss=0.366]\u001b[A\n","Epoch 4:  17%|█▋        | 18/109 [03:50<18:50, 12.43s/it, training_loss=0.206]\u001b[A\n","Epoch 4:  17%|█▋        | 19/109 [03:50<18:10, 12.11s/it, training_loss=0.206]\u001b[A\n","Epoch 4:  17%|█▋        | 19/109 [04:02<18:10, 12.11s/it, training_loss=0.211]\u001b[A\n","Epoch 4:  18%|█▊        | 20/109 [04:02<17:45, 11.97s/it, training_loss=0.211]\u001b[A\n","Epoch 4:  18%|█▊        | 20/109 [04:15<17:45, 11.97s/it, training_loss=0.312]\u001b[A\n","Epoch 4:  19%|█▉        | 21/109 [04:15<17:57, 12.25s/it, training_loss=0.312]\u001b[A\n","Epoch 4:  19%|█▉        | 21/109 [04:27<17:57, 12.25s/it, training_loss=0.194]\u001b[A\n","Epoch 4:  20%|██        | 22/109 [04:27<17:48, 12.28s/it, training_loss=0.194]\u001b[A\n","Epoch 4:  20%|██        | 22/109 [04:38<17:48, 12.28s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  21%|██        | 23/109 [04:38<16:52, 11.77s/it, training_loss=0.193]\u001b[A\n","Epoch 4:  21%|██        | 23/109 [04:51<16:52, 11.77s/it, training_loss=0.236]\u001b[A\n","Epoch 4:  22%|██▏       | 24/109 [04:51<17:15, 12.18s/it, training_loss=0.236]\u001b[A\n","Epoch 4:  22%|██▏       | 24/109 [05:04<17:15, 12.18s/it, training_loss=0.394]\u001b[A\n","Epoch 4:  23%|██▎       | 25/109 [05:04<17:22, 12.41s/it, training_loss=0.394]\u001b[A\n","Epoch 4:  23%|██▎       | 25/109 [05:14<17:22, 12.41s/it, training_loss=0.663]\u001b[A\n","Epoch 4:  24%|██▍       | 26/109 [05:14<16:24, 11.86s/it, training_loss=0.663]\u001b[A\n","Epoch 4:  24%|██▍       | 26/109 [05:27<16:24, 11.86s/it, training_loss=0.242]\u001b[A\n","Epoch 4:  25%|██▍       | 27/109 [05:27<16:20, 11.96s/it, training_loss=0.242]\u001b[A\n","Epoch 4:  25%|██▍       | 27/109 [05:40<16:20, 11.96s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  26%|██▌       | 28/109 [05:40<16:32, 12.25s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  26%|██▌       | 28/109 [05:51<16:32, 12.25s/it, training_loss=0.777]\u001b[A\n","Epoch 4:  27%|██▋       | 29/109 [05:51<16:11, 12.15s/it, training_loss=0.777]\u001b[A\n","Epoch 4:  27%|██▋       | 29/109 [06:02<16:11, 12.15s/it, training_loss=0.350]\u001b[A\n","Epoch 4:  28%|██▊       | 30/109 [06:02<15:34, 11.83s/it, training_loss=0.350]\u001b[A\n","Epoch 4:  28%|██▊       | 30/109 [06:16<15:34, 11.83s/it, training_loss=0.362]\u001b[A\n","Epoch 4:  28%|██▊       | 31/109 [06:16<15:51, 12.20s/it, training_loss=0.362]\u001b[A\n","Epoch 4:  28%|██▊       | 31/109 [06:29<15:51, 12.20s/it, training_loss=0.289]\u001b[A\n","Epoch 4:  29%|██▉       | 32/109 [06:29<15:58, 12.45s/it, training_loss=0.289]\u001b[A\n","Epoch 4:  29%|██▉       | 32/109 [06:39<15:58, 12.45s/it, training_loss=0.240]\u001b[A\n","Epoch 4:  30%|███       | 33/109 [06:39<14:58, 11.82s/it, training_loss=0.240]\u001b[A\n","Epoch 4:  30%|███       | 33/109 [06:52<14:58, 11.82s/it, training_loss=0.381]\u001b[A\n","Epoch 4:  31%|███       | 34/109 [06:52<15:05, 12.07s/it, training_loss=0.381]\u001b[A\n","Epoch 4:  31%|███       | 34/109 [07:05<15:05, 12.07s/it, training_loss=0.109]\u001b[A\n","Epoch 4:  32%|███▏      | 35/109 [07:05<15:18, 12.41s/it, training_loss=0.109]\u001b[A\n","Epoch 4:  32%|███▏      | 35/109 [07:16<15:18, 12.41s/it, training_loss=0.260]\u001b[A\n","Epoch 4:  33%|███▎      | 36/109 [07:16<14:50, 12.19s/it, training_loss=0.260]\u001b[A\n","Epoch 4:  33%|███▎      | 36/109 [07:28<14:50, 12.19s/it, training_loss=0.497]\u001b[A\n","Epoch 4:  34%|███▍      | 37/109 [07:28<14:20, 11.96s/it, training_loss=0.497]\u001b[A\n","Epoch 4:  34%|███▍      | 37/109 [07:41<14:20, 11.96s/it, training_loss=0.286]\u001b[A\n","Epoch 4:  35%|███▍      | 38/109 [07:41<14:31, 12.28s/it, training_loss=0.286]\u001b[A\n","Epoch 4:  35%|███▍      | 38/109 [07:54<14:31, 12.28s/it, training_loss=0.216]\u001b[A\n","Epoch 4:  36%|███▌      | 39/109 [07:54<14:34, 12.49s/it, training_loss=0.216]\u001b[A\n","Epoch 4:  36%|███▌      | 39/109 [08:04<14:34, 12.49s/it, training_loss=0.119]\u001b[A\n","Epoch 4:  37%|███▋      | 40/109 [08:04<13:39, 11.87s/it, training_loss=0.119]\u001b[A\n","Epoch 4:  37%|███▋      | 40/109 [08:17<13:39, 11.87s/it, training_loss=0.435]\u001b[A\n","Epoch 4:  38%|███▊      | 41/109 [08:17<13:47, 12.16s/it, training_loss=0.435]\u001b[A\n","Epoch 4:  38%|███▊      | 41/109 [08:30<13:47, 12.16s/it, training_loss=0.109]\u001b[A\n","Epoch 4:  39%|███▊      | 42/109 [08:30<13:51, 12.41s/it, training_loss=0.109]\u001b[A\n","Epoch 4:  39%|███▊      | 42/109 [08:42<13:51, 12.41s/it, training_loss=0.422]\u001b[A\n","Epoch 4:  39%|███▉      | 43/109 [08:42<13:18, 12.10s/it, training_loss=0.422]\u001b[A\n","Epoch 4:  39%|███▉      | 43/109 [08:53<13:18, 12.10s/it, training_loss=0.234]\u001b[A\n","Epoch 4:  40%|████      | 44/109 [08:53<12:54, 11.92s/it, training_loss=0.234]\u001b[A\n","Epoch 4:  40%|████      | 44/109 [09:06<12:54, 11.92s/it, training_loss=0.275]\u001b[A\n","Epoch 4:  41%|████▏     | 45/109 [09:06<13:03, 12.24s/it, training_loss=0.275]\u001b[A\n","Epoch 4:  41%|████▏     | 45/109 [09:19<13:03, 12.24s/it, training_loss=0.366]\u001b[A\n","Epoch 4:  42%|████▏     | 46/109 [09:19<13:00, 12.39s/it, training_loss=0.366]\u001b[A\n","Epoch 4:  42%|████▏     | 46/109 [09:29<13:00, 12.39s/it, training_loss=0.173]\u001b[A\n","Epoch 4:  43%|████▎     | 47/109 [09:29<12:10, 11.79s/it, training_loss=0.173]\u001b[A\n","Epoch 4:  43%|████▎     | 47/109 [09:42<12:10, 11.79s/it, training_loss=0.108]\u001b[A\n","Epoch 4:  44%|████▍     | 48/109 [09:42<12:21, 12.15s/it, training_loss=0.108]\u001b[A\n","Epoch 4:  44%|████▍     | 48/109 [09:55<12:21, 12.15s/it, training_loss=0.194]\u001b[A\n","Epoch 4:  45%|████▍     | 49/109 [09:55<12:26, 12.43s/it, training_loss=0.194]\u001b[A\n","Epoch 4:  45%|████▍     | 49/109 [10:06<12:26, 12.43s/it, training_loss=0.182]\u001b[A\n","Epoch 4:  46%|████▌     | 50/109 [10:06<11:50, 12.05s/it, training_loss=0.182]\u001b[A\n","Epoch 4:  46%|████▌     | 50/109 [10:18<11:50, 12.05s/it, training_loss=0.091]\u001b[A\n","Epoch 4:  47%|████▋     | 51/109 [10:18<11:33, 11.96s/it, training_loss=0.091]\u001b[A\n","Epoch 4:  47%|████▋     | 51/109 [10:31<11:33, 11.96s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  48%|████▊     | 52/109 [10:31<11:41, 12.31s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  48%|████▊     | 52/109 [10:44<11:41, 12.31s/it, training_loss=0.368]\u001b[A\n","Epoch 4:  49%|████▊     | 53/109 [10:44<11:32, 12.36s/it, training_loss=0.368]\u001b[A\n","Epoch 4:  49%|████▊     | 53/109 [10:54<11:32, 12.36s/it, training_loss=0.523]\u001b[A\n","Epoch 4:  50%|████▉     | 54/109 [10:54<10:52, 11.86s/it, training_loss=0.523]\u001b[A\n","Epoch 4:  50%|████▉     | 54/109 [11:07<10:52, 11.86s/it, training_loss=0.169]\u001b[A\n","Epoch 4:  50%|█████     | 55/109 [11:07<10:56, 12.15s/it, training_loss=0.169]\u001b[A\n","Epoch 4:  50%|█████     | 55/109 [11:20<10:56, 12.15s/it, training_loss=0.244]\u001b[A\n","Epoch 4:  51%|█████▏    | 56/109 [11:20<10:56, 12.38s/it, training_loss=0.244]\u001b[A\n","Epoch 4:  51%|█████▏    | 56/109 [11:31<10:56, 12.38s/it, training_loss=0.304]\u001b[A\n","Epoch 4:  52%|█████▏    | 57/109 [11:31<10:14, 11.82s/it, training_loss=0.304]\u001b[A\n","Epoch 4:  52%|█████▏    | 57/109 [11:43<10:14, 11.82s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  53%|█████▎    | 58/109 [11:43<10:08, 11.94s/it, training_loss=0.221]\u001b[A\n","Epoch 4:  53%|█████▎    | 58/109 [11:56<10:08, 11.94s/it, training_loss=0.311]\u001b[A\n","Epoch 4:  54%|█████▍    | 59/109 [11:56<10:12, 12.25s/it, training_loss=0.311]\u001b[A\n","Epoch 4:  54%|█████▍    | 59/109 [12:08<10:12, 12.25s/it, training_loss=0.235]\u001b[A\n","Epoch 4:  55%|█████▌    | 60/109 [12:08<09:51, 12.07s/it, training_loss=0.235]\u001b[A\n","Epoch 4:  55%|█████▌    | 60/109 [12:19<09:51, 12.07s/it, training_loss=0.144]\u001b[A\n","Epoch 4:  56%|█████▌    | 61/109 [12:19<09:27, 11.82s/it, training_loss=0.144]\u001b[A\n","Epoch 4:  56%|█████▌    | 61/109 [12:32<09:27, 11.82s/it, training_loss=0.118]\u001b[A\n","Epoch 4:  57%|█████▋    | 62/109 [12:32<09:33, 12.19s/it, training_loss=0.118]\u001b[A\n","Epoch 4:  57%|█████▋    | 62/109 [12:45<09:33, 12.19s/it, training_loss=0.397]\u001b[A\n","Epoch 4:  58%|█████▊    | 63/109 [12:45<09:29, 12.38s/it, training_loss=0.397]\u001b[A\n","Epoch 4:  58%|█████▊    | 63/109 [12:55<09:29, 12.38s/it, training_loss=0.397]\u001b[A\n","Epoch 4:  59%|█████▊    | 64/109 [12:55<08:49, 11.78s/it, training_loss=0.397]\u001b[A\n","Epoch 4:  59%|█████▊    | 64/109 [13:08<08:49, 11.78s/it, training_loss=0.700]\u001b[A\n","Epoch 4:  60%|█████▉    | 65/109 [13:08<08:54, 12.15s/it, training_loss=0.700]\u001b[A\n","Epoch 4:  60%|█████▉    | 65/109 [13:21<08:54, 12.15s/it, training_loss=0.246]\u001b[A\n","Epoch 4:  61%|██████    | 66/109 [13:21<08:53, 12.41s/it, training_loss=0.246]\u001b[A\n","Epoch 4:  61%|██████    | 66/109 [13:32<08:53, 12.41s/it, training_loss=0.186]\u001b[A\n","Epoch 4:  61%|██████▏   | 67/109 [13:32<08:27, 12.08s/it, training_loss=0.186]\u001b[A\n","Epoch 4:  61%|██████▏   | 67/109 [13:44<08:27, 12.08s/it, training_loss=0.455]\u001b[A\n","Epoch 4:  62%|██████▏   | 68/109 [13:44<08:08, 11.92s/it, training_loss=0.455]\u001b[A\n","Epoch 4:  62%|██████▏   | 68/109 [13:57<08:08, 11.92s/it, training_loss=0.141]\u001b[A\n","Epoch 4:  63%|██████▎   | 69/109 [13:57<08:11, 12.29s/it, training_loss=0.141]\u001b[A\n","Epoch 4:  63%|██████▎   | 69/109 [14:10<08:11, 12.29s/it, training_loss=0.569]\u001b[A\n","Epoch 4:  64%|██████▍   | 70/109 [14:10<08:03, 12.40s/it, training_loss=0.569]\u001b[A\n","Epoch 4:  64%|██████▍   | 70/109 [14:20<08:03, 12.40s/it, training_loss=0.315]\u001b[A\n","Epoch 4:  65%|██████▌   | 71/109 [14:20<07:29, 11.82s/it, training_loss=0.315]\u001b[A\n","Epoch 4:  65%|██████▌   | 71/109 [14:33<07:29, 11.82s/it, training_loss=0.340]\u001b[A\n","Epoch 4:  66%|██████▌   | 72/109 [14:33<07:30, 12.18s/it, training_loss=0.340]\u001b[A\n","Epoch 4:  66%|██████▌   | 72/109 [14:46<07:30, 12.18s/it, training_loss=0.245]\u001b[A\n","Epoch 4:  67%|██████▋   | 73/109 [14:46<07:27, 12.44s/it, training_loss=0.245]\u001b[A\n","Epoch 4:  67%|██████▋   | 73/109 [14:57<07:27, 12.44s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  68%|██████▊   | 74/109 [14:57<07:01, 12.04s/it, training_loss=0.294]\u001b[A\n","Epoch 4:  68%|██████▊   | 74/109 [15:09<07:01, 12.04s/it, training_loss=0.205]\u001b[A\n","Epoch 4:  69%|██████▉   | 75/109 [15:09<06:47, 11.99s/it, training_loss=0.205]\u001b[A\n","Epoch 4:  69%|██████▉   | 75/109 [15:22<06:47, 11.99s/it, training_loss=0.384]\u001b[A\n","Epoch 4:  70%|██████▉   | 76/109 [15:22<06:45, 12.30s/it, training_loss=0.384]\u001b[A\n","Epoch 4:  70%|██████▉   | 76/109 [15:35<06:45, 12.30s/it, training_loss=0.252]\u001b[A\n","Epoch 4:  71%|███████   | 77/109 [15:35<06:36, 12.39s/it, training_loss=0.252]\u001b[A\n","Epoch 4:  71%|███████   | 77/109 [15:45<06:36, 12.39s/it, training_loss=0.274]\u001b[A\n","Epoch 4:  72%|███████▏  | 78/109 [15:45<06:07, 11.85s/it, training_loss=0.274]\u001b[A\n","Epoch 4:  72%|███████▏  | 78/109 [15:59<06:07, 11.85s/it, training_loss=0.434]\u001b[A\n","Epoch 4:  72%|███████▏  | 79/109 [15:59<06:06, 12.22s/it, training_loss=0.434]\u001b[A\n","Epoch 4:  72%|███████▏  | 79/109 [16:12<06:06, 12.22s/it, training_loss=0.276]\u001b[A\n","Epoch 4:  73%|███████▎  | 80/109 [16:12<06:01, 12.47s/it, training_loss=0.276]\u001b[A\n","Epoch 4:  73%|███████▎  | 80/109 [16:22<06:01, 12.47s/it, training_loss=0.365]\u001b[A\n","Epoch 4:  74%|███████▍  | 81/109 [16:22<05:35, 11.99s/it, training_loss=0.365]\u001b[A\n","Epoch 4:  74%|███████▍  | 81/109 [16:35<05:35, 11.99s/it, training_loss=0.782]\u001b[A\n","Epoch 4:  75%|███████▌  | 82/109 [16:35<05:24, 12.03s/it, training_loss=0.782]\u001b[A\n","Epoch 4:  75%|███████▌  | 82/109 [16:48<05:24, 12.03s/it, training_loss=0.150]\u001b[A\n","Epoch 4:  76%|███████▌  | 83/109 [16:48<05:20, 12.32s/it, training_loss=0.150]\u001b[A\n","Epoch 4:  76%|███████▌  | 83/109 [17:00<05:20, 12.32s/it, training_loss=0.567]\u001b[A\n","Epoch 4:  77%|███████▋  | 84/109 [17:00<05:08, 12.34s/it, training_loss=0.567]\u001b[A\n","Epoch 4:  77%|███████▋  | 84/109 [17:11<05:08, 12.34s/it, training_loss=0.347]\u001b[A\n","Epoch 4:  78%|███████▊  | 85/109 [17:11<04:44, 11.85s/it, training_loss=0.347]\u001b[A\n","Epoch 4:  78%|███████▊  | 85/109 [17:24<04:44, 11.85s/it, training_loss=0.293]\u001b[A\n","Epoch 4:  79%|███████▉  | 86/109 [17:24<04:41, 12.24s/it, training_loss=0.293]\u001b[A\n","Epoch 4:  79%|███████▉  | 86/109 [17:37<04:41, 12.24s/it, training_loss=0.677]\u001b[A\n","Epoch 4:  80%|███████▉  | 87/109 [17:37<04:33, 12.45s/it, training_loss=0.677]\u001b[A\n","Epoch 4:  80%|███████▉  | 87/109 [17:47<04:33, 12.45s/it, training_loss=0.335]\u001b[A\n","Epoch 4:  81%|████████  | 88/109 [17:47<04:09, 11.90s/it, training_loss=0.335]\u001b[A\n","Epoch 4:  81%|████████  | 88/109 [18:00<04:09, 11.90s/it, training_loss=0.284]\u001b[A\n","Epoch 4:  82%|████████▏ | 89/109 [18:00<04:01, 12.05s/it, training_loss=0.284]\u001b[A\n","Epoch 4:  82%|████████▏ | 89/109 [18:13<04:01, 12.05s/it, training_loss=0.153]\u001b[A\n","Epoch 4:  83%|████████▎ | 90/109 [18:13<03:56, 12.43s/it, training_loss=0.153]\u001b[A\n","Epoch 4:  83%|████████▎ | 90/109 [18:25<03:56, 12.43s/it, training_loss=0.223]\u001b[A\n","Epoch 4:  83%|████████▎ | 91/109 [18:25<03:42, 12.34s/it, training_loss=0.223]\u001b[A\n","Epoch 4:  83%|████████▎ | 91/109 [18:36<03:42, 12.34s/it, training_loss=0.078]\u001b[A\n","Epoch 4:  84%|████████▍ | 92/109 [18:36<03:22, 11.92s/it, training_loss=0.078]\u001b[A\n","Epoch 4:  84%|████████▍ | 92/109 [18:49<03:22, 11.92s/it, training_loss=0.737]\u001b[A\n","Epoch 4:  85%|████████▌ | 93/109 [18:49<03:16, 12.27s/it, training_loss=0.737]\u001b[A\n","Epoch 4:  85%|████████▌ | 93/109 [19:02<03:16, 12.27s/it, training_loss=0.398]\u001b[A\n","Epoch 4:  86%|████████▌ | 94/109 [19:03<03:08, 12.57s/it, training_loss=0.398]\u001b[A\n","Epoch 4:  86%|████████▌ | 94/109 [19:13<03:08, 12.57s/it, training_loss=0.379]\u001b[A\n","Epoch 4:  87%|████████▋ | 95/109 [19:13<02:48, 12.01s/it, training_loss=0.379]\u001b[A\n","Epoch 4:  87%|████████▋ | 95/109 [19:26<02:48, 12.01s/it, training_loss=0.243]\u001b[A\n","Epoch 4:  88%|████████▊ | 96/109 [19:26<02:37, 12.12s/it, training_loss=0.243]\u001b[A\n","Epoch 4:  88%|████████▊ | 96/109 [19:39<02:37, 12.12s/it, training_loss=0.361]\u001b[A\n","Epoch 4:  89%|████████▉ | 97/109 [19:39<02:28, 12.41s/it, training_loss=0.361]\u001b[A\n","Epoch 4:  89%|████████▉ | 97/109 [19:51<02:28, 12.41s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  90%|████████▉ | 98/109 [19:51<02:15, 12.29s/it, training_loss=0.213]\u001b[A\n","Epoch 4:  90%|████████▉ | 98/109 [20:02<02:15, 12.29s/it, training_loss=0.245]\u001b[A\n","Epoch 4:  91%|█████████ | 99/109 [20:02<01:58, 11.90s/it, training_loss=0.245]\u001b[A\n","Epoch 4:  91%|█████████ | 99/109 [20:15<01:58, 11.90s/it, training_loss=0.266]\u001b[A\n","Epoch 4:  92%|█████████▏| 100/109 [20:15<01:49, 12.20s/it, training_loss=0.266]\u001b[A\n","Epoch 4:  92%|█████████▏| 100/109 [20:27<01:49, 12.20s/it, training_loss=0.168]\u001b[A\n","Epoch 4:  93%|█████████▎| 101/109 [20:27<01:39, 12.41s/it, training_loss=0.168]\u001b[A\n","Epoch 4:  93%|█████████▎| 101/109 [20:38<01:39, 12.41s/it, training_loss=0.279]\u001b[A\n","Epoch 4:  94%|█████████▎| 102/109 [20:38<01:22, 11.74s/it, training_loss=0.279]\u001b[A\n","Epoch 4:  94%|█████████▎| 102/109 [20:50<01:22, 11.74s/it, training_loss=0.113]\u001b[A\n","Epoch 4:  94%|█████████▍| 103/109 [20:50<01:12, 12.02s/it, training_loss=0.113]\u001b[A\n","Epoch 4:  94%|█████████▍| 103/109 [21:03<01:12, 12.02s/it, training_loss=0.321]\u001b[A\n","Epoch 4:  95%|█████████▌| 104/109 [21:03<01:01, 12.36s/it, training_loss=0.321]\u001b[A\n","Epoch 4:  95%|█████████▌| 104/109 [21:15<01:01, 12.36s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  96%|█████████▋| 105/109 [21:15<00:48, 12.08s/it, training_loss=0.188]\u001b[A\n","Epoch 4:  96%|█████████▋| 105/109 [21:27<00:48, 12.08s/it, training_loss=0.314]\u001b[A\n","Epoch 4:  97%|█████████▋| 106/109 [21:27<00:35, 11.94s/it, training_loss=0.314]\u001b[A\n","Epoch 4:  97%|█████████▋| 106/109 [21:40<00:35, 11.94s/it, training_loss=0.251]\u001b[A\n","Epoch 4:  98%|█████████▊| 107/109 [21:40<00:24, 12.27s/it, training_loss=0.251]\u001b[A\n","Epoch 4:  98%|█████████▊| 107/109 [21:52<00:24, 12.27s/it, training_loss=0.189]\u001b[A\n","Epoch 4:  99%|█████████▉| 108/109 [21:52<00:12, 12.41s/it, training_loss=0.189]\u001b[A\n","Epoch 4:  99%|█████████▉| 108/109 [22:03<00:12, 12.41s/it, training_loss=0.139]\u001b[A\n","Epoch 4: 100%|██████████| 109/109 [22:03<00:00, 11.84s/it, training_loss=0.139]\u001b[A\n"," 75%|███████▌  | 3/4 [1:34:01<23:56, 1436.38s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 0.9299957478811981\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [1:35:45<00:00, 1436.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.184847122856549\n","F1 Score (Weighted): 0.534773378946261\n","QWK Score: 0.4237073067568997\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import pandas as pd\n","\n","path_dir = '/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Politik'\n","list_dir = os.listdir(path_dir)\n","\n","list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","\n","for m in list_pre_trained_model:\n","    print(m)\n","    for idx, ele in enumerate(list_dir):\n","        df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                               sheet_name='Soal',\n","                               header=1,\n","                               index_col=0,\n","                               usecols='B:D')\n","\n","        list_final = []\n","\n","        for i in df_raw.itertuples():\n","            list_final.append(\n","                {\n","                    'soal': i[1],\n","                    'jawaban': i[2],\n","                    'nilai': 100,\n","                    'tipe': 'train'\n","                }\n","            )\n","            df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","            df_tmp = df_tmp.dropna()\n","            for j in df_tmp.itertuples():\n","                list_final.append(\n","                    {\n","                        'soal': i[1],\n","                        'jawaban': j[2],\n","                        'nilai': j[12],\n","                        'tipe': 'test'\n","                    }\n","                )\n","        if idx == 0:\n","            df_final = pd.DataFrame(list_final)\n","        else:\n","            df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","        print(' '.join(ele.rstrip('.xslx').split('_')))\n","        train_eval(df_final, m)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"_L2EdYIAAYkI","executionInfo":{"status":"ok","timestamp":1680440853208,"user_tz":-420,"elapsed":2,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["a = 2"]},{"cell_type":"code","source":["def train_eval_raw(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False, duplicates='drop')\n","\n","    # concatenate soal and jawaban\n","    df_final['soal-jawaban'] = df_final['soal']+df_final['jawaban']\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['soal-jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","        torch.save(model.state_dict(), f'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Politik_Save/finetuned_BERT_raw_epoch_{epoch}.model')\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')\n"],"metadata":{"id":"rVnD3QknFELV","executionInfo":{"status":"ok","timestamp":1680446013399,"user_tz":-420,"elapsed":5,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","path_dir = '/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data_Lagi/Politik'\n","list_dir = os.listdir(path_dir)\n","\n","list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","\n","for m in list_pre_trained_model:\n","    print(m)\n","    for idx, ele in enumerate(list_dir):\n","        df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                               sheet_name='Soal',\n","                               header=1,\n","                               index_col=0,\n","                               usecols='B:D')\n","\n","        list_final = []\n","\n","        for i in df_raw.itertuples():\n","            list_final.append(\n","                {\n","                    'soal': i[1],\n","                    'jawaban': i[2],\n","                    'nilai': 100,\n","                    'tipe': 'train'\n","                }\n","            )\n","            df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","            df_tmp = df_tmp.dropna()\n","            for j in df_tmp.itertuples():\n","                list_final.append(\n","                    {\n","                        'soal': i[1],\n","                        'jawaban': j[2],\n","                        'nilai': j[12],\n","                        'tipe': 'test'\n","                    }\n","                )\n","        if idx == 0:\n","            df_final = pd.DataFrame(list_final)\n","        else:\n","            df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","        print(' '.join(ele.rstrip('.xslx').split('_')))\n","        train_eval_raw(df_final, m)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRWtmApfFOHT","outputId":"2adb090e-cc25-4b56-cff9-2bddbda61564"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["indobenchmark/indobert-lite-base-p2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Analisis Essay Grading Politik\n"]},{"output_type":"stream","name":"stderr","text":["You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['pooler.bias', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'classifier.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/109 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/109 [00:23<?, ?it/s, training_loss=0.541]\u001b[A\n","Epoch 1:   1%|          | 1/109 [00:23<42:15, 23.48s/it, training_loss=0.541]\u001b[A\n","Epoch 1:   1%|          | 1/109 [00:39<42:15, 23.48s/it, training_loss=0.636]\u001b[A\n","Epoch 1:   2%|▏         | 2/109 [00:39<34:18, 19.24s/it, training_loss=0.636]\u001b[A\n","Epoch 1:   2%|▏         | 2/109 [00:53<34:18, 19.24s/it, training_loss=0.669]\u001b[A\n","Epoch 1:   3%|▎         | 3/109 [00:53<29:13, 16.54s/it, training_loss=0.669]\u001b[A\n","Epoch 1:   3%|▎         | 3/109 [01:03<29:13, 16.54s/it, training_loss=0.803]\u001b[A\n","Epoch 1:   4%|▎         | 4/109 [01:03<24:58, 14.27s/it, training_loss=0.803]\u001b[A\n","Epoch 1:   4%|▎         | 4/109 [01:16<24:58, 14.27s/it, training_loss=0.573]\u001b[A\n","Epoch 1:   5%|▍         | 5/109 [01:16<23:33, 13.59s/it, training_loss=0.573]\u001b[A\n","Epoch 1:   5%|▍         | 5/109 [01:29<23:33, 13.59s/it, training_loss=0.624]\u001b[A\n","Epoch 1:   6%|▌         | 6/109 [01:29<23:02, 13.42s/it, training_loss=0.624]\u001b[A\n","Epoch 1:   6%|▌         | 6/109 [01:41<23:02, 13.42s/it, training_loss=0.625]\u001b[A\n","Epoch 1:   6%|▋         | 7/109 [01:41<22:08, 13.03s/it, training_loss=0.625]\u001b[A\n","Epoch 1:   6%|▋         | 7/109 [01:52<22:08, 13.03s/it, training_loss=0.449]\u001b[A\n","Epoch 1:   7%|▋         | 8/109 [01:52<20:48, 12.36s/it, training_loss=0.449]\u001b[A\n","Epoch 1:   7%|▋         | 8/109 [02:05<20:48, 12.36s/it, training_loss=0.543]\u001b[A\n","Epoch 1:   8%|▊         | 9/109 [02:05<20:58, 12.58s/it, training_loss=0.543]\u001b[A\n","Epoch 1:   8%|▊         | 9/109 [02:20<20:58, 12.58s/it, training_loss=0.618]\u001b[A\n","Epoch 1:   9%|▉         | 10/109 [02:20<21:53, 13.26s/it, training_loss=0.618]\u001b[A\n","Epoch 1:   9%|▉         | 10/109 [02:34<21:53, 13.26s/it, training_loss=0.539]\u001b[A\n","Epoch 1:  10%|█         | 11/109 [02:34<22:02, 13.49s/it, training_loss=0.539]\u001b[A\n","Epoch 1:  10%|█         | 11/109 [02:44<22:02, 13.49s/it, training_loss=0.720]\u001b[A\n","Epoch 1:  11%|█         | 12/109 [02:44<20:16, 12.54s/it, training_loss=0.720]\u001b[A\n","Epoch 1:  11%|█         | 12/109 [02:59<20:16, 12.54s/it, training_loss=0.774]\u001b[A\n","Epoch 1:  12%|█▏        | 13/109 [02:59<21:12, 13.25s/it, training_loss=0.774]\u001b[A\n","Epoch 1:  12%|█▏        | 13/109 [03:12<21:12, 13.25s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  13%|█▎        | 14/109 [03:12<20:57, 13.24s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  13%|█▎        | 14/109 [03:25<20:57, 13.24s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  14%|█▍        | 15/109 [03:25<20:22, 13.01s/it, training_loss=0.593]\u001b[A\n","Epoch 1:  14%|█▍        | 15/109 [03:46<20:22, 13.01s/it, training_loss=0.411]\u001b[A\n","Epoch 1:  15%|█▍        | 16/109 [03:46<23:46, 15.34s/it, training_loss=0.411]\u001b[A\n","Epoch 1:  15%|█▍        | 16/109 [04:04<23:46, 15.34s/it, training_loss=0.528]\u001b[A\n","Epoch 1:  16%|█▌        | 17/109 [04:04<25:02, 16.33s/it, training_loss=0.528]\u001b[A\n","Epoch 1:  16%|█▌        | 17/109 [04:15<25:02, 16.33s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  17%|█▋        | 18/109 [04:15<22:27, 14.80s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  17%|█▋        | 18/109 [04:27<22:27, 14.80s/it, training_loss=0.512]\u001b[A\n","Epoch 1:  17%|█▋        | 19/109 [04:27<20:49, 13.88s/it, training_loss=0.512]\u001b[A\n","Epoch 1:  17%|█▋        | 19/109 [04:40<20:49, 13.88s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  18%|█▊        | 20/109 [04:40<20:11, 13.62s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  18%|█▊        | 20/109 [04:53<20:11, 13.62s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  19%|█▉        | 21/109 [04:53<19:35, 13.36s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  19%|█▉        | 21/109 [05:03<19:35, 13.36s/it, training_loss=0.616]\u001b[A\n","Epoch 1:  20%|██        | 22/109 [05:03<18:03, 12.45s/it, training_loss=0.616]\u001b[A\n","Epoch 1:  20%|██        | 22/109 [05:16<18:03, 12.45s/it, training_loss=0.677]\u001b[A\n","Epoch 1:  21%|██        | 23/109 [05:16<18:01, 12.58s/it, training_loss=0.677]\u001b[A\n","Epoch 1:  21%|██        | 23/109 [05:30<18:01, 12.58s/it, training_loss=0.682]\u001b[A\n","Epoch 1:  22%|██▏       | 24/109 [05:30<18:17, 12.91s/it, training_loss=0.682]\u001b[A\n","Epoch 1:  22%|██▏       | 24/109 [05:41<18:17, 12.91s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  23%|██▎       | 25/109 [05:41<17:28, 12.49s/it, training_loss=0.503]\u001b[A\n","Epoch 1:  23%|██▎       | 25/109 [05:52<17:28, 12.49s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  24%|██▍       | 26/109 [05:52<16:41, 12.07s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  24%|██▍       | 26/109 [06:05<16:41, 12.07s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  25%|██▍       | 27/109 [06:05<16:41, 12.21s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  25%|██▍       | 27/109 [06:18<16:41, 12.21s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  26%|██▌       | 28/109 [06:18<16:41, 12.36s/it, training_loss=0.592]\u001b[A\n","Epoch 1:  26%|██▌       | 28/109 [06:29<16:41, 12.36s/it, training_loss=0.453]\u001b[A\n","Epoch 1:  27%|██▋       | 29/109 [06:29<16:08, 12.10s/it, training_loss=0.453]\u001b[A\n","Epoch 1:  27%|██▋       | 29/109 [06:40<16:08, 12.10s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  28%|██▊       | 30/109 [06:40<15:33, 11.81s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  28%|██▊       | 30/109 [06:53<15:33, 11.81s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  28%|██▊       | 31/109 [06:53<15:36, 12.01s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  28%|██▊       | 31/109 [07:05<15:36, 12.01s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  29%|██▉       | 32/109 [07:05<15:38, 12.19s/it, training_loss=0.609]\u001b[A\n","Epoch 1:  29%|██▉       | 32/109 [07:16<15:38, 12.19s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  30%|███       | 33/109 [07:16<14:57, 11.80s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  30%|███       | 33/109 [07:28<14:57, 11.80s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  31%|███       | 34/109 [07:28<14:41, 11.75s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  31%|███       | 34/109 [07:41<14:41, 11.75s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  32%|███▏      | 35/109 [07:41<14:48, 12.01s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  32%|███▏      | 35/109 [07:53<14:48, 12.01s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  33%|███▎      | 36/109 [07:53<14:50, 12.19s/it, training_loss=0.508]\u001b[A\n","Epoch 1:  33%|███▎      | 36/109 [08:04<14:50, 12.19s/it, training_loss=0.563]\u001b[A\n","Epoch 1:  34%|███▍      | 37/109 [08:04<14:08, 11.79s/it, training_loss=0.563]\u001b[A\n","Epoch 1:  34%|███▍      | 37/109 [08:16<14:08, 11.79s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  35%|███▍      | 38/109 [08:16<13:56, 11.78s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  35%|███▍      | 38/109 [08:28<13:56, 11.78s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  36%|███▌      | 39/109 [08:28<14:03, 12.05s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  36%|███▌      | 39/109 [08:41<14:03, 12.05s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  37%|███▋      | 40/109 [08:41<14:04, 12.24s/it, training_loss=0.505]\u001b[A\n","Epoch 1:  37%|███▋      | 40/109 [08:52<14:04, 12.24s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  38%|███▊      | 41/109 [08:52<13:18, 11.74s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  38%|███▊      | 41/109 [09:04<13:18, 11.74s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  39%|███▊      | 42/109 [09:04<13:08, 11.77s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  39%|███▊      | 42/109 [09:16<13:08, 11.77s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  39%|███▉      | 43/109 [09:16<13:12, 12.01s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  39%|███▉      | 43/109 [09:29<13:12, 12.01s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  40%|████      | 44/109 [09:29<13:11, 12.17s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  40%|████      | 44/109 [09:39<13:11, 12.17s/it, training_loss=0.492]\u001b[A\n","Epoch 1:  41%|████▏     | 45/109 [09:39<12:23, 11.61s/it, training_loss=0.492]\u001b[A\n","Epoch 1:  41%|████▏     | 45/109 [09:51<12:23, 11.61s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  42%|████▏     | 46/109 [09:51<12:23, 11.80s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  42%|████▏     | 46/109 [10:04<12:23, 11.80s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  43%|████▎     | 47/109 [10:04<12:27, 12.05s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  43%|████▎     | 47/109 [10:16<12:27, 12.05s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  44%|████▍     | 48/109 [10:16<12:21, 12.15s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  44%|████▍     | 48/109 [10:27<12:21, 12.15s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  45%|████▍     | 49/109 [10:27<11:41, 11.70s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  45%|████▍     | 49/109 [10:39<11:41, 11.70s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  46%|████▌     | 50/109 [10:39<11:45, 11.96s/it, training_loss=0.515]\u001b[A\n","Epoch 1:  46%|████▌     | 50/109 [10:52<11:45, 11.96s/it, training_loss=0.487]\u001b[A\n","Epoch 1:  47%|████▋     | 51/109 [10:52<11:44, 12.15s/it, training_loss=0.487]\u001b[A\n","Epoch 1:  47%|████▋     | 51/109 [11:04<11:44, 12.15s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  48%|████▊     | 52/109 [11:04<11:31, 12.13s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  48%|████▊     | 52/109 [11:15<11:31, 12.13s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  49%|████▊     | 53/109 [11:15<10:52, 11.66s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  49%|████▊     | 53/109 [11:27<10:52, 11.66s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  50%|████▉     | 54/109 [11:27<10:55, 11.92s/it, training_loss=0.520]\u001b[A\n","Epoch 1:  50%|████▉     | 54/109 [11:40<10:55, 11.92s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  50%|█████     | 55/109 [11:40<10:55, 12.14s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  50%|█████     | 55/109 [11:52<10:55, 12.14s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  51%|█████▏    | 56/109 [11:52<10:38, 12.05s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  51%|█████▏    | 56/109 [12:03<10:38, 12.05s/it, training_loss=0.608]\u001b[A\n","Epoch 1:  52%|█████▏    | 57/109 [12:03<10:08, 11.71s/it, training_loss=0.608]\u001b[A\n","Epoch 1:  52%|█████▏    | 57/109 [12:15<10:08, 11.71s/it, training_loss=0.443]\u001b[A\n","Epoch 1:  53%|█████▎    | 58/109 [12:15<10:10, 11.98s/it, training_loss=0.443]\u001b[A\n","Epoch 1:  53%|█████▎    | 58/109 [12:28<10:10, 11.98s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  54%|█████▍    | 59/109 [12:28<10:09, 12.19s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  54%|█████▍    | 59/109 [12:39<10:09, 12.19s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  55%|█████▌    | 60/109 [12:39<09:46, 11.97s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  55%|█████▌    | 60/109 [12:50<09:46, 11.97s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  56%|█████▌    | 61/109 [12:50<09:21, 11.69s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  56%|█████▌    | 61/109 [13:03<09:21, 11.69s/it, training_loss=0.510]\u001b[A\n","Epoch 1:  57%|█████▋    | 62/109 [13:03<09:21, 11.94s/it, training_loss=0.510]\u001b[A\n","Epoch 1:  57%|█████▋    | 62/109 [13:15<09:21, 11.94s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  58%|█████▊    | 63/109 [13:15<09:17, 12.12s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  58%|█████▊    | 63/109 [13:26<09:17, 12.12s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  59%|█████▊    | 64/109 [13:26<08:49, 11.77s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  59%|█████▊    | 64/109 [13:38<08:49, 11.77s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  60%|█████▉    | 65/109 [13:38<08:33, 11.66s/it, training_loss=0.517]\u001b[A\n","Epoch 1:  60%|█████▉    | 65/109 [13:50<08:33, 11.66s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  61%|██████    | 66/109 [13:50<08:33, 11.94s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  61%|██████    | 66/109 [14:03<08:33, 11.94s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  61%|██████▏   | 67/109 [14:03<08:31, 12.17s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  61%|██████▏   | 67/109 [14:14<08:31, 12.17s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  62%|██████▏   | 68/109 [14:14<07:58, 11.67s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  62%|██████▏   | 68/109 [14:25<07:58, 11.67s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  63%|██████▎   | 69/109 [14:25<07:48, 11.72s/it, training_loss=0.518]\u001b[A\n","Epoch 1:  63%|██████▎   | 69/109 [14:38<07:48, 11.72s/it, training_loss=0.492]\u001b[A\n","Epoch 1:  64%|██████▍   | 70/109 [14:38<07:47, 11.99s/it, training_loss=0.492]\u001b[A\n","Epoch 1:  64%|██████▍   | 70/109 [14:52<07:47, 11.99s/it, training_loss=0.453]\u001b[A\n","Epoch 1:  65%|██████▌   | 71/109 [14:52<08:00, 12.63s/it, training_loss=0.453]\u001b[A\n","Epoch 1:  65%|██████▌   | 71/109 [15:03<08:00, 12.63s/it, training_loss=0.504]\u001b[A\n","Epoch 1:  66%|██████▌   | 72/109 [15:03<07:30, 12.18s/it, training_loss=0.504]\u001b[A\n","Epoch 1:  66%|██████▌   | 72/109 [15:15<07:30, 12.18s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  67%|██████▋   | 73/109 [15:15<07:09, 11.94s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  67%|██████▋   | 73/109 [15:27<07:09, 11.94s/it, training_loss=0.676]\u001b[A\n","Epoch 1:  68%|██████▊   | 74/109 [15:27<07:05, 12.14s/it, training_loss=0.676]\u001b[A\n","Epoch 1:  68%|██████▊   | 74/109 [15:43<07:05, 12.14s/it, training_loss=0.691]\u001b[A\n","Epoch 1:  69%|██████▉   | 75/109 [15:43<07:29, 13.22s/it, training_loss=0.691]\u001b[A\n","Epoch 1:  69%|██████▉   | 75/109 [15:55<07:29, 13.22s/it, training_loss=0.715]\u001b[A\n","Epoch 1:  70%|██████▉   | 76/109 [15:55<07:01, 12.78s/it, training_loss=0.715]\u001b[A\n","Epoch 1:  70%|██████▉   | 76/109 [16:06<07:01, 12.78s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  71%|███████   | 77/109 [16:06<06:30, 12.20s/it, training_loss=0.532]\u001b[A\n","Epoch 1:  71%|███████   | 77/109 [16:18<06:30, 12.20s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  72%|███████▏  | 78/109 [16:18<06:21, 12.32s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  72%|███████▏  | 78/109 [16:31<06:21, 12.32s/it, training_loss=0.462]\u001b[A\n","Epoch 1:  72%|███████▏  | 79/109 [16:31<06:12, 12.41s/it, training_loss=0.462]\u001b[A\n","Epoch 1:  72%|███████▏  | 79/109 [16:42<06:12, 12.41s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  73%|███████▎  | 80/109 [16:42<05:50, 12.07s/it, training_loss=0.484]\u001b[A\n","Epoch 1:  73%|███████▎  | 80/109 [16:53<05:50, 12.07s/it, training_loss=0.389]\u001b[A\n","Epoch 1:  74%|███████▍  | 81/109 [16:53<05:31, 11.84s/it, training_loss=0.389]\u001b[A\n","Epoch 1:  74%|███████▍  | 81/109 [17:06<05:31, 11.84s/it, training_loss=0.427]\u001b[A\n","Epoch 1:  75%|███████▌  | 82/109 [17:06<05:26, 12.09s/it, training_loss=0.427]\u001b[A\n","Epoch 1:  75%|███████▌  | 82/109 [17:19<05:26, 12.09s/it, training_loss=0.480]\u001b[A\n","Epoch 1:  76%|███████▌  | 83/109 [17:19<05:18, 12.24s/it, training_loss=0.480]\u001b[A\n","Epoch 1:  76%|███████▌  | 83/109 [17:30<05:18, 12.24s/it, training_loss=0.357]\u001b[A\n","Epoch 1:  77%|███████▋  | 84/109 [17:30<04:58, 11.93s/it, training_loss=0.357]\u001b[A\n","Epoch 1:  77%|███████▋  | 84/109 [17:41<04:58, 11.93s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  78%|███████▊  | 85/109 [17:41<04:42, 11.76s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  78%|███████▊  | 85/109 [17:54<04:42, 11.76s/it, training_loss=0.368]\u001b[A\n","Epoch 1:  79%|███████▉  | 86/109 [17:54<04:36, 12.00s/it, training_loss=0.368]\u001b[A\n","Epoch 1:  79%|███████▉  | 86/109 [18:06<04:36, 12.00s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  80%|███████▉  | 87/109 [18:06<04:28, 12.19s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  80%|███████▉  | 87/109 [18:17<04:28, 12.19s/it, training_loss=0.366]\u001b[A\n","Epoch 1:  81%|████████  | 88/109 [18:17<04:06, 11.76s/it, training_loss=0.366]\u001b[A\n","Epoch 1:  81%|████████  | 88/109 [18:29<04:06, 11.76s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  82%|████████▏ | 89/109 [18:29<03:54, 11.73s/it, training_loss=0.527]\u001b[A\n","Epoch 1:  82%|████████▏ | 89/109 [18:41<03:54, 11.73s/it, training_loss=0.428]\u001b[A\n","Epoch 1:  83%|████████▎ | 90/109 [18:41<03:47, 11.98s/it, training_loss=0.428]\u001b[A\n","Epoch 1:  83%|████████▎ | 90/109 [18:54<03:47, 11.98s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  83%|████████▎ | 91/109 [18:54<03:38, 12.15s/it, training_loss=0.526]\u001b[A\n","Epoch 1:  83%|████████▎ | 91/109 [19:05<03:38, 12.15s/it, training_loss=0.449]\u001b[A\n","Epoch 1:  84%|████████▍ | 92/109 [19:05<03:18, 11.70s/it, training_loss=0.449]\u001b[A\n","Epoch 1:  84%|████████▍ | 92/109 [19:17<03:18, 11.70s/it, training_loss=0.359]\u001b[A\n","Epoch 1:  85%|████████▌ | 93/109 [19:17<03:08, 11.80s/it, training_loss=0.359]\u001b[A\n","Epoch 1:  85%|████████▌ | 93/109 [19:29<03:08, 11.80s/it, training_loss=0.308]\u001b[A\n","Epoch 1:  86%|████████▌ | 94/109 [19:29<03:00, 12.04s/it, training_loss=0.308]\u001b[A\n","Epoch 1:  86%|████████▌ | 94/109 [19:42<03:00, 12.04s/it, training_loss=0.366]\u001b[A\n","Epoch 1:  87%|████████▋ | 95/109 [19:42<02:49, 12.13s/it, training_loss=0.366]\u001b[A\n","Epoch 1:  87%|████████▋ | 95/109 [19:52<02:49, 12.13s/it, training_loss=0.427]\u001b[A\n","Epoch 1:  88%|████████▊ | 96/109 [19:52<02:30, 11.57s/it, training_loss=0.427]\u001b[A\n","Epoch 1:  88%|████████▊ | 96/109 [20:04<02:30, 11.57s/it, training_loss=0.086]\u001b[A\n","Epoch 1:  89%|████████▉ | 97/109 [20:04<02:22, 11.87s/it, training_loss=0.086]\u001b[A\n","Epoch 1:  89%|████████▉ | 97/109 [20:17<02:22, 11.87s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  90%|████████▉ | 98/109 [20:17<02:13, 12.11s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  90%|████████▉ | 98/109 [20:29<02:13, 12.11s/it, training_loss=0.793]\u001b[A\n","Epoch 1:  91%|█████████ | 99/109 [20:29<02:01, 12.10s/it, training_loss=0.793]\u001b[A\n","Epoch 1:  91%|█████████ | 99/109 [20:40<02:01, 12.10s/it, training_loss=0.848]\u001b[A\n","Epoch 1:  92%|█████████▏| 100/109 [20:40<01:44, 11.66s/it, training_loss=0.848]\u001b[A\n","Epoch 1:  92%|█████████▏| 100/109 [20:52<01:44, 11.66s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  93%|█████████▎| 101/109 [20:52<01:35, 11.93s/it, training_loss=0.632]\u001b[A"]}]},{"cell_type":"code","source":["while 1:\n","  print(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fAr8fvMVYzCF","executionInfo":{"status":"error","timestamp":1680452988740,"user_tz":-420,"elapsed":10737,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"dfc4e875-b588-4149-aa94-8330f99762e5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-0c462dd19bad>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"J_YU45ehj90W"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxytXHqWOAiG1CKqF92tip"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cf6b39bc447f484d9671319c26596af8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77cb5a406ff4457a9a5278dfb80be2a0","IPY_MODEL_ad98ad9838e4447abbcf04633395a5ab","IPY_MODEL_535ee4fa2b7346149d9371cb2ee38bee"],"layout":"IPY_MODEL_9bc6b52ee82e424f9fdbfe7f4971b757"}},"77cb5a406ff4457a9a5278dfb80be2a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ae974ec05b417da819850949154e17","placeholder":"​","style":"IPY_MODEL_f2c5ee9900f24d48b5877064079abe0d","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"ad98ad9838e4447abbcf04633395a5ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_362c3b5b03d743a583bf73690da6a389","max":224974,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4435a68cf50947c3bda90443192e0366","value":224974}},"535ee4fa2b7346149d9371cb2ee38bee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65995a3f023d4d12ba6e0ce5f7891aaf","placeholder":"​","style":"IPY_MODEL_76ebc46fd67c40709f42cfa5db9a93ef","value":" 225k/225k [00:00&lt;00:00, 1.96MB/s]"}},"9bc6b52ee82e424f9fdbfe7f4971b757":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ae974ec05b417da819850949154e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c5ee9900f24d48b5877064079abe0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"362c3b5b03d743a583bf73690da6a389":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4435a68cf50947c3bda90443192e0366":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65995a3f023d4d12ba6e0ce5f7891aaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ebc46fd67c40709f42cfa5db9a93ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21cdea9a429f4b368632c6b7ec98cf76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e7a6896728d4939902ceaa6356a54bf","IPY_MODEL_f94481ee5c314d7f9ff8a6d1d8a39c47","IPY_MODEL_954ab8de3bc849d0a1c1483c57598c19"],"layout":"IPY_MODEL_910083d48d3e4269a3f466032d3c6eeb"}},"6e7a6896728d4939902ceaa6356a54bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_201563030b0c4bcead2253698e01cd64","placeholder":"​","style":"IPY_MODEL_92c7e118883f4244aa0e4060e1a9dd14","value":"Downloading (…)cial_tokens_map.json: 100%"}},"f94481ee5c314d7f9ff8a6d1d8a39c47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_decd9456a7f54c62b8e55f2408cd0504","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_249e92f6680d4393bc66b1c3e1b8ebce","value":112}},"954ab8de3bc849d0a1c1483c57598c19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ece0ca3df91b4cefb1db45a29a690bda","placeholder":"​","style":"IPY_MODEL_6e9e841711344153b9549c21669602ad","value":" 112/112 [00:00&lt;00:00, 4.75kB/s]"}},"910083d48d3e4269a3f466032d3c6eeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"201563030b0c4bcead2253698e01cd64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92c7e118883f4244aa0e4060e1a9dd14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"decd9456a7f54c62b8e55f2408cd0504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"249e92f6680d4393bc66b1c3e1b8ebce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ece0ca3df91b4cefb1db45a29a690bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9e841711344153b9549c21669602ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2501b901f47e44a5b433b68e57aac24a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c850e17369a94aa4a82056b8869834c4","IPY_MODEL_dfcf3550d47240af8ef79e074c464eca","IPY_MODEL_9a034c290b5542a484a0024e720b9085"],"layout":"IPY_MODEL_fc3aee9ab947445ca301229f7f49c7e9"}},"c850e17369a94aa4a82056b8869834c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bed8f438f64946248324e1685357efee","placeholder":"​","style":"IPY_MODEL_2743b65fa4d747779edcd53b6e883c23","value":"Downloading (…)okenizer_config.json: 100%"}},"dfcf3550d47240af8ef79e074c464eca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc9921133ae742c099928b3eb252f888","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3b3a198511c476a84ef92ea51b45565","value":2}},"9a034c290b5542a484a0024e720b9085":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60e06725b23b40a6a04b5c58a508cc32","placeholder":"​","style":"IPY_MODEL_625ed921fd4d4e3d98ba4437f370a56e","value":" 2.00/2.00 [00:00&lt;00:00, 53.6B/s]"}},"fc3aee9ab947445ca301229f7f49c7e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bed8f438f64946248324e1685357efee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2743b65fa4d747779edcd53b6e883c23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc9921133ae742c099928b3eb252f888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b3a198511c476a84ef92ea51b45565":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60e06725b23b40a6a04b5c58a508cc32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"625ed921fd4d4e3d98ba4437f370a56e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57074098443042c4babcb99406c27768":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d8464ba294e456ea6500c782ef85ebb","IPY_MODEL_a334fb82881f4f119fe278f91200d741","IPY_MODEL_ecc1a64b417c4f658808731601fefa47"],"layout":"IPY_MODEL_1f5d6e583c0f4d209a17a9eb0b73770a"}},"6d8464ba294e456ea6500c782ef85ebb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e0429881c81450683fd0904f18b3c68","placeholder":"​","style":"IPY_MODEL_83199933b9a54ba99574c170c3708776","value":"Downloading (…)lve/main/config.json: 100%"}},"a334fb82881f4f119fe278f91200d741":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0abcc3227aa547d7b7c0660c885521ca","max":1542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e7d807db6e046a88c6b039dbbabb916","value":1542}},"ecc1a64b417c4f658808731601fefa47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f084488020ac4fa4aca86e7aec443d2a","placeholder":"​","style":"IPY_MODEL_8eb500b779f348c0a385f3e90984abc1","value":" 1.54k/1.54k [00:00&lt;00:00, 54.8kB/s]"}},"1f5d6e583c0f4d209a17a9eb0b73770a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e0429881c81450683fd0904f18b3c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83199933b9a54ba99574c170c3708776":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0abcc3227aa547d7b7c0660c885521ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e7d807db6e046a88c6b039dbbabb916":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f084488020ac4fa4aca86e7aec443d2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb500b779f348c0a385f3e90984abc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cbc80fca59341ee8e9fcd22357c4365":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28c9d2ad3bd54ee7a78f0f18874ada3f","IPY_MODEL_4cacf3bf87b846ee98c4c5d8f348181b","IPY_MODEL_68fb046afa0e43a589cb67e8af0ebacd"],"layout":"IPY_MODEL_1f6687906fa04d4292ee64769cf4f9f5"}},"28c9d2ad3bd54ee7a78f0f18874ada3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d72c92092094f9abace50f7228eaaa7","placeholder":"​","style":"IPY_MODEL_63ca50bb7070416ba91005e84072f882","value":"Downloading pytorch_model.bin: 100%"}},"4cacf3bf87b846ee98c4c5d8f348181b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf468ef261144a8cab0247cd2ddcdd7a","max":46739879,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90c0aebbfe364906a4ab85e550e79fba","value":46739879}},"68fb046afa0e43a589cb67e8af0ebacd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7bb924787fe4c86996be33a57c2f038","placeholder":"​","style":"IPY_MODEL_d095b474b5724c6b863899c8e5834a5f","value":" 46.7M/46.7M [00:01&lt;00:00, 44.3MB/s]"}},"1f6687906fa04d4292ee64769cf4f9f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d72c92092094f9abace50f7228eaaa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63ca50bb7070416ba91005e84072f882":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf468ef261144a8cab0247cd2ddcdd7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90c0aebbfe364906a4ab85e550e79fba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7bb924787fe4c86996be33a57c2f038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d095b474b5724c6b863899c8e5834a5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}