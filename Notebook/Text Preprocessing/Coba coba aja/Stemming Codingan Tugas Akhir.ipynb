{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5545,"status":"ok","timestamp":1679820208991,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"MbN-qdA5z1G-","outputId":"718de53d-41ad-4b47-b30a-37a274f95a66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"id":"MbN-qdA5z1G-"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3947,"status":"ok","timestamp":1679820212934,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"EcXBnbTmz2nW","outputId":"0d7b264a-2e43-477d-b300-42835b3a51a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n"]}],"source":["pip install sastrawi"],"id":"EcXBnbTmz2nW"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6059,"status":"ok","timestamp":1679820218987,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"1AVL6mTkz2x9","outputId":"3ce5a910-70d1-49fe-ea68-6dee03f3b45e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk) (1.16.0)\n"]}],"source":["pip install nltk"],"id":"1AVL6mTkz2x9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1519,"status":"ok","timestamp":1679820220502,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"DFkbHffjz299","outputId":"23c25618-8748-43c5-9dda-e96a70e3b72b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')"],"id":"DFkbHffjz299"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1679820220503,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"wRQaDdXaz6fl","outputId":"fb79c913-65a0-4e9f-95c2-3643031cd18a"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('punkt')"],"id":"wRQaDdXaz6fl"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":752,"status":"ok","timestamp":1679820221251,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"1d61a3ba","outputId":"cf5bd931-ae82-48bb-f0ee-4dc5ea106cf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Indonesian Query Answering Dataset for Online Essay Test System.zip', 'dict.json', 'Preprocessing', 'Analysis Data', 'Text Preprocessing', 'Data', 'dataset.py', '__pycache__']\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","import os\n","import re\n","import nltk\n","import random\n","from nltk.corpus import stopwords\n","from gensim.models import Word2Vec\n","from nltk.tokenize import sent_tokenize, LineTokenizer, RegexpTokenizer\n","from nltk.tokenize import word_tokenize\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","\n","print(os.listdir(\"/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/\"))\n","factory = StemmerFactory()\n","stemmer = factory.create_stemmer()\n","import string\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","stopwords_indonesia = stopwords.words('indonesian')\n","stop_words = set(stopwords.words('indonesian'))\n","import sys\n","import os"],"id":"1d61a3ba"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbTgH1-D-kLA"},"outputs":[],"source":[],"id":"UbTgH1-D-kLA"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5348,"status":"ok","timestamp":1679820226596,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"icJEdL3SOegH","outputId":"87af771e-8ba5-4a19-c4bc-89d24cd00509"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nlp_id in /usr/local/lib/python3.9/dist-packages (0.1.13.0)\n","Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.4.5)\n","Requirement already satisfied: scikit-learn==1.1.0 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (1.1.0)\n","Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.4.5->nlp_id) (1.16.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.22.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.10.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.1.1)\n"]}],"source":["pip install nlp_id"],"id":"icJEdL3SOegH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4447,"status":"ok","timestamp":1679820231028,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"LMdPOnmpOkt_","outputId":"3821ced8-cf6c-4d1b-97ae-be958e5ab7ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"]}],"source":["pip install transformers"],"id":"LMdPOnmpOkt_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPqvrG0rEKSC"},"outputs":[],"source":["# fungsi untuk menghapus kata negasi\n","def hapus_kata_negasi(kalimat):\n","    # membuat daftar kata negasi\n","    negasi = ['tidak', 'bukan', 'belum', 'tak', 'jangan', 'tidaklah', 'bukannya', 'tiada', 'gak', 'ngga', 'nggak', 'enggak']\n","    # melakukan split kalimat menjadi token\n","    result = []\n","    negate = False\n","    for word in kalimat:\n","        if any(neg == word for neg in negasi):\n","            negate = True\n","        elif negate and word not in string.punctuation:\n","            word = 'tidak_' + word\n","            negate = False\n","        result.append(word)\n","    return result\n","\n","def remove_stopword(token):\n","    return ' '. join(token)"],"id":"ZPqvrG0rEKSC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4N6fkUEOk65"},"outputs":[],"source":["import re\n","import random\n","import pandas as pd\n","import torch\n","import tensorflow as tf\n","import numpy as np\n","\n","from nlp_id.lemmatizer import Lemmatizer\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.metrics import f1_score, cohen_kappa_score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from nltk.corpus import stopwords"],"id":"t4N6fkUEOk65"},{"cell_type":"code","execution_count":null,"metadata":{"id":"32c4042a"},"outputs":[],"source":["seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","punctuation = r'[^\\w\\s]'\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def qwk_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return cohen_kappa_score(labels_flat, preds_flat)\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","\n","def evaluate(dataloader_val, device, model):\n","\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_val:\n","\n","        batch = tuple(b.to(device) for b in batch)\n","\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total/len(dataloader_val)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals\n","\n","def train_eval(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False)\n","\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: x.lower())\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: re.sub(punctuation, '', x))\n","    df_final['jawaban'] = df_final['jawaban'].apply(nltk.word_tokenize)\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: [word for word in x if word not in stop_words])\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: remove_stopword(x))\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: hapus_kata_negasi(x))\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: remove_stopword(x))    \n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: [stemmer.stem(token) for token in x])\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: remove_stopword(x)) \n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","\n","        torch.save(model.state_dict(), f'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Model_Save/finetuned_BERT_Stemming_epoch_{epoch}.model')\n","\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')"],"id":"32c4042a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ju3GxLhL-4I_"},"outputs":[],"source":["def asag_systems(path_dir):\n","    list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","    list_dir = os.listdir(path_dir)\n","    for m in list_pre_trained_model:\n","        print(m)\n","        for idx, ele in enumerate(list_dir):\n","            df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                  sheet_name='Soal',\n","                                  header=1,\n","                                  index_col=0,\n","                                  usecols='B:D')\n","\n","            list_final = []\n","\n","            for i in df_raw.itertuples():\n","                list_final.append(\n","                    {\n","                        'jawaban': i[1],\n","                        'nilai': 100,\n","                        'tipe': 'train',\n","                        'path': f'Stemming',\n","                    }\n","                )\n","                df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","                \n","                df_tmp = df_tmp.dropna()\n","                for j in df_tmp.itertuples():\n","                    list_final.append(\n","                        {\n","                            'jawaban': j[1],\n","                            'nilai': j[12],\n","                            'tipe': 'test',\n","                            'path': f'Stemming',\n","                        }\n","                    )\n","            if idx == 0:\n","                df_final = pd.DataFrame(list_final)\n","            else:\n","                df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","            print(' '.join(ele.rstrip('.xslx').split('_')))\n","    \n","            train_eval(df_final, m)\n"],"id":"Ju3GxLhL-4I_"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVH_6Fb1IUOS","executionInfo":{"status":"error","timestamp":1679840828573,"user_tz":-420,"elapsed":4851588,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"912bb8fc-1dc6-435d-d6f3-c01d2394ae0e"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["indobenchmark/indobert-lite-base-p2\n","Analisis Essay Grading Lifestyle\n"]},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'encoder.embedding_hidden_mapping_in.bias', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'pooler.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'classifier.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'pooler.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/116 [00:12<?, ?it/s, training_loss=0.529]\u001b[A\n","Epoch 1:   1%|          | 1/116 [00:12<24:36, 12.84s/it, training_loss=0.529]\u001b[A\n","Epoch 1:   1%|          | 1/116 [00:26<24:36, 12.84s/it, training_loss=0.874]\u001b[A\n","Epoch 1:   2%|▏         | 2/116 [00:26<24:47, 13.05s/it, training_loss=0.874]\u001b[A\n","Epoch 1:   2%|▏         | 2/116 [00:39<24:47, 13.05s/it, training_loss=0.696]\u001b[A\n","Epoch 1:   3%|▎         | 3/116 [00:39<24:47, 13.17s/it, training_loss=0.696]\u001b[A\n","Epoch 1:   3%|▎         | 3/116 [00:52<24:47, 13.17s/it, training_loss=0.460]\u001b[A\n","Epoch 1:   3%|▎         | 4/116 [00:52<24:42, 13.24s/it, training_loss=0.460]\u001b[A\n","Epoch 1:   3%|▎         | 4/116 [01:04<24:42, 13.24s/it, training_loss=0.605]\u001b[A\n","Epoch 1:   4%|▍         | 5/116 [01:04<23:40, 12.79s/it, training_loss=0.605]\u001b[A\n","Epoch 1:   4%|▍         | 5/116 [01:15<23:40, 12.79s/it, training_loss=0.710]\u001b[A\n","Epoch 1:   5%|▌         | 6/116 [01:16<22:31, 12.29s/it, training_loss=0.710]\u001b[A\n","Epoch 1:   5%|▌         | 6/116 [01:29<22:31, 12.29s/it, training_loss=0.503]\u001b[A\n","Epoch 1:   6%|▌         | 7/116 [01:29<22:46, 12.54s/it, training_loss=0.503]\u001b[A\n","Epoch 1:   6%|▌         | 7/116 [01:42<22:46, 12.54s/it, training_loss=0.833]\u001b[A\n","Epoch 1:   7%|▋         | 8/116 [01:42<22:52, 12.71s/it, training_loss=0.833]\u001b[A\n","Epoch 1:   7%|▋         | 8/116 [01:52<22:52, 12.71s/it, training_loss=0.817]\u001b[A\n","Epoch 1:   8%|▊         | 9/116 [01:52<21:32, 12.08s/it, training_loss=0.817]\u001b[A\n","Epoch 1:   8%|▊         | 9/116 [02:04<21:32, 12.08s/it, training_loss=0.718]\u001b[A\n","Epoch 1:   9%|▊         | 10/116 [02:04<21:22, 12.10s/it, training_loss=0.718]\u001b[A\n","Epoch 1:   9%|▊         | 10/116 [02:17<21:22, 12.10s/it, training_loss=0.680]\u001b[A\n","Epoch 1:   9%|▉         | 11/116 [02:18<21:40, 12.39s/it, training_loss=0.680]\u001b[A\n","Epoch 1:   9%|▉         | 11/116 [02:30<21:40, 12.39s/it, training_loss=0.634]\u001b[A\n","Epoch 1:  10%|█         | 12/116 [02:30<21:24, 12.35s/it, training_loss=0.634]\u001b[A\n","Epoch 1:  10%|█         | 12/116 [02:41<21:24, 12.35s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  11%|█         | 13/116 [02:41<20:30, 11.94s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  11%|█         | 13/116 [02:54<20:30, 11.94s/it, training_loss=0.605]\u001b[A\n","Epoch 1:  12%|█▏        | 14/116 [02:54<20:52, 12.28s/it, training_loss=0.605]\u001b[A\n","Epoch 1:  12%|█▏        | 14/116 [03:07<20:52, 12.28s/it, training_loss=0.717]\u001b[A\n","Epoch 1:  13%|█▎        | 15/116 [03:07<21:04, 12.52s/it, training_loss=0.717]\u001b[A\n","Epoch 1:  13%|█▎        | 15/116 [03:18<21:04, 12.52s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  14%|█▍        | 16/116 [03:18<20:10, 12.10s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  14%|█▍        | 16/116 [03:30<20:10, 12.10s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  15%|█▍        | 17/116 [03:30<19:51, 12.04s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  15%|█▍        | 17/116 [03:43<19:51, 12.04s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  16%|█▌        | 18/116 [03:43<20:04, 12.29s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  16%|█▌        | 18/116 [03:55<20:04, 12.29s/it, training_loss=0.447]\u001b[A\n","Epoch 1:  16%|█▋        | 19/116 [03:55<19:48, 12.26s/it, training_loss=0.447]\u001b[A\n","Epoch 1:  16%|█▋        | 19/116 [04:06<19:48, 12.26s/it, training_loss=0.644]\u001b[A\n","Epoch 1:  17%|█▋        | 20/116 [04:06<18:52, 11.79s/it, training_loss=0.644]\u001b[A\n","Epoch 1:  17%|█▋        | 20/116 [04:19<18:52, 11.79s/it, training_loss=0.670]\u001b[A\n","Epoch 1:  18%|█▊        | 21/116 [04:19<19:13, 12.14s/it, training_loss=0.670]\u001b[A\n","Epoch 1:  18%|█▊        | 21/116 [04:31<19:13, 12.14s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  19%|█▉        | 22/116 [04:31<19:21, 12.35s/it, training_loss=0.619]\u001b[A\n","Epoch 1:  19%|█▉        | 22/116 [04:42<19:21, 12.35s/it, training_loss=0.568]\u001b[A\n","Epoch 1:  20%|█▉        | 23/116 [04:42<18:29, 11.93s/it, training_loss=0.568]\u001b[A\n","Epoch 1:  20%|█▉        | 23/116 [04:55<18:29, 11.93s/it, training_loss=0.589]\u001b[A\n","Epoch 1:  21%|██        | 24/116 [04:55<18:25, 12.02s/it, training_loss=0.589]\u001b[A\n","Epoch 1:  21%|██        | 24/116 [05:08<18:25, 12.02s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  22%|██▏       | 25/116 [05:08<18:41, 12.32s/it, training_loss=0.465]\u001b[A\n","Epoch 1:  22%|██▏       | 25/116 [05:20<18:41, 12.32s/it, training_loss=0.595]\u001b[A\n","Epoch 1:  22%|██▏       | 26/116 [05:20<18:29, 12.33s/it, training_loss=0.595]\u001b[A\n","Epoch 1:  22%|██▏       | 26/116 [05:31<18:29, 12.33s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  23%|██▎       | 27/116 [05:31<17:32, 11.83s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  23%|██▎       | 27/116 [05:44<17:32, 11.83s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  24%|██▍       | 28/116 [05:44<17:49, 12.15s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  24%|██▍       | 28/116 [05:57<17:49, 12.15s/it, training_loss=0.559]\u001b[A\n","Epoch 1:  25%|██▌       | 29/116 [05:57<17:58, 12.40s/it, training_loss=0.559]\u001b[A\n","Epoch 1:  25%|██▌       | 29/116 [06:07<17:58, 12.40s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  26%|██▌       | 30/116 [06:07<17:03, 11.91s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  26%|██▌       | 30/116 [06:19<17:03, 11.91s/it, training_loss=0.507]\u001b[A\n","Epoch 1:  27%|██▋       | 31/116 [06:19<16:48, 11.87s/it, training_loss=0.507]\u001b[A\n","Epoch 1:  27%|██▋       | 31/116 [06:32<16:48, 11.87s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  28%|██▊       | 32/116 [06:32<16:59, 12.13s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  28%|██▊       | 32/116 [06:44<16:59, 12.13s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  28%|██▊       | 33/116 [06:44<16:47, 12.13s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  28%|██▊       | 33/116 [06:55<16:47, 12.13s/it, training_loss=0.597]\u001b[A\n","Epoch 1:  29%|██▉       | 34/116 [06:55<16:04, 11.77s/it, training_loss=0.597]\u001b[A\n","Epoch 1:  29%|██▉       | 34/116 [07:08<16:04, 11.77s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  30%|███       | 35/116 [07:08<16:22, 12.13s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  30%|███       | 35/116 [07:21<16:22, 12.13s/it, training_loss=0.528]\u001b[A\n","Epoch 1:  31%|███       | 36/116 [07:21<16:34, 12.44s/it, training_loss=0.528]\u001b[A\n","Epoch 1:  31%|███       | 36/116 [07:33<16:34, 12.44s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  32%|███▏      | 37/116 [07:33<16:08, 12.26s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  32%|███▏      | 37/116 [07:45<16:08, 12.26s/it, training_loss=0.529]\u001b[A\n","Epoch 1:  33%|███▎      | 38/116 [07:45<15:48, 12.17s/it, training_loss=0.529]\u001b[A\n","Epoch 1:  33%|███▎      | 38/116 [07:58<15:48, 12.17s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  34%|███▎      | 39/116 [07:58<15:55, 12.41s/it, training_loss=0.613]\u001b[A\n","Epoch 1:  34%|███▎      | 39/116 [08:11<15:55, 12.41s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  34%|███▍      | 40/116 [08:11<15:51, 12.52s/it, training_loss=0.531]\u001b[A\n","Epoch 1:  34%|███▍      | 40/116 [08:21<15:51, 12.52s/it, training_loss=0.557]\u001b[A\n","Epoch 1:  35%|███▌      | 41/116 [08:21<14:53, 11.91s/it, training_loss=0.557]\u001b[A\n","Epoch 1:  35%|███▌      | 41/116 [08:34<14:53, 11.91s/it, training_loss=0.525]\u001b[A\n","Epoch 1:  36%|███▌      | 42/116 [08:34<15:05, 12.24s/it, training_loss=0.525]\u001b[A\n","Epoch 1:  36%|███▌      | 42/116 [08:47<15:05, 12.24s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  37%|███▋      | 43/116 [08:47<15:10, 12.48s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  37%|███▋      | 43/116 [08:59<15:10, 12.48s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  38%|███▊      | 44/116 [08:59<14:35, 12.16s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  38%|███▊      | 44/116 [09:10<14:35, 12.16s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  39%|███▉      | 45/116 [09:10<14:07, 11.94s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  39%|███▉      | 45/116 [09:23<14:07, 11.94s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  40%|███▉      | 46/116 [09:23<14:20, 12.29s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  40%|███▉      | 46/116 [09:36<14:20, 12.29s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  41%|████      | 47/116 [09:36<14:20, 12.47s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  41%|████      | 47/116 [09:46<14:20, 12.47s/it, training_loss=0.408]\u001b[A\n","Epoch 1:  41%|████▏     | 48/116 [09:46<13:25, 11.84s/it, training_loss=0.408]\u001b[A\n","Epoch 1:  41%|████▏     | 48/116 [09:59<13:25, 11.84s/it, training_loss=0.566]\u001b[A\n","Epoch 1:  42%|████▏     | 49/116 [09:59<13:31, 12.12s/it, training_loss=0.566]\u001b[A\n","Epoch 1:  42%|████▏     | 49/116 [10:12<13:31, 12.12s/it, training_loss=0.633]\u001b[A\n","Epoch 1:  43%|████▎     | 50/116 [10:12<13:38, 12.41s/it, training_loss=0.633]\u001b[A\n","Epoch 1:  43%|████▎     | 50/116 [10:24<13:38, 12.41s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  44%|████▍     | 51/116 [10:24<13:14, 12.22s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  44%|████▍     | 51/116 [10:35<13:14, 12.22s/it, training_loss=0.579]\u001b[A\n","Epoch 1:  45%|████▍     | 52/116 [10:35<12:41, 11.89s/it, training_loss=0.579]\u001b[A\n","Epoch 1:  45%|████▍     | 52/116 [10:48<12:41, 11.89s/it, training_loss=0.626]\u001b[A\n","Epoch 1:  46%|████▌     | 53/116 [10:48<12:52, 12.27s/it, training_loss=0.626]\u001b[A\n","Epoch 1:  46%|████▌     | 53/116 [11:01<12:52, 12.27s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  47%|████▋     | 54/116 [11:01<12:57, 12.54s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  47%|████▋     | 54/116 [11:12<12:57, 12.54s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  47%|████▋     | 55/116 [11:12<12:14, 12.04s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  47%|████▋     | 55/116 [11:25<12:14, 12.04s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  48%|████▊     | 56/116 [11:25<12:05, 12.09s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  48%|████▊     | 56/116 [11:37<12:05, 12.09s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  49%|████▉     | 57/116 [11:37<12:08, 12.35s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  49%|████▉     | 57/116 [11:50<12:08, 12.35s/it, training_loss=0.485]\u001b[A\n","Epoch 1:  50%|█████     | 58/116 [11:50<11:55, 12.33s/it, training_loss=0.485]\u001b[A\n","Epoch 1:  50%|█████     | 58/116 [12:01<11:55, 12.33s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  51%|█████     | 59/116 [12:01<11:16, 11.87s/it, training_loss=0.511]\u001b[A\n","Epoch 1:  51%|█████     | 59/116 [12:13<11:16, 11.87s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  52%|█████▏    | 60/116 [12:13<11:22, 12.19s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  52%|█████▏    | 60/116 [12:26<11:22, 12.19s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  53%|█████▎    | 61/116 [12:27<11:24, 12.44s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  53%|█████▎    | 61/116 [12:37<11:24, 12.44s/it, training_loss=0.539]\u001b[A\n","Epoch 1:  53%|█████▎    | 62/116 [12:37<10:46, 11.97s/it, training_loss=0.539]\u001b[A\n","Epoch 1:  53%|█████▎    | 62/116 [12:50<10:46, 11.97s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  54%|█████▍    | 63/116 [12:50<10:39, 12.06s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  54%|█████▍    | 63/116 [13:03<10:39, 12.06s/it, training_loss=0.655]\u001b[A\n","Epoch 1:  55%|█████▌    | 64/116 [13:03<10:42, 12.35s/it, training_loss=0.655]\u001b[A\n","Epoch 1:  55%|█████▌    | 64/116 [13:15<10:42, 12.35s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  56%|█████▌    | 65/116 [13:15<10:32, 12.40s/it, training_loss=0.603]\u001b[A\n","Epoch 1:  56%|█████▌    | 65/116 [13:26<10:32, 12.40s/it, training_loss=0.720]\u001b[A\n","Epoch 1:  57%|█████▋    | 66/116 [13:26<09:55, 11.92s/it, training_loss=0.720]\u001b[A\n","Epoch 1:  57%|█████▋    | 66/116 [13:39<09:55, 11.92s/it, training_loss=0.653]\u001b[A\n","Epoch 1:  58%|█████▊    | 67/116 [13:39<09:58, 12.22s/it, training_loss=0.653]\u001b[A\n","Epoch 1:  58%|█████▊    | 67/116 [13:52<09:58, 12.22s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  59%|█████▊    | 68/116 [13:52<09:57, 12.45s/it, training_loss=0.591]\u001b[A\n","Epoch 1:  59%|█████▊    | 68/116 [14:03<09:57, 12.45s/it, training_loss=0.536]\u001b[A\n","Epoch 1:  59%|█████▉    | 69/116 [14:03<09:23, 12.00s/it, training_loss=0.536]\u001b[A\n","Epoch 1:  59%|█████▉    | 69/116 [14:15<09:23, 12.00s/it, training_loss=0.566]\u001b[A\n","Epoch 1:  60%|██████    | 70/116 [14:15<09:10, 11.98s/it, training_loss=0.566]\u001b[A\n","Epoch 1:  60%|██████    | 70/116 [14:28<09:10, 11.98s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  61%|██████    | 71/116 [14:28<09:13, 12.29s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  61%|██████    | 71/116 [14:40<09:13, 12.29s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  62%|██████▏   | 72/116 [14:40<09:06, 12.42s/it, training_loss=0.513]\u001b[A\n","Epoch 1:  62%|██████▏   | 72/116 [14:51<09:06, 12.42s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  63%|██████▎   | 73/116 [14:51<08:30, 11.88s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  63%|██████▎   | 73/116 [15:04<08:30, 11.88s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  64%|██████▍   | 74/116 [15:04<08:34, 12.25s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  64%|██████▍   | 74/116 [15:17<08:34, 12.25s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  65%|██████▍   | 75/116 [15:17<08:32, 12.49s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  65%|██████▍   | 75/116 [15:29<08:32, 12.49s/it, training_loss=0.585]\u001b[A\n","Epoch 1:  66%|██████▌   | 76/116 [15:29<08:05, 12.14s/it, training_loss=0.585]\u001b[A\n","Epoch 1:  66%|██████▌   | 76/116 [15:40<08:05, 12.14s/it, training_loss=0.612]\u001b[A\n","Epoch 1:  66%|██████▋   | 77/116 [15:40<07:45, 11.94s/it, training_loss=0.612]\u001b[A\n","Epoch 1:  66%|██████▋   | 77/116 [15:53<07:45, 11.94s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  67%|██████▋   | 78/116 [15:53<07:46, 12.27s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  67%|██████▋   | 78/116 [16:06<07:46, 12.27s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  68%|██████▊   | 79/116 [16:06<07:38, 12.40s/it, training_loss=0.625]\u001b[A\n","Epoch 1:  68%|██████▊   | 79/116 [16:16<07:38, 12.40s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  69%|██████▉   | 80/116 [16:16<07:04, 11.80s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  69%|██████▉   | 80/116 [16:29<07:04, 11.80s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  70%|██████▉   | 81/116 [16:29<07:05, 12.14s/it, training_loss=0.572]\u001b[A\n","Epoch 1:  70%|██████▉   | 81/116 [16:42<07:05, 12.14s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  71%|███████   | 82/116 [16:42<07:02, 12.42s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  71%|███████   | 82/116 [16:54<07:02, 12.42s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  72%|███████▏  | 83/116 [16:54<06:39, 12.12s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  72%|███████▏  | 83/116 [17:05<06:39, 12.12s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  72%|███████▏  | 84/116 [17:05<06:22, 11.95s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  72%|███████▏  | 84/116 [17:18<06:22, 11.95s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  73%|███████▎  | 85/116 [17:18<06:21, 12.29s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  73%|███████▎  | 85/116 [17:31<06:21, 12.29s/it, training_loss=0.495]\u001b[A\n","Epoch 1:  74%|███████▍  | 86/116 [17:31<06:15, 12.51s/it, training_loss=0.495]\u001b[A\n","Epoch 1:  74%|███████▍  | 86/116 [17:42<06:15, 12.51s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  75%|███████▌  | 87/116 [17:42<05:45, 11.92s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  75%|███████▌  | 87/116 [17:54<05:45, 11.92s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  76%|███████▌  | 88/116 [17:54<05:38, 12.10s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  76%|███████▌  | 88/116 [18:07<05:38, 12.10s/it, training_loss=0.495]\u001b[A\n","Epoch 1:  77%|███████▋  | 89/116 [18:07<05:34, 12.37s/it, training_loss=0.495]\u001b[A\n","Epoch 1:  77%|███████▋  | 89/116 [18:19<05:34, 12.37s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  78%|███████▊  | 90/116 [18:19<05:18, 12.24s/it, training_loss=0.575]\u001b[A\n","Epoch 1:  78%|███████▊  | 90/116 [18:30<05:18, 12.24s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  78%|███████▊  | 91/116 [18:30<04:57, 11.90s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  78%|███████▊  | 91/116 [18:43<04:57, 11.90s/it, training_loss=0.470]\u001b[A\n","Epoch 1:  79%|███████▉  | 92/116 [18:43<04:53, 12.24s/it, training_loss=0.470]\u001b[A\n","Epoch 1:  79%|███████▉  | 92/116 [18:56<04:53, 12.24s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  80%|████████  | 93/116 [18:56<04:46, 12.47s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  80%|████████  | 93/116 [19:07<04:46, 12.47s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  81%|████████  | 94/116 [19:07<04:21, 11.89s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  81%|████████  | 94/116 [19:19<04:21, 11.89s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  82%|████████▏ | 95/116 [19:19<04:13, 12.06s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  82%|████████▏ | 95/116 [19:32<04:13, 12.06s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  83%|████████▎ | 96/116 [19:32<04:06, 12.33s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  83%|████████▎ | 96/116 [19:44<04:06, 12.33s/it, training_loss=0.630]\u001b[A\n","Epoch 1:  84%|████████▎ | 97/116 [19:44<03:52, 12.25s/it, training_loss=0.630]\u001b[A\n","Epoch 1:  84%|████████▎ | 97/116 [19:55<03:52, 12.25s/it, training_loss=0.559]\u001b[A\n","Epoch 1:  84%|████████▍ | 98/116 [19:55<03:32, 11.83s/it, training_loss=0.559]\u001b[A\n","Epoch 1:  84%|████████▍ | 98/116 [20:08<03:32, 11.83s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  85%|████████▌ | 99/116 [20:08<03:24, 12.04s/it, training_loss=0.622]\u001b[A\n","Epoch 1:  85%|████████▌ | 99/116 [20:20<03:24, 12.04s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  86%|████████▌ | 100/116 [20:20<03:15, 12.22s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  86%|████████▌ | 100/116 [20:32<03:15, 12.22s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  87%|████████▋ | 101/116 [20:32<03:01, 12.13s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  87%|████████▋ | 101/116 [20:43<03:01, 12.13s/it, training_loss=0.498]\u001b[A\n","Epoch 1:  88%|████████▊ | 102/116 [20:43<02:44, 11.72s/it, training_loss=0.498]\u001b[A\n","Epoch 1:  88%|████████▊ | 102/116 [20:56<02:44, 11.72s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  89%|████████▉ | 103/116 [20:56<02:36, 12.00s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  89%|████████▉ | 103/116 [21:09<02:36, 12.00s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  90%|████████▉ | 104/116 [21:09<02:26, 12.21s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  90%|████████▉ | 104/116 [21:20<02:26, 12.21s/it, training_loss=0.496]\u001b[A\n","Epoch 1:  91%|█████████ | 105/116 [21:20<02:13, 12.10s/it, training_loss=0.496]\u001b[A\n","Epoch 1:  91%|█████████ | 105/116 [21:31<02:13, 12.10s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  91%|█████████▏| 106/116 [21:31<01:57, 11.72s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  91%|█████████▏| 106/116 [21:44<01:57, 11.72s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  92%|█████████▏| 107/116 [21:44<01:47, 11.98s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  92%|█████████▏| 107/116 [21:56<01:47, 11.98s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  93%|█████████▎| 108/116 [21:56<01:37, 12.16s/it, training_loss=0.573]\u001b[A\n","Epoch 1:  93%|█████████▎| 108/116 [22:08<01:37, 12.16s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  94%|█████████▍| 109/116 [22:08<01:23, 11.97s/it, training_loss=0.488]\u001b[A\n","Epoch 1:  94%|█████████▍| 109/116 [22:19<01:23, 11.97s/it, training_loss=0.614]\u001b[A\n","Epoch 1:  95%|█████████▍| 110/116 [22:19<01:09, 11.66s/it, training_loss=0.614]\u001b[A\n","Epoch 1:  95%|█████████▍| 110/116 [22:31<01:09, 11.66s/it, training_loss=0.604]\u001b[A\n","Epoch 1:  96%|█████████▌| 111/116 [22:31<00:59, 11.89s/it, training_loss=0.604]\u001b[A\n","Epoch 1:  96%|█████████▌| 111/116 [22:44<00:59, 11.89s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  97%|█████████▋| 112/116 [22:44<00:48, 12.09s/it, training_loss=0.552]\u001b[A\n","Epoch 1:  97%|█████████▋| 112/116 [22:56<00:48, 12.09s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  97%|█████████▋| 113/116 [22:56<00:36, 12.02s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  97%|█████████▋| 113/116 [23:08<00:36, 12.02s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  98%|█████████▊| 114/116 [23:08<00:23, 11.99s/it, training_loss=0.500]\u001b[A\n","Epoch 1:  98%|█████████▊| 114/116 [23:20<00:23, 11.99s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  99%|█████████▉| 115/116 [23:20<00:12, 12.19s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  99%|█████████▉| 115/116 [23:26<00:12, 12.19s/it, training_loss=0.460]\u001b[A\n","Epoch 1: 100%|██████████| 116/116 [23:26<00:00, 10.34s/it, training_loss=0.460]\u001b[A\n","  0%|          | 0/4 [23:29<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.713089325304689\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [25:19<1:15:57, 1519.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6440618736990567\n","F1 Score (Weighted): 0.08928352725045927\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/116 [00:12<?, ?it/s, training_loss=0.537]\u001b[A\n","Epoch 2:   1%|          | 1/116 [00:12<24:28, 12.77s/it, training_loss=0.537]\u001b[A\n","Epoch 2:   1%|          | 1/116 [00:25<24:28, 12.77s/it, training_loss=0.511]\u001b[A\n","Epoch 2:   2%|▏         | 2/116 [00:25<24:06, 12.69s/it, training_loss=0.511]\u001b[A\n","Epoch 2:   2%|▏         | 2/116 [00:36<24:06, 12.69s/it, training_loss=0.531]\u001b[A\n","Epoch 2:   3%|▎         | 3/116 [00:36<22:36, 12.00s/it, training_loss=0.531]\u001b[A\n","Epoch 2:   3%|▎         | 3/116 [00:47<22:36, 12.00s/it, training_loss=0.561]\u001b[A\n","Epoch 2:   3%|▎         | 4/116 [00:47<21:53, 11.73s/it, training_loss=0.561]\u001b[A\n","Epoch 2:   3%|▎         | 4/116 [01:00<21:53, 11.73s/it, training_loss=0.570]\u001b[A\n","Epoch 2:   4%|▍         | 5/116 [01:00<22:14, 12.03s/it, training_loss=0.570]\u001b[A\n","Epoch 2:   4%|▍         | 5/116 [01:12<22:14, 12.03s/it, training_loss=0.619]\u001b[A\n","Epoch 2:   5%|▌         | 6/116 [01:12<22:22, 12.20s/it, training_loss=0.619]\u001b[A\n","Epoch 2:   5%|▌         | 6/116 [01:24<22:22, 12.20s/it, training_loss=0.511]\u001b[A\n","Epoch 2:   6%|▌         | 7/116 [01:24<21:30, 11.84s/it, training_loss=0.511]\u001b[A\n","Epoch 2:   6%|▌         | 7/116 [01:35<21:30, 11.84s/it, training_loss=0.557]\u001b[A\n","Epoch 2:   7%|▋         | 8/116 [01:35<21:10, 11.77s/it, training_loss=0.557]\u001b[A\n","Epoch 2:   7%|▋         | 8/116 [01:48<21:10, 11.77s/it, training_loss=0.577]\u001b[A\n","Epoch 2:   8%|▊         | 9/116 [01:48<21:29, 12.05s/it, training_loss=0.577]\u001b[A\n","Epoch 2:   8%|▊         | 9/116 [02:01<21:29, 12.05s/it, training_loss=0.545]\u001b[A\n","Epoch 2:   9%|▊         | 10/116 [02:01<21:38, 12.25s/it, training_loss=0.545]\u001b[A\n","Epoch 2:   9%|▊         | 10/116 [02:12<21:38, 12.25s/it, training_loss=0.524]\u001b[A\n","Epoch 2:   9%|▉         | 11/116 [02:12<20:48, 11.89s/it, training_loss=0.524]\u001b[A\n","Epoch 2:   9%|▉         | 11/116 [02:23<20:48, 11.89s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  10%|█         | 12/116 [02:23<20:17, 11.71s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  10%|█         | 12/116 [02:36<20:17, 11.71s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  11%|█         | 13/116 [02:36<20:35, 11.99s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  11%|█         | 13/116 [02:48<20:35, 11.99s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  12%|█▏        | 14/116 [02:48<20:40, 12.16s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  12%|█▏        | 14/116 [02:59<20:40, 12.16s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  13%|█▎        | 15/116 [02:59<19:53, 11.81s/it, training_loss=0.454]\u001b[A\n","Epoch 2:  13%|█▎        | 15/116 [03:11<19:53, 11.81s/it, training_loss=0.561]\u001b[A\n","Epoch 2:  14%|█▍        | 16/116 [03:11<19:33, 11.74s/it, training_loss=0.561]\u001b[A\n","Epoch 2:  14%|█▍        | 16/116 [03:23<19:33, 11.74s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  15%|█▍        | 17/116 [03:23<19:47, 12.00s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  15%|█▍        | 17/116 [03:36<19:47, 12.00s/it, training_loss=0.551]\u001b[A\n","Epoch 2:  16%|█▌        | 18/116 [03:36<19:56, 12.21s/it, training_loss=0.551]\u001b[A\n","Epoch 2:  16%|█▌        | 18/116 [03:47<19:56, 12.21s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  16%|█▋        | 19/116 [03:47<19:11, 11.87s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  16%|█▋        | 19/116 [03:59<19:11, 11.87s/it, training_loss=0.603]\u001b[A\n","Epoch 2:  17%|█▋        | 20/116 [03:59<18:49, 11.76s/it, training_loss=0.603]\u001b[A\n","Epoch 2:  17%|█▋        | 20/116 [04:11<18:49, 11.76s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  18%|█▊        | 21/116 [04:11<19:03, 12.04s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  18%|█▊        | 21/116 [04:24<19:03, 12.04s/it, training_loss=0.587]\u001b[A\n","Epoch 2:  19%|█▉        | 22/116 [04:24<19:07, 12.21s/it, training_loss=0.587]\u001b[A\n","Epoch 2:  19%|█▉        | 22/116 [04:35<19:07, 12.21s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  20%|█▉        | 23/116 [04:35<18:20, 11.84s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  20%|█▉        | 23/116 [04:46<18:20, 11.84s/it, training_loss=0.539]\u001b[A\n","Epoch 2:  21%|██        | 24/116 [04:46<17:59, 11.73s/it, training_loss=0.539]\u001b[A\n","Epoch 2:  21%|██        | 24/116 [04:59<17:59, 11.73s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  22%|██▏       | 25/116 [04:59<18:10, 11.98s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  22%|██▏       | 25/116 [05:11<18:10, 11.98s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  22%|██▏       | 26/116 [05:11<18:14, 12.16s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  22%|██▏       | 26/116 [05:23<18:14, 12.16s/it, training_loss=0.519]\u001b[A\n","Epoch 2:  23%|██▎       | 27/116 [05:23<17:31, 11.82s/it, training_loss=0.519]\u001b[A\n","Epoch 2:  23%|██▎       | 27/116 [05:34<17:31, 11.82s/it, training_loss=0.569]\u001b[A\n","Epoch 2:  24%|██▍       | 28/116 [05:34<17:15, 11.77s/it, training_loss=0.569]\u001b[A\n","Epoch 2:  24%|██▍       | 28/116 [05:47<17:15, 11.77s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  25%|██▌       | 29/116 [05:47<17:26, 12.03s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  25%|██▌       | 29/116 [05:59<17:26, 12.03s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  26%|██▌       | 30/116 [05:59<17:31, 12.22s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  26%|██▌       | 30/116 [06:10<17:31, 12.22s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  27%|██▋       | 31/116 [06:10<16:45, 11.83s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  27%|██▋       | 31/116 [06:22<16:45, 11.83s/it, training_loss=0.512]\u001b[A\n","Epoch 2:  28%|██▊       | 32/116 [06:22<16:27, 11.76s/it, training_loss=0.512]\u001b[A\n","Epoch 2:  28%|██▊       | 32/116 [06:35<16:27, 11.76s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  28%|██▊       | 33/116 [06:35<16:36, 12.00s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  28%|██▊       | 33/116 [06:47<16:36, 12.00s/it, training_loss=0.500]\u001b[A\n","Epoch 2:  29%|██▉       | 34/116 [06:47<16:39, 12.19s/it, training_loss=0.500]\u001b[A\n","Epoch 2:  29%|██▉       | 34/116 [06:58<16:39, 12.19s/it, training_loss=0.524]\u001b[A\n","Epoch 2:  30%|███       | 35/116 [06:58<15:55, 11.80s/it, training_loss=0.524]\u001b[A\n","Epoch 2:  30%|███       | 35/116 [07:10<15:55, 11.80s/it, training_loss=0.553]\u001b[A\n","Epoch 2:  31%|███       | 36/116 [07:10<15:43, 11.79s/it, training_loss=0.553]\u001b[A\n","Epoch 2:  31%|███       | 36/116 [07:22<15:43, 11.79s/it, training_loss=0.570]\u001b[A\n","Epoch 2:  32%|███▏      | 37/116 [07:22<15:51, 12.04s/it, training_loss=0.570]\u001b[A\n","Epoch 2:  32%|███▏      | 37/116 [07:35<15:51, 12.04s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  33%|███▎      | 38/116 [07:35<15:54, 12.24s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  33%|███▎      | 38/116 [07:46<15:54, 12.24s/it, training_loss=0.549]\u001b[A\n","Epoch 2:  34%|███▎      | 39/116 [07:46<15:12, 11.85s/it, training_loss=0.549]\u001b[A\n","Epoch 2:  34%|███▎      | 39/116 [07:58<15:12, 11.85s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  34%|███▍      | 40/116 [07:58<14:56, 11.80s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  34%|███▍      | 40/116 [08:10<14:56, 11.80s/it, training_loss=0.605]\u001b[A\n","Epoch 2:  35%|███▌      | 41/116 [08:10<15:04, 12.06s/it, training_loss=0.605]\u001b[A\n","Epoch 2:  35%|███▌      | 41/116 [08:23<15:04, 12.06s/it, training_loss=0.529]\u001b[A\n","Epoch 2:  36%|███▌      | 42/116 [08:23<15:03, 12.21s/it, training_loss=0.529]\u001b[A\n","Epoch 2:  36%|███▌      | 42/116 [08:34<15:03, 12.21s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  37%|███▋      | 43/116 [08:34<14:20, 11.79s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  37%|███▋      | 43/116 [08:45<14:20, 11.79s/it, training_loss=0.607]\u001b[A\n","Epoch 2:  38%|███▊      | 44/116 [08:45<14:04, 11.73s/it, training_loss=0.607]\u001b[A\n","Epoch 2:  38%|███▊      | 44/116 [08:58<14:04, 11.73s/it, training_loss=0.484]\u001b[A\n","Epoch 2:  39%|███▉      | 45/116 [08:58<14:09, 11.96s/it, training_loss=0.484]\u001b[A\n","Epoch 2:  39%|███▉      | 45/116 [09:10<14:09, 11.96s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  40%|███▉      | 46/116 [09:10<14:08, 12.12s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  40%|███▉      | 46/116 [09:21<14:08, 12.12s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  41%|████      | 47/116 [09:21<13:23, 11.65s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  41%|████      | 47/116 [09:33<13:23, 11.65s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  41%|████▏     | 48/116 [09:33<13:20, 11.77s/it, training_loss=0.517]\u001b[A\n","Epoch 2:  41%|████▏     | 48/116 [09:46<13:20, 11.77s/it, training_loss=0.566]\u001b[A\n","Epoch 2:  42%|████▏     | 49/116 [09:46<13:26, 12.04s/it, training_loss=0.566]\u001b[A\n","Epoch 2:  42%|████▏     | 49/116 [09:58<13:26, 12.04s/it, training_loss=0.525]\u001b[A\n","Epoch 2:  43%|████▎     | 50/116 [09:58<13:26, 12.22s/it, training_loss=0.525]\u001b[A\n","Epoch 2:  43%|████▎     | 50/116 [10:09<13:26, 12.22s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  44%|████▍     | 51/116 [10:09<12:42, 11.73s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  44%|████▍     | 51/116 [10:21<12:42, 11.73s/it, training_loss=0.618]\u001b[A\n","Epoch 2:  45%|████▍     | 52/116 [10:21<12:34, 11.79s/it, training_loss=0.618]\u001b[A\n","Epoch 2:  45%|████▍     | 52/116 [10:33<12:34, 11.79s/it, training_loss=0.540]\u001b[A\n","Epoch 2:  46%|████▌     | 53/116 [10:33<12:35, 11.99s/it, training_loss=0.540]\u001b[A\n","Epoch 2:  46%|████▌     | 53/116 [10:46<12:35, 11.99s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  47%|████▋     | 54/116 [10:46<12:30, 12.11s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  47%|████▋     | 54/116 [10:56<12:30, 12.11s/it, training_loss=0.563]\u001b[A\n","Epoch 2:  47%|████▋     | 55/116 [10:56<11:45, 11.57s/it, training_loss=0.563]\u001b[A\n","Epoch 2:  47%|████▋     | 55/116 [11:08<11:45, 11.57s/it, training_loss=0.541]\u001b[A\n","Epoch 2:  48%|████▊     | 56/116 [11:09<11:51, 11.86s/it, training_loss=0.541]\u001b[A\n","Epoch 2:  48%|████▊     | 56/116 [11:21<11:51, 11.86s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  49%|████▉     | 57/116 [11:21<11:52, 12.08s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  49%|████▉     | 57/116 [11:33<11:52, 12.08s/it, training_loss=0.525]\u001b[A\n","Epoch 2:  50%|█████     | 58/116 [11:33<11:45, 12.16s/it, training_loss=0.525]\u001b[A\n","Epoch 2:  50%|█████     | 58/116 [11:44<11:45, 12.16s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  51%|█████     | 59/116 [11:44<11:01, 11.61s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  51%|█████     | 59/116 [11:56<11:01, 11.61s/it, training_loss=0.539]\u001b[A\n","Epoch 2:  52%|█████▏    | 60/116 [11:56<11:05, 11.89s/it, training_loss=0.539]\u001b[A\n","Epoch 2:  52%|█████▏    | 60/116 [12:09<11:05, 11.89s/it, training_loss=0.590]\u001b[A\n","Epoch 2:  53%|█████▎    | 61/116 [12:09<11:06, 12.12s/it, training_loss=0.590]\u001b[A\n","Epoch 2:  53%|█████▎    | 61/116 [12:21<11:06, 12.12s/it, training_loss=0.547]\u001b[A\n","Epoch 2:  53%|█████▎    | 62/116 [12:21<10:56, 12.16s/it, training_loss=0.547]\u001b[A\n","Epoch 2:  53%|█████▎    | 62/116 [12:32<10:56, 12.16s/it, training_loss=0.613]\u001b[A\n","Epoch 2:  54%|█████▍    | 63/116 [12:32<10:16, 11.62s/it, training_loss=0.613]\u001b[A\n","Epoch 2:  54%|█████▍    | 63/116 [12:44<10:16, 11.62s/it, training_loss=0.600]\u001b[A\n","Epoch 2:  55%|█████▌    | 64/116 [12:44<10:17, 11.88s/it, training_loss=0.600]\u001b[A\n","Epoch 2:  55%|█████▌    | 64/116 [12:57<10:17, 11.88s/it, training_loss=0.498]\u001b[A\n","Epoch 2:  56%|█████▌    | 65/116 [12:57<10:16, 12.10s/it, training_loss=0.498]\u001b[A\n","Epoch 2:  56%|█████▌    | 65/116 [13:09<10:16, 12.10s/it, training_loss=0.487]\u001b[A\n","Epoch 2:  57%|█████▋    | 66/116 [13:09<10:02, 12.06s/it, training_loss=0.487]\u001b[A\n","Epoch 2:  57%|█████▋    | 66/116 [13:19<10:02, 12.06s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  58%|█████▊    | 67/116 [13:19<09:30, 11.65s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  58%|█████▊    | 67/116 [13:32<09:30, 11.65s/it, training_loss=0.583]\u001b[A\n","Epoch 2:  59%|█████▊    | 68/116 [13:32<09:33, 11.95s/it, training_loss=0.583]\u001b[A\n","Epoch 2:  59%|█████▊    | 68/116 [13:45<09:33, 11.95s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  59%|█████▉    | 69/116 [13:45<09:32, 12.18s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  59%|█████▉    | 69/116 [13:57<09:32, 12.18s/it, training_loss=0.590]\u001b[A\n","Epoch 2:  60%|██████    | 70/116 [13:57<09:17, 12.13s/it, training_loss=0.590]\u001b[A\n","Epoch 2:  60%|██████    | 70/116 [14:08<09:17, 12.13s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  61%|██████    | 71/116 [14:08<08:50, 11.79s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  61%|██████    | 71/116 [14:20<08:50, 11.79s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  62%|██████▏   | 72/116 [14:20<08:49, 12.04s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  62%|██████▏   | 72/116 [14:33<08:49, 12.04s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  63%|██████▎   | 73/116 [14:33<08:45, 12.23s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  63%|██████▎   | 73/116 [14:45<08:45, 12.23s/it, training_loss=0.481]\u001b[A\n","Epoch 2:  64%|██████▍   | 74/116 [14:45<08:31, 12.18s/it, training_loss=0.481]\u001b[A\n","Epoch 2:  64%|██████▍   | 74/116 [14:56<08:31, 12.18s/it, training_loss=0.580]\u001b[A\n","Epoch 2:  65%|██████▍   | 75/116 [14:56<08:03, 11.79s/it, training_loss=0.580]\u001b[A\n","Epoch 2:  65%|██████▍   | 75/116 [15:09<08:03, 11.79s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  66%|██████▌   | 76/116 [15:09<08:02, 12.06s/it, training_loss=0.495]\u001b[A\n","Epoch 2:  66%|██████▌   | 76/116 [15:21<08:02, 12.06s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  66%|██████▋   | 77/116 [15:21<07:58, 12.26s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  66%|██████▋   | 77/116 [15:34<07:58, 12.26s/it, training_loss=0.482]\u001b[A\n","Epoch 2:  67%|██████▋   | 78/116 [15:34<07:44, 12.22s/it, training_loss=0.482]\u001b[A\n","Epoch 2:  67%|██████▋   | 78/116 [15:44<07:44, 12.22s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  68%|██████▊   | 79/116 [15:44<07:14, 11.74s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  68%|██████▊   | 79/116 [15:57<07:14, 11.74s/it, training_loss=0.582]\u001b[A\n","Epoch 2:  69%|██████▉   | 80/116 [15:57<07:11, 11.99s/it, training_loss=0.582]\u001b[A\n","Epoch 2:  69%|██████▉   | 80/116 [16:09<07:11, 11.99s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  70%|██████▉   | 81/116 [16:09<07:06, 12.18s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  70%|██████▉   | 81/116 [16:21<07:06, 12.18s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  71%|███████   | 82/116 [16:21<06:49, 12.04s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  71%|███████   | 82/116 [16:32<06:49, 12.04s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  72%|███████▏  | 83/116 [16:32<06:26, 11.70s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  72%|███████▏  | 83/116 [16:45<06:26, 11.70s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  72%|███████▏  | 84/116 [16:45<06:22, 11.96s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  72%|███████▏  | 84/116 [16:57<06:22, 11.96s/it, training_loss=0.558]\u001b[A\n","Epoch 2:  73%|███████▎  | 85/116 [16:57<06:16, 12.14s/it, training_loss=0.558]\u001b[A\n","Epoch 2:  73%|███████▎  | 85/116 [17:08<06:16, 12.14s/it, training_loss=0.481]\u001b[A\n","Epoch 2:  74%|███████▍  | 86/116 [17:08<05:57, 11.92s/it, training_loss=0.481]\u001b[A\n","Epoch 2:  74%|███████▍  | 86/116 [17:20<05:57, 11.92s/it, training_loss=0.457]\u001b[A\n","Epoch 2:  75%|███████▌  | 87/116 [17:20<05:39, 11.71s/it, training_loss=0.457]\u001b[A\n","Epoch 2:  75%|███████▌  | 87/116 [17:32<05:39, 11.71s/it, training_loss=0.570]\u001b[A\n","Epoch 2:  76%|███████▌  | 88/116 [17:32<05:36, 12.03s/it, training_loss=0.570]\u001b[A\n","Epoch 2:  76%|███████▌  | 88/116 [17:45<05:36, 12.03s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  77%|███████▋  | 89/116 [17:45<05:30, 12.25s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  77%|███████▋  | 89/116 [17:57<05:30, 12.25s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  78%|███████▊  | 90/116 [17:57<05:15, 12.15s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  78%|███████▊  | 90/116 [18:08<05:15, 12.15s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  78%|███████▊  | 91/116 [18:08<04:55, 11.81s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  78%|███████▊  | 91/116 [18:21<04:55, 11.81s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  79%|███████▉  | 92/116 [18:21<04:49, 12.05s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  79%|███████▉  | 92/116 [18:33<04:49, 12.05s/it, training_loss=0.553]\u001b[A\n","Epoch 2:  80%|████████  | 93/116 [18:33<04:41, 12.23s/it, training_loss=0.553]\u001b[A\n","Epoch 2:  80%|████████  | 93/116 [18:45<04:41, 12.23s/it, training_loss=0.549]\u001b[A\n","Epoch 2:  81%|████████  | 94/116 [18:45<04:26, 12.11s/it, training_loss=0.549]\u001b[A\n","Epoch 2:  81%|████████  | 94/116 [18:56<04:26, 12.11s/it, training_loss=0.630]\u001b[A\n","Epoch 2:  82%|████████▏ | 95/116 [18:56<04:07, 11.77s/it, training_loss=0.630]\u001b[A\n","Epoch 2:  82%|████████▏ | 95/116 [19:09<04:07, 11.77s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  83%|████████▎ | 96/116 [19:09<04:00, 12.04s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  83%|████████▎ | 96/116 [19:22<04:00, 12.04s/it, training_loss=0.515]\u001b[A\n","Epoch 2:  84%|████████▎ | 97/116 [19:22<03:52, 12.23s/it, training_loss=0.515]\u001b[A\n","Epoch 2:  84%|████████▎ | 97/116 [19:33<03:52, 12.23s/it, training_loss=0.547]\u001b[A\n","Epoch 2:  84%|████████▍ | 98/116 [19:33<03:38, 12.12s/it, training_loss=0.547]\u001b[A\n","Epoch 2:  84%|████████▍ | 98/116 [19:44<03:38, 12.12s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  85%|████████▌ | 99/116 [19:44<03:20, 11.79s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  85%|████████▌ | 99/116 [19:57<03:20, 11.79s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  86%|████████▌ | 100/116 [19:57<03:13, 12.09s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  86%|████████▌ | 100/116 [20:10<03:13, 12.09s/it, training_loss=0.579]\u001b[A\n","Epoch 2:  87%|████████▋ | 101/116 [20:10<03:04, 12.28s/it, training_loss=0.579]\u001b[A\n","Epoch 2:  87%|████████▋ | 101/116 [20:22<03:04, 12.28s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  88%|████████▊ | 102/116 [20:22<02:50, 12.18s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  88%|████████▊ | 102/116 [20:33<02:50, 12.18s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  89%|████████▉ | 103/116 [20:33<02:32, 11.74s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  89%|████████▉ | 103/116 [20:45<02:32, 11.74s/it, training_loss=0.553]\u001b[A\n","Epoch 2:  90%|████████▉ | 104/116 [20:45<02:24, 12.01s/it, training_loss=0.553]\u001b[A\n","Epoch 2:  90%|████████▉ | 104/116 [20:58<02:24, 12.01s/it, training_loss=0.520]\u001b[A\n","Epoch 2:  91%|█████████ | 105/116 [20:58<02:14, 12.24s/it, training_loss=0.520]\u001b[A\n","Epoch 2:  91%|█████████ | 105/116 [21:10<02:14, 12.24s/it, training_loss=0.543]\u001b[A\n","Epoch 2:  91%|█████████▏| 106/116 [21:10<02:01, 12.15s/it, training_loss=0.543]\u001b[A\n","Epoch 2:  91%|█████████▏| 106/116 [21:21<02:01, 12.15s/it, training_loss=0.598]\u001b[A\n","Epoch 2:  92%|█████████▏| 107/116 [21:21<01:45, 11.77s/it, training_loss=0.598]\u001b[A\n","Epoch 2:  92%|█████████▏| 107/116 [21:34<01:45, 11.77s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  93%|█████████▎| 108/116 [21:34<01:36, 12.03s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  93%|█████████▎| 108/116 [21:46<01:36, 12.03s/it, training_loss=0.528]\u001b[A\n","Epoch 2:  94%|█████████▍| 109/116 [21:46<01:25, 12.23s/it, training_loss=0.528]\u001b[A\n","Epoch 2:  94%|█████████▍| 109/116 [21:58<01:25, 12.23s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  95%|█████████▍| 110/116 [21:58<01:12, 12.15s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  95%|█████████▍| 110/116 [22:09<01:12, 12.15s/it, training_loss=0.550]\u001b[A\n","Epoch 2:  96%|█████████▌| 111/116 [22:09<00:58, 11.76s/it, training_loss=0.550]\u001b[A\n","Epoch 2:  96%|█████████▌| 111/116 [22:22<00:58, 11.76s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  97%|█████████▋| 112/116 [22:22<00:48, 12.02s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  97%|█████████▋| 112/116 [22:34<00:48, 12.02s/it, training_loss=0.591]\u001b[A\n","Epoch 2:  97%|█████████▋| 113/116 [22:34<00:36, 12.20s/it, training_loss=0.591]\u001b[A\n","Epoch 2:  97%|█████████▋| 113/116 [22:46<00:36, 12.20s/it, training_loss=0.558]\u001b[A\n","Epoch 2:  98%|█████████▊| 114/116 [22:46<00:24, 12.08s/it, training_loss=0.558]\u001b[A\n","Epoch 2:  98%|█████████▊| 114/116 [22:57<00:24, 12.08s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  99%|█████████▉| 115/116 [22:57<00:11, 11.75s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  99%|█████████▉| 115/116 [23:06<00:11, 11.75s/it, training_loss=0.527]\u001b[A\n","Epoch 2: 100%|██████████| 116/116 [23:06<00:00, 11.04s/it, training_loss=0.527]\u001b[A\n"," 25%|██▌       | 1/4 [48:28<1:15:57, 1519.16s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.6353076285329358\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [50:17<50:14, 1507.04s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6469409054723279\n","F1 Score (Weighted): 0.02642399730367375\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/116 [00:10<?, ?it/s, training_loss=0.494]\u001b[A\n","Epoch 3:   1%|          | 1/116 [00:10<20:11, 10.54s/it, training_loss=0.494]\u001b[A\n","Epoch 3:   1%|          | 1/116 [00:22<20:11, 10.54s/it, training_loss=0.555]\u001b[A\n","Epoch 3:   2%|▏         | 2/116 [00:22<22:08, 11.65s/it, training_loss=0.555]\u001b[A\n","Epoch 3:   2%|▏         | 2/116 [00:35<22:08, 11.65s/it, training_loss=0.558]\u001b[A\n","Epoch 3:   3%|▎         | 3/116 [00:35<22:51, 12.13s/it, training_loss=0.558]\u001b[A\n","Epoch 3:   3%|▎         | 3/116 [00:48<22:51, 12.13s/it, training_loss=0.558]\u001b[A\n","Epoch 3:   3%|▎         | 4/116 [00:48<23:02, 12.35s/it, training_loss=0.558]\u001b[A\n","Epoch 3:   3%|▎         | 4/116 [00:58<23:02, 12.35s/it, training_loss=0.491]\u001b[A\n","Epoch 3:   4%|▍         | 5/116 [00:58<21:41, 11.72s/it, training_loss=0.491]\u001b[A\n","Epoch 3:   4%|▍         | 5/116 [01:11<21:41, 11.72s/it, training_loss=0.544]\u001b[A\n","Epoch 3:   5%|▌         | 6/116 [01:11<21:50, 11.92s/it, training_loss=0.544]\u001b[A\n","Epoch 3:   5%|▌         | 6/116 [01:23<21:50, 11.92s/it, training_loss=0.497]\u001b[A\n","Epoch 3:   6%|▌         | 7/116 [01:23<22:06, 12.17s/it, training_loss=0.497]\u001b[A\n","Epoch 3:   6%|▌         | 7/116 [01:36<22:06, 12.17s/it, training_loss=0.549]\u001b[A\n","Epoch 3:   7%|▋         | 8/116 [01:36<22:09, 12.31s/it, training_loss=0.549]\u001b[A\n","Epoch 3:   7%|▋         | 8/116 [01:47<22:09, 12.31s/it, training_loss=0.537]\u001b[A\n","Epoch 3:   8%|▊         | 9/116 [01:47<20:55, 11.73s/it, training_loss=0.537]\u001b[A\n","Epoch 3:   8%|▊         | 9/116 [01:59<20:55, 11.73s/it, training_loss=0.479]\u001b[A\n","Epoch 3:   9%|▊         | 10/116 [01:59<21:00, 11.89s/it, training_loss=0.479]\u001b[A\n","Epoch 3:   9%|▊         | 10/116 [02:11<21:00, 11.89s/it, training_loss=0.528]\u001b[A\n","Epoch 3:   9%|▉         | 11/116 [02:11<21:14, 12.13s/it, training_loss=0.528]\u001b[A\n","Epoch 3:   9%|▉         | 11/116 [02:24<21:14, 12.13s/it, training_loss=0.591]\u001b[A\n","Epoch 3:  10%|█         | 12/116 [02:24<21:18, 12.29s/it, training_loss=0.591]\u001b[A\n","Epoch 3:  10%|█         | 12/116 [02:35<21:18, 12.29s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  11%|█         | 13/116 [02:35<20:10, 11.75s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  11%|█         | 13/116 [02:47<20:10, 11.75s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  12%|█▏        | 14/116 [02:47<20:09, 11.86s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  12%|█▏        | 14/116 [02:59<20:09, 11.86s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  13%|█▎        | 15/116 [03:00<20:25, 12.14s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  13%|█▎        | 15/116 [03:12<20:25, 12.14s/it, training_loss=0.522]\u001b[A\n","Epoch 3:  14%|█▍        | 16/116 [03:12<20:26, 12.27s/it, training_loss=0.522]\u001b[A\n","Epoch 3:  14%|█▍        | 16/116 [03:23<20:26, 12.27s/it, training_loss=0.487]\u001b[A\n","Epoch 3:  15%|█▍        | 17/116 [03:23<19:23, 11.75s/it, training_loss=0.487]\u001b[A\n","Epoch 3:  15%|█▍        | 17/116 [03:35<19:23, 11.75s/it, training_loss=0.629]\u001b[A\n","Epoch 3:  16%|█▌        | 18/116 [03:35<19:23, 11.87s/it, training_loss=0.629]\u001b[A\n","Epoch 3:  16%|█▌        | 18/116 [03:47<19:23, 11.87s/it, training_loss=0.514]\u001b[A\n","Epoch 3:  16%|█▋        | 19/116 [03:47<19:31, 12.08s/it, training_loss=0.514]\u001b[A\n","Epoch 3:  16%|█▋        | 19/116 [04:00<19:31, 12.08s/it, training_loss=0.493]\u001b[A\n","Epoch 3:  17%|█▋        | 20/116 [04:00<19:32, 12.21s/it, training_loss=0.493]\u001b[A\n","Epoch 3:  17%|█▋        | 20/116 [04:10<19:32, 12.21s/it, training_loss=0.562]\u001b[A\n","Epoch 3:  18%|█▊        | 21/116 [04:10<18:31, 11.70s/it, training_loss=0.562]\u001b[A\n","Epoch 3:  18%|█▊        | 21/116 [04:23<18:31, 11.70s/it, training_loss=0.537]\u001b[A\n","Epoch 3:  19%|█▉        | 22/116 [04:23<18:35, 11.86s/it, training_loss=0.537]\u001b[A\n","Epoch 3:  19%|█▉        | 22/116 [04:35<18:35, 11.86s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  20%|█▉        | 23/116 [04:35<18:46, 12.11s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  20%|█▉        | 23/116 [04:48<18:46, 12.11s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  21%|██        | 24/116 [04:48<18:48, 12.26s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  21%|██        | 24/116 [04:58<18:48, 12.26s/it, training_loss=0.498]\u001b[A\n","Epoch 3:  22%|██▏       | 25/116 [04:58<17:49, 11.75s/it, training_loss=0.498]\u001b[A\n","Epoch 3:  22%|██▏       | 25/116 [05:11<17:49, 11.75s/it, training_loss=0.528]\u001b[A\n","Epoch 3:  22%|██▏       | 26/116 [05:11<17:47, 11.86s/it, training_loss=0.528]\u001b[A\n","Epoch 3:  22%|██▏       | 26/116 [05:23<17:47, 11.86s/it, training_loss=0.530]\u001b[A\n","Epoch 3:  23%|██▎       | 27/116 [05:23<17:53, 12.06s/it, training_loss=0.530]\u001b[A\n","Epoch 3:  23%|██▎       | 27/116 [05:36<17:53, 12.06s/it, training_loss=0.615]\u001b[A\n","Epoch 3:  24%|██▍       | 28/116 [05:36<17:50, 12.16s/it, training_loss=0.615]\u001b[A\n","Epoch 3:  24%|██▍       | 28/116 [05:46<17:50, 12.16s/it, training_loss=0.655]\u001b[A\n","Epoch 3:  25%|██▌       | 29/116 [05:46<16:47, 11.58s/it, training_loss=0.655]\u001b[A\n","Epoch 3:  25%|██▌       | 29/116 [05:58<16:47, 11.58s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  26%|██▌       | 30/116 [05:58<16:59, 11.85s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  26%|██▌       | 30/116 [06:11<16:59, 11.85s/it, training_loss=0.543]\u001b[A\n","Epoch 3:  27%|██▋       | 31/116 [06:11<17:09, 12.11s/it, training_loss=0.543]\u001b[A\n","Epoch 3:  27%|██▋       | 31/116 [06:23<17:09, 12.11s/it, training_loss=0.581]\u001b[A\n","Epoch 3:  28%|██▊       | 32/116 [06:23<17:02, 12.17s/it, training_loss=0.581]\u001b[A\n","Epoch 3:  28%|██▊       | 32/116 [06:34<17:02, 12.17s/it, training_loss=0.586]\u001b[A\n","Epoch 3:  28%|██▊       | 33/116 [06:34<16:10, 11.69s/it, training_loss=0.586]\u001b[A\n","Epoch 3:  28%|██▊       | 33/116 [06:46<16:10, 11.69s/it, training_loss=0.522]\u001b[A\n","Epoch 3:  29%|██▉       | 34/116 [06:46<16:21, 11.96s/it, training_loss=0.522]\u001b[A\n","Epoch 3:  29%|██▉       | 34/116 [06:59<16:21, 11.96s/it, training_loss=0.529]\u001b[A\n","Epoch 3:  30%|███       | 35/116 [06:59<16:26, 12.18s/it, training_loss=0.529]\u001b[A\n","Epoch 3:  30%|███       | 35/116 [07:11<16:26, 12.18s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  31%|███       | 36/116 [07:11<16:16, 12.20s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  31%|███       | 36/116 [07:22<16:16, 12.20s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  32%|███▏      | 37/116 [07:22<15:24, 11.70s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  32%|███▏      | 37/116 [07:34<15:24, 11.70s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  33%|███▎      | 38/116 [07:34<15:33, 11.97s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  33%|███▎      | 38/116 [07:47<15:33, 11.97s/it, training_loss=0.500]\u001b[A\n","Epoch 3:  34%|███▎      | 39/116 [07:47<15:36, 12.17s/it, training_loss=0.500]\u001b[A\n","Epoch 3:  34%|███▎      | 39/116 [07:59<15:36, 12.17s/it, training_loss=0.519]\u001b[A\n","Epoch 3:  34%|███▍      | 40/116 [07:59<15:25, 12.18s/it, training_loss=0.519]\u001b[A\n","Epoch 3:  34%|███▍      | 40/116 [08:10<15:25, 12.18s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  35%|███▌      | 41/116 [08:10<14:35, 11.67s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  35%|███▌      | 41/116 [08:22<14:35, 11.67s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  36%|███▌      | 42/116 [08:22<14:45, 11.96s/it, training_loss=0.505]\u001b[A\n","Epoch 3:  36%|███▌      | 42/116 [08:35<14:45, 11.96s/it, training_loss=0.543]\u001b[A\n","Epoch 3:  37%|███▋      | 43/116 [08:35<14:50, 12.21s/it, training_loss=0.543]\u001b[A\n","Epoch 3:  37%|███▋      | 43/116 [08:47<14:50, 12.21s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  38%|███▊      | 44/116 [08:47<14:40, 12.23s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  38%|███▊      | 44/116 [08:58<14:40, 12.23s/it, training_loss=0.531]\u001b[A\n","Epoch 3:  39%|███▉      | 45/116 [08:58<13:55, 11.76s/it, training_loss=0.531]\u001b[A\n","Epoch 3:  39%|███▉      | 45/116 [09:11<13:55, 11.76s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  40%|███▉      | 46/116 [09:11<14:00, 12.01s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  40%|███▉      | 46/116 [09:23<14:00, 12.01s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  41%|████      | 47/116 [09:23<14:01, 12.19s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  41%|████      | 47/116 [09:36<14:01, 12.19s/it, training_loss=0.523]\u001b[A\n","Epoch 3:  41%|████▏     | 48/116 [09:36<13:50, 12.21s/it, training_loss=0.523]\u001b[A\n","Epoch 3:  41%|████▏     | 48/116 [09:46<13:50, 12.21s/it, training_loss=0.558]\u001b[A\n","Epoch 3:  42%|████▏     | 49/116 [09:46<13:04, 11.71s/it, training_loss=0.558]\u001b[A\n","Epoch 3:  42%|████▏     | 49/116 [09:59<13:04, 11.71s/it, training_loss=0.568]\u001b[A\n","Epoch 3:  43%|████▎     | 50/116 [09:59<13:09, 11.96s/it, training_loss=0.568]\u001b[A\n","Epoch 3:  43%|████▎     | 50/116 [10:11<13:09, 11.96s/it, training_loss=0.550]\u001b[A\n","Epoch 3:  44%|████▍     | 51/116 [10:11<13:11, 12.18s/it, training_loss=0.550]\u001b[A\n","Epoch 3:  44%|████▍     | 51/116 [10:24<13:11, 12.18s/it, training_loss=0.472]\u001b[A\n","Epoch 3:  45%|████▍     | 52/116 [10:24<12:59, 12.18s/it, training_loss=0.472]\u001b[A\n","Epoch 3:  45%|████▍     | 52/116 [10:34<12:59, 12.18s/it, training_loss=0.665]\u001b[A\n","Epoch 3:  46%|████▌     | 53/116 [10:34<12:20, 11.76s/it, training_loss=0.665]\u001b[A\n","Epoch 3:  46%|████▌     | 53/116 [10:47<12:20, 11.76s/it, training_loss=0.543]\u001b[A\n","Epoch 3:  47%|████▋     | 54/116 [10:47<12:24, 12.01s/it, training_loss=0.543]\u001b[A\n","Epoch 3:  47%|████▋     | 54/116 [11:00<12:24, 12.01s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  47%|████▋     | 55/116 [11:00<12:25, 12.22s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  47%|████▋     | 55/116 [11:12<12:25, 12.22s/it, training_loss=0.456]\u001b[A\n","Epoch 3:  48%|████▊     | 56/116 [11:12<12:13, 12.23s/it, training_loss=0.456]\u001b[A\n","Epoch 3:  48%|████▊     | 56/116 [11:22<12:13, 12.23s/it, training_loss=0.603]\u001b[A\n","Epoch 3:  49%|████▉     | 57/116 [11:22<11:31, 11.72s/it, training_loss=0.603]\u001b[A\n","Epoch 3:  49%|████▉     | 57/116 [11:35<11:31, 11.72s/it, training_loss=0.596]\u001b[A\n","Epoch 3:  50%|█████     | 58/116 [11:35<11:34, 11.98s/it, training_loss=0.596]\u001b[A\n","Epoch 3:  50%|█████     | 58/116 [11:48<11:34, 11.98s/it, training_loss=0.626]\u001b[A\n","Epoch 3:  51%|█████     | 59/116 [11:48<11:34, 12.18s/it, training_loss=0.626]\u001b[A\n","Epoch 3:  51%|█████     | 59/116 [12:00<11:34, 12.18s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  52%|█████▏    | 60/116 [12:00<11:19, 12.13s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  52%|█████▏    | 60/116 [12:11<11:19, 12.13s/it, training_loss=0.608]\u001b[A\n","Epoch 3:  53%|█████▎    | 61/116 [12:11<10:45, 11.74s/it, training_loss=0.608]\u001b[A\n","Epoch 3:  53%|█████▎    | 61/116 [12:23<10:45, 11.74s/it, training_loss=0.481]\u001b[A\n","Epoch 3:  53%|█████▎    | 62/116 [12:23<10:49, 12.03s/it, training_loss=0.481]\u001b[A\n","Epoch 3:  53%|█████▎    | 62/116 [12:36<10:49, 12.03s/it, training_loss=0.476]\u001b[A\n","Epoch 3:  54%|█████▍    | 63/116 [12:36<10:50, 12.27s/it, training_loss=0.476]\u001b[A\n","Epoch 3:  54%|█████▍    | 63/116 [12:48<10:50, 12.27s/it, training_loss=0.559]\u001b[A\n","Epoch 3:  55%|█████▌    | 64/116 [12:48<10:37, 12.26s/it, training_loss=0.559]\u001b[A\n","Epoch 3:  55%|█████▌    | 64/116 [12:59<10:37, 12.26s/it, training_loss=0.512]\u001b[A\n","Epoch 3:  56%|█████▌    | 65/116 [12:59<10:01, 11.80s/it, training_loss=0.512]\u001b[A\n","Epoch 3:  56%|█████▌    | 65/116 [13:12<10:01, 11.80s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  57%|█████▋    | 66/116 [13:12<10:02, 12.06s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  57%|█████▋    | 66/116 [13:24<10:02, 12.06s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  58%|█████▊    | 67/116 [13:24<09:58, 12.22s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  58%|█████▊    | 67/116 [13:36<09:58, 12.22s/it, training_loss=0.501]\u001b[A\n","Epoch 3:  59%|█████▊    | 68/116 [13:36<09:43, 12.16s/it, training_loss=0.501]\u001b[A\n","Epoch 3:  59%|█████▊    | 68/116 [13:47<09:43, 12.16s/it, training_loss=0.555]\u001b[A\n","Epoch 3:  59%|█████▉    | 69/116 [13:47<09:10, 11.71s/it, training_loss=0.555]\u001b[A\n","Epoch 3:  59%|█████▉    | 69/116 [14:00<09:10, 11.71s/it, training_loss=0.550]\u001b[A\n","Epoch 3:  60%|██████    | 70/116 [14:00<09:11, 11.98s/it, training_loss=0.550]\u001b[A\n","Epoch 3:  60%|██████    | 70/116 [14:12<09:11, 11.98s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  61%|██████    | 71/116 [14:12<09:10, 12.23s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  61%|██████    | 71/116 [14:24<09:10, 12.23s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  62%|██████▏   | 72/116 [14:24<08:56, 12.19s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  62%|██████▏   | 72/116 [14:35<08:56, 12.19s/it, training_loss=0.591]\u001b[A\n","Epoch 3:  63%|██████▎   | 73/116 [14:35<08:27, 11.80s/it, training_loss=0.591]\u001b[A\n","Epoch 3:  63%|██████▎   | 73/116 [14:48<08:27, 11.80s/it, training_loss=0.534]\u001b[A\n","Epoch 3:  64%|██████▍   | 74/116 [14:48<08:25, 12.04s/it, training_loss=0.534]\u001b[A\n","Epoch 3:  64%|██████▍   | 74/116 [15:01<08:25, 12.04s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  65%|██████▍   | 75/116 [15:01<08:21, 12.24s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  65%|██████▍   | 75/116 [15:13<08:21, 12.24s/it, training_loss=0.533]\u001b[A\n","Epoch 3:  66%|██████▌   | 76/116 [15:13<08:08, 12.20s/it, training_loss=0.533]\u001b[A\n","Epoch 3:  66%|██████▌   | 76/116 [15:24<08:08, 12.20s/it, training_loss=0.547]\u001b[A\n","Epoch 3:  66%|██████▋   | 77/116 [15:24<07:39, 11.79s/it, training_loss=0.547]\u001b[A\n","Epoch 3:  66%|██████▋   | 77/116 [15:36<07:39, 11.79s/it, training_loss=0.567]\u001b[A\n","Epoch 3:  67%|██████▋   | 78/116 [15:36<07:38, 12.06s/it, training_loss=0.567]\u001b[A\n","Epoch 3:  67%|██████▋   | 78/116 [15:49<07:38, 12.06s/it, training_loss=0.563]\u001b[A\n","Epoch 3:  68%|██████▊   | 79/116 [15:49<07:31, 12.21s/it, training_loss=0.563]\u001b[A\n","Epoch 3:  68%|██████▊   | 79/116 [16:01<07:31, 12.21s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  69%|██████▉   | 80/116 [16:01<07:16, 12.14s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  69%|██████▉   | 80/116 [16:12<07:16, 12.14s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  70%|██████▉   | 81/116 [16:12<06:50, 11.71s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  70%|██████▉   | 81/116 [16:24<06:50, 11.71s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  71%|███████   | 82/116 [16:24<06:47, 11.98s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  71%|███████   | 82/116 [16:37<06:47, 11.98s/it, training_loss=0.578]\u001b[A\n","Epoch 3:  72%|███████▏  | 83/116 [16:37<06:43, 12.21s/it, training_loss=0.578]\u001b[A\n","Epoch 3:  72%|███████▏  | 83/116 [16:49<06:43, 12.21s/it, training_loss=0.555]\u001b[A\n","Epoch 3:  72%|███████▏  | 84/116 [16:49<06:30, 12.21s/it, training_loss=0.555]\u001b[A\n","Epoch 3:  72%|███████▏  | 84/116 [17:00<06:30, 12.21s/it, training_loss=0.540]\u001b[A\n","Epoch 3:  73%|███████▎  | 85/116 [17:00<06:05, 11.80s/it, training_loss=0.540]\u001b[A\n","Epoch 3:  73%|███████▎  | 85/116 [17:13<06:05, 11.80s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  74%|███████▍  | 86/116 [17:13<06:02, 12.07s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  74%|███████▍  | 86/116 [17:25<06:02, 12.07s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  75%|███████▌  | 87/116 [17:25<05:54, 12.23s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  75%|███████▌  | 87/116 [17:37<05:54, 12.23s/it, training_loss=0.540]\u001b[A\n","Epoch 3:  76%|███████▌  | 88/116 [17:37<05:40, 12.15s/it, training_loss=0.540]\u001b[A\n","Epoch 3:  76%|███████▌  | 88/116 [17:48<05:40, 12.15s/it, training_loss=0.552]\u001b[A\n","Epoch 3:  77%|███████▋  | 89/116 [17:48<05:16, 11.70s/it, training_loss=0.552]\u001b[A\n","Epoch 3:  77%|███████▋  | 89/116 [18:00<05:16, 11.70s/it, training_loss=0.534]\u001b[A\n","Epoch 3:  78%|███████▊  | 90/116 [18:00<05:11, 11.96s/it, training_loss=0.534]\u001b[A\n","Epoch 3:  78%|███████▊  | 90/116 [18:14<05:11, 11.96s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  78%|███████▊  | 91/116 [18:14<05:11, 12.46s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  78%|███████▊  | 91/116 [18:26<05:11, 12.46s/it, training_loss=0.559]\u001b[A\n","Epoch 3:  79%|███████▉  | 92/116 [18:26<04:54, 12.29s/it, training_loss=0.559]\u001b[A\n","Epoch 3:  79%|███████▉  | 92/116 [18:37<04:54, 12.29s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  80%|████████  | 93/116 [18:37<04:34, 11.92s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  80%|████████  | 93/116 [18:50<04:34, 11.92s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  81%|████████  | 94/116 [18:50<04:28, 12.20s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  81%|████████  | 94/116 [19:03<04:28, 12.20s/it, training_loss=0.546]\u001b[A\n","Epoch 3:  82%|████████▏ | 95/116 [19:03<04:19, 12.35s/it, training_loss=0.546]\u001b[A\n","Epoch 3:  82%|████████▏ | 95/116 [19:15<04:19, 12.35s/it, training_loss=0.554]\u001b[A\n","Epoch 3:  83%|████████▎ | 96/116 [19:15<04:05, 12.26s/it, training_loss=0.554]\u001b[A\n","Epoch 3:  83%|████████▎ | 96/116 [19:25<04:05, 12.26s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  84%|████████▎ | 97/116 [19:25<03:44, 11.81s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  84%|████████▎ | 97/116 [19:38<03:44, 11.81s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  84%|████████▍ | 98/116 [19:38<03:36, 12.06s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  84%|████████▍ | 98/116 [19:51<03:36, 12.06s/it, training_loss=0.517]\u001b[A\n","Epoch 3:  85%|████████▌ | 99/116 [19:51<03:28, 12.27s/it, training_loss=0.517]\u001b[A\n","Epoch 3:  85%|████████▌ | 99/116 [20:03<03:28, 12.27s/it, training_loss=0.540]\u001b[A\n","Epoch 3:  86%|████████▌ | 100/116 [20:03<03:14, 12.18s/it, training_loss=0.540]\u001b[A\n","Epoch 3:  86%|████████▌ | 100/116 [20:14<03:14, 12.18s/it, training_loss=0.530]\u001b[A\n","Epoch 3:  87%|████████▋ | 101/116 [20:14<02:56, 11.79s/it, training_loss=0.530]\u001b[A\n","Epoch 3:  87%|████████▋ | 101/116 [20:26<02:56, 11.79s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  88%|████████▊ | 102/116 [20:26<02:48, 12.03s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  88%|████████▊ | 102/116 [20:39<02:48, 12.03s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  89%|████████▉ | 103/116 [20:39<02:39, 12.27s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  89%|████████▉ | 103/116 [20:51<02:39, 12.27s/it, training_loss=0.573]\u001b[A\n","Epoch 3:  90%|████████▉ | 104/116 [20:51<02:26, 12.24s/it, training_loss=0.573]\u001b[A\n","Epoch 3:  90%|████████▉ | 104/116 [21:02<02:26, 12.24s/it, training_loss=0.519]\u001b[A\n","Epoch 3:  91%|█████████ | 105/116 [21:02<02:10, 11.85s/it, training_loss=0.519]\u001b[A\n","Epoch 3:  91%|█████████ | 105/116 [21:15<02:10, 11.85s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  91%|█████████▏| 106/116 [21:15<02:01, 12.11s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  91%|█████████▏| 106/116 [21:27<02:01, 12.11s/it, training_loss=0.514]\u001b[A\n","Epoch 3:  92%|█████████▏| 107/116 [21:28<01:50, 12.27s/it, training_loss=0.514]\u001b[A\n","Epoch 3:  92%|█████████▏| 107/116 [21:40<01:50, 12.27s/it, training_loss=0.618]\u001b[A\n","Epoch 3:  93%|█████████▎| 108/116 [21:40<01:37, 12.19s/it, training_loss=0.618]\u001b[A\n","Epoch 3:  93%|█████████▎| 108/116 [21:50<01:37, 12.19s/it, training_loss=0.529]\u001b[A\n","Epoch 3:  94%|█████████▍| 109/116 [21:50<01:22, 11.76s/it, training_loss=0.529]\u001b[A\n","Epoch 3:  94%|█████████▍| 109/116 [22:03<01:22, 11.76s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  95%|█████████▍| 110/116 [22:03<01:11, 11.99s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  95%|█████████▍| 110/116 [22:15<01:11, 11.99s/it, training_loss=0.588]\u001b[A\n","Epoch 3:  96%|█████████▌| 111/116 [22:16<01:01, 12.21s/it, training_loss=0.588]\u001b[A\n","Epoch 3:  96%|█████████▌| 111/116 [22:28<01:01, 12.21s/it, training_loss=0.572]\u001b[A\n","Epoch 3:  97%|█████████▋| 112/116 [22:28<00:48, 12.17s/it, training_loss=0.572]\u001b[A\n","Epoch 3:  97%|█████████▋| 112/116 [22:38<00:48, 12.17s/it, training_loss=0.580]\u001b[A\n","Epoch 3:  97%|█████████▋| 113/116 [22:38<00:35, 11.79s/it, training_loss=0.580]\u001b[A\n","Epoch 3:  97%|█████████▋| 113/116 [22:51<00:35, 11.79s/it, training_loss=0.585]\u001b[A\n","Epoch 3:  98%|█████████▊| 114/116 [22:51<00:24, 12.08s/it, training_loss=0.585]\u001b[A\n","Epoch 3:  98%|█████████▊| 114/116 [23:04<00:24, 12.08s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  99%|█████████▉| 115/116 [23:04<00:12, 12.25s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  99%|█████████▉| 115/116 [23:10<00:12, 12.25s/it, training_loss=0.578]\u001b[A\n","Epoch 3: 100%|██████████| 116/116 [23:10<00:00, 10.31s/it, training_loss=0.578]\u001b[A\n"," 50%|█████     | 2/4 [1:13:30<50:14, 1507.04s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 1.6310103432885532\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [1:15:19<25:04, 1504.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6178871845376903\n","F1 Score (Weighted): 0.08928352725045927\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/116 [00:12<?, ?it/s, training_loss=0.502]\u001b[A\n","Epoch 4:   1%|          | 1/116 [00:12<24:31, 12.80s/it, training_loss=0.502]\u001b[A\n","Epoch 4:   1%|          | 1/116 [00:25<24:31, 12.80s/it, training_loss=0.579]\u001b[A\n","Epoch 4:   2%|▏         | 2/116 [00:25<24:06, 12.69s/it, training_loss=0.579]\u001b[A\n","Epoch 4:   2%|▏         | 2/116 [00:35<24:06, 12.69s/it, training_loss=0.558]\u001b[A\n","Epoch 4:   3%|▎         | 3/116 [00:35<21:57, 11.66s/it, training_loss=0.558]\u001b[A\n","Epoch 4:   3%|▎         | 3/116 [00:48<21:57, 11.66s/it, training_loss=0.544]\u001b[A\n","Epoch 4:   3%|▎         | 4/116 [00:48<22:18, 11.95s/it, training_loss=0.544]\u001b[A\n","Epoch 4:   3%|▎         | 4/116 [01:01<22:18, 11.95s/it, training_loss=0.557]\u001b[A\n","Epoch 4:   4%|▍         | 5/116 [01:01<23:04, 12.47s/it, training_loss=0.557]\u001b[A\n","Epoch 4:   4%|▍         | 5/116 [01:14<23:04, 12.47s/it, training_loss=0.539]\u001b[A\n","Epoch 4:   5%|▌         | 6/116 [01:14<23:17, 12.70s/it, training_loss=0.539]\u001b[A\n","Epoch 4:   5%|▌         | 6/116 [01:25<23:17, 12.70s/it, training_loss=0.523]\u001b[A\n","Epoch 4:   6%|▌         | 7/116 [01:25<22:06, 12.17s/it, training_loss=0.523]\u001b[A\n","Epoch 4:   6%|▌         | 7/116 [01:37<22:06, 12.17s/it, training_loss=0.542]\u001b[A\n","Epoch 4:   7%|▋         | 8/116 [01:37<21:36, 12.00s/it, training_loss=0.542]\u001b[A\n","Epoch 4:   7%|▋         | 8/116 [01:50<21:36, 12.00s/it, training_loss=0.524]\u001b[A\n","Epoch 4:   8%|▊         | 9/116 [01:50<21:51, 12.25s/it, training_loss=0.524]\u001b[A\n","Epoch 4:   8%|▊         | 9/116 [02:03<21:51, 12.25s/it, training_loss=0.564]\u001b[A\n","Epoch 4:   9%|▊         | 10/116 [02:03<21:56, 12.42s/it, training_loss=0.564]\u001b[A\n","Epoch 4:   9%|▊         | 10/116 [02:14<21:56, 12.42s/it, training_loss=0.541]\u001b[A\n","Epoch 4:   9%|▉         | 11/116 [02:14<21:08, 12.08s/it, training_loss=0.541]\u001b[A\n","Epoch 4:   9%|▉         | 11/116 [02:25<21:08, 12.08s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  10%|█         | 12/116 [02:25<20:30, 11.83s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  10%|█         | 12/116 [02:38<20:30, 11.83s/it, training_loss=0.523]\u001b[A\n","Epoch 4:  11%|█         | 13/116 [02:38<20:38, 12.02s/it, training_loss=0.523]\u001b[A\n","Epoch 4:  11%|█         | 13/116 [02:50<20:38, 12.02s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  12%|█▏        | 14/116 [02:50<20:48, 12.24s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  12%|█▏        | 14/116 [03:02<20:48, 12.24s/it, training_loss=0.522]\u001b[A\n","Epoch 4:  13%|█▎        | 15/116 [03:02<20:06, 11.94s/it, training_loss=0.522]\u001b[A\n","Epoch 4:  13%|█▎        | 15/116 [03:13<20:06, 11.94s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  14%|█▍        | 16/116 [03:13<19:38, 11.79s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  14%|█▍        | 16/116 [03:26<19:38, 11.79s/it, training_loss=0.552]\u001b[A\n","Epoch 4:  15%|█▍        | 17/116 [03:26<20:02, 12.15s/it, training_loss=0.552]\u001b[A\n","Epoch 4:  15%|█▍        | 17/116 [03:40<20:02, 12.15s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  16%|█▌        | 18/116 [03:40<20:40, 12.65s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  16%|█▌        | 18/116 [03:52<20:40, 12.65s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  16%|█▋        | 19/116 [03:52<20:18, 12.56s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  16%|█▋        | 19/116 [04:03<20:18, 12.56s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  17%|█▋        | 20/116 [04:03<19:15, 12.04s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  17%|█▋        | 20/116 [04:16<19:15, 12.04s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  18%|█▊        | 21/116 [04:16<19:19, 12.21s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  18%|█▊        | 21/116 [04:28<19:19, 12.21s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  19%|█▉        | 22/116 [04:28<19:19, 12.33s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  19%|█▉        | 22/116 [04:40<19:19, 12.33s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  20%|█▉        | 23/116 [04:40<18:56, 12.22s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  20%|█▉        | 23/116 [04:51<18:56, 12.22s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  21%|██        | 24/116 [04:51<18:07, 11.82s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  21%|██        | 24/116 [05:04<18:07, 11.82s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  22%|██▏       | 25/116 [05:04<18:18, 12.07s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  22%|██▏       | 25/116 [05:17<18:18, 12.07s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  22%|██▏       | 26/116 [05:17<18:25, 12.29s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  22%|██▏       | 26/116 [05:29<18:25, 12.29s/it, training_loss=0.551]\u001b[A\n","Epoch 4:  23%|██▎       | 27/116 [05:29<18:12, 12.28s/it, training_loss=0.551]\u001b[A\n","Epoch 4:  23%|██▎       | 27/116 [05:40<18:12, 12.28s/it, training_loss=0.542]\u001b[A\n","Epoch 4:  24%|██▍       | 28/116 [05:40<17:25, 11.88s/it, training_loss=0.542]\u001b[A\n","Epoch 4:  24%|██▍       | 28/116 [05:53<17:25, 11.88s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  25%|██▌       | 29/116 [05:53<17:39, 12.18s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  25%|██▌       | 29/116 [06:07<17:39, 12.18s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  26%|██▌       | 30/116 [06:07<18:15, 12.74s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  26%|██▌       | 30/116 [06:19<18:15, 12.74s/it, training_loss=0.544]\u001b[A\n","Epoch 4:  27%|██▋       | 31/116 [06:19<18:00, 12.71s/it, training_loss=0.544]\u001b[A\n","Epoch 4:  27%|██▋       | 31/116 [06:30<18:00, 12.71s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  28%|██▊       | 32/116 [06:30<16:55, 12.09s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  28%|██▊       | 32/116 [06:42<16:55, 12.09s/it, training_loss=0.543]\u001b[A\n","Epoch 4:  28%|██▊       | 33/116 [06:42<16:43, 12.09s/it, training_loss=0.543]\u001b[A\n","Epoch 4:  28%|██▊       | 33/116 [06:55<16:43, 12.09s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  29%|██▉       | 34/116 [06:55<16:44, 12.25s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  29%|██▉       | 34/116 [07:07<16:44, 12.25s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  30%|███       | 35/116 [07:07<16:40, 12.35s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  30%|███       | 35/116 [07:18<16:40, 12.35s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  31%|███       | 36/116 [07:18<15:46, 11.83s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  31%|███       | 36/116 [07:30<15:46, 11.83s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  32%|███▏      | 37/116 [07:30<15:41, 11.92s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  32%|███▏      | 37/116 [07:43<15:41, 11.92s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  33%|███▎      | 38/116 [07:43<15:46, 12.13s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  33%|███▎      | 38/116 [07:55<15:46, 12.13s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  34%|███▎      | 39/116 [07:55<15:47, 12.31s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  34%|███▎      | 39/116 [08:06<15:47, 12.31s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  34%|███▍      | 40/116 [08:06<14:59, 11.84s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  34%|███▍      | 40/116 [08:18<14:59, 11.84s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  35%|███▌      | 41/116 [08:18<14:50, 11.87s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  35%|███▌      | 41/116 [08:31<14:50, 11.87s/it, training_loss=0.524]\u001b[A\n","Epoch 4:  36%|███▌      | 42/116 [08:31<15:11, 12.31s/it, training_loss=0.524]\u001b[A\n","Epoch 4:  36%|███▌      | 42/116 [08:47<15:11, 12.31s/it, training_loss=0.540]\u001b[A\n","Epoch 4:  37%|███▋      | 43/116 [08:47<16:17, 13.39s/it, training_loss=0.540]\u001b[A\n","Epoch 4:  37%|███▋      | 43/116 [08:59<16:17, 13.39s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  38%|███▊      | 44/116 [08:59<15:32, 12.95s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  38%|███▊      | 44/116 [09:11<15:32, 12.95s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  39%|███▉      | 45/116 [09:11<14:54, 12.60s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  39%|███▉      | 45/116 [09:24<14:54, 12.60s/it, training_loss=0.519]\u001b[A\n","Epoch 4:  40%|███▉      | 46/116 [09:24<14:44, 12.64s/it, training_loss=0.519]\u001b[A\n","Epoch 4:  40%|███▉      | 46/116 [09:36<14:44, 12.64s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  41%|████      | 47/116 [09:36<14:32, 12.65s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  41%|████      | 47/116 [09:48<14:32, 12.65s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  41%|████▏     | 48/116 [09:48<13:57, 12.31s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  41%|████▏     | 48/116 [09:59<13:57, 12.31s/it, training_loss=0.522]\u001b[A\n","Epoch 4:  42%|████▏     | 49/116 [09:59<13:26, 12.03s/it, training_loss=0.522]\u001b[A\n","Epoch 4:  42%|████▏     | 49/116 [10:12<13:26, 12.03s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  43%|████▎     | 50/116 [10:12<13:27, 12.24s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  43%|████▎     | 50/116 [10:25<13:27, 12.24s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  44%|████▍     | 51/116 [10:25<13:25, 12.39s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  44%|████▍     | 51/116 [10:36<13:25, 12.39s/it, training_loss=0.558]\u001b[A\n","Epoch 4:  45%|████▍     | 52/116 [10:36<12:57, 12.15s/it, training_loss=0.558]\u001b[A\n","Epoch 4:  45%|████▍     | 52/116 [10:48<12:57, 12.15s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  46%|████▌     | 53/116 [10:48<12:26, 11.84s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  46%|████▌     | 53/116 [11:01<12:26, 11.84s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  47%|████▋     | 54/116 [11:01<12:42, 12.29s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  47%|████▋     | 54/116 [11:14<12:42, 12.29s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  47%|████▋     | 55/116 [11:14<12:45, 12.55s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  47%|████▋     | 55/116 [11:26<12:45, 12.55s/it, training_loss=0.567]\u001b[A\n","Epoch 4:  48%|████▊     | 56/116 [11:26<12:27, 12.46s/it, training_loss=0.567]\u001b[A\n","Epoch 4:  48%|████▊     | 56/116 [11:37<12:27, 12.46s/it, training_loss=0.479]\u001b[A\n","Epoch 4:  49%|████▉     | 57/116 [11:37<11:42, 11.91s/it, training_loss=0.479]\u001b[A\n","Epoch 4:  49%|████▉     | 57/116 [11:50<11:42, 11.91s/it, training_loss=0.510]\u001b[A\n","Epoch 4:  50%|█████     | 58/116 [11:50<11:45, 12.17s/it, training_loss=0.510]\u001b[A\n","Epoch 4:  50%|█████     | 58/116 [12:02<11:45, 12.17s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  51%|█████     | 59/116 [12:02<11:44, 12.36s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  51%|█████     | 59/116 [12:15<11:44, 12.36s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  52%|█████▏    | 60/116 [12:15<11:32, 12.37s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  52%|█████▏    | 60/116 [12:25<11:32, 12.37s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  53%|█████▎    | 61/116 [12:25<10:49, 11.82s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  53%|█████▎    | 61/116 [12:38<10:49, 11.82s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  53%|█████▎    | 62/116 [12:38<10:50, 12.04s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  53%|█████▎    | 62/116 [12:51<10:50, 12.04s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  54%|█████▍    | 63/116 [12:51<10:46, 12.20s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  54%|█████▍    | 63/116 [13:03<10:46, 12.20s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  55%|█████▌    | 64/116 [13:03<10:32, 12.16s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  55%|█████▌    | 64/116 [13:16<10:32, 12.16s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  56%|█████▌    | 65/116 [13:16<10:39, 12.53s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  56%|█████▌    | 65/116 [13:28<10:39, 12.53s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  57%|█████▋    | 66/116 [13:28<10:16, 12.33s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  57%|█████▋    | 66/116 [13:41<10:16, 12.33s/it, training_loss=0.561]\u001b[A\n","Epoch 4:  58%|█████▊    | 67/116 [13:41<10:20, 12.67s/it, training_loss=0.561]\u001b[A\n","Epoch 4:  58%|█████▊    | 67/116 [13:54<10:20, 12.67s/it, training_loss=0.505]\u001b[A\n","Epoch 4:  59%|█████▊    | 68/116 [13:54<10:10, 12.71s/it, training_loss=0.505]\u001b[A\n","Epoch 4:  59%|█████▊    | 68/116 [14:06<10:10, 12.71s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  59%|█████▉    | 69/116 [14:06<09:42, 12.39s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  59%|█████▉    | 69/116 [14:17<09:42, 12.39s/it, training_loss=0.540]\u001b[A\n","Epoch 4:  60%|██████    | 70/116 [14:17<09:12, 12.02s/it, training_loss=0.540]\u001b[A\n","Epoch 4:  60%|██████    | 70/116 [14:29<09:12, 12.02s/it, training_loss=0.504]\u001b[A\n","Epoch 4:  61%|██████    | 71/116 [14:29<09:08, 12.18s/it, training_loss=0.504]\u001b[A\n","Epoch 4:  61%|██████    | 71/116 [14:42<09:08, 12.18s/it, training_loss=0.483]\u001b[A\n","Epoch 4:  62%|██████▏   | 72/116 [14:42<09:00, 12.29s/it, training_loss=0.483]\u001b[A\n","Epoch 4:  62%|██████▏   | 72/116 [14:53<09:00, 12.29s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  63%|██████▎   | 73/116 [14:53<08:37, 12.03s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  63%|██████▎   | 73/116 [15:05<08:37, 12.03s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  64%|██████▍   | 74/116 [15:05<08:16, 11.81s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  64%|██████▍   | 74/116 [15:17<08:16, 11.81s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  65%|██████▍   | 75/116 [15:18<08:15, 12.10s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  65%|██████▍   | 75/116 [15:30<08:15, 12.10s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  66%|██████▌   | 76/116 [15:30<08:13, 12.33s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  66%|██████▌   | 76/116 [15:42<08:13, 12.33s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  66%|██████▋   | 77/116 [15:42<07:53, 12.15s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  66%|██████▋   | 77/116 [15:53<07:53, 12.15s/it, training_loss=0.504]\u001b[A\n","Epoch 4:  67%|██████▋   | 78/116 [15:53<07:30, 11.86s/it, training_loss=0.504]\u001b[A\n","Epoch 4:  67%|██████▋   | 78/116 [16:07<07:30, 11.86s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  68%|██████▊   | 79/116 [16:07<07:43, 12.52s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  68%|██████▊   | 79/116 [16:20<07:43, 12.52s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  69%|██████▉   | 80/116 [16:20<07:33, 12.59s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  69%|██████▉   | 80/116 [16:32<07:33, 12.59s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  70%|██████▉   | 81/116 [16:32<07:17, 12.50s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  70%|██████▉   | 81/116 [16:43<07:17, 12.50s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  71%|███████   | 82/116 [16:43<06:46, 11.95s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  71%|███████   | 82/116 [16:56<06:46, 11.95s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  72%|███████▏  | 83/116 [16:56<06:40, 12.14s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  72%|███████▏  | 83/116 [17:08<06:40, 12.14s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  72%|███████▏  | 84/116 [17:08<06:33, 12.31s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  72%|███████▏  | 84/116 [17:21<06:33, 12.31s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  73%|███████▎  | 85/116 [17:21<06:20, 12.27s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  73%|███████▎  | 85/116 [17:31<06:20, 12.27s/it, training_loss=0.528]\u001b[A\n","Epoch 4:  74%|███████▍  | 86/116 [17:31<05:55, 11.83s/it, training_loss=0.528]\u001b[A\n","Epoch 4:  74%|███████▍  | 86/116 [17:44<05:55, 11.83s/it, training_loss=0.505]\u001b[A\n","Epoch 4:  75%|███████▌  | 87/116 [17:44<05:50, 12.09s/it, training_loss=0.505]\u001b[A\n","Epoch 4:  75%|███████▌  | 87/116 [17:57<05:50, 12.09s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  76%|███████▌  | 88/116 [17:57<05:43, 12.27s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  76%|███████▌  | 88/116 [18:09<05:43, 12.27s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  77%|███████▋  | 89/116 [18:09<05:30, 12.23s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  77%|███████▋  | 89/116 [18:19<05:30, 12.23s/it, training_loss=0.576]\u001b[A\n","Epoch 4:  78%|███████▊  | 90/116 [18:19<05:05, 11.73s/it, training_loss=0.576]\u001b[A\n","Epoch 4:  78%|███████▊  | 90/116 [18:33<05:05, 11.73s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  78%|███████▊  | 91/116 [18:33<05:07, 12.30s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  78%|███████▊  | 91/116 [18:46<05:07, 12.30s/it, training_loss=0.575]\u001b[A\n","Epoch 4:  79%|███████▉  | 92/116 [18:46<04:58, 12.45s/it, training_loss=0.575]\u001b[A\n","Epoch 4:  79%|███████▉  | 92/116 [18:58<04:58, 12.45s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  80%|████████  | 93/116 [18:58<04:46, 12.44s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  80%|████████  | 93/116 [19:09<04:46, 12.44s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  81%|████████  | 94/116 [19:09<04:20, 11.84s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  81%|████████  | 94/116 [19:21<04:20, 11.84s/it, training_loss=0.573]\u001b[A\n","Epoch 4:  82%|████████▏ | 95/116 [19:21<04:12, 12.02s/it, training_loss=0.573]\u001b[A\n","Epoch 4:  82%|████████▏ | 95/116 [19:34<04:12, 12.02s/it, training_loss=0.515]\u001b[A\n","Epoch 4:  83%|████████▎ | 96/116 [19:34<04:04, 12.24s/it, training_loss=0.515]\u001b[A\n","Epoch 4:  83%|████████▎ | 96/116 [19:46<04:04, 12.24s/it, training_loss=0.558]\u001b[A\n","Epoch 4:  84%|████████▎ | 97/116 [19:46<03:52, 12.26s/it, training_loss=0.558]\u001b[A\n","Epoch 4:  84%|████████▎ | 97/116 [19:57<03:52, 12.26s/it, training_loss=0.501]\u001b[A\n","Epoch 4:  84%|████████▍ | 98/116 [19:57<03:30, 11.71s/it, training_loss=0.501]\u001b[A\n","Epoch 4:  84%|████████▍ | 98/116 [20:09<03:30, 11.71s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  85%|████████▌ | 99/116 [20:09<03:23, 11.98s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  85%|████████▌ | 99/116 [20:22<03:23, 11.98s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  86%|████████▌ | 100/116 [20:22<03:14, 12.16s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  86%|████████▌ | 100/116 [20:34<03:14, 12.16s/it, training_loss=0.567]\u001b[A\n","Epoch 4:  87%|████████▋ | 101/116 [20:34<03:02, 12.14s/it, training_loss=0.567]\u001b[A\n","Epoch 4:  87%|████████▋ | 101/116 [20:44<03:02, 12.14s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  88%|████████▊ | 102/116 [20:44<02:42, 11.62s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  88%|████████▊ | 102/116 [20:57<02:42, 11.62s/it, training_loss=0.505]\u001b[A\n","Epoch 4:  89%|████████▉ | 103/116 [20:57<02:35, 11.95s/it, training_loss=0.505]\u001b[A\n","Epoch 4:  89%|████████▉ | 103/116 [21:11<02:35, 11.95s/it, training_loss=0.518]\u001b[A\n","Epoch 4:  90%|████████▉ | 104/116 [21:11<02:29, 12.42s/it, training_loss=0.518]\u001b[A\n","Epoch 4:  90%|████████▉ | 104/116 [21:23<02:29, 12.42s/it, training_loss=0.566]\u001b[A\n","Epoch 4:  91%|█████████ | 105/116 [21:23<02:16, 12.42s/it, training_loss=0.566]\u001b[A\n","Epoch 4:  91%|█████████ | 105/116 [21:33<02:16, 12.42s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  91%|█████████▏| 106/116 [21:33<01:58, 11.83s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  91%|█████████▏| 106/116 [21:46<01:58, 11.83s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  92%|█████████▏| 107/116 [21:46<01:48, 12.05s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  92%|█████████▏| 107/116 [21:59<01:48, 12.05s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  93%|█████████▎| 108/116 [21:59<01:38, 12.26s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  93%|█████████▎| 108/116 [22:11<01:38, 12.26s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  94%|█████████▍| 109/116 [22:11<01:26, 12.29s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  94%|█████████▍| 109/116 [22:21<01:26, 12.29s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  95%|█████████▍| 110/116 [22:21<01:10, 11.68s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  95%|█████████▍| 110/116 [22:34<01:10, 11.68s/it, training_loss=0.584]\u001b[A\n","Epoch 4:  96%|█████████▌| 111/116 [22:34<00:59, 11.96s/it, training_loss=0.584]\u001b[A\n","Epoch 4:  96%|█████████▌| 111/116 [22:47<00:59, 11.96s/it, training_loss=0.537]\u001b[A\n","Epoch 4:  97%|█████████▋| 112/116 [22:47<00:48, 12.16s/it, training_loss=0.537]\u001b[A\n","Epoch 4:  97%|█████████▋| 112/116 [22:59<00:48, 12.16s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  97%|█████████▋| 113/116 [22:59<00:36, 12.17s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  97%|█████████▋| 113/116 [23:09<00:36, 12.17s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  98%|█████████▊| 114/116 [23:09<00:23, 11.63s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  98%|█████████▊| 114/116 [23:22<00:23, 11.63s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  99%|█████████▉| 115/116 [23:22<00:11, 11.89s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  99%|█████████▉| 115/116 [23:29<00:11, 11.89s/it, training_loss=0.545]\u001b[A\n","Epoch 4: 100%|██████████| 116/116 [23:29<00:00, 10.52s/it, training_loss=0.545]\u001b[A\n"," 75%|███████▌  | 3/4 [1:38:52<25:04, 1504.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 1.6155100701184109\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [1:40:38<00:00, 1509.60s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6316360070787628\n","F1 Score (Weighted): 0.02642399730367375\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-39-9c29dbba6ffb>:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df_final.append(pd.DataFrame(list_final), ignore_index=True)\n"]},{"output_type":"stream","name":"stdout","text":["Analisis Essay Grading Olahraga\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-b277799f1436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masag_systems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data Lagi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-39-9c29dbba6ffb>\u001b[0m in \u001b[0;36masag_systems\u001b[0;34m(path_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.xslx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-38-c74b3798ec97>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(df_final, pretrainedmodel)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrainedmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# bin nilai (continuous variable) into intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nilai'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nilai'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jawaban'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jawaban'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     fac, bins = _bins_to_cuts(\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_bins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mduplicates\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0;34mf\"Bin edges must be unique: {repr(bins)}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0;34mf\"You can drop duplicate edges by setting the 'duplicates' kwarg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: array([0., 0., 1., 2., 3., 4.]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg"]}],"source":["asag_systems('/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data Lagi')"],"id":"yVH_6Fb1IUOS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiMhZm_1SKoz"},"outputs":[],"source":[],"id":"WiMhZm_1SKoz"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"766caac7eb69e8a0a4a596af183e8606e532f32ec205da93d6afbc58c03966c0"}}},"nbformat":4,"nbformat_minor":5}