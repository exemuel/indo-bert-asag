{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbN-qdA5z1G-","executionInfo":{"status":"ok","timestamp":1679820084547,"user_tz":-420,"elapsed":4591,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"4c35d4e5-f434-4877-85e6-403ca783da6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"id":"MbN-qdA5z1G-"},{"cell_type":"code","source":["pip install sastrawi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcXBnbTmz2nW","executionInfo":{"status":"ok","timestamp":1679820089857,"user_tz":-420,"elapsed":5313,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"825e4612-190c-4523-d5a3-0b904f7353e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n"]}],"id":"EcXBnbTmz2nW"},{"cell_type":"code","source":["pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AVL6mTkz2x9","executionInfo":{"status":"ok","timestamp":1679820096510,"user_tz":-420,"elapsed":6658,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"e6ccef05-4b58-4112-aff3-e317d8ee5981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.4.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk) (1.16.0)\n"]}],"id":"1AVL6mTkz2x9"},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFkbHffjz299","executionInfo":{"status":"ok","timestamp":1679820097720,"user_tz":-420,"elapsed":1214,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"30b08967-54ca-44ed-aa6a-6c6ecf1e30a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"id":"DFkbHffjz299"},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRQaDdXaz6fl","executionInfo":{"status":"ok","timestamp":1679820097720,"user_tz":-420,"elapsed":7,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"0cc4780b-97c0-49c8-dcd0-d4ae0643e9aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"id":"wRQaDdXaz6fl"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1d61a3ba","executionInfo":{"status":"ok","timestamp":1679820098274,"user_tz":-420,"elapsed":557,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}},"outputId":"7aa6576c-321e-4b32-b773-349c741468d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Indonesian Query Answering Dataset for Online Essay Test System.zip', 'dict.json', 'Preprocessing', 'Analysis Data', 'Text Preprocessing', 'Data', 'dataset.py', '__pycache__']\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","import os\n","import re\n","import nltk\n","import random\n","from nltk.corpus import stopwords\n","from gensim.models import Word2Vec\n","from nltk.tokenize import sent_tokenize, LineTokenizer, RegexpTokenizer\n","from nltk.tokenize import word_tokenize\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","\n","print(os.listdir(\"/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/\"))\n","factory = StemmerFactory()\n","stemmer = factory.create_stemmer()\n","import string\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","stopwords_indonesia = stopwords.words('indonesian')\n","stop_words = set(stopwords.words('indonesian'))\n","import sys\n","import os"],"id":"1d61a3ba"},{"cell_type":"code","source":[],"metadata":{"id":"UbTgH1-D-kLA"},"id":"UbTgH1-D-kLA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5791,"status":"ok","timestamp":1679820104063,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"icJEdL3SOegH","outputId":"29d9ad0d-5c35-41a8-d939-6a876ea2f3a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nlp_id in /usr/local/lib/python3.9/dist-packages (0.1.13.0)\n","Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.4.5)\n","Requirement already satisfied: scikit-learn==1.1.0 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (1.1.0)\n","Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.9/dist-packages (from nlp_id) (3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.4.5->nlp_id) (1.16.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.22.4)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.1.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.0->nlp_id) (3.1.0)\n"]}],"source":["pip install nlp_id"],"id":"icJEdL3SOegH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11183,"status":"ok","timestamp":1679820115232,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"},"user_tz":-420},"id":"LMdPOnmpOkt_","outputId":"ba97f3b3-218b-49d2-d946-1e7dc76aa94d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"]}],"source":["pip install transformers"],"id":"LMdPOnmpOkt_"},{"cell_type":"code","source":["# fungsi untuk menghapus kata negasi\n","def hapus_kata_negasi(kalimat):\n","    # membuat daftar kata negasi\n","    negasi = ['tidak', 'bukan', 'belum', 'tak', 'jangan', 'tidaklah', 'bukannya', 'tiada', 'gak', 'ngga', 'nggak', 'enggak']\n","    # melakukan split kalimat menjadi token\n","    result = []\n","    negate = False\n","    for word in kalimat:\n","        if any(neg == word for neg in negasi):\n","            negate = True\n","        elif negate and word not in string.punctuation:\n","            word = 'tidak_' + word\n","            negate = False\n","        result.append(word)\n","    return result\n","\n","def remove_stopword(token):\n","    return ' '. join(token)"],"metadata":{"id":"DXIGh1jyEHuP"},"id":"DXIGh1jyEHuP","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4N6fkUEOk65"},"outputs":[],"source":["import re\n","import random\n","import pandas as pd\n","import torch\n","import tensorflow as tf\n","import numpy as np\n","\n","from nlp_id.lemmatizer import Lemmatizer\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.metrics import f1_score, cohen_kappa_score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from nltk.corpus import stopwords"],"id":"t4N6fkUEOk65"},{"cell_type":"code","execution_count":37,"id":"32c4042a","metadata":{"id":"32c4042a","executionInfo":{"status":"ok","timestamp":1679834680061,"user_tz":-420,"elapsed":702,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"outputs":[],"source":["seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","punctuation = r'[^\\w\\s]'\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def qwk_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return cohen_kappa_score(labels_flat, preds_flat)\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","\n","def evaluate(dataloader_val, device, model):\n","\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_val:\n","\n","        batch = tuple(b.to(device) for b in batch)\n","\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total/len(dataloader_val)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals\n","\n","def train_eval(df_final, pretrainedmodel):\n","    # bin nilai (continuous variable) into intervals\n","    df_final['nilai'] = pd.qcut(df_final['nilai'], 5, labels=False)\n","\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: x.lower())\n","    df_final['jawaban'] = df_final['jawaban'].apply(lambda x: re.sub(punctuation, '', x))\n","\n","    # make sure that the training set and test set ratio is 80:20\n","    add = len(df_final[df_final['tipe'] == 'test']) - (round(0.2*(len(df_final[df_final['tipe'] == 'train'])+len(df_final[df_final['tipe'] == 'test']))))\n","    for i in df_final[df_final['tipe'] == 'test'].sample(n = add).itertuples():\n","        df_final.at[i.Index, 'tipe'] = 'train'\n","\n","    # load model and tokenizer\n","    tokenizer = BertTokenizer.from_pretrained(pretrainedmodel, ignore_mismatched_sizes=True)\n","\n","    encoded_data_train = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='train']['jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(\n","        df_final[df_final.tipe=='test']['jawaban'].values,\n","        add_special_tokens=True,\n","        return_attention_mask=True,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        max_length=256,\n","        padding='max_length',\n","        return_tensors='pt'\n","    )\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df_final[df_final.tipe=='train'].nilai.values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df_final[df_final.tipe=='test'].nilai.values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","\n","    model = BertForSequenceClassification.from_pretrained(pretrainedmodel,\n","                                                          num_labels=5,\n","                                                          output_attentions=False,\n","                                                          output_hidden_states=False, ignore_mismatched_sizes=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    batch_size = 4\n","\n","    dataloader_train = DataLoader(dataset_train,\n","                                  sampler=RandomSampler(dataset_train),\n","                                  batch_size=batch_size)\n","\n","    dataloader_validation = DataLoader(dataset_val,\n","                                       sampler=SequentialSampler(dataset_val),\n","                                       batch_size=batch_size)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(),\n","                      lr=2e-5,\n","                      eps=1e-8)\n","\n","    epochs = 4\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train)*epochs)\n","\n","    for epoch in tqdm(range(1, epochs+1)):\n","\n","        model.train()\n","\n","        loss_train_total = 0\n","\n","        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","        for batch in progress_bar:\n","\n","            model.zero_grad()\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","\n","        torch.save(model.state_dict(), f'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Model_Save/finetuned_BERT_Punctuation_epoch_{epoch}.model')\n","\n","        tqdm.write(f'\\nEpoch {epoch}')\n","\n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","        val_loss, predictions, true_vals = evaluate(dataloader_validation, device, model)\n","        val_f1 = f1_score_func(predictions, true_vals)\n","        val_qwk = qwk_score_func(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","        tqdm.write(f'QWK Score: {val_qwk}')"]},{"cell_type":"code","source":["def asag_systems(path_dir):\n","    list_pre_trained_model = ['indobenchmark/indobert-lite-base-p2']\n","    list_dir = os.listdir(path_dir)\n","    for m in list_pre_trained_model:\n","        print(m)\n","        for idx, ele in enumerate(list_dir):\n","            df_raw = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                  sheet_name='Soal',\n","                                  header=1,\n","                                  index_col=0,\n","                                  usecols='B:D')\n","\n","            list_final = []\n","\n","            for i in df_raw.itertuples():\n","                list_final.append(\n","                    {\n","                        'jawaban': i[1],\n","                        'nilai': 100,\n","                        'tipe': 'train',\n","                        'path': f'Punctuation',\n","                    }\n","                )\n","                df_tmp = pd.read_excel(open(path_dir+'/'+ele, 'rb'),\n","                                        sheet_name='No.'+str(i.Index),\n","                                        header=1,\n","                                        index_col=0,\n","                                        usecols='B:N')\n","                \n","                df_tmp = df_tmp.dropna()\n","                for j in df_tmp.itertuples():\n","                    list_final.append(\n","                        {\n","                            'jawaban': j[1],\n","                            'nilai': j[12],\n","                            'tipe': 'test',\n","                            'path': f'Punctuation',\n","                        }\n","                    )\n","            if idx == 0:\n","                df_final = pd.DataFrame(list_final)\n","            else:\n","                df_final.append(pd.DataFrame(list_final), ignore_index=True)\n","\n","            print(' '.join(ele.rstrip('.xslx').split('_')))\n","    \n","            train_eval(df_final, m)\n"],"metadata":{"id":"Ju3GxLhL-4I_","executionInfo":{"status":"ok","timestamp":1679834680062,"user_tz":-420,"elapsed":5,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"id":"Ju3GxLhL-4I_","execution_count":38,"outputs":[]},{"cell_type":"code","source":["asag_systems('/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data Lagi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VIIldNIOGheE","outputId":"316e91a0-f183-423e-efdc-cf004a083253","executionInfo":{"status":"error","timestamp":1679840148404,"user_tz":-420,"elapsed":4172343,"user":{"displayName":"Raja Muda Gading","userId":"11199760221932474938"}}},"id":"VIIldNIOGheE","execution_count":39,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["indobenchmark/indobert-lite-base-p2\n","Analisis Essay Grading Lifestyle\n"]},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at indobenchmark/indobert-lite-base-p2 were not used when initializing BertForSequenceClassification: ['encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'encoder.embedding_hidden_mapping_in.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'encoder.embedding_hidden_mapping_in.bias', 'pooler.bias', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'pooler.weight', 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized: ['encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'classifier.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'classifier.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-lite-base-p2 and are newly initialized because the shapes did not match:\n","- embeddings.word_embeddings.weight: found shape torch.Size([30000, 128]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated\n","- embeddings.position_embeddings.weight: found shape torch.Size([512, 128]) in the checkpoint and torch.Size([512, 768]) in the model instantiated\n","- embeddings.token_type_embeddings.weight: found shape torch.Size([2, 128]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- embeddings.LayerNorm.weight: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","- embeddings.LayerNorm.bias: found shape torch.Size([128]) in the checkpoint and torch.Size([768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/4 [00:00<?, ?it/s]\n","Epoch 1:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:   0%|          | 0/116 [00:12<?, ?it/s, training_loss=0.541]\u001b[A\n","Epoch 1:   1%|          | 1/116 [00:12<23:59, 12.52s/it, training_loss=0.541]\u001b[A\n","Epoch 1:   1%|          | 1/116 [00:23<23:59, 12.52s/it, training_loss=0.852]\u001b[A\n","Epoch 1:   2%|▏         | 2/116 [00:23<21:49, 11.49s/it, training_loss=0.852]\u001b[A\n","Epoch 1:   2%|▏         | 2/116 [00:35<21:49, 11.49s/it, training_loss=0.700]\u001b[A\n","Epoch 1:   3%|▎         | 3/116 [00:35<21:58, 11.67s/it, training_loss=0.700]\u001b[A\n","Epoch 1:   3%|▎         | 3/116 [00:47<21:58, 11.67s/it, training_loss=0.470]\u001b[A\n","Epoch 1:   3%|▎         | 4/116 [00:47<21:55, 11.75s/it, training_loss=0.470]\u001b[A\n","Epoch 1:   3%|▎         | 4/116 [00:58<21:55, 11.75s/it, training_loss=0.611]\u001b[A\n","Epoch 1:   4%|▍         | 5/116 [00:58<21:22, 11.56s/it, training_loss=0.611]\u001b[A\n","Epoch 1:   4%|▍         | 5/116 [01:08<21:22, 11.56s/it, training_loss=0.705]\u001b[A\n","Epoch 1:   5%|▌         | 6/116 [01:08<20:37, 11.25s/it, training_loss=0.705]\u001b[A\n","Epoch 1:   5%|▌         | 6/116 [01:20<20:37, 11.25s/it, training_loss=0.505]\u001b[A\n","Epoch 1:   6%|▌         | 7/116 [01:20<20:52, 11.49s/it, training_loss=0.505]\u001b[A\n","Epoch 1:   6%|▌         | 7/116 [01:32<20:52, 11.49s/it, training_loss=0.828]\u001b[A\n","Epoch 1:   7%|▋         | 8/116 [01:32<20:43, 11.51s/it, training_loss=0.828]\u001b[A\n","Epoch 1:   7%|▋         | 8/116 [01:42<20:43, 11.51s/it, training_loss=0.799]\u001b[A\n","Epoch 1:   8%|▊         | 9/116 [01:42<19:29, 10.93s/it, training_loss=0.799]\u001b[A\n","Epoch 1:   8%|▊         | 9/116 [01:54<19:29, 10.93s/it, training_loss=0.707]\u001b[A\n","Epoch 1:   9%|▊         | 10/116 [01:54<19:57, 11.30s/it, training_loss=0.707]\u001b[A\n","Epoch 1:   9%|▊         | 10/116 [02:07<19:57, 11.30s/it, training_loss=0.683]\u001b[A\n","Epoch 1:   9%|▉         | 11/116 [02:07<20:51, 11.92s/it, training_loss=0.683]\u001b[A\n","Epoch 1:   9%|▉         | 11/116 [02:20<20:51, 11.92s/it, training_loss=0.640]\u001b[A\n","Epoch 1:  10%|█         | 12/116 [02:20<21:02, 12.14s/it, training_loss=0.640]\u001b[A\n","Epoch 1:  10%|█         | 12/116 [02:35<21:02, 12.14s/it, training_loss=0.579]\u001b[A\n","Epoch 1:  11%|█         | 13/116 [02:35<22:20, 13.01s/it, training_loss=0.579]\u001b[A\n","Epoch 1:  11%|█         | 13/116 [02:46<22:20, 13.01s/it, training_loss=0.620]\u001b[A\n","Epoch 1:  12%|█▏        | 14/116 [02:46<21:12, 12.47s/it, training_loss=0.620]\u001b[A\n","Epoch 1:  12%|█▏        | 14/116 [02:58<21:12, 12.47s/it, training_loss=0.707]\u001b[A\n","Epoch 1:  13%|█▎        | 15/116 [02:58<20:44, 12.32s/it, training_loss=0.707]\u001b[A\n","Epoch 1:  13%|█▎        | 15/116 [03:08<20:44, 12.32s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  14%|█▍        | 16/116 [03:08<19:25, 11.66s/it, training_loss=0.550]\u001b[A\n","Epoch 1:  14%|█▍        | 16/116 [03:19<19:25, 11.66s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  15%|█▍        | 17/116 [03:19<18:52, 11.44s/it, training_loss=0.581]\u001b[A\n","Epoch 1:  15%|█▍        | 17/116 [03:31<18:52, 11.44s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  16%|█▌        | 18/116 [03:31<18:56, 11.59s/it, training_loss=0.570]\u001b[A\n","Epoch 1:  16%|█▌        | 18/116 [03:41<18:56, 11.59s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  16%|█▋        | 19/116 [03:41<18:06, 11.20s/it, training_loss=0.455]\u001b[A\n","Epoch 1:  16%|█▋        | 19/116 [03:52<18:06, 11.20s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  17%|█▋        | 20/116 [03:52<17:44, 11.09s/it, training_loss=0.647]\u001b[A\n","Epoch 1:  17%|█▋        | 20/116 [04:05<17:44, 11.09s/it, training_loss=0.677]\u001b[A\n","Epoch 1:  18%|█▊        | 21/116 [04:05<18:29, 11.68s/it, training_loss=0.677]\u001b[A\n","Epoch 1:  18%|█▊        | 21/116 [04:16<18:29, 11.68s/it, training_loss=0.614]\u001b[A\n","Epoch 1:  19%|█▉        | 22/116 [04:16<17:56, 11.45s/it, training_loss=0.614]\u001b[A\n","Epoch 1:  19%|█▉        | 22/116 [04:26<17:56, 11.45s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  20%|█▉        | 23/116 [04:26<17:13, 11.11s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  20%|█▉        | 23/116 [04:38<17:13, 11.11s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  21%|██        | 24/116 [04:38<17:25, 11.36s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  21%|██        | 24/116 [04:49<17:25, 11.36s/it, training_loss=0.471]\u001b[A\n","Epoch 1:  22%|██▏       | 25/116 [04:50<17:10, 11.32s/it, training_loss=0.471]\u001b[A\n","Epoch 1:  22%|██▏       | 25/116 [05:00<17:10, 11.32s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  22%|██▏       | 26/116 [05:00<16:23, 10.93s/it, training_loss=0.606]\u001b[A\n","Epoch 1:  22%|██▏       | 26/116 [05:11<16:23, 10.93s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  23%|██▎       | 27/116 [05:11<16:36, 11.20s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  23%|██▎       | 27/116 [05:23<16:36, 11.20s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  24%|██▍       | 28/116 [05:23<16:27, 11.22s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  24%|██▍       | 28/116 [05:33<16:27, 11.22s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  25%|██▌       | 29/116 [05:33<15:43, 10.85s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  25%|██▌       | 29/116 [05:44<15:43, 10.85s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  26%|██▌       | 30/116 [05:45<16:00, 11.16s/it, training_loss=0.554]\u001b[A\n","Epoch 1:  26%|██▌       | 30/116 [05:56<16:00, 11.16s/it, training_loss=0.502]\u001b[A\n","Epoch 1:  27%|██▋       | 31/116 [05:56<15:50, 11.19s/it, training_loss=0.502]\u001b[A\n","Epoch 1:  27%|██▋       | 31/116 [06:06<15:50, 11.19s/it, training_loss=0.529]\u001b[A\n","Epoch 1:  28%|██▊       | 32/116 [06:06<15:11, 10.85s/it, training_loss=0.529]\u001b[A\n","Epoch 1:  28%|██▊       | 32/116 [06:18<15:11, 10.85s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  28%|██▊       | 33/116 [06:18<15:27, 11.18s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  28%|██▊       | 33/116 [06:29<15:27, 11.18s/it, training_loss=0.604]\u001b[A\n","Epoch 1:  29%|██▉       | 34/116 [06:29<15:23, 11.26s/it, training_loss=0.604]\u001b[A\n","Epoch 1:  29%|██▉       | 34/116 [06:39<15:23, 11.26s/it, training_loss=0.629]\u001b[A\n","Epoch 1:  30%|███       | 35/116 [06:39<14:37, 10.84s/it, training_loss=0.629]\u001b[A\n","Epoch 1:  30%|███       | 35/116 [06:51<14:37, 10.84s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  31%|███       | 36/116 [06:51<14:53, 11.17s/it, training_loss=0.523]\u001b[A\n","Epoch 1:  31%|███       | 36/116 [07:03<14:53, 11.17s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  32%|███▏      | 37/116 [07:03<14:52, 11.30s/it, training_loss=0.548]\u001b[A\n","Epoch 1:  32%|███▏      | 37/116 [07:12<14:52, 11.30s/it, training_loss=0.529]\u001b[A\n","Epoch 1:  33%|███▎      | 38/116 [07:12<14:04, 10.82s/it, training_loss=0.529]\u001b[A\n","Epoch 1:  33%|███▎      | 38/116 [07:24<14:04, 10.82s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  34%|███▎      | 39/116 [07:24<14:18, 11.16s/it, training_loss=0.617]\u001b[A\n","Epoch 1:  34%|███▎      | 39/116 [07:36<14:18, 11.16s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  34%|███▍      | 40/116 [07:36<14:21, 11.33s/it, training_loss=0.530]\u001b[A\n","Epoch 1:  34%|███▍      | 40/116 [07:46<14:21, 11.33s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  35%|███▌      | 41/116 [07:46<13:32, 10.83s/it, training_loss=0.556]\u001b[A\n","Epoch 1:  35%|███▌      | 41/116 [07:58<13:32, 10.83s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  36%|███▌      | 42/116 [07:58<13:47, 11.18s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  36%|███▌      | 42/116 [08:09<13:47, 11.18s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  37%|███▋      | 43/116 [08:09<13:48, 11.35s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  37%|███▋      | 43/116 [08:19<13:48, 11.35s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  38%|███▊      | 44/116 [08:19<12:59, 10.82s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  38%|███▊      | 44/116 [08:31<12:59, 10.82s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  39%|███▉      | 45/116 [08:31<13:14, 11.19s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  39%|███▉      | 45/116 [08:43<13:14, 11.19s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  40%|███▉      | 46/116 [08:43<13:18, 11.41s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  40%|███▉      | 46/116 [08:52<13:18, 11.41s/it, training_loss=0.457]\u001b[A\n","Epoch 1:  41%|████      | 47/116 [08:52<12:28, 10.85s/it, training_loss=0.457]\u001b[A\n","Epoch 1:  41%|████      | 47/116 [09:04<12:28, 10.85s/it, training_loss=0.407]\u001b[A\n","Epoch 1:  41%|████▏     | 48/116 [09:04<12:39, 11.17s/it, training_loss=0.407]\u001b[A\n","Epoch 1:  41%|████▏     | 48/116 [09:16<12:39, 11.17s/it, training_loss=0.566]\u001b[A\n","Epoch 1:  42%|████▏     | 49/116 [09:16<12:44, 11.40s/it, training_loss=0.566]\u001b[A\n","Epoch 1:  42%|████▏     | 49/116 [09:26<12:44, 11.40s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  43%|████▎     | 50/116 [09:26<11:57, 10.87s/it, training_loss=0.635]\u001b[A\n","Epoch 1:  43%|████▎     | 50/116 [09:38<11:57, 10.87s/it, training_loss=0.638]\u001b[A\n","Epoch 1:  44%|████▍     | 51/116 [09:38<12:06, 11.18s/it, training_loss=0.638]\u001b[A\n","Epoch 1:  44%|████▍     | 51/116 [09:50<12:06, 11.18s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  45%|████▍     | 52/116 [09:50<12:10, 11.41s/it, training_loss=0.582]\u001b[A\n","Epoch 1:  45%|████▍     | 52/116 [10:00<12:10, 11.41s/it, training_loss=0.628]\u001b[A\n","Epoch 1:  46%|████▌     | 53/116 [10:00<11:26, 10.89s/it, training_loss=0.628]\u001b[A\n","Epoch 1:  46%|████▌     | 53/116 [10:11<11:26, 10.89s/it, training_loss=0.543]\u001b[A\n","Epoch 1:  47%|████▋     | 54/116 [10:11<11:29, 11.13s/it, training_loss=0.543]\u001b[A\n","Epoch 1:  47%|████▋     | 54/116 [10:23<11:29, 11.13s/it, training_loss=0.537]\u001b[A\n","Epoch 1:  47%|████▋     | 55/116 [10:23<11:33, 11.36s/it, training_loss=0.537]\u001b[A\n","Epoch 1:  47%|████▋     | 55/116 [10:33<11:33, 11.36s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  48%|████▊     | 56/116 [10:33<10:54, 10.91s/it, training_loss=0.541]\u001b[A\n","Epoch 1:  48%|████▊     | 56/116 [10:44<10:54, 10.91s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  49%|████▉     | 57/116 [10:44<10:50, 11.02s/it, training_loss=0.577]\u001b[A\n","Epoch 1:  49%|████▉     | 57/116 [10:56<10:50, 11.02s/it, training_loss=0.482]\u001b[A\n","Epoch 1:  50%|█████     | 58/116 [10:56<10:55, 11.30s/it, training_loss=0.482]\u001b[A\n","Epoch 1:  50%|█████     | 58/116 [11:06<10:55, 11.30s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  51%|█████     | 59/116 [11:06<10:20, 10.88s/it, training_loss=0.514]\u001b[A\n","Epoch 1:  51%|█████     | 59/116 [11:17<10:20, 10.88s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  52%|█████▏    | 60/116 [11:17<10:15, 10.99s/it, training_loss=0.519]\u001b[A\n","Epoch 1:  52%|█████▏    | 60/116 [11:29<10:15, 10.99s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  53%|█████▎    | 61/116 [11:29<10:20, 11.29s/it, training_loss=0.473]\u001b[A\n","Epoch 1:  53%|█████▎    | 61/116 [11:39<10:20, 11.29s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  53%|█████▎    | 62/116 [11:39<09:50, 10.94s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  53%|█████▎    | 62/116 [11:50<09:50, 10.94s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  54%|█████▍    | 63/116 [11:50<09:39, 10.94s/it, training_loss=0.618]\u001b[A\n","Epoch 1:  54%|█████▍    | 63/116 [12:02<09:39, 10.94s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  55%|█████▌    | 64/116 [12:02<09:45, 11.26s/it, training_loss=0.652]\u001b[A\n","Epoch 1:  55%|█████▌    | 64/116 [12:13<09:45, 11.26s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  56%|█████▌    | 65/116 [12:13<09:19, 10.97s/it, training_loss=0.599]\u001b[A\n","Epoch 1:  56%|█████▌    | 65/116 [12:24<09:19, 10.97s/it, training_loss=0.716]\u001b[A\n","Epoch 1:  57%|█████▋    | 66/116 [12:24<09:07, 10.96s/it, training_loss=0.716]\u001b[A\n","Epoch 1:  57%|█████▋    | 66/116 [12:36<09:07, 10.96s/it, training_loss=0.648]\u001b[A\n","Epoch 1:  58%|█████▊    | 67/116 [12:36<09:12, 11.28s/it, training_loss=0.648]\u001b[A\n","Epoch 1:  58%|█████▊    | 67/116 [12:46<09:12, 11.28s/it, training_loss=0.589]\u001b[A\n","Epoch 1:  59%|█████▊    | 68/116 [12:46<08:50, 11.05s/it, training_loss=0.589]\u001b[A\n","Epoch 1:  59%|█████▊    | 68/116 [12:57<08:50, 11.05s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  59%|█████▉    | 69/116 [12:57<08:31, 10.88s/it, training_loss=0.535]\u001b[A\n","Epoch 1:  59%|█████▉    | 69/116 [13:08<08:31, 10.88s/it, training_loss=0.565]\u001b[A\n","Epoch 1:  60%|██████    | 70/116 [13:09<08:33, 11.17s/it, training_loss=0.565]\u001b[A\n","Epoch 1:  60%|██████    | 70/116 [13:19<08:33, 11.17s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  61%|██████    | 71/116 [13:19<08:14, 10.99s/it, training_loss=0.580]\u001b[A\n","Epoch 1:  61%|██████    | 71/116 [13:30<08:14, 10.99s/it, training_loss=0.516]\u001b[A\n","Epoch 1:  62%|██████▏   | 72/116 [13:30<07:57, 10.85s/it, training_loss=0.516]\u001b[A\n","Epoch 1:  62%|██████▏   | 72/116 [13:42<07:57, 10.85s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  63%|██████▎   | 73/116 [13:42<08:00, 11.18s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  63%|██████▎   | 73/116 [13:53<08:00, 11.18s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  64%|██████▍   | 74/116 [13:53<07:47, 11.13s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  64%|██████▍   | 74/116 [14:03<07:47, 11.13s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  65%|██████▍   | 75/116 [14:03<07:27, 10.91s/it, training_loss=0.544]\u001b[A\n","Epoch 1:  65%|██████▍   | 75/116 [14:15<07:27, 10.91s/it, training_loss=0.588]\u001b[A\n","Epoch 1:  66%|██████▌   | 76/116 [14:15<07:30, 11.27s/it, training_loss=0.588]\u001b[A\n","Epoch 1:  66%|██████▌   | 76/116 [14:26<07:30, 11.27s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  66%|██████▋   | 77/116 [14:26<07:20, 11.29s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  66%|██████▋   | 77/116 [14:37<07:20, 11.29s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  67%|██████▋   | 78/116 [14:37<06:56, 10.95s/it, training_loss=0.549]\u001b[A\n","Epoch 1:  67%|██████▋   | 78/116 [14:49<06:56, 10.95s/it, training_loss=0.623]\u001b[A\n","Epoch 1:  68%|██████▊   | 79/116 [14:49<06:56, 11.27s/it, training_loss=0.623]\u001b[A\n","Epoch 1:  68%|██████▊   | 79/116 [15:00<06:56, 11.27s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  69%|██████▉   | 80/116 [15:00<06:48, 11.34s/it, training_loss=0.538]\u001b[A\n","Epoch 1:  69%|██████▉   | 80/116 [15:10<06:48, 11.34s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  70%|██████▉   | 81/116 [15:10<06:20, 10.87s/it, training_loss=0.576]\u001b[A\n","Epoch 1:  70%|██████▉   | 81/116 [15:22<06:20, 10.87s/it, training_loss=0.522]\u001b[A\n","Epoch 1:  71%|███████   | 82/116 [15:22<06:21, 11.22s/it, training_loss=0.522]\u001b[A\n","Epoch 1:  71%|███████   | 82/116 [15:34<06:21, 11.22s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  72%|███████▏  | 83/116 [15:34<06:15, 11.38s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  72%|███████▏  | 83/116 [15:43<06:15, 11.38s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  72%|███████▏  | 84/116 [15:43<05:47, 10.85s/it, training_loss=0.551]\u001b[A\n","Epoch 1:  72%|███████▏  | 84/116 [15:55<05:47, 10.85s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  73%|███████▎  | 85/116 [15:55<05:46, 11.19s/it, training_loss=0.545]\u001b[A\n","Epoch 1:  73%|███████▎  | 85/116 [16:07<05:46, 11.19s/it, training_loss=0.492]\u001b[A\n","Epoch 1:  74%|███████▍  | 86/116 [16:07<05:42, 11.42s/it, training_loss=0.492]\u001b[A\n","Epoch 1:  74%|███████▍  | 86/116 [16:17<05:42, 11.42s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  75%|███████▌  | 87/116 [16:17<05:14, 10.85s/it, training_loss=0.600]\u001b[A\n","Epoch 1:  75%|███████▌  | 87/116 [16:29<05:14, 10.85s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  76%|███████▌  | 88/116 [16:29<05:14, 11.22s/it, training_loss=0.524]\u001b[A\n","Epoch 1:  76%|███████▌  | 88/116 [16:41<05:14, 11.22s/it, training_loss=0.498]\u001b[A\n","Epoch 1:  77%|███████▋  | 89/116 [16:41<05:08, 11.42s/it, training_loss=0.498]\u001b[A\n","Epoch 1:  77%|███████▋  | 89/116 [16:50<05:08, 11.42s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  78%|███████▊  | 90/116 [16:50<04:41, 10.82s/it, training_loss=0.578]\u001b[A\n","Epoch 1:  78%|███████▊  | 90/116 [17:02<04:41, 10.82s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  78%|███████▊  | 91/116 [17:02<04:38, 11.13s/it, training_loss=0.534]\u001b[A\n","Epoch 1:  78%|███████▊  | 91/116 [17:14<04:38, 11.13s/it, training_loss=0.468]\u001b[A\n","Epoch 1:  79%|███████▉  | 92/116 [17:14<04:32, 11.37s/it, training_loss=0.468]\u001b[A\n","Epoch 1:  79%|███████▉  | 92/116 [17:23<04:32, 11.37s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  80%|████████  | 93/116 [17:23<04:08, 10.82s/it, training_loss=0.611]\u001b[A\n","Epoch 1:  80%|████████  | 93/116 [17:35<04:08, 10.82s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  81%|████████  | 94/116 [17:35<04:04, 11.13s/it, training_loss=0.521]\u001b[A\n","Epoch 1:  81%|████████  | 94/116 [17:47<04:04, 11.13s/it, training_loss=0.516]\u001b[A\n","Epoch 1:  82%|████████▏ | 95/116 [17:47<04:00, 11.44s/it, training_loss=0.516]\u001b[A\n","Epoch 1:  82%|████████▏ | 95/116 [17:58<04:00, 11.44s/it, training_loss=0.584]\u001b[A\n","Epoch 1:  83%|████████▎ | 96/116 [17:58<03:44, 11.22s/it, training_loss=0.584]\u001b[A\n","Epoch 1:  83%|████████▎ | 96/116 [18:10<03:44, 11.22s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  84%|████████▎ | 97/116 [18:10<03:38, 11.52s/it, training_loss=0.632]\u001b[A\n","Epoch 1:  84%|████████▎ | 97/116 [18:22<03:38, 11.52s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  84%|████████▍ | 98/116 [18:22<03:30, 11.69s/it, training_loss=0.560]\u001b[A\n","Epoch 1:  84%|████████▍ | 98/116 [18:33<03:30, 11.69s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  85%|████████▌ | 99/116 [18:33<03:14, 11.43s/it, training_loss=0.624]\u001b[A\n","Epoch 1:  85%|████████▌ | 99/116 [18:44<03:14, 11.43s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  86%|████████▌ | 100/116 [18:44<02:58, 11.14s/it, training_loss=0.562]\u001b[A\n","Epoch 1:  86%|████████▌ | 100/116 [18:56<02:58, 11.14s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  87%|████████▋ | 101/116 [18:56<02:51, 11.41s/it, training_loss=0.547]\u001b[A\n","Epoch 1:  87%|████████▋ | 101/116 [19:07<02:51, 11.41s/it, training_loss=0.499]\u001b[A\n","Epoch 1:  88%|████████▊ | 102/116 [19:07<02:39, 11.36s/it, training_loss=0.499]\u001b[A\n","Epoch 1:  88%|████████▊ | 102/116 [19:17<02:39, 11.36s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  89%|████████▉ | 103/116 [19:17<02:22, 10.98s/it, training_loss=0.542]\u001b[A\n","Epoch 1:  89%|████████▉ | 103/116 [19:29<02:22, 10.98s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  90%|████████▉ | 104/116 [19:29<02:15, 11.27s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  90%|████████▉ | 104/116 [19:40<02:15, 11.27s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  91%|█████████ | 105/116 [19:40<02:04, 11.28s/it, training_loss=0.497]\u001b[A\n","Epoch 1:  91%|█████████ | 105/116 [19:50<02:04, 11.28s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  91%|█████████▏| 106/116 [19:50<01:48, 10.89s/it, training_loss=0.571]\u001b[A\n","Epoch 1:  91%|█████████▏| 106/116 [20:02<01:48, 10.89s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  92%|█████████▏| 107/116 [20:02<01:41, 11.24s/it, training_loss=0.598]\u001b[A\n","Epoch 1:  92%|█████████▏| 107/116 [20:14<01:41, 11.24s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  93%|█████████▎| 108/116 [20:14<01:30, 11.35s/it, training_loss=0.574]\u001b[A\n","Epoch 1:  93%|█████████▎| 108/116 [20:24<01:30, 11.35s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  94%|█████████▍| 109/116 [20:24<01:16, 10.94s/it, training_loss=0.490]\u001b[A\n","Epoch 1:  94%|█████████▍| 109/116 [20:36<01:16, 10.94s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  95%|█████████▍| 110/116 [20:36<01:07, 11.31s/it, training_loss=0.610]\u001b[A\n","Epoch 1:  95%|█████████▍| 110/116 [20:48<01:07, 11.31s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  96%|█████████▌| 111/116 [20:48<00:57, 11.50s/it, training_loss=0.602]\u001b[A\n","Epoch 1:  96%|█████████▌| 111/116 [20:58<00:57, 11.50s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  97%|█████████▋| 112/116 [20:58<00:43, 10.92s/it, training_loss=0.555]\u001b[A\n","Epoch 1:  97%|█████████▋| 112/116 [21:10<00:43, 10.92s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  97%|█████████▋| 113/116 [21:10<00:33, 11.21s/it, training_loss=0.569]\u001b[A\n","Epoch 1:  97%|█████████▋| 113/116 [21:21<00:33, 11.21s/it, training_loss=0.501]\u001b[A\n","Epoch 1:  98%|█████████▊| 114/116 [21:21<00:22, 11.41s/it, training_loss=0.501]\u001b[A\n","Epoch 1:  98%|█████████▊| 114/116 [21:31<00:22, 11.41s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  99%|█████████▉| 115/116 [21:31<00:10, 10.85s/it, training_loss=0.546]\u001b[A\n","Epoch 1:  99%|█████████▉| 115/116 [21:38<00:10, 10.85s/it, training_loss=0.460]\u001b[A\n","Epoch 1: 100%|██████████| 116/116 [21:38<00:00,  9.84s/it, training_loss=0.460]\u001b[A\n","  0%|          | 0/4 [21:40<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Training loss: 1.7139462838912833\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 1/4 [23:17<1:09:52, 1397.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6403625258084\n","F1 Score (Weighted): 0.08928352725045927\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:   0%|          | 0/116 [00:11<?, ?it/s, training_loss=0.538]\u001b[A\n","Epoch 2:   1%|          | 1/116 [00:11<22:26, 11.71s/it, training_loss=0.538]\u001b[A\n","Epoch 2:   1%|          | 1/116 [00:22<22:26, 11.71s/it, training_loss=0.511]\u001b[A\n","Epoch 2:   2%|▏         | 2/116 [00:22<20:41, 10.89s/it, training_loss=0.511]\u001b[A\n","Epoch 2:   2%|▏         | 2/116 [00:32<20:41, 10.89s/it, training_loss=0.531]\u001b[A\n","Epoch 2:   3%|▎         | 3/116 [00:32<20:04, 10.66s/it, training_loss=0.531]\u001b[A\n","Epoch 2:   3%|▎         | 3/116 [00:43<20:04, 10.66s/it, training_loss=0.558]\u001b[A\n","Epoch 2:   3%|▎         | 4/116 [00:43<20:34, 11.02s/it, training_loss=0.558]\u001b[A\n","Epoch 2:   3%|▎         | 4/116 [00:55<20:34, 11.02s/it, training_loss=0.568]\u001b[A\n","Epoch 2:   4%|▍         | 5/116 [00:55<20:35, 11.13s/it, training_loss=0.568]\u001b[A\n","Epoch 2:   4%|▍         | 5/116 [01:05<20:35, 11.13s/it, training_loss=0.616]\u001b[A\n","Epoch 2:   5%|▌         | 6/116 [01:05<19:31, 10.65s/it, training_loss=0.616]\u001b[A\n","Epoch 2:   5%|▌         | 6/116 [01:16<19:31, 10.65s/it, training_loss=0.510]\u001b[A\n","Epoch 2:   6%|▌         | 7/116 [01:16<19:53, 10.95s/it, training_loss=0.510]\u001b[A\n","Epoch 2:   6%|▌         | 7/116 [01:28<19:53, 10.95s/it, training_loss=0.556]\u001b[A\n","Epoch 2:   7%|▋         | 8/116 [01:28<20:04, 11.15s/it, training_loss=0.556]\u001b[A\n","Epoch 2:   7%|▋         | 8/116 [01:37<20:04, 11.15s/it, training_loss=0.576]\u001b[A\n","Epoch 2:   8%|▊         | 9/116 [01:37<19:01, 10.67s/it, training_loss=0.576]\u001b[A\n","Epoch 2:   8%|▊         | 9/116 [01:48<19:01, 10.67s/it, training_loss=0.545]\u001b[A\n","Epoch 2:   9%|▊         | 10/116 [01:48<19:06, 10.82s/it, training_loss=0.545]\u001b[A\n","Epoch 2:   9%|▊         | 10/116 [02:00<19:06, 10.82s/it, training_loss=0.523]\u001b[A\n","Epoch 2:   9%|▉         | 11/116 [02:00<19:17, 11.02s/it, training_loss=0.523]\u001b[A\n","Epoch 2:   9%|▉         | 11/116 [02:10<19:17, 11.02s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  10%|█         | 12/116 [02:10<18:39, 10.77s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  10%|█         | 12/116 [02:21<18:39, 10.77s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  11%|█         | 13/116 [02:21<18:18, 10.66s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  11%|█         | 13/116 [02:32<18:18, 10.66s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  12%|█▏        | 14/116 [02:32<18:34, 10.93s/it, training_loss=0.535]\u001b[A\n","Epoch 2:  12%|█▏        | 14/116 [02:43<18:34, 10.93s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  13%|█▎        | 15/116 [02:43<18:29, 10.98s/it, training_loss=0.455]\u001b[A\n","Epoch 2:  13%|█▎        | 15/116 [02:53<18:29, 10.98s/it, training_loss=0.561]\u001b[A\n","Epoch 2:  14%|█▍        | 16/116 [02:53<17:43, 10.63s/it, training_loss=0.561]\u001b[A\n","Epoch 2:  14%|█▍        | 16/116 [03:05<17:43, 10.63s/it, training_loss=0.543]\u001b[A\n","Epoch 2:  15%|█▍        | 17/116 [03:05<17:58, 10.90s/it, training_loss=0.543]\u001b[A\n","Epoch 2:  15%|█▍        | 17/116 [03:16<17:58, 10.90s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  16%|█▌        | 18/116 [03:16<18:05, 11.08s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  16%|█▌        | 18/116 [03:25<18:05, 11.08s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  16%|█▋        | 19/116 [03:25<17:07, 10.60s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  16%|█▋        | 19/116 [03:37<17:07, 10.60s/it, training_loss=0.603]\u001b[A\n","Epoch 2:  17%|█▋        | 20/116 [03:37<17:22, 10.85s/it, training_loss=0.603]\u001b[A\n","Epoch 2:  17%|█▋        | 20/116 [03:49<17:22, 10.85s/it, training_loss=0.490]\u001b[A\n","Epoch 2:  18%|█▊        | 21/116 [03:49<17:31, 11.07s/it, training_loss=0.490]\u001b[A\n","Epoch 2:  18%|█▊        | 21/116 [03:58<17:31, 11.07s/it, training_loss=0.586]\u001b[A\n","Epoch 2:  19%|█▉        | 22/116 [03:58<16:48, 10.73s/it, training_loss=0.586]\u001b[A\n","Epoch 2:  19%|█▉        | 22/116 [04:09<16:48, 10.73s/it, training_loss=0.547]\u001b[A\n","Epoch 2:  20%|█▉        | 23/116 [04:09<16:32, 10.67s/it, training_loss=0.547]\u001b[A\n","Epoch 2:  20%|█▉        | 23/116 [04:21<16:32, 10.67s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  21%|██        | 24/116 [04:21<16:47, 10.95s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  21%|██        | 24/116 [04:31<16:47, 10.95s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  22%|██▏       | 25/116 [04:31<16:32, 10.91s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  22%|██▏       | 25/116 [04:41<16:32, 10.91s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  22%|██▏       | 26/116 [04:41<15:59, 10.66s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  22%|██▏       | 26/116 [04:53<15:59, 10.66s/it, training_loss=0.520]\u001b[A\n","Epoch 2:  23%|██▎       | 27/116 [04:53<16:14, 10.95s/it, training_loss=0.520]\u001b[A\n","Epoch 2:  23%|██▎       | 27/116 [05:05<16:14, 10.95s/it, training_loss=0.566]\u001b[A\n","Epoch 2:  24%|██▍       | 28/116 [05:05<16:18, 11.12s/it, training_loss=0.566]\u001b[A\n","Epoch 2:  24%|██▍       | 28/116 [05:14<16:18, 11.12s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  25%|██▌       | 29/116 [05:14<15:26, 10.64s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  25%|██▌       | 29/116 [05:26<15:26, 10.64s/it, training_loss=0.544]\u001b[A\n","Epoch 2:  26%|██▌       | 30/116 [05:26<15:40, 10.94s/it, training_loss=0.544]\u001b[A\n","Epoch 2:  26%|██▌       | 30/116 [05:37<15:40, 10.94s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  27%|██▋       | 31/116 [05:37<15:47, 11.15s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  27%|██▋       | 31/116 [05:47<15:47, 11.15s/it, training_loss=0.512]\u001b[A\n","Epoch 2:  28%|██▊       | 32/116 [05:47<15:07, 10.81s/it, training_loss=0.512]\u001b[A\n","Epoch 2:  28%|██▊       | 32/116 [05:58<15:07, 10.81s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  28%|██▊       | 33/116 [05:58<14:54, 10.77s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  28%|██▊       | 33/116 [06:10<14:54, 10.77s/it, training_loss=0.499]\u001b[A\n","Epoch 2:  29%|██▉       | 34/116 [06:10<15:01, 11.00s/it, training_loss=0.499]\u001b[A\n","Epoch 2:  29%|██▉       | 34/116 [06:21<15:01, 11.00s/it, training_loss=0.527]\u001b[A\n","Epoch 2:  30%|███       | 35/116 [06:21<14:47, 10.96s/it, training_loss=0.527]\u001b[A\n","Epoch 2:  30%|███       | 35/116 [06:30<14:47, 10.96s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  31%|███       | 36/116 [06:30<14:13, 10.66s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  31%|███       | 36/116 [06:42<14:13, 10.66s/it, training_loss=0.571]\u001b[A\n","Epoch 2:  32%|███▏      | 37/116 [06:42<14:22, 10.92s/it, training_loss=0.571]\u001b[A\n","Epoch 2:  32%|███▏      | 37/116 [06:54<14:22, 10.92s/it, training_loss=0.452]\u001b[A\n","Epoch 2:  33%|███▎      | 38/116 [06:54<14:27, 11.13s/it, training_loss=0.452]\u001b[A\n","Epoch 2:  33%|███▎      | 38/116 [07:03<14:27, 11.13s/it, training_loss=0.549]\u001b[A\n","Epoch 2:  34%|███▎      | 39/116 [07:03<13:38, 10.63s/it, training_loss=0.549]\u001b[A\n","Epoch 2:  34%|███▎      | 39/116 [07:15<13:38, 10.63s/it, training_loss=0.532]\u001b[A\n","Epoch 2:  34%|███▍      | 40/116 [07:15<13:46, 10.88s/it, training_loss=0.532]\u001b[A\n","Epoch 2:  34%|███▍      | 40/116 [07:26<13:46, 10.88s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  35%|███▌      | 41/116 [07:26<13:53, 11.11s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  35%|███▌      | 41/116 [07:36<13:53, 11.11s/it, training_loss=0.528]\u001b[A\n","Epoch 2:  36%|███▌      | 42/116 [07:36<13:12, 10.71s/it, training_loss=0.528]\u001b[A\n","Epoch 2:  36%|███▌      | 42/116 [07:47<13:12, 10.71s/it, training_loss=0.557]\u001b[A\n","Epoch 2:  37%|███▋      | 43/116 [07:47<13:07, 10.79s/it, training_loss=0.557]\u001b[A\n","Epoch 2:  37%|███▋      | 43/116 [07:59<13:07, 10.79s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  38%|███▊      | 44/116 [07:59<13:14, 11.03s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  38%|███▊      | 44/116 [08:09<13:14, 11.03s/it, training_loss=0.484]\u001b[A\n","Epoch 2:  39%|███▉      | 45/116 [08:09<12:58, 10.97s/it, training_loss=0.484]\u001b[A\n","Epoch 2:  39%|███▉      | 45/116 [08:20<12:58, 10.97s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  40%|███▉      | 46/116 [08:20<12:30, 10.72s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  40%|███▉      | 46/116 [08:31<12:30, 10.72s/it, training_loss=0.591]\u001b[A\n","Epoch 2:  41%|████      | 47/116 [08:31<12:37, 10.98s/it, training_loss=0.591]\u001b[A\n","Epoch 2:  41%|████      | 47/116 [08:43<12:37, 10.98s/it, training_loss=0.516]\u001b[A\n","Epoch 2:  41%|████▏     | 48/116 [08:43<12:37, 11.14s/it, training_loss=0.516]\u001b[A\n","Epoch 2:  41%|████▏     | 48/116 [08:52<12:37, 11.14s/it, training_loss=0.565]\u001b[A\n","Epoch 2:  42%|████▏     | 49/116 [08:52<11:52, 10.64s/it, training_loss=0.565]\u001b[A\n","Epoch 2:  42%|████▏     | 49/116 [09:04<11:52, 10.64s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  43%|████▎     | 50/116 [09:04<11:59, 10.91s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  43%|████▎     | 50/116 [09:15<11:59, 10.91s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  44%|████▍     | 51/116 [09:15<12:02, 11.12s/it, training_loss=0.589]\u001b[A\n","Epoch 2:  44%|████▍     | 51/116 [09:25<12:02, 11.12s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  45%|████▍     | 52/116 [09:25<11:29, 10.78s/it, training_loss=0.614]\u001b[A\n","Epoch 2:  45%|████▍     | 52/116 [09:36<11:29, 10.78s/it, training_loss=0.540]\u001b[A\n","Epoch 2:  46%|████▌     | 53/116 [09:36<11:18, 10.78s/it, training_loss=0.540]\u001b[A\n","Epoch 2:  46%|████▌     | 53/116 [09:48<11:18, 10.78s/it, training_loss=0.534]\u001b[A\n","Epoch 2:  47%|████▋     | 54/116 [09:48<11:22, 11.01s/it, training_loss=0.534]\u001b[A\n","Epoch 2:  47%|████▋     | 54/116 [09:58<11:22, 11.01s/it, training_loss=0.565]\u001b[A\n","Epoch 2:  47%|████▋     | 55/116 [09:58<11:09, 10.98s/it, training_loss=0.565]\u001b[A\n","Epoch 2:  47%|████▋     | 55/116 [10:08<11:09, 10.98s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  48%|████▊     | 56/116 [10:08<10:39, 10.65s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  48%|████▊     | 56/116 [10:20<10:39, 10.65s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  49%|████▉     | 57/116 [10:20<10:50, 11.03s/it, training_loss=0.545]\u001b[A\n","Epoch 2:  49%|████▉     | 57/116 [10:32<10:50, 11.03s/it, training_loss=0.529]\u001b[A\n","Epoch 2:  50%|█████     | 58/116 [10:32<10:49, 11.19s/it, training_loss=0.529]\u001b[A\n","Epoch 2:  50%|█████     | 58/116 [10:41<10:49, 11.19s/it, training_loss=0.503]\u001b[A\n","Epoch 2:  51%|█████     | 59/116 [10:41<10:10, 10.72s/it, training_loss=0.503]\u001b[A\n","Epoch 2:  51%|█████     | 59/116 [10:53<10:10, 10.72s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  52%|█████▏    | 60/116 [10:53<10:12, 10.95s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  52%|█████▏    | 60/116 [11:04<10:12, 10.95s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  53%|█████▎    | 61/116 [11:04<10:12, 11.14s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  53%|█████▎    | 61/116 [11:15<10:12, 11.14s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  53%|█████▎    | 62/116 [11:15<09:44, 10.82s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  53%|█████▎    | 62/116 [11:25<09:44, 10.82s/it, training_loss=0.616]\u001b[A\n","Epoch 2:  54%|█████▍    | 63/116 [11:25<09:28, 10.72s/it, training_loss=0.616]\u001b[A\n","Epoch 2:  54%|█████▍    | 63/116 [11:37<09:28, 10.72s/it, training_loss=0.602]\u001b[A\n","Epoch 2:  55%|█████▌    | 64/116 [11:37<09:31, 11.00s/it, training_loss=0.602]\u001b[A\n","Epoch 2:  55%|█████▌    | 64/116 [11:48<09:31, 11.00s/it, training_loss=0.496]\u001b[A\n","Epoch 2:  56%|█████▌    | 65/116 [11:48<09:20, 11.00s/it, training_loss=0.496]\u001b[A\n","Epoch 2:  56%|█████▌    | 65/116 [11:58<09:20, 11.00s/it, training_loss=0.486]\u001b[A\n","Epoch 2:  57%|█████▋    | 66/116 [11:58<08:52, 10.66s/it, training_loss=0.486]\u001b[A\n","Epoch 2:  57%|█████▋    | 66/116 [12:09<08:52, 10.66s/it, training_loss=0.594]\u001b[A\n","Epoch 2:  58%|█████▊    | 67/116 [12:09<08:54, 10.91s/it, training_loss=0.594]\u001b[A\n","Epoch 2:  58%|█████▊    | 67/116 [12:21<08:54, 10.91s/it, training_loss=0.586]\u001b[A\n","Epoch 2:  59%|█████▊    | 68/116 [12:21<08:52, 11.10s/it, training_loss=0.586]\u001b[A\n","Epoch 2:  59%|█████▊    | 68/116 [12:30<08:52, 11.10s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  59%|█████▉    | 69/116 [12:30<08:18, 10.61s/it, training_loss=0.526]\u001b[A\n","Epoch 2:  59%|█████▉    | 69/116 [12:42<08:18, 10.61s/it, training_loss=0.588]\u001b[A\n","Epoch 2:  60%|██████    | 70/116 [12:42<08:20, 10.88s/it, training_loss=0.588]\u001b[A\n","Epoch 2:  60%|██████    | 70/116 [12:53<08:20, 10.88s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  61%|██████    | 71/116 [12:53<08:19, 11.10s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  61%|██████    | 71/116 [13:03<08:19, 11.10s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  62%|██████▏   | 72/116 [13:03<07:52, 10.74s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  62%|██████▏   | 72/116 [13:14<07:52, 10.74s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  63%|██████▎   | 73/116 [13:14<07:41, 10.74s/it, training_loss=0.504]\u001b[A\n","Epoch 2:  63%|██████▎   | 73/116 [13:25<07:41, 10.74s/it, training_loss=0.480]\u001b[A\n","Epoch 2:  64%|██████▍   | 74/116 [13:25<07:40, 10.97s/it, training_loss=0.480]\u001b[A\n","Epoch 2:  64%|██████▍   | 74/116 [13:36<07:40, 10.97s/it, training_loss=0.579]\u001b[A\n","Epoch 2:  65%|██████▍   | 75/116 [13:36<07:24, 10.85s/it, training_loss=0.579]\u001b[A\n","Epoch 2:  65%|██████▍   | 75/116 [13:46<07:24, 10.85s/it, training_loss=0.494]\u001b[A\n","Epoch 2:  66%|██████▌   | 76/116 [13:46<07:05, 10.63s/it, training_loss=0.494]\u001b[A\n","Epoch 2:  66%|██████▌   | 76/116 [13:58<07:05, 10.63s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  66%|██████▋   | 77/116 [13:58<07:05, 10.91s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  66%|██████▋   | 77/116 [14:09<07:05, 10.91s/it, training_loss=0.481]\u001b[A\n","Epoch 2:  67%|██████▋   | 78/116 [14:09<06:59, 11.04s/it, training_loss=0.481]\u001b[A\n","Epoch 2:  67%|██████▋   | 78/116 [14:18<06:59, 11.04s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  68%|██████▊   | 79/116 [14:18<06:31, 10.58s/it, training_loss=0.483]\u001b[A\n","Epoch 2:  68%|██████▊   | 79/116 [14:30<06:31, 10.58s/it, training_loss=0.580]\u001b[A\n","Epoch 2:  69%|██████▉   | 80/116 [14:30<06:31, 10.86s/it, training_loss=0.580]\u001b[A\n","Epoch 2:  69%|██████▉   | 80/116 [14:42<06:31, 10.86s/it, training_loss=0.557]\u001b[A\n","Epoch 2:  70%|██████▉   | 81/116 [14:42<06:28, 11.09s/it, training_loss=0.557]\u001b[A\n","Epoch 2:  70%|██████▉   | 81/116 [14:51<06:28, 11.09s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  71%|███████   | 82/116 [14:51<06:03, 10.68s/it, training_loss=0.538]\u001b[A\n","Epoch 2:  71%|███████   | 82/116 [15:02<06:03, 10.68s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  72%|███████▏  | 83/116 [15:02<05:55, 10.77s/it, training_loss=0.536]\u001b[A\n","Epoch 2:  72%|███████▏  | 83/116 [15:14<05:55, 10.77s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  72%|███████▏  | 84/116 [15:14<05:52, 11.02s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  72%|███████▏  | 84/116 [15:24<05:52, 11.02s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  73%|███████▎  | 85/116 [15:24<05:35, 10.82s/it, training_loss=0.556]\u001b[A\n","Epoch 2:  73%|███████▎  | 85/116 [15:34<05:35, 10.82s/it, training_loss=0.482]\u001b[A\n","Epoch 2:  74%|███████▍  | 86/116 [15:35<05:19, 10.65s/it, training_loss=0.482]\u001b[A\n","Epoch 2:  74%|███████▍  | 86/116 [15:48<05:19, 10.65s/it, training_loss=0.456]\u001b[A\n","Epoch 2:  75%|███████▌  | 87/116 [15:48<05:32, 11.47s/it, training_loss=0.456]\u001b[A\n","Epoch 2:  75%|███████▌  | 87/116 [15:59<05:32, 11.47s/it, training_loss=0.571]\u001b[A\n","Epoch 2:  76%|███████▌  | 88/116 [15:59<05:17, 11.33s/it, training_loss=0.571]\u001b[A\n","Epoch 2:  76%|███████▌  | 88/116 [16:09<05:17, 11.33s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  77%|███████▋  | 89/116 [16:09<04:52, 10.85s/it, training_loss=0.574]\u001b[A\n","Epoch 2:  77%|███████▋  | 89/116 [16:20<04:52, 10.85s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  78%|███████▊  | 90/116 [16:20<04:46, 11.03s/it, training_loss=0.555]\u001b[A\n","Epoch 2:  78%|███████▊  | 90/116 [16:32<04:46, 11.03s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  78%|███████▊  | 91/116 [16:32<04:38, 11.16s/it, training_loss=0.521]\u001b[A\n","Epoch 2:  78%|███████▊  | 91/116 [16:41<04:38, 11.16s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  79%|███████▉  | 92/116 [16:41<04:15, 10.63s/it, training_loss=0.606]\u001b[A\n","Epoch 2:  79%|███████▉  | 92/116 [16:52<04:15, 10.63s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  80%|████████  | 93/116 [16:52<04:10, 10.91s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  80%|████████  | 93/116 [17:04<04:10, 10.91s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  81%|████████  | 94/116 [17:04<04:04, 11.10s/it, training_loss=0.548]\u001b[A\n","Epoch 2:  81%|████████  | 94/116 [17:14<04:04, 11.10s/it, training_loss=0.629]\u001b[A\n","Epoch 2:  82%|████████▏ | 95/116 [17:14<03:46, 10.77s/it, training_loss=0.629]\u001b[A\n","Epoch 2:  82%|████████▏ | 95/116 [17:25<03:46, 10.77s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  83%|████████▎ | 96/116 [17:25<03:34, 10.73s/it, training_loss=0.522]\u001b[A\n","Epoch 2:  83%|████████▎ | 96/116 [17:36<03:34, 10.73s/it, training_loss=0.515]\u001b[A\n","Epoch 2:  84%|████████▎ | 97/116 [17:36<03:28, 10.95s/it, training_loss=0.515]\u001b[A\n","Epoch 2:  84%|████████▎ | 97/116 [17:47<03:28, 10.95s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  84%|████████▍ | 98/116 [17:47<03:15, 10.86s/it, training_loss=0.546]\u001b[A\n","Epoch 2:  84%|████████▍ | 98/116 [17:57<03:15, 10.86s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  85%|████████▌ | 99/116 [17:57<03:00, 10.62s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  85%|████████▌ | 99/116 [18:08<03:00, 10.62s/it, training_loss=0.590]\u001b[A\n","Epoch 2:  86%|████████▌ | 100/116 [18:08<02:54, 10.89s/it, training_loss=0.590]\u001b[A\n","Epoch 2:  86%|████████▌ | 100/116 [18:20<02:54, 10.89s/it, training_loss=0.577]\u001b[A\n","Epoch 2:  87%|████████▋ | 101/116 [18:20<02:45, 11.03s/it, training_loss=0.577]\u001b[A\n","Epoch 2:  87%|████████▋ | 101/116 [18:29<02:45, 11.03s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  88%|████████▊ | 102/116 [18:29<02:27, 10.55s/it, training_loss=0.533]\u001b[A\n","Epoch 2:  88%|████████▊ | 102/116 [18:41<02:27, 10.55s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  89%|████████▉ | 103/116 [18:41<02:21, 10.85s/it, training_loss=0.509]\u001b[A\n","Epoch 2:  89%|████████▉ | 103/116 [18:52<02:21, 10.85s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  90%|████████▉ | 104/116 [18:52<02:13, 11.09s/it, training_loss=0.552]\u001b[A\n","Epoch 2:  90%|████████▉ | 104/116 [19:02<02:13, 11.09s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  91%|█████████ | 105/116 [19:02<01:57, 10.65s/it, training_loss=0.523]\u001b[A\n","Epoch 2:  91%|█████████ | 105/116 [19:13<01:57, 10.65s/it, training_loss=0.541]\u001b[A\n","Epoch 2:  91%|█████████▏| 106/116 [19:13<01:47, 10.78s/it, training_loss=0.541]\u001b[A\n","Epoch 2:  91%|█████████▏| 106/116 [19:25<01:47, 10.78s/it, training_loss=0.596]\u001b[A\n","Epoch 2:  92%|█████████▏| 107/116 [19:25<01:39, 11.04s/it, training_loss=0.596]\u001b[A\n","Epoch 2:  92%|█████████▏| 107/116 [19:35<01:39, 11.04s/it, training_loss=0.554]\u001b[A\n","Epoch 2:  93%|█████████▎| 108/116 [19:35<01:26, 10.84s/it, training_loss=0.554]\u001b[A\n","Epoch 2:  93%|█████████▎| 108/116 [19:45<01:26, 10.84s/it, training_loss=0.527]\u001b[A\n","Epoch 2:  94%|█████████▍| 109/116 [19:45<01:14, 10.69s/it, training_loss=0.527]\u001b[A\n","Epoch 2:  94%|█████████▍| 109/116 [19:57<01:14, 10.69s/it, training_loss=0.525]\u001b[A\n","Epoch 2:  95%|█████████▍| 110/116 [19:57<01:05, 10.95s/it, training_loss=0.525]\u001b[A\n","Epoch 2:  95%|█████████▍| 110/116 [20:08<01:05, 10.95s/it, training_loss=0.550]\u001b[A\n","Epoch 2:  96%|█████████▌| 111/116 [20:08<00:54, 10.98s/it, training_loss=0.550]\u001b[A\n","Epoch 2:  96%|█████████▌| 111/116 [20:18<00:54, 10.98s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  97%|█████████▋| 112/116 [20:18<00:42, 10.58s/it, training_loss=0.489]\u001b[A\n","Epoch 2:  97%|█████████▋| 112/116 [20:29<00:42, 10.58s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  97%|█████████▋| 113/116 [20:29<00:32, 10.86s/it, training_loss=0.593]\u001b[A\n","Epoch 2:  97%|█████████▋| 113/116 [20:41<00:32, 10.86s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  98%|█████████▊| 114/116 [20:41<00:22, 11.03s/it, training_loss=0.560]\u001b[A\n","Epoch 2:  98%|█████████▊| 114/116 [20:50<00:22, 11.03s/it, training_loss=0.561]\u001b[A\n","Epoch 2:  99%|█████████▉| 115/116 [20:50<00:10, 10.56s/it, training_loss=0.561]\u001b[A\n","Epoch 2:  99%|█████████▉| 115/116 [20:58<00:10, 10.56s/it, training_loss=0.530]\u001b[A\n","Epoch 2: 100%|██████████| 116/116 [20:58<00:00,  9.63s/it, training_loss=0.530]\u001b[A\n"," 25%|██▌       | 1/4 [44:17<1:09:52, 1397.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2\n","Training loss: 1.6346433049645916\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 2/4 [45:53<45:46, 1373.30s/it]  "]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6467510009634083\n","F1 Score (Weighted): 0.02642399730367375\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:   0%|          | 0/116 [00:11<?, ?it/s, training_loss=0.495]\u001b[A\n","Epoch 3:   1%|          | 1/116 [00:11<22:25, 11.70s/it, training_loss=0.495]\u001b[A\n","Epoch 3:   1%|          | 1/116 [00:22<22:25, 11.70s/it, training_loss=0.554]\u001b[A\n","Epoch 3:   2%|▏         | 2/116 [00:22<20:50, 10.97s/it, training_loss=0.554]\u001b[A\n","Epoch 3:   2%|▏         | 2/116 [00:32<20:50, 10.97s/it, training_loss=0.556]\u001b[A\n","Epoch 3:   3%|▎         | 3/116 [00:32<19:59, 10.61s/it, training_loss=0.556]\u001b[A\n","Epoch 3:   3%|▎         | 3/116 [00:43<19:59, 10.61s/it, training_loss=0.559]\u001b[A\n","Epoch 3:   3%|▎         | 4/116 [00:43<20:27, 10.96s/it, training_loss=0.559]\u001b[A\n","Epoch 3:   3%|▎         | 4/116 [00:55<20:27, 10.96s/it, training_loss=0.491]\u001b[A\n","Epoch 3:   4%|▍         | 5/116 [00:55<20:27, 11.06s/it, training_loss=0.491]\u001b[A\n","Epoch 3:   4%|▍         | 5/116 [01:04<20:27, 11.06s/it, training_loss=0.543]\u001b[A\n","Epoch 3:   5%|▌         | 6/116 [01:04<19:21, 10.56s/it, training_loss=0.543]\u001b[A\n","Epoch 3:   5%|▌         | 6/116 [01:16<19:21, 10.56s/it, training_loss=0.498]\u001b[A\n","Epoch 3:   6%|▌         | 7/116 [01:16<19:45, 10.87s/it, training_loss=0.498]\u001b[A\n","Epoch 3:   6%|▌         | 7/116 [01:27<19:45, 10.87s/it, training_loss=0.548]\u001b[A\n","Epoch 3:   7%|▋         | 8/116 [01:27<19:55, 11.07s/it, training_loss=0.548]\u001b[A\n","Epoch 3:   7%|▋         | 8/116 [01:37<19:55, 11.07s/it, training_loss=0.536]\u001b[A\n","Epoch 3:   8%|▊         | 9/116 [01:37<18:50, 10.56s/it, training_loss=0.536]\u001b[A\n","Epoch 3:   8%|▊         | 9/116 [01:48<18:50, 10.56s/it, training_loss=0.478]\u001b[A\n","Epoch 3:   9%|▊         | 10/116 [01:48<19:00, 10.76s/it, training_loss=0.478]\u001b[A\n","Epoch 3:   9%|▊         | 10/116 [01:59<19:00, 10.76s/it, training_loss=0.528]\u001b[A\n","Epoch 3:   9%|▉         | 11/116 [01:59<19:13, 10.98s/it, training_loss=0.528]\u001b[A\n","Epoch 3:   9%|▉         | 11/116 [02:09<19:13, 10.98s/it, training_loss=0.592]\u001b[A\n","Epoch 3:  10%|█         | 12/116 [02:09<18:33, 10.71s/it, training_loss=0.592]\u001b[A\n","Epoch 3:  10%|█         | 12/116 [02:20<18:33, 10.71s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  11%|█         | 13/116 [02:20<18:16, 10.65s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  11%|█         | 13/116 [02:31<18:16, 10.65s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  12%|█▏        | 14/116 [02:31<18:34, 10.92s/it, training_loss=0.504]\u001b[A\n","Epoch 3:  12%|█▏        | 14/116 [02:42<18:34, 10.92s/it, training_loss=0.503]\u001b[A\n","Epoch 3:  13%|█▎        | 15/116 [02:42<18:23, 10.92s/it, training_loss=0.503]\u001b[A\n","Epoch 3:  13%|█▎        | 15/116 [02:52<18:23, 10.92s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  14%|█▍        | 16/116 [02:52<17:40, 10.61s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  14%|█▍        | 16/116 [03:04<17:40, 10.61s/it, training_loss=0.485]\u001b[A\n","Epoch 3:  15%|█▍        | 17/116 [03:04<17:56, 10.88s/it, training_loss=0.485]\u001b[A\n","Epoch 3:  15%|█▍        | 17/116 [03:15<17:56, 10.88s/it, training_loss=0.631]\u001b[A\n","Epoch 3:  16%|█▌        | 18/116 [03:15<18:03, 11.05s/it, training_loss=0.631]\u001b[A\n","Epoch 3:  16%|█▌        | 18/116 [03:25<18:03, 11.05s/it, training_loss=0.514]\u001b[A\n","Epoch 3:  16%|█▋        | 19/116 [03:25<17:05, 10.57s/it, training_loss=0.514]\u001b[A\n","Epoch 3:  16%|█▋        | 19/116 [03:36<17:05, 10.57s/it, training_loss=0.493]\u001b[A\n","Epoch 3:  17%|█▋        | 20/116 [03:36<17:18, 10.81s/it, training_loss=0.493]\u001b[A\n","Epoch 3:  17%|█▋        | 20/116 [03:48<17:18, 10.81s/it, training_loss=0.565]\u001b[A\n","Epoch 3:  18%|█▊        | 21/116 [03:48<17:26, 11.01s/it, training_loss=0.565]\u001b[A\n","Epoch 3:  18%|█▊        | 21/116 [03:57<17:26, 11.01s/it, training_loss=0.537]\u001b[A\n","Epoch 3:  19%|█▉        | 22/116 [03:57<16:42, 10.66s/it, training_loss=0.537]\u001b[A\n","Epoch 3:  19%|█▉        | 22/116 [04:08<16:42, 10.66s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  20%|█▉        | 23/116 [04:08<16:35, 10.70s/it, training_loss=0.584]\u001b[A\n","Epoch 3:  20%|█▉        | 23/116 [04:20<16:35, 10.70s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  21%|██        | 24/116 [04:20<16:49, 10.97s/it, training_loss=0.569]\u001b[A\n","Epoch 3:  21%|██        | 24/116 [04:30<16:49, 10.97s/it, training_loss=0.499]\u001b[A\n","Epoch 3:  22%|██▏       | 25/116 [04:31<16:31, 10.90s/it, training_loss=0.499]\u001b[A\n","Epoch 3:  22%|██▏       | 25/116 [04:41<16:31, 10.90s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  22%|██▏       | 26/116 [04:41<15:56, 10.63s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  22%|██▏       | 26/116 [04:52<15:56, 10.63s/it, training_loss=0.530]\u001b[A\n","Epoch 3:  23%|██▎       | 27/116 [04:52<16:10, 10.91s/it, training_loss=0.530]\u001b[A\n","Epoch 3:  23%|██▎       | 27/116 [05:03<16:10, 10.91s/it, training_loss=0.614]\u001b[A\n","Epoch 3:  24%|██▍       | 28/116 [05:03<16:12, 11.05s/it, training_loss=0.614]\u001b[A\n","Epoch 3:  24%|██▍       | 28/116 [05:13<16:12, 11.05s/it, training_loss=0.653]\u001b[A\n","Epoch 3:  25%|██▌       | 29/116 [05:13<15:17, 10.55s/it, training_loss=0.653]\u001b[A\n","Epoch 3:  25%|██▌       | 29/116 [05:24<15:17, 10.55s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  26%|██▌       | 30/116 [05:24<15:30, 10.82s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  26%|██▌       | 30/116 [05:36<15:30, 10.82s/it, training_loss=0.542]\u001b[A\n","Epoch 3:  27%|██▋       | 31/116 [05:36<15:34, 11.00s/it, training_loss=0.542]\u001b[A\n","Epoch 3:  27%|██▋       | 31/116 [05:45<15:34, 11.00s/it, training_loss=0.581]\u001b[A\n","Epoch 3:  28%|██▊       | 32/116 [05:45<14:45, 10.54s/it, training_loss=0.581]\u001b[A\n","Epoch 3:  28%|██▊       | 32/116 [05:56<14:45, 10.54s/it, training_loss=0.585]\u001b[A\n","Epoch 3:  28%|██▊       | 33/116 [05:56<14:47, 10.70s/it, training_loss=0.585]\u001b[A\n","Epoch 3:  28%|██▊       | 33/116 [06:08<14:47, 10.70s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  29%|██▉       | 34/116 [06:08<14:56, 10.93s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  29%|██▉       | 34/116 [06:18<14:56, 10.93s/it, training_loss=0.528]\u001b[A\n","Epoch 3:  30%|███       | 35/116 [06:18<14:27, 10.71s/it, training_loss=0.528]\u001b[A\n","Epoch 3:  30%|███       | 35/116 [06:28<14:27, 10.71s/it, training_loss=0.524]\u001b[A\n","Epoch 3:  31%|███       | 36/116 [06:28<14:08, 10.61s/it, training_loss=0.524]\u001b[A\n","Epoch 3:  31%|███       | 36/116 [06:40<14:08, 10.61s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  32%|███▏      | 37/116 [06:40<14:19, 10.88s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  32%|███▏      | 37/116 [06:51<14:19, 10.88s/it, training_loss=0.513]\u001b[A\n","Epoch 3:  33%|███▎      | 38/116 [06:51<14:12, 10.93s/it, training_loss=0.513]\u001b[A\n","Epoch 3:  33%|███▎      | 38/116 [07:01<14:12, 10.93s/it, training_loss=0.497]\u001b[A\n","Epoch 3:  34%|███▎      | 39/116 [07:01<13:32, 10.56s/it, training_loss=0.497]\u001b[A\n","Epoch 3:  34%|███▎      | 39/116 [07:12<13:32, 10.56s/it, training_loss=0.519]\u001b[A\n","Epoch 3:  34%|███▍      | 40/116 [07:12<13:42, 10.83s/it, training_loss=0.519]\u001b[A\n","Epoch 3:  34%|███▍      | 40/116 [07:23<13:42, 10.83s/it, training_loss=0.588]\u001b[A\n","Epoch 3:  35%|███▌      | 41/116 [07:23<13:45, 11.00s/it, training_loss=0.588]\u001b[A\n","Epoch 3:  35%|███▌      | 41/116 [07:33<13:45, 11.00s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  36%|███▌      | 42/116 [07:33<12:57, 10.51s/it, training_loss=0.507]\u001b[A\n","Epoch 3:  36%|███▌      | 42/116 [07:44<12:57, 10.51s/it, training_loss=0.542]\u001b[A\n","Epoch 3:  37%|███▋      | 43/116 [07:44<13:07, 10.78s/it, training_loss=0.542]\u001b[A\n","Epoch 3:  37%|███▋      | 43/116 [07:56<13:07, 10.78s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  38%|███▊      | 44/116 [07:56<13:11, 10.99s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  38%|███▊      | 44/116 [08:05<13:11, 10.99s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  39%|███▉      | 45/116 [08:05<12:32, 10.60s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  39%|███▉      | 45/116 [08:16<12:32, 10.60s/it, training_loss=0.523]\u001b[A\n","Epoch 3:  40%|███▉      | 46/116 [08:16<12:28, 10.70s/it, training_loss=0.523]\u001b[A\n","Epoch 3:  40%|███▉      | 46/116 [08:28<12:28, 10.70s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  41%|████      | 47/116 [08:28<12:35, 10.95s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  41%|████      | 47/116 [08:38<12:35, 10.95s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  41%|████▏     | 48/116 [08:38<12:18, 10.86s/it, training_loss=0.521]\u001b[A\n","Epoch 3:  41%|████▏     | 48/116 [08:49<12:18, 10.86s/it, training_loss=0.558]\u001b[A\n","Epoch 3:  42%|████▏     | 49/116 [08:49<11:52, 10.63s/it, training_loss=0.558]\u001b[A\n","Epoch 3:  42%|████▏     | 49/116 [09:00<11:52, 10.63s/it, training_loss=0.567]\u001b[A\n","Epoch 3:  43%|████▎     | 50/116 [09:00<12:00, 10.91s/it, training_loss=0.567]\u001b[A\n","Epoch 3:  43%|████▎     | 50/116 [09:11<12:00, 10.91s/it, training_loss=0.549]\u001b[A\n","Epoch 3:  44%|████▍     | 51/116 [09:11<11:57, 11.04s/it, training_loss=0.549]\u001b[A\n","Epoch 3:  44%|████▍     | 51/116 [09:21<11:57, 11.04s/it, training_loss=0.469]\u001b[A\n","Epoch 3:  45%|████▍     | 52/116 [09:21<11:14, 10.54s/it, training_loss=0.469]\u001b[A\n","Epoch 3:  45%|████▍     | 52/116 [09:32<11:14, 10.54s/it, training_loss=0.668]\u001b[A\n","Epoch 3:  46%|████▌     | 53/116 [09:32<11:20, 10.81s/it, training_loss=0.668]\u001b[A\n","Epoch 3:  46%|████▌     | 53/116 [09:44<11:20, 10.81s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  47%|████▋     | 54/116 [09:44<11:21, 11.00s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  47%|████▋     | 54/116 [09:53<11:21, 11.00s/it, training_loss=0.562]\u001b[A\n","Epoch 3:  47%|████▋     | 55/116 [09:53<10:43, 10.55s/it, training_loss=0.562]\u001b[A\n","Epoch 3:  47%|████▋     | 55/116 [10:04<10:43, 10.55s/it, training_loss=0.454]\u001b[A\n","Epoch 3:  48%|████▊     | 56/116 [10:04<10:43, 10.73s/it, training_loss=0.454]\u001b[A\n","Epoch 3:  48%|████▊     | 56/116 [10:16<10:43, 10.73s/it, training_loss=0.605]\u001b[A\n","Epoch 3:  49%|████▉     | 57/116 [10:16<10:47, 10.97s/it, training_loss=0.605]\u001b[A\n","Epoch 3:  49%|████▉     | 57/116 [10:26<10:47, 10.97s/it, training_loss=0.597]\u001b[A\n","Epoch 3:  50%|█████     | 58/116 [10:26<10:24, 10.76s/it, training_loss=0.597]\u001b[A\n","Epoch 3:  50%|█████     | 58/116 [10:37<10:24, 10.76s/it, training_loss=0.628]\u001b[A\n","Epoch 3:  51%|█████     | 59/116 [10:37<10:06, 10.65s/it, training_loss=0.628]\u001b[A\n","Epoch 3:  51%|█████     | 59/116 [10:48<10:06, 10.65s/it, training_loss=0.560]\u001b[A\n","Epoch 3:  52%|█████▏    | 60/116 [10:48<10:10, 10.90s/it, training_loss=0.560]\u001b[A\n","Epoch 3:  52%|█████▏    | 60/116 [10:59<10:10, 10.90s/it, training_loss=0.609]\u001b[A\n","Epoch 3:  53%|█████▎    | 61/116 [10:59<10:03, 10.97s/it, training_loss=0.609]\u001b[A\n","Epoch 3:  53%|█████▎    | 61/116 [11:09<10:03, 10.97s/it, training_loss=0.481]\u001b[A\n","Epoch 3:  53%|█████▎    | 62/116 [11:09<09:32, 10.60s/it, training_loss=0.481]\u001b[A\n","Epoch 3:  53%|█████▎    | 62/116 [11:20<09:32, 10.60s/it, training_loss=0.475]\u001b[A\n","Epoch 3:  54%|█████▍    | 63/116 [11:20<09:34, 10.84s/it, training_loss=0.475]\u001b[A\n","Epoch 3:  54%|█████▍    | 63/116 [11:32<09:34, 10.84s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  55%|█████▌    | 64/116 [11:32<09:32, 11.01s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  55%|█████▌    | 64/116 [11:41<09:32, 11.01s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  56%|█████▌    | 65/116 [11:41<08:55, 10.50s/it, training_loss=0.510]\u001b[A\n","Epoch 3:  56%|█████▌    | 65/116 [11:52<08:55, 10.50s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  57%|█████▋    | 66/116 [11:52<08:58, 10.77s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  57%|█████▋    | 66/116 [12:04<08:58, 10.77s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  58%|█████▊    | 67/116 [12:04<08:58, 10.99s/it, training_loss=0.561]\u001b[A\n","Epoch 3:  58%|█████▊    | 67/116 [12:14<08:58, 10.99s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  59%|█████▊    | 68/116 [12:14<08:30, 10.64s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  59%|█████▊    | 68/116 [12:25<08:30, 10.64s/it, training_loss=0.554]\u001b[A\n","Epoch 3:  59%|█████▉    | 69/116 [12:25<08:22, 10.69s/it, training_loss=0.554]\u001b[A\n","Epoch 3:  59%|█████▉    | 69/116 [12:36<08:22, 10.69s/it, training_loss=0.551]\u001b[A\n","Epoch 3:  60%|██████    | 70/116 [12:36<08:22, 10.93s/it, training_loss=0.551]\u001b[A\n","Epoch 3:  60%|██████    | 70/116 [12:47<08:22, 10.93s/it, training_loss=0.509]\u001b[A\n","Epoch 3:  61%|██████    | 71/116 [12:47<08:07, 10.83s/it, training_loss=0.509]\u001b[A\n","Epoch 3:  61%|██████    | 71/116 [12:57<08:07, 10.83s/it, training_loss=0.581]\u001b[A\n","Epoch 3:  62%|██████▏   | 72/116 [12:57<07:46, 10.61s/it, training_loss=0.581]\u001b[A\n","Epoch 3:  62%|██████▏   | 72/116 [13:08<07:46, 10.61s/it, training_loss=0.590]\u001b[A\n","Epoch 3:  63%|██████▎   | 73/116 [13:08<07:47, 10.86s/it, training_loss=0.590]\u001b[A\n","Epoch 3:  63%|██████▎   | 73/116 [13:19<07:47, 10.86s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  64%|██████▍   | 74/116 [13:19<07:41, 10.99s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  64%|██████▍   | 74/116 [13:29<07:41, 10.99s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  65%|██████▍   | 75/116 [13:29<07:11, 10.52s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  65%|██████▍   | 75/116 [13:40<07:11, 10.52s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  66%|██████▌   | 76/116 [13:40<07:11, 10.78s/it, training_loss=0.532]\u001b[A\n","Epoch 3:  66%|██████▌   | 76/116 [13:52<07:11, 10.78s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  66%|██████▋   | 77/116 [13:52<07:08, 10.98s/it, training_loss=0.545]\u001b[A\n","Epoch 3:  66%|██████▋   | 77/116 [14:01<07:08, 10.98s/it, training_loss=0.566]\u001b[A\n","Epoch 3:  67%|██████▋   | 78/116 [14:01<06:40, 10.53s/it, training_loss=0.566]\u001b[A\n","Epoch 3:  67%|██████▋   | 78/116 [14:12<06:40, 10.53s/it, training_loss=0.559]\u001b[A\n","Epoch 3:  68%|██████▊   | 79/116 [14:12<06:37, 10.74s/it, training_loss=0.559]\u001b[A\n","Epoch 3:  68%|██████▊   | 79/116 [14:24<06:37, 10.74s/it, training_loss=0.566]\u001b[A\n","Epoch 3:  69%|██████▉   | 80/116 [14:24<06:34, 10.96s/it, training_loss=0.566]\u001b[A\n","Epoch 3:  69%|██████▉   | 80/116 [14:34<06:34, 10.96s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  70%|██████▉   | 81/116 [14:34<06:14, 10.71s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  70%|██████▉   | 81/116 [14:44<06:14, 10.71s/it, training_loss=0.534]\u001b[A\n","Epoch 3:  71%|███████   | 82/116 [14:44<06:01, 10.62s/it, training_loss=0.534]\u001b[A\n","Epoch 3:  71%|███████   | 82/116 [14:56<06:01, 10.62s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  72%|███████▏  | 83/116 [14:56<05:59, 10.88s/it, training_loss=0.577]\u001b[A\n","Epoch 3:  72%|███████▏  | 83/116 [15:07<05:59, 10.88s/it, training_loss=0.554]\u001b[A\n","Epoch 3:  72%|███████▏  | 84/116 [15:07<05:48, 10.91s/it, training_loss=0.554]\u001b[A\n","Epoch 3:  72%|███████▏  | 84/116 [15:17<05:48, 10.91s/it, training_loss=0.541]\u001b[A\n","Epoch 3:  73%|███████▎  | 85/116 [15:17<05:27, 10.57s/it, training_loss=0.541]\u001b[A\n","Epoch 3:  73%|███████▎  | 85/116 [15:28<05:27, 10.57s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  74%|███████▍  | 86/116 [15:28<05:25, 10.83s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  74%|███████▍  | 86/116 [15:40<05:25, 10.83s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  75%|███████▌  | 87/116 [15:40<05:19, 11.01s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  75%|███████▌  | 87/116 [15:49<05:19, 11.01s/it, training_loss=0.539]\u001b[A\n","Epoch 3:  76%|███████▌  | 88/116 [15:49<04:54, 10.51s/it, training_loss=0.539]\u001b[A\n","Epoch 3:  76%|███████▌  | 88/116 [16:00<04:54, 10.51s/it, training_loss=0.552]\u001b[A\n","Epoch 3:  77%|███████▋  | 89/116 [16:00<04:51, 10.81s/it, training_loss=0.552]\u001b[A\n","Epoch 3:  77%|███████▋  | 89/116 [16:12<04:51, 10.81s/it, training_loss=0.533]\u001b[A\n","Epoch 3:  78%|███████▊  | 90/116 [16:12<04:46, 11.03s/it, training_loss=0.533]\u001b[A\n","Epoch 3:  78%|███████▊  | 90/116 [16:22<04:46, 11.03s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  78%|███████▊  | 91/116 [16:22<04:27, 10.69s/it, training_loss=0.525]\u001b[A\n","Epoch 3:  78%|███████▊  | 91/116 [16:33<04:27, 10.69s/it, training_loss=0.558]\u001b[A\n","Epoch 3:  79%|███████▉  | 92/116 [16:33<04:17, 10.71s/it, training_loss=0.558]\u001b[A\n","Epoch 3:  79%|███████▉  | 92/116 [16:44<04:17, 10.71s/it, training_loss=0.567]\u001b[A\n","Epoch 3:  80%|████████  | 93/116 [16:44<04:11, 10.96s/it, training_loss=0.567]\u001b[A\n","Epoch 3:  80%|████████  | 93/116 [16:55<04:11, 10.96s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  81%|████████  | 94/116 [16:55<03:59, 10.91s/it, training_loss=0.544]\u001b[A\n","Epoch 3:  81%|████████  | 94/116 [17:05<03:59, 10.91s/it, training_loss=0.547]\u001b[A\n","Epoch 3:  82%|████████▏ | 95/116 [17:05<03:42, 10.61s/it, training_loss=0.547]\u001b[A\n","Epoch 3:  82%|████████▏ | 95/116 [17:18<03:42, 10.61s/it, training_loss=0.553]\u001b[A\n","Epoch 3:  83%|████████▎ | 96/116 [17:18<03:45, 11.29s/it, training_loss=0.553]\u001b[A\n","Epoch 3:  83%|████████▎ | 96/116 [17:29<03:45, 11.29s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  84%|████████▎ | 97/116 [17:29<03:35, 11.35s/it, training_loss=0.535]\u001b[A\n","Epoch 3:  84%|████████▎ | 97/116 [17:39<03:35, 11.35s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  84%|████████▍ | 98/116 [17:39<03:14, 10.82s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  84%|████████▍ | 98/116 [17:50<03:14, 10.82s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  85%|████████▌ | 99/116 [17:50<03:04, 10.84s/it, training_loss=0.515]\u001b[A\n","Epoch 3:  85%|████████▌ | 99/116 [18:01<03:04, 10.84s/it, training_loss=0.539]\u001b[A\n","Epoch 3:  86%|████████▌ | 100/116 [18:01<02:56, 11.04s/it, training_loss=0.539]\u001b[A\n","Epoch 3:  86%|████████▌ | 100/116 [18:12<02:56, 11.04s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  87%|████████▋ | 101/116 [18:12<02:42, 10.84s/it, training_loss=0.527]\u001b[A\n","Epoch 3:  87%|████████▋ | 101/116 [18:22<02:42, 10.84s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  88%|████████▊ | 102/116 [18:22<02:29, 10.66s/it, training_loss=0.526]\u001b[A\n","Epoch 3:  88%|████████▊ | 102/116 [18:33<02:29, 10.66s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  89%|████████▉ | 103/116 [18:33<02:22, 10.94s/it, training_loss=0.536]\u001b[A\n","Epoch 3:  89%|████████▉ | 103/116 [18:44<02:22, 10.94s/it, training_loss=0.574]\u001b[A\n","Epoch 3:  90%|████████▉ | 104/116 [18:44<02:11, 10.99s/it, training_loss=0.574]\u001b[A\n","Epoch 3:  90%|████████▉ | 104/116 [18:54<02:11, 10.99s/it, training_loss=0.522]\u001b[A\n","Epoch 3:  91%|█████████ | 105/116 [18:54<01:56, 10.57s/it, training_loss=0.522]\u001b[A\n","Epoch 3:  91%|█████████ | 105/116 [19:06<01:56, 10.57s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  91%|█████████▏| 106/116 [19:06<01:48, 10.85s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  91%|█████████▏| 106/116 [19:17<01:48, 10.85s/it, training_loss=0.512]\u001b[A\n","Epoch 3:  92%|█████████▏| 107/116 [19:17<01:39, 11.04s/it, training_loss=0.512]\u001b[A\n","Epoch 3:  92%|█████████▏| 107/116 [19:26<01:39, 11.04s/it, training_loss=0.620]\u001b[A\n","Epoch 3:  93%|█████████▎| 108/116 [19:26<01:24, 10.56s/it, training_loss=0.620]\u001b[A\n","Epoch 3:  93%|█████████▎| 108/116 [19:38<01:24, 10.56s/it, training_loss=0.529]\u001b[A\n","Epoch 3:  94%|█████████▍| 109/116 [19:38<01:15, 10.80s/it, training_loss=0.529]\u001b[A\n","Epoch 3:  94%|█████████▍| 109/116 [19:49<01:15, 10.80s/it, training_loss=0.503]\u001b[A\n","Epoch 3:  95%|█████████▍| 110/116 [19:49<01:06, 11.01s/it, training_loss=0.503]\u001b[A\n","Epoch 3:  95%|█████████▍| 110/116 [19:59<01:06, 11.01s/it, training_loss=0.590]\u001b[A\n","Epoch 3:  96%|█████████▌| 111/116 [19:59<00:53, 10.72s/it, training_loss=0.590]\u001b[A\n","Epoch 3:  96%|█████████▌| 111/116 [20:10<00:53, 10.72s/it, training_loss=0.571]\u001b[A\n","Epoch 3:  97%|█████████▋| 112/116 [20:10<00:42, 10.70s/it, training_loss=0.571]\u001b[A\n","Epoch 3:  97%|█████████▋| 112/116 [20:22<00:42, 10.70s/it, training_loss=0.580]\u001b[A\n","Epoch 3:  97%|█████████▋| 113/116 [20:22<00:32, 10.95s/it, training_loss=0.580]\u001b[A\n","Epoch 3:  97%|█████████▋| 113/116 [20:32<00:32, 10.95s/it, training_loss=0.588]\u001b[A\n","Epoch 3:  98%|█████████▊| 114/116 [20:32<00:21, 10.93s/it, training_loss=0.588]\u001b[A\n","Epoch 3:  98%|█████████▊| 114/116 [20:42<00:21, 10.93s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  99%|█████████▉| 115/116 [20:42<00:10, 10.63s/it, training_loss=0.502]\u001b[A\n","Epoch 3:  99%|█████████▉| 115/116 [20:50<00:10, 10.63s/it, training_loss=0.580]\u001b[A\n","Epoch 3: 100%|██████████| 116/116 [20:50<00:00,  9.66s/it, training_loss=0.580]\u001b[A\n"," 50%|█████     | 2/4 [1:06:46<45:46, 1373.30s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3\n","Training loss: 1.629960486601139\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [1:08:25<22:43, 1363.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6175195471993808\n","F1 Score (Weighted): 0.08928352725045927\n","QWK Score: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4:   0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:   0%|          | 0/116 [00:11<?, ?it/s, training_loss=0.500]\u001b[A\n","Epoch 4:   1%|          | 1/116 [00:11<22:46, 11.89s/it, training_loss=0.500]\u001b[A\n","Epoch 4:   1%|          | 1/116 [00:21<22:46, 11.89s/it, training_loss=0.580]\u001b[A\n","Epoch 4:   2%|▏         | 2/116 [00:21<20:32, 10.81s/it, training_loss=0.580]\u001b[A\n","Epoch 4:   2%|▏         | 2/116 [00:32<20:32, 10.81s/it, training_loss=0.560]\u001b[A\n","Epoch 4:   3%|▎         | 3/116 [00:32<20:14, 10.75s/it, training_loss=0.560]\u001b[A\n","Epoch 4:   3%|▎         | 3/116 [00:44<20:14, 10.75s/it, training_loss=0.544]\u001b[A\n","Epoch 4:   3%|▎         | 4/116 [00:44<20:39, 11.06s/it, training_loss=0.544]\u001b[A\n","Epoch 4:   3%|▎         | 4/116 [00:54<20:39, 11.06s/it, training_loss=0.557]\u001b[A\n","Epoch 4:   4%|▍         | 5/116 [00:54<20:16, 10.96s/it, training_loss=0.557]\u001b[A\n","Epoch 4:   4%|▍         | 5/116 [01:04<20:16, 10.96s/it, training_loss=0.538]\u001b[A\n","Epoch 4:   5%|▌         | 6/116 [01:04<19:29, 10.63s/it, training_loss=0.538]\u001b[A\n","Epoch 4:   5%|▌         | 6/116 [01:16<19:29, 10.63s/it, training_loss=0.523]\u001b[A\n","Epoch 4:   6%|▌         | 7/116 [01:16<19:49, 10.92s/it, training_loss=0.523]\u001b[A\n","Epoch 4:   6%|▌         | 7/116 [01:27<19:49, 10.92s/it, training_loss=0.541]\u001b[A\n","Epoch 4:   7%|▋         | 8/116 [01:27<19:58, 11.10s/it, training_loss=0.541]\u001b[A\n","Epoch 4:   7%|▋         | 8/116 [01:37<19:58, 11.10s/it, training_loss=0.525]\u001b[A\n","Epoch 4:   8%|▊         | 9/116 [01:37<18:58, 10.64s/it, training_loss=0.525]\u001b[A\n","Epoch 4:   8%|▊         | 9/116 [01:49<18:58, 10.64s/it, training_loss=0.565]\u001b[A\n","Epoch 4:   9%|▊         | 10/116 [01:49<19:15, 10.90s/it, training_loss=0.565]\u001b[A\n","Epoch 4:   9%|▊         | 10/116 [02:00<19:15, 10.90s/it, training_loss=0.539]\u001b[A\n","Epoch 4:   9%|▉         | 11/116 [02:00<19:24, 11.09s/it, training_loss=0.539]\u001b[A\n","Epoch 4:   9%|▉         | 11/116 [02:10<19:24, 11.09s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  10%|█         | 12/116 [02:10<18:37, 10.74s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  10%|█         | 12/116 [02:21<18:37, 10.74s/it, training_loss=0.523]\u001b[A\n","Epoch 4:  11%|█         | 13/116 [02:21<18:24, 10.72s/it, training_loss=0.523]\u001b[A\n","Epoch 4:  11%|█         | 13/116 [02:32<18:24, 10.72s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  12%|█▏        | 14/116 [02:32<18:39, 10.98s/it, training_loss=0.533]\u001b[A\n","Epoch 4:  12%|█▏        | 14/116 [02:43<18:39, 10.98s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  13%|█▎        | 15/116 [02:43<18:21, 10.90s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  13%|█▎        | 15/116 [02:53<18:21, 10.90s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  14%|█▍        | 16/116 [02:53<17:42, 10.63s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  14%|█▍        | 16/116 [03:04<17:42, 10.63s/it, training_loss=0.551]\u001b[A\n","Epoch 4:  15%|█▍        | 17/116 [03:05<17:58, 10.90s/it, training_loss=0.551]\u001b[A\n","Epoch 4:  15%|█▍        | 17/116 [03:16<17:58, 10.90s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  16%|█▌        | 18/116 [03:16<18:01, 11.03s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  16%|█▌        | 18/116 [03:25<18:01, 11.03s/it, training_loss=0.515]\u001b[A\n","Epoch 4:  16%|█▋        | 19/116 [03:25<17:04, 10.56s/it, training_loss=0.515]\u001b[A\n","Epoch 4:  16%|█▋        | 19/116 [03:37<17:04, 10.56s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  17%|█▋        | 20/116 [03:37<17:24, 10.88s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  17%|█▋        | 20/116 [03:48<17:24, 10.88s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  18%|█▊        | 21/116 [03:49<17:32, 11.08s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  18%|█▊        | 21/116 [03:58<17:32, 11.08s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  19%|█▉        | 22/116 [03:58<16:42, 10.66s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  19%|█▉        | 22/116 [04:09<16:42, 10.66s/it, training_loss=0.552]\u001b[A\n","Epoch 4:  20%|█▉        | 23/116 [04:09<16:39, 10.75s/it, training_loss=0.552]\u001b[A\n","Epoch 4:  20%|█▉        | 23/116 [04:21<16:39, 10.75s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  21%|██        | 24/116 [04:21<16:52, 11.00s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  21%|██        | 24/116 [04:31<16:52, 11.00s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  22%|██▏       | 25/116 [04:31<16:31, 10.90s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  22%|██▏       | 25/116 [04:42<16:31, 10.90s/it, training_loss=0.528]\u001b[A\n","Epoch 4:  22%|██▏       | 26/116 [04:42<16:00, 10.67s/it, training_loss=0.528]\u001b[A\n","Epoch 4:  22%|██▏       | 26/116 [04:53<16:00, 10.67s/it, training_loss=0.550]\u001b[A\n","Epoch 4:  23%|██▎       | 27/116 [04:53<16:15, 10.97s/it, training_loss=0.550]\u001b[A\n","Epoch 4:  23%|██▎       | 27/116 [05:05<16:15, 10.97s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  24%|██▍       | 28/116 [05:05<16:16, 11.09s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  24%|██▍       | 28/116 [05:14<16:16, 11.09s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  25%|██▌       | 29/116 [05:14<15:20, 10.58s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  25%|██▌       | 29/116 [05:25<15:20, 10.58s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  26%|██▌       | 30/116 [05:25<15:34, 10.87s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  26%|██▌       | 30/116 [05:37<15:34, 10.87s/it, training_loss=0.544]\u001b[A\n","Epoch 4:  27%|██▋       | 31/116 [05:37<15:43, 11.10s/it, training_loss=0.544]\u001b[A\n","Epoch 4:  27%|██▋       | 31/116 [05:47<15:43, 11.10s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  28%|██▊       | 32/116 [05:47<14:59, 10.70s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  28%|██▊       | 32/116 [05:58<14:59, 10.70s/it, training_loss=0.542]\u001b[A\n","Epoch 4:  28%|██▊       | 33/116 [05:58<14:55, 10.79s/it, training_loss=0.542]\u001b[A\n","Epoch 4:  28%|██▊       | 33/116 [06:09<14:55, 10.79s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  29%|██▉       | 34/116 [06:09<15:04, 11.03s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  29%|██▉       | 34/116 [06:20<15:04, 11.03s/it, training_loss=0.540]\u001b[A\n","Epoch 4:  30%|███       | 35/116 [06:20<14:45, 10.93s/it, training_loss=0.540]\u001b[A\n","Epoch 4:  30%|███       | 35/116 [06:30<14:45, 10.93s/it, training_loss=0.524]\u001b[A\n","Epoch 4:  31%|███       | 36/116 [06:30<14:14, 10.68s/it, training_loss=0.524]\u001b[A\n","Epoch 4:  31%|███       | 36/116 [06:42<14:14, 10.68s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  32%|███▏      | 37/116 [06:42<14:23, 10.93s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  32%|███▏      | 37/116 [06:53<14:23, 10.93s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  33%|███▎      | 38/116 [06:53<14:20, 11.03s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  33%|███▎      | 38/116 [07:03<14:20, 11.03s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  34%|███▎      | 39/116 [07:03<13:32, 10.56s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  34%|███▎      | 39/116 [07:14<13:32, 10.56s/it, training_loss=0.519]\u001b[A\n","Epoch 4:  34%|███▍      | 40/116 [07:14<13:43, 10.84s/it, training_loss=0.519]\u001b[A\n","Epoch 4:  34%|███▍      | 40/116 [07:25<13:43, 10.84s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  35%|███▌      | 41/116 [07:25<13:47, 11.03s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  35%|███▌      | 41/116 [07:35<13:47, 11.03s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  36%|███▌      | 42/116 [07:35<13:04, 10.60s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  36%|███▌      | 42/116 [07:46<13:04, 10.60s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  37%|███▋      | 43/116 [07:46<13:07, 10.79s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  37%|███▋      | 43/116 [07:58<13:07, 10.79s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  38%|███▊      | 44/116 [07:58<13:13, 11.02s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  38%|███▊      | 44/116 [08:08<13:13, 11.02s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  39%|███▉      | 45/116 [08:08<12:50, 10.85s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  39%|███▉      | 45/116 [08:19<12:50, 10.85s/it, training_loss=0.518]\u001b[A\n","Epoch 4:  40%|███▉      | 46/116 [08:19<12:27, 10.68s/it, training_loss=0.518]\u001b[A\n","Epoch 4:  40%|███▉      | 46/116 [08:30<12:27, 10.68s/it, training_loss=0.510]\u001b[A\n","Epoch 4:  41%|████      | 47/116 [08:30<12:35, 10.95s/it, training_loss=0.510]\u001b[A\n","Epoch 4:  41%|████      | 47/116 [08:41<12:35, 10.95s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  41%|████▏     | 48/116 [08:41<12:29, 11.02s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  41%|████▏     | 48/116 [08:51<12:29, 11.02s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  42%|████▏     | 49/116 [08:51<11:49, 10.59s/it, training_loss=0.521]\u001b[A\n","Epoch 4:  42%|████▏     | 49/116 [09:02<11:49, 10.59s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  43%|████▎     | 50/116 [09:02<11:57, 10.87s/it, training_loss=0.516]\u001b[A\n","Epoch 4:  43%|████▎     | 50/116 [09:14<11:57, 10.87s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  44%|████▍     | 51/116 [09:14<12:00, 11.08s/it, training_loss=0.532]\u001b[A\n","Epoch 4:  44%|████▍     | 51/116 [09:24<12:00, 11.08s/it, training_loss=0.559]\u001b[A\n","Epoch 4:  45%|████▍     | 52/116 [09:24<11:17, 10.59s/it, training_loss=0.559]\u001b[A\n","Epoch 4:  45%|████▍     | 52/116 [09:35<11:17, 10.59s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  46%|████▌     | 53/116 [09:35<11:22, 10.84s/it, training_loss=0.535]\u001b[A\n","Epoch 4:  46%|████▌     | 53/116 [09:47<11:22, 10.84s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  47%|████▋     | 54/116 [09:47<11:27, 11.08s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  47%|████▋     | 54/116 [09:57<11:27, 11.08s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  47%|████▋     | 55/116 [09:57<11:02, 10.85s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  47%|████▋     | 55/116 [10:07<11:02, 10.85s/it, training_loss=0.570]\u001b[A\n","Epoch 4:  48%|████▊     | 56/116 [10:07<10:45, 10.76s/it, training_loss=0.570]\u001b[A\n","Epoch 4:  48%|████▊     | 56/116 [10:19<10:45, 10.76s/it, training_loss=0.475]\u001b[A\n","Epoch 4:  49%|████▉     | 57/116 [10:19<10:49, 11.01s/it, training_loss=0.475]\u001b[A\n","Epoch 4:  49%|████▉     | 57/116 [10:30<10:49, 11.01s/it, training_loss=0.507]\u001b[A\n","Epoch 4:  50%|█████     | 58/116 [10:30<10:42, 11.08s/it, training_loss=0.507]\u001b[A\n","Epoch 4:  50%|█████     | 58/116 [10:40<10:42, 11.08s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  51%|█████     | 59/116 [10:40<10:06, 10.63s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  51%|█████     | 59/116 [10:51<10:06, 10.63s/it, training_loss=0.568]\u001b[A\n","Epoch 4:  52%|█████▏    | 60/116 [10:51<10:10, 10.89s/it, training_loss=0.568]\u001b[A\n","Epoch 4:  52%|█████▏    | 60/116 [11:03<10:10, 10.89s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  53%|█████▎    | 61/116 [11:03<10:09, 11.07s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  53%|█████▎    | 61/116 [11:12<10:09, 11.07s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  53%|█████▎    | 62/116 [11:12<09:32, 10.60s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  53%|█████▎    | 62/116 [11:24<09:32, 10.60s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  54%|█████▍    | 63/116 [11:24<09:32, 10.81s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  54%|█████▍    | 63/116 [11:35<09:32, 10.81s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  55%|█████▌    | 64/116 [11:35<09:33, 11.03s/it, training_loss=0.562]\u001b[A\n","Epoch 4:  55%|█████▌    | 64/116 [11:45<09:33, 11.03s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  56%|█████▌    | 65/116 [11:45<09:09, 10.77s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  56%|█████▌    | 65/116 [11:56<09:09, 10.77s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  57%|█████▋    | 66/116 [11:56<08:53, 10.68s/it, training_loss=0.565]\u001b[A\n","Epoch 4:  57%|█████▋    | 66/116 [12:07<08:53, 10.68s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  58%|█████▊    | 67/116 [12:07<08:56, 10.94s/it, training_loss=0.563]\u001b[A\n","Epoch 4:  58%|█████▊    | 67/116 [12:18<08:56, 10.94s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  59%|█████▊    | 68/116 [12:18<08:45, 10.95s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  59%|█████▊    | 68/116 [12:28<08:45, 10.95s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  59%|█████▉    | 69/116 [12:28<08:19, 10.62s/it, training_loss=0.530]\u001b[A\n","Epoch 4:  59%|█████▉    | 69/116 [12:40<08:19, 10.62s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  60%|██████    | 70/116 [12:40<08:20, 10.89s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  60%|██████    | 70/116 [12:51<08:20, 10.89s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  61%|██████    | 71/116 [12:51<08:16, 11.04s/it, training_loss=0.502]\u001b[A\n","Epoch 4:  61%|██████    | 71/116 [13:00<08:16, 11.04s/it, training_loss=0.478]\u001b[A\n","Epoch 4:  62%|██████▏   | 72/116 [13:00<07:43, 10.54s/it, training_loss=0.478]\u001b[A\n","Epoch 4:  62%|██████▏   | 72/116 [13:12<07:43, 10.54s/it, training_loss=0.555]\u001b[A\n","Epoch 4:  63%|██████▎   | 73/116 [13:12<07:45, 10.83s/it, training_loss=0.555]\u001b[A\n","Epoch 4:  63%|██████▎   | 73/116 [13:23<07:45, 10.83s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  64%|██████▍   | 74/116 [13:23<07:43, 11.03s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  64%|██████▍   | 74/116 [13:33<07:43, 11.03s/it, training_loss=0.564]\u001b[A\n","Epoch 4:  65%|██████▍   | 75/116 [13:33<07:18, 10.70s/it, training_loss=0.564]\u001b[A\n","Epoch 4:  65%|██████▍   | 75/116 [13:44<07:18, 10.70s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  66%|██████▌   | 76/116 [13:44<07:09, 10.73s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  66%|██████▌   | 76/116 [13:56<07:09, 10.73s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  66%|██████▋   | 77/116 [13:56<07:07, 10.97s/it, training_loss=0.531]\u001b[A\n","Epoch 4:  66%|██████▋   | 77/116 [14:07<07:07, 10.97s/it, training_loss=0.500]\u001b[A\n","Epoch 4:  67%|██████▋   | 78/116 [14:07<06:55, 10.92s/it, training_loss=0.500]\u001b[A\n","Epoch 4:  67%|██████▋   | 78/116 [14:17<06:55, 10.92s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  68%|██████▊   | 79/116 [14:17<06:34, 10.67s/it, training_loss=0.529]\u001b[A\n","Epoch 4:  68%|██████▊   | 79/116 [14:28<06:34, 10.67s/it, training_loss=0.499]\u001b[A\n","Epoch 4:  69%|██████▉   | 80/116 [14:28<06:33, 10.94s/it, training_loss=0.499]\u001b[A\n","Epoch 4:  69%|██████▉   | 80/116 [14:40<06:33, 10.94s/it, training_loss=0.564]\u001b[A\n","Epoch 4:  70%|██████▉   | 81/116 [14:40<06:27, 11.08s/it, training_loss=0.564]\u001b[A\n","Epoch 4:  70%|██████▉   | 81/116 [14:49<06:27, 11.08s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  71%|███████   | 82/116 [14:49<05:59, 10.57s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  71%|███████   | 82/116 [15:00<05:59, 10.57s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  72%|███████▏  | 83/116 [15:00<05:57, 10.84s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  72%|███████▏  | 83/116 [15:12<05:57, 10.84s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  72%|███████▏  | 84/116 [15:12<05:53, 11.05s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  72%|███████▏  | 84/116 [15:22<05:53, 11.05s/it, training_loss=0.541]\u001b[A\n","Epoch 4:  73%|███████▎  | 85/116 [15:22<05:29, 10.62s/it, training_loss=0.541]\u001b[A\n","Epoch 4:  73%|███████▎  | 85/116 [15:33<05:29, 10.62s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  74%|███████▍  | 86/116 [15:33<05:22, 10.74s/it, training_loss=0.527]\u001b[A\n","Epoch 4:  74%|███████▍  | 86/116 [15:44<05:22, 10.74s/it, training_loss=0.500]\u001b[A\n","Epoch 4:  75%|███████▌  | 87/116 [15:44<05:18, 11.00s/it, training_loss=0.500]\u001b[A\n","Epoch 4:  75%|███████▌  | 87/116 [15:55<05:18, 11.00s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  76%|███████▌  | 88/116 [15:55<05:02, 10.82s/it, training_loss=0.526]\u001b[A\n","Epoch 4:  76%|███████▌  | 88/116 [16:05<05:02, 10.82s/it, training_loss=0.524]\u001b[A\n","Epoch 4:  77%|███████▋  | 89/116 [16:05<04:47, 10.66s/it, training_loss=0.524]\u001b[A\n","Epoch 4:  77%|███████▋  | 89/116 [16:17<04:47, 10.66s/it, training_loss=0.577]\u001b[A\n","Epoch 4:  78%|███████▊  | 90/116 [16:17<04:44, 10.93s/it, training_loss=0.577]\u001b[A\n","Epoch 4:  78%|███████▊  | 90/116 [16:28<04:44, 10.93s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  78%|███████▊  | 91/116 [16:28<04:35, 11.03s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  78%|███████▊  | 91/116 [16:37<04:35, 11.03s/it, training_loss=0.579]\u001b[A\n","Epoch 4:  79%|███████▉  | 92/116 [16:37<04:13, 10.57s/it, training_loss=0.579]\u001b[A\n","Epoch 4:  79%|███████▉  | 92/116 [16:49<04:13, 10.57s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  80%|████████  | 93/116 [16:49<04:09, 10.84s/it, training_loss=0.545]\u001b[A\n","Epoch 4:  80%|████████  | 93/116 [17:00<04:09, 10.84s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  81%|████████  | 94/116 [17:00<04:02, 11.03s/it, training_loss=0.546]\u001b[A\n","Epoch 4:  81%|████████  | 94/116 [17:10<04:02, 11.03s/it, training_loss=0.576]\u001b[A\n","Epoch 4:  82%|████████▏ | 95/116 [17:10<03:41, 10.55s/it, training_loss=0.576]\u001b[A\n","Epoch 4:  82%|████████▏ | 95/116 [17:21<03:41, 10.55s/it, training_loss=0.512]\u001b[A\n","Epoch 4:  83%|████████▎ | 96/116 [17:21<03:36, 10.80s/it, training_loss=0.512]\u001b[A\n","Epoch 4:  83%|████████▎ | 96/116 [17:33<03:36, 10.80s/it, training_loss=0.559]\u001b[A\n","Epoch 4:  84%|████████▎ | 97/116 [17:33<03:29, 11.02s/it, training_loss=0.559]\u001b[A\n","Epoch 4:  84%|████████▎ | 97/116 [17:43<03:29, 11.02s/it, training_loss=0.499]\u001b[A\n","Epoch 4:  84%|████████▍ | 98/116 [17:43<03:12, 10.71s/it, training_loss=0.499]\u001b[A\n","Epoch 4:  84%|████████▍ | 98/116 [17:53<03:12, 10.71s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  85%|████████▌ | 99/116 [17:53<03:02, 10.71s/it, training_loss=0.553]\u001b[A\n","Epoch 4:  85%|████████▌ | 99/116 [18:05<03:02, 10.71s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  86%|████████▌ | 100/116 [18:05<02:55, 10.97s/it, training_loss=0.538]\u001b[A\n","Epoch 4:  86%|████████▌ | 100/116 [18:16<02:55, 10.97s/it, training_loss=0.566]\u001b[A\n","Epoch 4:  87%|████████▋ | 101/116 [18:16<02:43, 10.93s/it, training_loss=0.566]\u001b[A\n","Epoch 4:  87%|████████▋ | 101/116 [18:26<02:43, 10.93s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  88%|████████▊ | 102/116 [18:26<02:28, 10.62s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  88%|████████▊ | 102/116 [18:37<02:28, 10.62s/it, training_loss=0.504]\u001b[A\n","Epoch 4:  89%|████████▉ | 103/116 [18:37<02:21, 10.88s/it, training_loss=0.504]\u001b[A\n","Epoch 4:  89%|████████▉ | 103/116 [18:49<02:21, 10.88s/it, training_loss=0.517]\u001b[A\n","Epoch 4:  90%|████████▉ | 104/116 [18:49<02:15, 11.29s/it, training_loss=0.517]\u001b[A\n","Epoch 4:  90%|████████▉ | 104/116 [18:59<02:15, 11.29s/it, training_loss=0.564]\u001b[A\n","Epoch 4:  91%|█████████ | 105/116 [18:59<01:57, 10.72s/it, training_loss=0.564]\u001b[A\n","Epoch 4:  91%|█████████ | 105/116 [19:10<01:57, 10.72s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  91%|█████████▏| 106/116 [19:10<01:49, 10.95s/it, training_loss=0.539]\u001b[A\n","Epoch 4:  91%|█████████▏| 106/116 [19:22<01:49, 10.95s/it, training_loss=0.558]\u001b[A\n","Epoch 4:  92%|█████████▏| 107/116 [19:22<01:40, 11.12s/it, training_loss=0.558]\u001b[A\n","Epoch 4:  92%|█████████▏| 107/116 [19:31<01:40, 11.12s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  93%|█████████▎| 108/116 [19:32<01:25, 10.73s/it, training_loss=0.560]\u001b[A\n","Epoch 4:  93%|█████████▎| 108/116 [19:42<01:25, 10.73s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  94%|█████████▍| 109/116 [19:42<01:15, 10.78s/it, training_loss=0.557]\u001b[A\n","Epoch 4:  94%|█████████▍| 109/116 [19:54<01:15, 10.78s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  95%|█████████▍| 110/116 [19:54<01:06, 11.00s/it, training_loss=0.534]\u001b[A\n","Epoch 4:  95%|█████████▍| 110/116 [20:05<01:06, 11.00s/it, training_loss=0.583]\u001b[A\n","Epoch 4:  96%|█████████▌| 111/116 [20:05<00:54, 10.88s/it, training_loss=0.583]\u001b[A\n","Epoch 4:  96%|█████████▌| 111/116 [20:15<00:54, 10.88s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  97%|█████████▋| 112/116 [20:15<00:42, 10.66s/it, training_loss=0.536]\u001b[A\n","Epoch 4:  97%|█████████▋| 112/116 [20:26<00:42, 10.66s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  97%|█████████▋| 113/116 [20:26<00:32, 10.93s/it, training_loss=0.556]\u001b[A\n","Epoch 4:  97%|█████████▋| 113/116 [20:38<00:32, 10.93s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  98%|█████████▊| 114/116 [20:38<00:22, 11.05s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  98%|█████████▊| 114/116 [20:47<00:22, 11.05s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  99%|█████████▉| 115/116 [20:47<00:10, 10.58s/it, training_loss=0.525]\u001b[A\n","Epoch 4:  99%|█████████▉| 115/116 [20:55<00:10, 10.58s/it, training_loss=0.547]\u001b[A\n","Epoch 4: 100%|██████████| 116/116 [20:55<00:00,  9.65s/it, training_loss=0.547]\u001b[A\n"," 75%|███████▌  | 3/4 [1:29:23<22:43, 1363.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4\n","Training loss: 1.613644942127425\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [1:31:01<00:00, 1365.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validation loss: 1.6330126030691738\n","F1 Score (Weighted): 0.02642399730367375\n","QWK Score: 0.0\n","Analisis Essay Grading Olahraga\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-38-22088ae0f0e1>:43: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df_final.append(pd.DataFrame(list_final), ignore_index=True)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-b277799f1436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masag_systems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Paper_TA_ASAG/DATASET_TA/Data/Data Lagi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-38-22088ae0f0e1>\u001b[0m in \u001b[0;36masag_systems\u001b[0;34m(path_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.xslx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-d69a638cb420>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(df_final, pretrainedmodel)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrainedmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# bin nilai (continuous variable) into intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nilai'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nilai'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jawaban'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jawaban'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     fac, bins = _bins_to_cuts(\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_bins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mduplicates\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0;34mf\"Bin edges must be unique: {repr(bins)}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0;34mf\"You can drop duplicate edges by setting the 'duplicates' kwarg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: array([0., 0., 1., 2., 3., 4.]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bCEYaqo4SHAF"},"id":"bCEYaqo4SHAF","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"766caac7eb69e8a0a4a596af183e8606e532f32ec205da93d6afbc58c03966c0"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}